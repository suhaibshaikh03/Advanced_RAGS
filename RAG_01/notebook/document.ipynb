{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76fb6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "## document data structure\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e49abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=Document(\n",
    "    page_content=\"Hello, world!\",\n",
    "     metadata={\"source\": \"example.com\"}\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46da6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "file_path = \"../data/docker.pdf\"\n",
    "loader = PyMuPDFLoader(file_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f729a648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 0}, page_content=''),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 1}, page_content='Docker Deep Dive\\nZero to Docker in a single book!\\nNigel Poulton\\nThis book is available at https://leanpub.com/dockerdeepdive\\nThis version was published on 2025-05-12\\nISBN 9781916585133\\nThis is a Leanpub book. Leanpub empowers authors and publishers with the Lean\\nPublishing process. Lean Publishing is the act of publishing an in-progress ebook using\\nlightweight tools and many iterations to get reader feedback, pivot until you have the\\nright book and build traction once you do.\\n© 2016 - 2025 Nigel Poulton'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 2}, page_content='Huge thanks to my wife and kids for putting up with a geek in the house who genuinely thinks\\nhe’s a bunch of software running inside of a container on top of midrange biological hardware. It\\ncan’t be easy living with me!\\nMassive thanks as well to everyone who watches my Pluralsight videos. I love connecting with you\\nand really appreciate all the feedback I’ve gotten over the years. This was one of the major reasons\\nI decided to write this book! I hope it’ll be an amazing tool to help you drive your careers even\\nfurther forward.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 3}, page_content='Contents\\nAbout this edition\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n1\\nAbout the author\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n2\\n0: About the book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n3\\nPart 1: The big picture stuff . . . . . . . . . . . . . . . . . . . . .\\n6\\n1: Containers from 30,000 feet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nThe bad old days . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nHello VMware! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nVMwarts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nHello Containers! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nLinux containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nHello Docker! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\nDocker and Windows . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\nWhat about Wasm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\nDocker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\nWhat about Kubernetes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n2: Docker and container-related standards and projects . . . . . . . . . . . . . . . . 13\\nDocker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nContainer-related standards and projects . . . . . . . . . . . . . . . . . . . . . . . . 15\\n3: Getting Docker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nDocker Desktop\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nInstalling Docker with Multipass\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nInstalling Docker on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4: The big picture\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nThe Ops Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nThe Dev Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='CONTENTS\\nPart 2: The technical stuff . . . . . . . . . . . . . . . . . . . . . . . 35\\n5: The Docker Engine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\nDocker Engine – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\nThe Docker Engine\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\nThe influence of the Open Container Initiative (OCI) . . . . . . . . . . . . . . . . . 39\\nrunc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\ncontainerd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\nStarting a new container (example) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\\nWhat’s the shim all about? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nHow it’s implemented on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n6: Working with Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDocker images – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nIntro to images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nPulling images\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nImage registries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nImage naming and tagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nImages and layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\nPulling images by digest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nMulti-architecture images\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nVulnerability scanning with Docker Scout . . . . . . . . . . . . . . . . . . . . . . . . 66\\nDeleting Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\\nImages – The commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\\n7: Working with containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nContainers – The TLDR\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nContainers vs VMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nImages and Containers\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\nCheck Docker is running . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nStarting a container\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\nHow containers start apps\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\\nConnecting to a running container . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\\nInspecting container processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\\nThe docker inspect command . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\nWriting data to a container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\nStopping, restarting, and deleting a container . . . . . . . . . . . . . . . . . . . . . . 85\\nKilling a container’s main process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nDebugging slim images and containers with Docker Debug\\n. . . . . . . . . . . . . 89\\nSelf-healing containers with restart policies . . . . . . . . . . . . . . . . . . . . . . . 94\\nContainers – The commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\\n8: Containerizing an app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='CONTENTS\\nContainerizing an app – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\\nContainerize a single-container app\\n. . . . . . . . . . . . . . . . . . . . . . . . . . .100\\nMoving to production with multi-stage builds\\n. . . . . . . . . . . . . . . . . . . . . 111\\nBuildx, BuildKit, drivers, and Build Cloud . . . . . . . . . . . . . . . . . . . . . . . .116\\nMulti-architecture builds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .118\\nA few good practices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\nContainerizing an app – The commands . . . . . . . . . . . . . . . . . . . . . . . . . 124\\n9: Multi-container apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nDocker Compose – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\\nCompose background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nInstalling Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nThe sample app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .128\\nCompose files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .130\\nDeploying apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .133\\nManaging apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .136\\nDeploying apps with Compose – The commands . . . . . . . . . . . . . . . . . . . .139\\n10: Docker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner background . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . .142\\nInstalling Docker Model Runner . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nExplore Docker Model Runner\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .145\\nUse Docker Model Runner with Compose . . . . . . . . . . . . . . . . . . . . . . . .152\\nUse Docker Model Runner with Open WebUI\\n. . . . . . . . . . . . . . . . . . . . .155\\nRunning models in containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .160\\nDocker Model Runner – The commands . . . . . . . . . . . . . . . . . . . . . . . . .162\\nChapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .163\\n11: Docker and Wasm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\\nPre-reqs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .165\\nIntro to Wasm and Wasm containers . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\\nWrite a Wasm app\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .168\\nContainerize a Wasm app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .170\\nRun a Wasm container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172\\nClean up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173\\nChapter summary\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n12: Docker Swarm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nSwarm primer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175\\nBuild a swarm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .176\\nDeploy Swarm app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .179\\nDocker Swarm – The Commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='CONTENTS\\n13: Docker Networking\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nDocker Networking – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189\\nDocker networking theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189\\nSingle-host bridge networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .193\\nExternal access via port mappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . .200\\nDocker Networking – The Commands . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\n14: Docker overlay networking\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nDocker overlay networking – The TLDR\\n. . . . . . . . . . . . . . . . . . . . . . . .216\\nDocker overlay networking history . . . . . . . . . . . . . . . . . . . . . . . . . . . .216\\nBuilding and testing Docker overlay networks\\n. . . . . . . . . . . . . . . . . . . . . 217\\nOverlay networks explained . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDocker overlay networking – The commands . . . . . . . . . . . . . . . . . . . . . .229\\n15: Volumes and persistent data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nVolumes and persistent data – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . 231\\nContainers without volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .232\\nContainers with volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .233\\nVolumes and persistent data – The Commands . . . . . . . . . . . . . . . . . . . . .240\\n16: Docker security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nDocker security – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .242\\nKernel Namespaces\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\\nControl Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .246\\nCapabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .246\\nMandatory Access Control systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\nseccomp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\nDocker security technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nSwarm security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nDocker Scout and vulnerability scanning\\n. . . . . . . . . . . . . . . . . . . . . . . .256\\nSigning and verifying images with Docker Content Trust . . . . . . . . . . . . . . .258\\nDocker Secrets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nWhat next . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\\nTerminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 7}, page_content='CONTENTS\\n1\\nAbout this edition\\nThis edition was published in May 2025 and is up to date with the latest industry trends\\nand the latest enhancements to Docker.\\nMajor changes include:\\n• Brand new Docker Model Runner chapter with full AI LLM project\\n• Updates to BuildKit, buildx, and the new Docker Build Cloud\\n• Updates to Docker Debug content\\n• Updates to Wasm content\\n• Streamlined Swarm chapter\\nEnjoy the book, and get ready to master containers!\\n&copy 2025 Nigel Poulton Ltd.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 8}, page_content='About the author\\nNigel is a technology geek with a passion for learning new technologies and making\\nthem easier for others to learn. He’s the author of best-selling books on Docker and\\nKubernetes, as is the author of AI Explained: Facts, Fiction, and Future, a brutal read\\ninto the impacts of AI on society and the future of humanity.\\nNigel is a Docker Captain and has held senior technology roles at large and small\\nenterprises.\\nIn his free time, he listens to audiobooks and coaches youth football (soccer). He wishes\\nhe lived in the future and could understand the mysteries of life and the universe. He’s\\npassionate about learning, cars, and football (soccer). He lives in England with his\\nfabulous wife and three children.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 9}, page_content='0: About the book\\nThis May 2025 edition gets you up to speed with Docker and containers fast, no prior\\nexperience necessary.\\nIt has a brand-new chapter covering the latest and greatest Docker Model Runner\\ncontent for running local LLMs through Docker!\\nWhy should I read this book or care about Docker?\\nDocker has already changed how we build, share, and run applications, and it’s now\\nplaying a major role in emerging technologies such as Wasm and AI.\\nSo, if you want the best jobs working with the best technologies, you need a strong\\nDocker skillset.\\nHow I’ve organized the book\\nI’ve divided the book into two main sections:\\n1. The big picture stuff\\n2. The technical stuff\\nThe big picture stuff gets you up to speed with the basics, such as what Docker is, why we\\nuse containers, and fundamental jargon such as cloud-native, microservices, and orchestration.\\nThe technical stuff section covers everything you need to know about images, containers,\\nmulti-container microservices apps, orchestration, and the increasingly important topics of\\nWebAssembly, running local AI models, vulnerability scanning, debugging containers,\\nand more.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 10}, page_content='0: About the book\\n4\\nChapter breakdown\\n• Chapter 1: Summarizes the history and future of Docker and containers\\n• Chapter 2: Explains the most important container-related standards and projects\\n• Chapter 3: Shows you a few ways to get Docker\\n• Chapter 4: Walks you through deploying your first container\\n• Chapter 5: Deep dive into the Docker Engine architecture\\n• Chapter 6: Deep dive into images and image management\\n• Chapter 7: Deep dive into containers and container management\\n• Chapter 8: Deep dive into containerizing applications\\n• Chapter 9: Walks you through deploying and managing a multi-container AI\\nchatbot app with Docker Compose\\n• Chapter 10: Dives into the exciting new world of running local AI models with\\nDocker Model Runner\\n• Chapter 11: Walks you through building, containerizing, and running a Wasm app\\nwith Docker\\n• Chapter 12: Walks you through building a swarm cluster and deploying apps to it\\n• Chapter 13: Deep dive into Docker networking\\n• Chapter 14: Walks you through building and working with overlay networks\\n• Chapter 15: Introduces you to persistent and non-persistent data in Docker\\n• Chapter 16: Covers all the major Linux and Docker security technologies\\nEditions and updates\\nDocker, AI, and the cloud-native ecosystem are evolving fast, and 2-3-year-old books\\nare dangerously outdated. As a result, I’m committed to updating this book at least once\\nper year.\\nIf that sounds excessive, welcome to the new normal. For example, I released a big\\nupdate in January 2025. Then, less than three months later, I was writing a full new\\nchapter on Docker Model Runner for this May 2025 edition! This is hard work, but I’m\\ncommitted to keeping this the best Docker book in the world.\\nThe book is available in hardback, paperback, and e-book on all good book publishing\\nplatforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 11}, page_content='0: About the book\\n5\\nKindle updates\\nUnfortunately, Kindle readers cannot get updates. I have absolutely no control over\\nthis and was devastated when this change happened. Some people have successfully\\ncontacted Kindle Support and had the support team delete the old copy and push the\\nnew edition. However, this doesn’t always work. Please contact the Kindle Support team\\nfor updates, but if they can’t help, feel free to ping me at the book’s email address.\\nFeedback\\nIf you like the book and it helps your career, share the love by recommending it to a\\nfriend and leaving a review on Amazon or Goodreads.\\nIf you spot a typo or want to make a recommendation, drop me a quick email at\\nddd@nigelpoulton.com and I’ll do my best to respond.\\nThat’s everything. Let’s get rocking with Docker!'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 12}, page_content='Part 1: The big picture stuff'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 13}, page_content='1: Containers from 30,000 feet\\nContainers have taken over the world!\\nIn this chapter, you’ll learn why we have containers, what they do for us, and where we\\ncan use them.\\nThe bad old days\\nApplications are the powerhouse of every modern business. When applications break,\\nbusinesses break.\\nMost applications run on servers, and in the past, we were limited to running one\\napplication per server. As a result, the story went something like this:\\nEvery time a business needed a new application, it had to buy a new server. Unfor-\\ntunately, we weren’t very good at modeling the performance requirements of new\\napplications, and we had to guess. This resulted in businesses buying bigger, faster, and\\nmore expensive servers than necessary. After all, nobody wanted underpowered servers\\nincapable of handling the app, resulting in unhappy customers and lost revenue. As\\na result, we ended up with racks and racks of overpowered servers operating as low\\nas 5-10% of their potential capacity. This was a tragic waste of company capital and\\nenvironmental resources.\\nHello VMware!\\nAmid all this, VMware, Inc. gave the world a gift — the virtual machine (VM) — a\\ntechnology that allowed us to run multiple business applications on a single server\\nsafely.\\nIt was a game-changer. Businesses could run new apps on the spare capacity of existing\\nservers, spawning a golden age of maximizing the value of existing assets.\\nVMwarts\\nBut, and there’s always a but! As great as VMs are, they’re far from perfect.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 14}, page_content='1: Containers from 30,000 feet\\n8\\nFor example, every VM needs its own dedicated operating system (OS). Unfortunately,\\nthis has several drawbacks, including:\\n• Every OS consumes CPU, RAM, and other resources we’d rather use on applica-\\ntions\\n• Every VM and OS needs patching\\n• Every VM and OS needs monitoring\\nVMs are also slow to boot and not very portable.\\nHello Containers!\\nWhile most of us were reaping the benefits of VMs, web scalers like Google had already\\nmoved on from VMs and were using containers.\\nA feature of the container model is that every container shares the OS of the host it’s\\nrunning on. This means a single host can run more containers than VMs. For example,\\na host that can run 10 VMs might be able to run 50 containers, making containers far\\nmore efficient than VMs.\\nContainers are also faster and more portable than VMs.\\nLinux containers\\nModern containers started in the Linux world and are the product of incredible work\\nfrom many people over many years. For example, Google contributed many container-\\nrelated technologies to the Linux kernel. It’s thanks to many contributions like these\\nthat we have containers today.\\nSome of the major technologies underpinning modern containers include kernel\\nnamespaces, control groups (cgroups), and capabilities.\\nHowever, despite all this great work, containers were incredibly complicated, and it\\nwasn’t until Docker came along that they became accessible to the masses.\\nNote: I know that many container-like technologies pre-date Docker and\\nmodern containers. However, none of them changed the world the way\\nDocker has.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 15}, page_content='1: Containers from 30,000 feet\\n9\\nHello Docker!\\nDocker was the magic that made Linux containers easy and brought them to the masses.\\nWe’ll talk a lot more about Docker in the next chapter.\\nDocker and Windows\\nMicrosoft worked hard to bring Docker and container technologies to the Windows\\nplatform.\\nAt the time of writing, Windows desktop and server platforms support both of the\\nfollowing:\\n• Windows containers\\n• Linux containers\\nWindows containers run Windows apps and require a host system with a Windows kernel.\\nWindows 10, Windows 11, and all modern versions of Windows Server natively support\\nWindows containers.\\nWindows systems can also run Linux containers via the WSL 2 (Windows Subsystem for\\nLinux) subsystem.\\nThis means Windows 10 and Windows 11 are great platforms for developing and testing\\nWindows and Linux containers.\\nHowever, despite all the work developing Windows containers, almost all containers are\\nLinux containers. This is because Linux containers are smaller and faster, and more\\ntooling exists for Linux.\\nAll of the examples in this edition of the book are Linux containers.\\nWindows containers vs Linux containers\\nIt’s vital to understand that containers share the kernel of the host they’re running on.\\nThis means containerized Windows apps need a host with a Windows kernel, whereas\\ncontainerized Linux apps need a host with a Linux kernel. However, as mentioned, you\\ncan run Linux containers on Windows systems that have the WSL 2 backend installed.\\nTerminology: A containerized app is an application running as a container.\\nWe’ll cover this in a lot of detail later.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 16}, page_content='1: Containers from 30,000 feet\\n10\\nWhat about Mac containers?\\nThere is no such thing as Mac containers. However, Macs are great platforms for\\nworking with containers, and I do all of my daily work with containers on a Mac.\\nThe most popular way of working with containers on a Mac is Docker Desktop. It works\\nby running Docker inside a lightweight Linux VM on your Mac. Other tools, such as\\nPodman and Rancher Desktop, are also great for working with containers on a Mac.\\nWhat about Wasm\\nWasm (WebAssembly) is a modern binary instruction set that builds applications that are\\nsmaller, faster, more secure, and more portable than containers. You write your app in\\nyour favorite language and compile it as a Wasm binary that will run anywhere you have\\na Wasm runtime.\\nHowever, Wasm apps have many limitations, and we’re still developing many of\\nthe standards. As a result, containers remain the dominant model for cloud-native\\napplications.\\nThe container ecosystem is also much richer and more mature than the Wasm ecosys-\\ntem.\\nAs you’ll see in the Wasm chapter, Docker and the container ecosystem are adapting\\nto work with Wasm apps, and you should expect a future where VMs, containers, and\\nWasm apps run side-by-side in most clouds and applications.\\nThis book is up-to-date with the latest Wasm and container developments.\\nDocker and AI\\nDevelopers and organizations are using more and more AI apps, and Docker is regularly\\nranked as the No. 1 most-desired and No. 1 most-used developer tool (Stack Overflow\\nAnnual Developer Survey).\\nUnfortunately, exposing GPUs and other AI acceleration hardware to apps running\\ninside containers is very hard. This is because they all have their own drivers and SDKs,\\nand it’s too much work for the industry to make them all work with containers. As\\na result, Docker has released Docker Model Runner as a way of running local LLMs\\noutside of containers so they have direct access to the host’s hardware.\\nChapter 10 is dedicated to running local AI models with Docker Model Runner, and it’s\\nvery exciting.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 17}, page_content='1: Containers from 30,000 feet\\n11\\nWhat about Kubernetes\\nKubernetes is the industry standard platform for deploying and managing containerized\\napps.\\nOlder versions of Kubernetes used Docker to start and stop containers. However, newer\\nversions use containerd, which is a stripped-down version of Docker optimized for use\\nby Kubernetes and other platforms.\\nThe important thing to know is that all Docker containers work on Kubernetes.\\nCheck out these books if you need to learn Kubernetes:\\n• Quick Start Kubernetes: This is ∼100 pages and will get you up-to-speed with\\nKubernetes in a single day!\\n• The Kubernetes Book. This is the ultimate book for mastering Kubernetes.\\nI update both books annually to ensure they’re up-to-date with the latest and greatest\\ndevelopments in the cloud native ecosystem.\\nChapter Summary\\nWe used to live in a world where every business application needed a dedicated, over-\\npowered server. VMware came along and allowed us to run multiple applications on\\nnew and existing servers. However, following the success of VMware and hypervisors,\\na newer, more efficient, and portable virtualization technology called containers came'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 18}, page_content='1: Containers from 30,000 feet\\n12\\nalong. However, containers were complex and hard to implement until Docker came\\nalong and made them easy. Wasm and AI are powering new innovations, and the Docker\\necosystem is evolving to work with both. The book has entire chapters dedicated to\\nworking with AI apps and Wasm apps on Docker.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 19}, page_content='2: Docker and container-related\\nstandards and projects\\nThis chapter introduces you to Docker and some of the most important standards and\\nprojects shaping the container ecosystem. The goal is to lay some foundations that we’ll\\nbuild on in later chapters.\\nThis chapter has two main parts:\\n• Docker\\n• Container-related standards and projects\\nDocker\\nDocker is at the heart of the container ecosystem. However, the term Docker can mean\\ntwo things:\\n1. The Docker platform\\n2. Docker, Inc.\\nThe Docker platform is a neatly packaged collection of technologies for creating, manag-\\ning, and orchestrating containers. Docker, Inc. is the company that created the Docker\\nplatform and continues to be the driving force behind developing new features.\\nLet’s dive a bit deeper.\\nDocker, Inc.\\nDocker, Inc. is a technology company based out of Palo Alto and founded by French-\\nborn American developer and entrepreneur Solomon Hykes. Solomon is no longer at\\nthe company.\\nThe company started as a platform as a service (PaaS) provider called dotCloud. Behind the\\nscenes, dotCloud delivered its services on top of containers and had an in-house tool to\\nhelp them deploy and manage those containers. They called this in-house tool Docker.\\nThe word Docker is a British expression short for dock worker referring to someone who\\nloads and unloads cargo from ships.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 20}, page_content='2: Docker and container-related standards and projects\\n14\\nIn 2013, dotCloud dropped the struggling PaaS side of the business, rebranded as\\nDocker, Inc., and focused on bringing Docker and containers to the world.\\nThe Docker technology\\nThe Docker platform makes it easy to build, share, and run containers.\\nAt a high level, there are two major parts to the Docker platform:\\n• The CLI (client)\\n• The engine (server)\\nThe CLI is the familiar docker command-line tool for deploying and managing contain-\\ners. It converts simple commands into API requests and sends them to the engine.\\nThe engine comprises all the server-side components that run and manage containers.\\nFigure 2.1 shows the high-level architecture. The client and engine can be on the same\\nhost or connected over the network.\\nFigure 2.1 - Docker client and engine.\\nIn later chapters, you’ll see that the client and engine are complex and comprise a lot of\\nsmall specialized parts. Figure 2.2 gives you an idea of some of the complexity behind\\nthe engine. However, the client hides all this complexity so you don’t have to care. For\\nexample, you type friendly docker commands into the CLI, the CLI converts them to\\nAPI requests and sends them to the daemon, and the daemon takes care of everything\\nelse.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 21}, page_content='2: Docker and container-related standards and projects\\n15\\nFigure 2.2 - Docker CLI and daemon hiding complexity.\\nLet’s switch focus and briefly look at some standards and governance bodies.\\nContainer-related standards and projects\\nSeveral important standards and governance bodies influence container development\\nand the container ecosystem. Some of these include:\\n• The OCI\\n• The CNCF\\n• The Moby Project\\nThe Open Container Initiative (OCI)\\nThe Open Container Initiative (OCI)1 is a governance council responsible for low-level\\ncontainer-related standards.\\nIt operates under the umbrella of the Linux Foundation2 and was founded in the early\\ndays of the container ecosystem when some of the people at a company called CoreOS\\ndidn’t like the way Docker was dominating the ecosystem. In response, CoreOS created\\nan open standard called appc3 that defined specifications for things such as image\\nformat and container runtime. They also created a reference implementation called rkt\\n(pronounced “rocket”).\\nThe appc standard did things differently from Docker and put the ecosystem in an\\nawkward position with two competing standards.\\nWhile competition is usually a good thing, competing standards are generally bad, as they\\ngenerate confusion that slows down user adoption. Fortunately, the main players in the\\n1https://www.opencontainers.org\\n2https://www.linuxfoundation.org/projects\\n3https://github.com/appc/spec/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 22}, page_content='2: Docker and container-related standards and projects\\n16\\necosystem came together and formed the OCI as a vendor-neutral lightweight council\\nto govern container standards. This allowed us to archive the appc project and place all\\nlow-level container-related specifications under the OCI’s governance.\\nAt the time of writing, the OCI maintains three standards called specs:\\n• The image-spec4\\n• The runtime-spec5\\n• The distribution-spec6\\nWe often use a rail tracks analogy when explaining the OCI standards:\\nWhen the size and properties of rail tracks were standardized, it gave entrepreneurs\\nin the rail industry confidence the trains, carriages, signaling systems, platforms, and\\nother products they built would work with the standardized tracks — nobody wanted\\ncompeting standards for track sizes.\\nThe OCI specifications did the same thing for the container ecosystem and it’s flour-\\nished ever since. Docker has also changed a lot since the formation of the OCI, and all\\nmodern versions of Docker implement all three OCI specs. For example:\\n• The Docker builder (BuildKit) creates OCI compliant-images\\n• Docker uses an OCI-compliant runtime to create OCI-compliant containers\\n• Docker Hub implements the OCI distribution spec and is an OCI-compliant registry\\nDocker, Inc. and many other companies have people serving on the OCI’s technical\\noversight board (TOB).\\nThe Cloud Native Computing Foundation (CNCF)\\nThe Cloud Native Computing Foundation (CNCF)7 is another Linux Foundation\\nproject that is influential in the container ecosystem. It was founded in 2015 with the\\ngoal of “…advancing container technologies… and making cloud native computing ubiquitous”.\\nInstead of creating and maintaining container-related specifications, the CNCF hosts\\nimportant projects such as Kubernetes, containerd, Notary, Prometheus, Cilium, and\\nlots more.\\nWhen we say the CNCF hosts these projects, we mean it provides a space, structure, and\\nsupport for projects to grow and mature. For example, all CNCF projects pass through\\nthe following three phases or stages:\\n4https://github.com/opencontainers/image-spec\\n5https://github.com/opencontainers/runtime-spec\\n6https://github.com/opencontainers/distribution-spec\\n7https://www.cncf.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 23}, page_content='2: Docker and container-related standards and projects\\n17\\n• Sandbox\\n• Incubating\\n• Graduated\\nEach phase increases a project’s maturity level by requiring higher standards of gov-\\nernance, documentation, auditing, contribution tracking, marketing, community\\nengagement, and more. For example, new projects accepted as sandbox projects may\\nhave great ideas and great technology but need help and resources to create strong\\ngovernance, etc. The CNCF helps with all of that.\\nGraduated projects are considered ready for production and are guaranteed to have strong\\ngovernance and implement good practices.\\nIf you look back to Figure 2.2, you’ll see that Docker uses at least two CNCF technolo-\\ngies — containerd and Notary.\\nThe Moby Project\\nDocker created the Moby project as a community-led place for developers to build\\nspecialized tools for building container platforms.\\nPlatform builders can pick the specific Moby tools they need to build their container\\nplatform. They can even compose their platforms using a mix of Moby tools, in-house\\ntools, and tools from other projects.\\nDocker, Inc. originally created the Moby project, but it now has members including\\nMicrosoft, Mirantis, and Nvidia.\\nThe Docker platform is built using tools from various projects, including the Moby\\nproject, the CNCF, and the OCI.\\nChapter summary\\nThis chapter introduced you to Docker and some of the major influences in the\\ncontainer ecosystem.\\nDocker, Inc., is a technology company based in Palo Alto that is changing how we do\\nsoftware. They were the first movers and instigators of the modern container revolution.\\nThe Docker platform focuses on running and managing application containers. It runs\\non Linux and Windows, can be installed almost anywhere, and offers a variety of free\\nand paid-for products.\\nThe Open Container Initiative (OCI) governs low-level container standards and\\nmaintains specifications for runtimes, image format, and registries.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 24}, page_content='2: Docker and container-related standards and projects\\n18\\nThe CNCF provides support for important cloud-native projects and helps them mature\\ninto production-grade tools.\\nThe Moby project hosts low-level tools developers can use to build container platforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 25}, page_content='3: Getting Docker\\nThere are lots of ways to get Docker and work with containers. This chapter will show\\nyou the following ways:\\n• Docker Desktop\\n• Multipass\\n• Server installs on Linux\\nI strongly recommend you install and use Docker Desktop. It’s the best way to work\\nwith Docker, and you’ll be able to use it to follow most of the examples in the book. I\\nuse it every day.\\nIf you can’t use Docker Desktop, we’ll show you how to install Docker in a Multipass\\nVM, as well as how to perform a simple installation on Linux. However, these installa-\\ntions don’t have all the features of Docker Desktop.\\nDocker Desktop\\nDocker Desktop is a desktop app from Docker, Inc. and is the best way to work with\\ncontainers. You get the Docker Engine, a slick UI, all the latest plugins and features,\\nand an extension system with a marketplace. You even get Docker Compose and a\\nKubernetes cluster if you want to learn Kubernetes.\\nIt’s free for personal use and education, but you’ll have to pay a license fee if you use it\\nfor work and your company has over 250 employees or does more than $10M in annual\\nrevenue.\\nDocker Desktop on Windows 10 and Windows 11 Professional and Enterprise editions\\nsupports Windows containers and Linux containers. Docker Desktop on Mac, Linux, and\\nHome editions of Windows only support Linux containers. All of the examples in the\\nbook and almost all of the containers in the real world are Linux containers.\\nLet’s install Docker Desktop on Windows and MacOS.\\nWindows prereqs\\nDocker Desktop on Windows requires all of the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 26}, page_content='3: Getting Docker\\n20\\n• 64-bit version of Windows 10/11\\n• Hardware virtualization support must be enabled in your system’s BIOS\\n• WSL 2\\nBe very careful changing anything in your system’s BIOS.\\nInstalling Docker Desktop on Windows 10 and 11\\nSearch the internet for “install Docker Desktop on Windows”. This will take you to the\\nrelevant download page, where you can download the installer and follow the instruc-\\ntions. When prompted, you should install and enable the WSL 2 backend (Windows\\nSubsystem for Linux).\\nOnce the installation is complete, you need to manually start Docker Desktop from the\\nWindows Start menu. It may take a minute to start, but you can watch the start progress\\nvia the animated whale icon on the Windows taskbar at the bottom of the screen.\\nOnce it’s running, you can open a terminal and type some simple docker commands.\\n$ docker version\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nGo version:\\ngo1.23.8\\nOS/Arch:\\nlinux/amd64\\n<Snip>\\nCongratulations. You now have a working installation of Docker on your Windows\\nmachine.\\nNotice how the Server output shows OS/Arch: linux/amd64. This is because a default\\ninstallation assumes you’ll be working with Linux containers.\\nSome versions of Windows let you switch to Windows containers by right-clicking the\\nDocker whale icon in the Windows notifications tray and selecting Switch to Windows\\ncontainers…. Doing this keeps existing Linux containers running in the background,\\nbut you won’t be able to see or manage them until you switch back to Linux containers\\nmode.\\nMake sure you’re running in Linux containers mode so you can follow along with the\\nexamples later in the book.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 27}, page_content='3: Getting Docker\\n21\\nInstalling Docker Desktop on Mac\\nDocker Desktop for Mac is like Docker Desktop for Windows — a packaged product\\nwith a slick UI that gets you the full Docker experience on your laptop.\\nBefore proceeding with the installation, you need to know that Docker Desktop on\\nMac installs the daemon and server-side components inside a lightweight Linux VM\\nthat seamlessly exposes the API to your local Mac environment. This means you can\\nopen a terminal on your Mac and run docker commands without ever knowing it’s all\\nrunning in a hidden VM. This is also why Mac versions of Docker Desktop only work\\nwith Linux containers — everything’s running inside a Linux VM.\\nFigure 3.1 shows the high-level architecture for Docker Desktop on Mac.\\nFigure 3.1\\nThe simplest way to install Docker Desktop on your Mac is to search the web for “install\\nDocker Desktop on MacOS”, follow the links to the download, and then complete the\\nsimple installer.\\nWhen the installer finishes, you’ll have to start Docker Desktop from the MacOS\\nLaunchpad. It may take a minute to start, but you can watch the animated Docker whale\\nicon in the status bar at the top of your screen. Once it’s started, you can click the whale\\nicon to manage Docker Desktop.\\nOpen a terminal window and run some regular Docker commands. Try the following.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 28}, page_content='3: Getting Docker\\n22\\n$ docker version\\nClient:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49\\nOS/Arch:\\ndarwin/arm64\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nOS/Arch:\\nlinux/arm64\\ncontainerd:\\nVersion:\\n1.7.21\\nrunc:\\nVersion:\\n1.2.5\\ndocker-init:\\nVersion:\\n0.19.0\\n<Snip>\\nNotice that the OS/Arch: for the Server component shows as linux/amd64 or lin-\\nux/arm64. This is because the daemon runs inside the Linux VM mentioned earlier. The\\nClient component is a native Mac application and runs directly on the Mac OS Darwin\\nkernel. This is why it shows as darwin/amd64 or darwin/arm64.\\nYou can now use Docker on your Mac.\\nInstalling Docker with Multipass\\nOnly consider this section if you can’t use Docker Desktop.\\nMultipass installations don’t ship with out-of-the-box support for features such as\\ndocker scout, docker debug, and docker init.\\nMultipass is a free tool for creating cloud-style Linux VMs on your Linux, Mac, or\\nWindows machine and is incredibly easy to install and use. It’s an easy way to create\\nmulti-node production-like Docker clusters.\\nGo to https://multipass.run/install and install the right edition for your hardware\\nand OS.\\nOnce installed, you only need three commands:\\n$ multipass launch\\n$ multipass ls\\n$ multipass shell\\nRun the following command to create a new VM called node1 based on the docker\\nimage. The docker image has Docker pre-installed and ready to go.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 29}, page_content='3: Getting Docker\\n23\\n$ multipass launch docker --name node1\\nIt’ll take a minute or two to download the image and launch the VM.\\nList VMs to make sure yours launched properly.\\n$ multipass ls\\nName\\nState\\nIPv4\\nImage\\nnode1\\nRunning\\n192.168.64.37\\nUbuntu 24.04 LTS\\n172.17.0.1\\n172.18.0.1\\nYou’ll use the 192.168.x.x IP address when working with the examples later in the book.\\nConnect to the VM with the following command.\\n$ multipass shell node1\\nOnce connected, you can run the following commands to check your Docker version\\nand list installed CLI plugins.\\n$ docker --version\\nDocker version 26.1.0, build 9714adc\\n$ docker info\\nClient: Docker Engine - Community\\nVersion:\\n27.3.1\\nContext:\\ndefault\\nDebug Mode: false\\nPlugins:\\nbuildx: Docker Buildx (Docker Inc.)\\nVersion:\\nv0.17.1\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-buildx\\ncompose: Docker Compose (Docker Inc.)\\nVersion:\\nv2.29.7\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-compose\\n<Snip>\\nYou can type exit to log out of the VM, and multipass shell node1 to log back in.\\nYou can also type multipass delete node1 and then multipass purge to delete it.\\nInstalling Docker on Linux\\nOnly consider this section if you can’t use Docker Desktop, as it doesn’t give you access\\nto docker scout, docker debug, or docker init.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 30}, page_content='3: Getting Docker\\n24\\nThese instructions show you how to install Docker on Ubuntu Linux 24.04 and are just\\nfor guidance purposes. Lots of other installation methods exist, and you should search\\nthe web for the latest instructions.\\n$ sudo snap install docker\\n<Snip>\\ndocker 27.2.0 from Canonical✓installed\\nRun some commands to test the installation. You’ll have to prefix them with sudo.\\n$ sudo docker --version\\nDocker version 27.2.0, build 3ab4256\\n$ sudo docker info\\n<Snip>\\nServer:\\nContainers: 0\\nRunning: 0\\nPaused: 0\\nStopped: 0\\nImages: 0\\nServer Version: 27.2.0\\n<Snip>\\nIf you don’t like adding sudo before Docker commands, you can run the following\\ncommands to create a docker group and add your user account to it.\\n$ sudo groupadd docker\\n$ sudo usermod -aG docker $(whoami)\\nYou’ll need to restart Docker for the changes to take effect. This is how you restart\\nDocker on many Ubuntu Linux distributions. Yours may be different.\\n$ sudo service docker start\\nChapter Summary\\nYou can run Docker almost anywhere, and installing it’s easier than ever.\\nDocker Desktop gives you a fully functional Docker environment on your Linux, Mac,\\nor Windows machine and is the best way to get a Docker development environment on\\nyour local machine. It’s easy to install, includes the Docker Engine, has a slick UI, and\\nhas a marketplace with lots of extensions to extend its capabilities. It works with docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 31}, page_content='3: Getting Docker\\n25\\nscout, docker debug, and docker init, and it even lets you spin up a Kubernetes\\ncluster.\\nMultipass is a great way to spin up a local VM running Docker, and there are lots of\\nways to install Docker on Linux servers. These give you access to most of the free\\nDocker features but lack some of the features of Docker Desktop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 32}, page_content='4: The big picture\\nThis chapter will give you some hands-on experience and a high-level view of images\\nand containers. The goal is to prepare you for more detail in the upcoming chapters.\\nWe’ll break this chapter into two parts:\\n• The Ops perspective\\n• The Dev perspective\\nThe ops perspective focuses on starting, stopping, deleting containers, and executing\\ncommands inside them.\\nThe dev perspective focuses more on the application side of things and runs through\\ntaking application source code, building it into a container image, and running it as a\\ncontainer.\\nI recommend you read both sections and follow the examples, as this will give you the\\ndev and ops perspectives. DevOps anyone?\\nThe Ops Perspective\\nIn this section, you’ll complete all of the following:\\n• Check Docker is working\\n• Download an image\\n• Start a container from the image\\n• Execute a command inside the container\\n• Delete the container\\nA typical Docker installation installs the client and the engine on the same machine and\\nconfigures them to talk to each other.\\nRun a docker version command to ensure both are installed and running.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 33}, page_content='4: The big picture\\n27\\n$ docker version\\nClient:\\n<<--- Start of client response\\nVersion:\\n28.1.1\\n----┐\\nAPI version:\\n1.49\\n|\\nGo version:\\ngo1.23.8\\n| Client info block\\nOS/Arch:\\ndarwin/arm64\\n|\\nContext:\\ndesktop-linux\\n----┘\\nServer: Docker Desktop 4.42.0 (192140)\\n<<--- Start of server response\\nEngine:\\n----┐\\nVersion:\\n28.11\\n|\\nAPI version:\\n1.49 (minimum version 1.24) |\\nGo version:\\ngo1.23.8\\n|\\nOS/Arch:\\nlinux/arm64\\n|\\ncontainerd:\\n| Server block\\nVersion:\\n1.7.27\\n|\\nrunc:\\n|\\nVersion:\\n1.2.5\\n|\\ndocker-init:\\n|\\nVersion:\\n0.19.0\\n----┘\\nIf your response from the client and server looks like the output in the book, everything\\nis working as expected.\\nIf you’re on Linux and get a permission denied while trying to connect to the\\nDocker daemon... error, try again with sudo in front of the command — sudo docker\\nversion. If it works with sudo, you’ll need to prefix all future docker commands with\\nsudo.\\nDownload an image\\nImages are objects that contain everything an app needs to run. This includes an OS\\nfilesystem, the application, and all dependencies. If you work in operations, they’re\\nsimilar to VM templates. If you’re a developer, they’re similar to classes.\\nRun a docker images command.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nIf you are working from a clean installation, you’ll have no images, and your output\\nwill be the same as the book. If you’re working with Multipass, you might see an image\\ncalled portainer/portainer-ce.\\nCopying new images onto your Docker host is called pulling. Pull the ubuntu:latest\\nimage.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 34}, page_content='4: The big picture\\n28\\n$ docker pull nginx:latest\\nlatest: Pulling from library/nginx\\nad5932596f78: Download complete\\ne4bc5c1a6721: Download complete\\n1bd52ec2c0cb: Download complete\\n411a98463f95: Download complete\\ndf25b2e5edb3: Download complete\\ne93f7200eab8: Download complete\\nDigest: sha256:fb197595ebe76b9c0c14ab68159fd3c08bd067ec62300583543f0ebda353b5be\\nStatus: Downloaded newer image for nginx:latest\\ndocker.io/library/nginx:latest\\nRun another docker images to confirm your pull command worked.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnginx\\nlatest\\nfb197595ebe7\\n10 days ago\\n280MB\\nWe’ll discuss where the image is stored and what’s inside it in later chapters. For now, all\\nyou need to know is that images contain enough of an operating system (OS) and all the\\ncode and dependencies required to run a desired application. The NGINX image you\\npulled includes a stripped-down version of Linux and the NGINX web server app.\\nStart a container from the image\\nIf you’ve been following along, you’ll have a copy of the nginx:latest image and you\\ncan use the docker run command to start a container from it.\\nRun the following docker run command to start a new container called test from the\\nubuntu:latest image.\\n$ docker run --name test -d -p 8080:80 nginx:latest\\ne08c3535...30557225\\nThe long number confirms the container was created.\\nLet’s quickly examine that docker run command.\\ndocker run tells Docker to start a new container. The --name flag told Docker to\\ncall this container test and the -d flag told it to start the container in the background\\n(detached mode) so it doesn’t take over your terminal. The -p flag told Docker to map\\nport 80 in the container to port 8080 on your Docker host. Finally, the command told\\nDocker to base the container on the nginx:latest image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 35}, page_content='4: The big picture\\n29\\nRun a docker ps command to see the running container.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\ne08c35352ff3\\nnginx:latest\\n\"/docker...\"\\n3 mins ago\\nUp 2 mins\\n0.0.0.0:8080->80/tcp\\ntest\\nYou should recognize the CONTAINER ID from the long number printed after the docker\\nrun command. You should also recognize the IMAGE, PORTS, and NAMES columns from\\nthe flags in the docker run command. The COMMAND field lists the command Docker\\nexecuted to start the NGINX app inside the container.\\nExecute a command inside the container\\nRun the following command to attach your shell to a new Bash process inside the\\ncontainer.\\n$ docker exec -it test bash\\nroot@e08c35352ff3:/#\\nYour shell prompt will change to indicate you’re connected to the container.\\nRun the following command to list files in your current directory.\\nroot@e08c35352ff3:/# ls -l\\ntotal 64\\nlrwxrwxrwx\\n1 root root\\n7 Jan\\n2 00:00 bin -> usr/bin\\ndrwxr-xr-x\\n2 root root 4096 Oct 31 11:04 boot\\ndrwxr-xr-x\\n5 root root\\n340 Jan 12 15:09 dev\\ndrwxr-xr-x\\n1 root root 4096 Jan\\n3 02:56 docker-entrypoint.d\\n-rwxr-xr-x\\n1 root root 1620 Jan\\n3 02:56 docker-entrypoint.sh\\ndrwxr-xr-x\\n1 root root 4096 Jan 12 15:09 etc\\n<Snip>\\nIf you’re familiar with Linux, you’ll recognize these are regular Linux files and directo-\\nries.\\nTry running a ps command to list running processes.\\nroot@e08c35352ff3:/# ps -elf\\nbash: ps: command not found\\nThe command is not found because most containers only ship with essential apps and\\ntools to keep them small and reduce attack vectors. Later in the book, we’ll show you'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 36}, page_content='4: The big picture\\n30\\nhow to use Docker Desktop and Docker Debug to connect to running containers and\\nexecute commands not included as part of the container.\\nType exit to terminate your bash process and connect your shell back to your local\\nterminal. Your shell prompt will revert.\\nRun the following command to verify the test container is still running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\ne08c35352ff3\\nnginx:latest\\n\"/docker...\"\\n7 mins ago\\nUp 7 mins\\n0.0.0.0:8080->80\\ntest\\nThe container is still running, and you can see it was created 7 minutes ago and has been\\nrunning for 7 minutes.\\nDelete the container\\nStop and kill the container using the docker stop and docker rm commands.\\n$ docker stop test\\ntest\\nIt can take a few seconds for the container to stop.\\n$ docker rm test\\ntest\\nVerify the container deleted properly by running the docker ps command with the -a\\nflag to list all containers, even those in the stopped state.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nCongratulations, you’ve pulled a Docker image, started a container from it, logged in to\\nit, executed a command inside it, stopped it, and deleted it.\\nThe Dev Perspective\\nContainers are all about applications.\\nYou’ll complete all of the following steps in this section:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 37}, page_content=\"4: The big picture\\n31\\n• Clone an app from a GitHub repo\\n• Inspect the app’s Dockerfile\\n• Containerize the app\\n• Run the app as a container\\nRun the following command to make a local clone of the repo. This will copy the\\napplication code to your machine so you can containerize it in a future step. You’ll need\\nthe git CLI for this to work.\\n$ git clone https://github.com/nigelpoulton/psweb.git\\nCloning into 'psweb'...\\nremote: Enumerating objects: 63, done.\\nremote: Counting objects: 100% (34/34), done.\\nremote: Compressing objects: 100% (22/22), done.\\nremote: Total 63 (delta 13), reused 25 (delta 9), pack-reused 29\\nReceiving objects: 100% (63/63), 13.29 KiB | 4.43 MiB/s, done.\\nResolving deltas: 100% (21/21), done.\\nChange into the psweb directory and list its contents.\\n$ cd psweb\\n$ ls -l\\ntotal 32\\n-rw-r--r--@ 1 nigelpoulton\\nstaff\\n324\\n5 Feb 12:31 Dockerfile\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n378\\n5 Feb 12:31 README.md\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n341\\n5 Feb 12:31 app.js\\n-rw-r--r--@ 1 nigelpoulton\\nstaff\\n355\\n5 Feb 12:47 package.json\\ndrwxr-xr-x\\n3 nigelpoulton\\nstaff\\n96\\n5 Feb 12:31 views\\nThe app is a simple Node.js web app running some static HTML.\\nInspect the app’s Dockerfile\\nThe Dockerfile is a plain-text document that tells Docker how to build the app and\\ndependencies into an image.\\nList the contents of the application’s Dockerfile.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 38}, page_content='4: The big picture\\n32\\n$ cat Dockerfile\\nFROM alpine\\nLABEL maintainer=\"nigelpoulton@hotmail.com\"\\nRUN apk add --update nodejs npm curl\\nCOPY . /src\\nWORKDIR /src\\nRUN\\nnpm install\\nEXPOSE 8080\\nENTRYPOINT [\"node\", \"./app.js\"]\\nYou’ll learn more about Dockerfiles later in the book. Right now, all you need to know is\\nthat each line represents an instruction Docker executes to build the app into an image.\\nIf you’ve been following along, you’ve pulled the application code from a remote Git\\nrepo and looked at the application’s Dockerfile.\\nContainerize the app\\nRun the following docker build command to create a new image based on the instruc-\\ntions in the Dockerfile. It will create a new Docker image called test:latest.\\nBe sure to run the command from within the psweb directory and include the trailing\\nperiod.\\n$ docker build -t test:latest .\\n[+] Building 36.2s (11/11) FINISHED\\n=> [internal] load .dockerignore\\n0.0s\\n=> => transferring context: 2B\\n0.0s\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n<Snip>\\n=> => naming to docker.io/library/test:latest\\n0.0s\\n=> => unpacking to docker.io/library/test:latest\\n0.7s\\nWhen the build completes, check that you have an image called test:latest.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\ntest\\nlatest\\n0435f2738cf6\\n21 seconds ago\\n160MB\\nCongratulations, you’ve containerized the app. That’s jargon for building it into a\\ncontainer image that contains the app and all dependencies.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 39}, page_content='4: The big picture\\n33\\nRun the app as a container\\nRun the following command to start a container called web1 from the image. If you’re\\non a Windows machine, you’ll need to replace the backslashes with backticks or run the\\ncommand on a single line without the backslashes.\\n$ docker run -d \\\\\\n--name web1 \\\\\\n--publish 8080:8080 \\\\\\ntest:latest\\nOpen a web browser and navigate to the DNS name or IP address of your Docker host\\non port 8080. If you’re following along on Docker Desktop, connect to localhost:8080\\nor 127.0.0.1:8080. If you’re following along on Multipass, connect to your Multipass\\nVM’s 192.168 address on port 8080. Run an ip a | grep 192 command from within\\nthe Multipass VM, or run a multipass ls from your local machine to find the address.\\nYou will see the following web page.\\nFigure 4.1\\nCongratulations. You’ve copied some application code from a remote Git repo, built it\\ninto a Docker image, and run it as a container. We call this containerizing an app.\\nClean up\\nRun the following commands to terminate the container and delete the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 40}, page_content='4: The big picture\\n34\\n$ docker rm web1 -f\\nweb1\\n$ docker rmi test:latest\\nUntagged: test:latest\\nDeleted: sha256:0435f27...cac8e2b\\nChapter Summary\\nIn the Ops section of the chapter, you downloaded a Docker image, launched a container\\nfrom it, logged into the container, executed a command inside of it, and then stopped\\nand deleted the container.\\nIn the Dev section, you containerized a simple application by pulling source code from\\nGitHub and building it into an image using instructions in a Dockerfile. You then ran\\nthe app as a container.\\nThe things you’ve learned in this chapter will help you in the upcoming chapters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 41}, page_content='Part 2: The technical stuff'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 42}, page_content='5: The Docker Engine\\nIn this chapter, we’ll look under the hood of the Docker Engine.\\nThis chapter has a strong operations focus, and you can use Docker without knowing\\neverything you’re about to learn. However, to truly master something, you need to\\nunderstand what’s going on under the hood. So, if you want to master Docker, you\\nshould read this chapter.\\nI’ve divided the chapter into the following sections:\\n• Docker Engine – The TLDR\\n• The Docker Engine\\n• The influence of the Open Container Initiative (OCI)\\n• runc\\n• containerd\\n• Starting a new container (example)\\n• What’s the shim all about\\n• How it’s implemented on Linux\\nLet’s learn about the Docker Engine.\\nDocker Engine – The TLDR\\nDocker Engine is jargon for the server-side components of Docker that run and manage\\ncontainers. If you’ve ever worked with VMware, the Docker Engine is similar to ESXi.\\nThe Docker Engine is modular and built from many small specialized components\\npulled from projects such as the OCI, the CNCF, and the Moby project.\\nIn many ways, the Docker Engine is like a car engine:\\n• A car engine is made from many specialized parts that work together to make a car\\ndrive — intake manifolds, throttle bodies, cylinders, pistons, spark plugs, exhaust\\nmanifolds, and more.\\n• The Docker Engine is made from many specialized tools that work together to\\ncreate and run containers — the API, image builder, high-level runtime, low-level\\nruntime, shims, etc.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 43}, page_content='5: The Docker Engine\\n37\\nFigure 5.1 shows the components of the Docker Engine that create and run containers.\\nOther components exist, but this simplified diagram focuses on the components that\\nstart and run containers.\\nFigure 5.1\\nThroughout the book, we’ll refer to runc and containerd with lowercase “r” and “c”, which\\nis how they’re both written in the official project documentation. This means sentences\\nstarting with either runc or containerd will not begin with a capital letter.\\nThe Docker Engine\\nWhen Docker was first released, the Docker Engine had two major components:\\n• The Docker daemon (sometimes referred to as just “the daemon”)\\n• LXC\\nThe daemon was a monolithic binary containing all the code for the API, image builders,\\ncontainer execution, volumes, networking, and more.\\nLXC did the hard work of interfacing with the Linux kernel and constructing the\\nrequired namespaces and cgroups to build and start containers.\\nReplacing LXC\\nRelying on LXC posed several problems for the Docker project.\\nFirst, LXC is Linux-specific, and Docker had aspirations of being multi-platform.\\nSecond, Docker was evolving fast, and there was no way of ensuring LXC evolved in the\\nways Docker needed.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 44}, page_content='5: The Docker Engine\\n38\\nTo improve the experience and help the project evolve more quickly, Docker replaced\\nLXC with its own tool, libcontainer. The goal of libcontainer was to be a platform-\\nagnostic tool that gave Docker access to the fundamental container building blocks in\\nthe host kernel.\\nLibcontainer replaced LXC in Docker a very long time ago.\\nBreaking up the monolithic Docker daemon\\nAs previously mentioned, the Docker Engine was originally a monolith with almost all\\nfunctionality coded into the daemon. However, as time passed, this became more and\\nmore problematic for the following reasons:\\n1. It got slower\\n2. It wasn’t what the ecosystem wanted\\n3. It’s hard to innovate on monolithic software\\nThe project recognized these challenges and began a long-running program to break\\napart and refactor the Engine so that every feature became its own small specialized tool.\\nPlatform builders could then re-use these tools to build other platforms.\\nThis work of breaking apart the Docker daemon is an ongoing process, and all of the\\ncode for building images and executing containers has been removed and refactored\\ninto small, specialized tools. Notable examples include removing the high-level and\\nlow-level runtime functionality and re-implementing them in separate tools called\\ncontainerd and runc, both of which are used by many different projects, including\\nDocker, Kubernetes, Firecracker, and Fargate. More recently (starting with Docker\\nDesktop 4.27.0), Docker has removed image management from the daemon and now\\nuses containerd’s image management capabilities.\\nFigure 5.2 shows another view of the Docker Engine components that are used to run\\ncontainers and lists the primary responsibilities of each component.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 45}, page_content='5: The Docker Engine\\n39\\nFigure 5.2 - Engine components and responsibilities\\nOther engine components exist.\\nThe influence of the Open Container Initiative (OCI)\\nAround the same time that Docker, Inc. was refactoring the Engine, the OCI8 was in the\\nprocess of defining two container-related standards:\\n1. Image Specification (image-spec)9\\n2. Runtime Specification (runtime-spec)10\\nBoth specifications were released as version 1.0 in July 2017 and are still vital today.\\nThey’ve even added a third specification called the Distribution Specification (distribu-\\ntion-spec) governing how images are distributed via registries.\\nAt the time of writing, the runtime-spec is at version 1.2.0, and the image-spec and\\ndistribution-spec are both at version 1.1.0. This demonstrates the slow-and-steady\\nnature of these low-level specifications that are heavily relied upon by so many other\\nprojects — stability is the name of the game for low-level OCI specs.\\n8https://www.opencontainers.org/\\n9https://github.com/opencontainers/image-spec\\n10https://github.com/opencontainers/runtime-spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 46}, page_content='5: The Docker Engine\\n40\\nDocker, Inc. was a founding member of the OCI and was heavily involved in defining\\nthe original specifications. It continues to be involved by contributing code and helping\\nguide the future of the specifications.\\nAll versions of Docker since 2016 have implemented the OCI specifications. For\\nexample, Docker uses runc, the reference implementation of the OCI runtime-spec, to\\ncreate OCI-compliant containers (runtime-spec). It also uses BuildKit to build OCI-\\ncompliant images (image-spec), and Docker Hub is an OCI-compliant registry (registry-\\nspec).\\nrunc\\nAs previously mentioned, runc11 (pronounced “run see” and always written with a\\nlowercase “r”) is the reference implementation of the OCI runtime-spec. Docker, Inc.\\nwas heavily involved in defining the spec and contributed the initial code for runc.\\nrunc is a lightweight CLI wrapper for libcontainer that you can download and use\\nto manage OCI-compliant containers. However, it’s a very low-level tool and lacks\\nalmost all of the features and add-ons you get with the Docker Engine. Fortunately, as\\npreviously shown in Figure 5.2, Docker uses runc as its low-level runtime. This means\\nyou get OCI-compliant containers and the feature-rich Docker user experience.\\nOn the jargon front, we sometimes say that runc operates at the OCI layer, and we often\\nrefer to it as a low-level runtime.\\nDocker and Kubernetes both use runc as their default low-level runtime, and both pair it\\nwith the containerd high-level runtime:\\n• containerd operates as the high-level runtime managing lifecycle events\\n• runc operates as the low-level runtime executing lifecycle events by interfacing\\nwith the kernel to do the work of actually building containers and deleting them\\nYou can see the latest releases here:\\n• https://github.com/opencontainers/runc/releases\\ncontainerd\\ncontainerd (pronounced “container dee” and always written with a lowercase “c”) is\\nanother tool that Docker created while stripping functionality out of the daemon.\\n11https://github.com/opencontainers/runc'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 47}, page_content='5: The Docker Engine\\n41\\nWe refer to containerd as a high-level runtime as it manages lifecycle events such as\\nstarting, stopping, and deleting containers. However, it needs a low-level runtime to\\nperform the actual work. Most of the time, containerd is paired with runc as its low-\\nlevel runtime. However, as you saw in Figure 5.3, it uses shims that make it possible to\\nreplace runc with other low-level runtimes. We’ll go into more detail in the WebAssem-\\nbly chapter when you’ll see how to use Docker to run WebAssembly apps.\\nThe original plan was for containerd to be a small specialized tool for managing\\ncontainer lifecycle events. However, it has since grown to include the ability to manage\\nimages, networks, and volumes.\\nOne reason for adding more functionality is for projects such as Kubernetes that want\\ncontainerd to be able to push and pull images. Fortunately, this extra functionality is\\nmodular, meaning projects like Kubernetes can include containerd but only take the\\npieces they need.\\ncontainerd was originally developed by Docker, Inc. and donated to the Cloud Native\\nComputing Foundation (CNCF). At the time of writing, containerd is a graduated\\nCNCF project, meaning it’s stable and production-ready. You can see the latest releases\\nhere:\\n• https://github.com/containerd/containerd/releases\\nStarting a new container (example)\\nNow that you’ve seen the big picture, let’s see how to use Docker to create a new\\ncontainer.\\nThe most common way of starting containers is using the Docker CLI. Feel free to run\\nthe following command to start a new container called ctr1 based on the nginx image.\\n$ docker run -d --name ctr1 nginx\\nRun a docker ps command to see if the container is running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\n9cfb0c9aacb2\\nnginx\\n\"/docker-entrypoint.…\"\\n9 seconds ago\\nUp 9 seconds\\n80/tcp\\nctr1\\nWhen you run commands like this, the Docker client converts them into API requests\\nand sends them to the API exposed by the daemon.\\nThe daemon can expose the API on a local socket or over the network. On Linux, the\\nlocal socket is /var/run/docker.sock and on Windows it’s \\\\pipe\\\\docker_engine.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 48}, page_content='5: The Docker Engine\\n42\\nThe daemon receives the request, interprets it as a request to create a new container,\\nand passes it to containerd. Remember that the daemon no longer contains any code\\nto create containers.\\nThe daemon communicates with containerd via a CRUD-style API over gRPC12.\\nDespite its name, even containerd cannot create containers. It converts the required\\nDocker image into an OCI bundle and tells runc to use this to create a new container.\\nrunc interfaces with the OS kernel to pull together all the constructs necessary to create\\na container (namespaces, cgroups, etc.). The container starts as a child process of runc,\\nand as soon as the container starts, runc exits.\\nFigure 5.3 summarizes the process.\\nFigure 5.3\\nDecoupling the container creation and management from the Docker daemon and\\nimplementing it in containerd and runc makes it possible to stop, restart, and even\\nupdate the daemon without impacting running containers. We sometimes call this\\ndaemonless containers.\\n12https://grpc.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 49}, page_content='5: The Docker Engine\\n43\\nIf you started the NGINX container earlier, you should delete it using the following\\ncommand.\\n$ docker rm ctr1 -f\\nWhat’s the shim all about?\\nSome of the diagrams in the chapter have shown a shim component.\\nShims are a popular software engineering pattern, and the Docker Engine uses them in\\nbetween containerd and the OCI layer, bringing the following benefits:\\n• Daemonless containers\\n• Improved efficiency\\n• Pluggable OCI layer\\nWe’ve already said that daemonless containers is the ability to stop, restart, and even\\nupdate the Docker daemon without impacting running containers.\\nOn the efficiency front, containerd forks a shim and a runc process for every new\\ncontainer. However, each runc process exits as soon as the container starts running,\\nleaving the shim process as the container’s parent process. The shim is lightweight\\nand sits between containerd and the container. It reports on the container’s status and\\nperforms low-level tasks such as keeping the container’s STDIN and STDOUT streams\\nopen.\\nShims also make it possible to replace runc with other low-level runtimes.\\nHow it’s implemented on Linux\\nOn a Linux system, Docker implements the components we’ve discussed as the follow-\\ning separate binaries:\\n• /usr/bin/dockerd (the Docker daemon)\\n• /usr/bin/containerd\\n• /usr/bin/containerd-shim-runc-v2\\n• /usr/bin/runc\\nYou can see all of these on a Linux-based Docker host by running a ps command. Some\\nof the processes will only be present when the system has running containers, and you\\ncan’t see them if you’re using Docker Desktop on a Mac because the Docker Engine is\\nrunning inside a VM.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 50}, page_content='5: The Docker Engine\\n44\\nDo we still need the daemon\\nAt the time of writing, Docker has stripped most of the functionality out of the daemon.\\nHowever, it still serves the Docker API.\\nChapter summary\\nThe Docker Engine comprises the server-side components of Docker and implements\\nmost of the code to build, share, and run containers. It implements the OCI standards\\nand is a modular app comprising many small, specialized components.\\nThe Docker daemon component implements the Docker API, but most other functionality\\nhas been stripped out and implemented as standalone composable tools such as\\ncontainerd and runc.\\ncontainerd performs image management tasks and oversees container lifecycle manage-\\nment, such as starting, stopping, and deleting containers. Docker, Inc. originally wrote it\\nand then contributed to the CNCF. It’s classed as a high-level runtime and used by many\\nother projects, including Kubernetes, Firecracker, and Fargate.\\ncontainerd relies on a low-level runtime called runc to interface with the host kernel and\\nbuild containers. runc is the reference implementation of the OCI runtime-spec and\\nexpects to start containers from OCI-compliant bundles. containerd talks to runc and\\nensures Docker images are presented to runc as OCI-compliant bundles.\\nrunc is based on code from libcontainer, you can run it as a standalone CLI tool to\\ncreate containers, and it’s used almost everywhere that containerd is used.\\nShims make it possible to use containerd with other low-level runtimes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 51}, page_content='6: Working with Images\\nThis chapter is a dive deep into Docker images. You’ll learn what images are, how to\\nwork with them, and how they work under the hood. You’ll learn how to build your own\\nin Chapter 8: Containerizing an application.\\nI’ve arranged the chapter as follows:\\n• Docker images – The TLDR\\n• Intro to images\\n• Pulling images\\n• Image registries\\n• Image naming and tagging\\n• Images and layers\\n• Pulling images by digest\\n• Multi-architecture images\\n• Vulnerability scanning with Docker Scout\\n• Deleting images\\nDocker images – The TLDR\\nBefore getting started, all of the following terms mean the same thing, and we’ll use\\nthem interchangeably: Image, Docker image, container image, and OCI image.\\nAn image is a read-only package containing everything you need to run an application.\\nThis means they include application code, dependencies, a minimal set of OS constructs,\\nand metadata. You can start multiple containers from a single image.\\nIf you’re familiar with VMware, images are a bit like VM templates — a VM template is\\nlike a stopped VM, whereas an image is like a stopped container. If you’re a developer,\\nimages are similar to classes — you can create one or more objects from a class, whereas\\nyou can create one or more containers from an image.\\nThe easiest way to get an image is to pull one from a registry. Docker Hub13 is the most\\ncommon registry, and pulling an image downloads it to your local machine where\\n13https://hub.docker.com'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 52}, page_content='6: Working with Images\\n46\\nDocker can use it to start one or more containers. Other registries exist, and Docker\\nworks with them all.\\nDocker creates images by stacking independent layers and representing them as a single\\nunified object. One layer might have the OS components, another layer might have\\napplication dependencies, and another layer might have the application. Docker stacks\\nthese layers and makes them look like a unified system.\\nImages are usually small. For example, the official NGINX image is around 80MB, and\\nthe official Redis image is around 40MB. However, Windows images can be huge.\\nThat’s the elevator pitch. Let’s dig a little deeper.\\nIntro to images\\nWe’ve already said that images are like stopped containers. You can even stop a con-\\ntainer and create a new image from it. With this in mind, images are build-time con-\\nstructs, whereas containers are run-time constructs. Figure 6.1 shows the build and run\\nnature of each and that you can start multiple containers from a single image.\\nFigure 6.1\\nThe docker run command is the most common way to start a container from an image.\\nOnce the container is running, the image and the container are bound, and you cannot\\ndelete the image until you stop and delete the container. If multiple containers use the\\nsame image, you can only delete the image after you’ve deleted all the containers using\\nit.\\nContainers are designed to run a single application or microservice. As such, they\\nshould only contain application code and dependencies. You should not include non-\\nessentials such as build tools or troubleshooting tools.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 53}, page_content='6: Working with Images\\n47\\nFor example, the official Alpine Linux image is currently about 3MB. This is because it\\ndoesn’t ship with six different shells, three different package managers, and a bunch of\\ntools you “might” need once every ten years. In fact, it’s increasingly common for images\\nto ship without a shell or a package manager — if the application doesn’t need it at run-\\ntime, the image doesn’t include it. We call these slim images.\\nAnother thing that keeps images small is the lack of an OS kernel. This is because con-\\ntainers use the kernel of the host they’re running on. The only OS-related components\\nin most images are filesystem objects, and you’ll sometimes hear people say images\\ncontain just enough OS.\\nUnfortunately, Windows images can be huge. For example, some Windows-based\\nimages can be gigabytes in size and take a long time to push and pull.\\nPulling images\\nA clean Docker installation has an empty local repository.\\nLocal repository is jargon for an area on your local machine where Docker stores images\\nfor more convenient access. We sometimes call it the image cache, and on Linux it’s\\nusually located in /var/lib/docker/<storage-driver>. However, if you’re using\\nDocker Desktop, it will be inside the Docker VM.\\nRun the following command to inspect the contents of your local repository. This\\nexample has three images relating to three Docker Desktop extensions I’m running.\\nYours will be different and may be empty.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\ndocker/disk-usage-extension\\n0.2.9\\nf4c95478a537\\n26 hours ago\\n3.64MB\\ndocker/logs-explorer-extension\\n0.2.6\\n417dd9a8f96d\\n26 hours ago\\n17.9MB\\nportainer/portainer-docker-extension\\n2.19.4\\n908d04d20e86\\n2 months ago\\n364MB\\nThe process of getting images is called pulling.\\nRun the following commands to pull the redis image and verify it exists in your local\\nrepository.\\nNote: If you are following along on Linux and haven’t added your user\\naccount to the local docker Unix group, you may need to add sudo to the\\nbeginning of all the following commands.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 54}, page_content=\"6: Working with Images\\n48\\n$ docker pull redis\\nUsing default tag: latest\\n<<---- Assume the 'latest' tag\\nlatest: Pulling from library/redis\\n<<---- Assume you want to pull from Docker Hub\\n08df40659127: Download complete\\n<<---- Pulling layer\\n4f4fb700ef54: Already exists\\n<<---- Pulling layer (local copy must exist)\\n4fe7fa4aab04: Download complete\\n<<---- Pulling layer\\n57dea0f129a5: Download complete\\n<<---- Pulling layer\\nf546e941f15b: Download complete\\n<<---- Pulling layer\\nf7f7da262cdb: Download complete\\n<<---- Pulling layer\\nf45ab649e450: Download complete\\n<<---- Pulling layer\\n983f900bbc88: Download complete\\n<<---- Pulling layer\\nDigest: sha256:76d5908f5e19fcdd73daf956a38826f790336ee4707d9028f32b24ad9ac72c08\\nStatus: Downloaded newer image for redis:latest\\ndocker.io/library/redis:latest\\n<<---- docker.io = Docker Hub\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nlatest\\n11c3e418c296\\n2 weeks ago\\n223MB\\n<Snip>\\nThe image now exists in your local repository. However, I’ve annotated a few interesting\\nlines from the docker pull output. We’ll cover them in more detail later in the chapter\\nbut they’re worth a quick mention now.\\nDocker is opinionated and made two assumptions when pulling the image:\\n1. It assumed you wanted to pull the image tagged as latest\\n2. It assumed you wanted to pull the image from Docker Hub\\nYou can override both, but Docker will use these as defaults if you don’t override them.\\nThe Redis image in the example has eight layers. However, Docker only pulled seven\\nlayers because it already had a local copy of one of them. This is because my system\\nruns the Portainer Docker Desktop extension, which is based on an image that shares a\\ncommon layer with the Redis image. You’ll learn about this very soon, but images can\\nshare layers, and Docker is clever enough only to pull the layers it doesn’t already have.\\nImage registries\\nWe store images in centralized places called registries. The job of a registry is to securely\\nstore images and make them easy to access from different environments.\\nFigure 6.2 shows the central nature of registries in the build > share > run pipeline.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 55}, page_content='6: Working with Images\\n49\\nFigure 6.2\\nMost modern registries implement the OCI distribution-spec, and we sometimes call\\nthem OCI registries. Most registries also implement the Docker Registry v2 API, meaning\\nyou can use the Docker CLI and other API tools to query them and work with them in\\nstandard ways. Some offer advanced features such as image scanning and integration\\nwith build pipelines.\\nThe most common registry is Docker Hub, but others exist, including 3rd-party\\ninternet-based registries and secure on-premises registries. However, as previously\\nmentioned, Docker is opinionated and will default to Docker Hub unless you tell it\\nthe name of a different registry. We’ll use Docker Hub for the rest of the book, but the\\nprinciples apply to other registries.\\nImage registries contain one or more image repositories, and image repositories contain\\none or more images. Figure 6.3 shows an image registry with three repositories, each\\nwith one or more images.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 56}, page_content='6: Working with Images\\n50\\nFigure 6.3 - Registry architecture\\nOfficial repositories\\nDocker Hub has the concept of official repositories that are home to images vetted and\\ncurated by Docker and the application vendor. This means they should contain up-to-\\ndate high-quality code that is secure, well-documented, and follows good practices.\\nMost of the popular applications and operating systems have official repositories on\\nDocker Hub, and they’re easy to identify because they live at the top level of the Docker\\nHub namespace and have a green Docker Official Image badge. The following list shows\\na few official repositories and their URLs that exist at the top level of the Docker Hub\\nnamespace:\\n• nginx: https://hub.docker.com/_/nginx/\\n• busybox: https://hub.docker.com/_/busybox/\\n• redis: https://hub.docker.com/_/redis/\\n• mongo: https://hub.docker.com/_/mongo/\\nFigure 6.4 shows the official Alpine and NGINX repositories on Docker Hub. Both have\\nthe green Docker Official Image badge and have over a billion pulls each. Also, notice how\\nboth are available for a wide range of CPU architectures.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 57}, page_content='6: Working with Images\\n51\\nFigure 6.4 - Official repos on Docker Hub\\nUnofficial repositories\\nThe next list shows two of my personal repositories in the “wild west” of unofficial\\nrepositories that you should be very careful when using.\\n• nigelpoulton/gsd — https://hub.docker.com/r/nigelpoulton/gsd-book/\\n• nigelpoulton/k8sbook — https://hub.docker.com/r/nigelpoulton/k8sbook/\\nNotice how they exist below the nigelpoulton second-level namespace. This is one of\\nseveral indications they are not official repositories.\\nWhile there are lots of great images in unofficial repositories, you should always start\\nwith the assumption that anything from an unofficial repository is unsafe. This is based\\non the good practice of never trusting software from the internet. In fact, you should\\nalso exercise caution when downloading and using Docker Official Images.\\nImage naming and tagging\\nMost of the time, you’ll work with images based on their names, and you can learn\\na lot about an image from its name. Figure 6.5 shows a fully qualified image name,\\nincluding the registry name, user/organization name, repository name, and tag. Docker\\nautomatically populates the registry and tag values if you don’t specify them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 58}, page_content=\"6: Working with Images\\n52\\nFigure 6.5 - Fully qualified image name\\nAddressing images from official repositories is easy. All you need to supply is the\\nrepository name and image name separated by a colon. Sometimes we call the image\\nname the tag. The format for a docker pull command pulling an image from an official\\nrepository is:\\n$ docker pull <repository>:<tag>\\nThe example from earlier pulled the Redis image with the following command. It pulled\\nthe image tagged as latest from the top-level redis repository.\\n$ docker pull redis:latest\\nThe following examples show how to pull a few different official images.\\n$ docker pull redis:8.0-M02\\n//Pulls the image tagged as '8.0-M02' from the official 'redis' repository.\\n$ docker pull busybox:glibc\\n//Pulls the image tagged as 'glibc' from the official 'busybox' repository.\\n$ docker pull alpine\\n//Pulls the image tagged as 'latest' from the official 'alpine' repository.\\nA couple of things are worth noting.\\n• As previously mentioned, if you don’t specify an image tag after the repository\\nname, Docker assumes you want the image tagged as latest. The command will\\nfail if the repository has no image tagged as latest.\\n• Images tagged as latest are not guaranteed to be the most up-to-date in the\\nrepository.\\nPulling images from unofficial repositories is almost the same as pulling from official\\nrepositories — you just need to add a Docker Hub username or organization name\\nbefore the repository name. The following example shows how to pull the v2 image\\nfrom the tu-demo repository owned by a not-to-be-trusted person whose Docker Hub\\nID is nigelpoulton.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 59}, page_content='6: Working with Images\\n53\\n$ docker pull nigelpoulton/tu-demo:v2\\nTo pull an image from a different registry, you just add the registry’s DNS name before\\nthe repository name. For example, the following command pulls the latest image from\\nBrandon Mitchell’s regclient/regsync repo on GitHub Container Registry (ghcr.io).\\n$ docker pull ghcr.io/regclient/regsync:latest\\nlatest: Pulling from regclient/regsync\\nf140ae7f526a: Download complete\\nc1cb552669af: Download complete\\nDigest: sha256:88b3d4dc3d7bf2d8ea6f641bea2be15142a9222db66d4b6f2043fc5cc19eead8\\nStatus: Downloaded newer image for ghcr.io/regclient/regsync:latest\\nghcr.io/regclient/regsync:latest\\nNotice how the pull looks the same as it did with Docker Hub. This is because GHCR\\nsupports the OCI registry-spec and implements the Docker Registry v2 API.\\nImages with multiple tags\\nYou can give a single image as many tags as you want.\\nAt first glance, the following output might look like it’s listing three images. However,\\non closer inspection it’s just two — the b4210d0aa52f image is tagged as latest and v1.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/tu-demo\\nlatest\\nb4210d0aa52f\\n2 days ago\\n115MB\\nnigelpoulton/tu-demo\\nv1\\nb4210d0aa52f\\n2 days ago\\n115MB\\nnigelpoulton/tu-demo\\nv2\\n6ba12825d092\\n12 minutes ago\\n115MB\\nThis is a great example of the latest tag not relating to the newest image in the repo.\\nIn this example, the latest tag refers to the same image as the v1 tag, which is actually\\nolder than the v2 image.\\nImages and layers\\nAs already mentioned, images are a collection of loosely connected read-only layers\\nwhere each layer comprises one or more files.\\nFigure 6.6 shows an image with four layers. Docker takes care of stacking them and\\nrepresenting them as a single unified image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 60}, page_content='6: Working with Images\\n54\\nFigure 6.6 - Image and stacked layers\\nYou’re about to look at all of the following ways to inspect layer information:\\n• Pull operations\\n• The docker inspect command\\n• The docker history command\\nRun the following command to pull the node:latest image and observe it pulling the\\nindividual layers. Some newer versions may have more or less layers, but the principle is\\nthe same.\\n$ docker pull node:latest\\nlatest: Pulling from library/ubuntu\\n952132ac251a: Pull complete\\n82659f8f1b76: Pull complete\\nc19118ca682d: Pull complete\\n8296858250fe: Pull complete\\n24e0251a0e2c: Pull complete\\nDigest: sha256:f4691c96e6bbaa99d...28ae95a60369c506dd6e6f6ab\\nStatus: Downloaded newer image for node:latest\\ndocker.io/node:latest\\nEach line ending with Pull complete represents a layer that Docker pulled. This image has\\nfive layers and is shown in Figure 6.7 with layer IDs.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 61}, page_content='6: Working with Images\\n55\\nFigure 6.7 - Image layers and IDs\\nAnother way to see image layers is to inspect the image with the docker inspect\\ncommand. The following example inspects the same node:latest image pulled in the\\nprevious step.\\n$ docker inspect node:latest\\n[\\n{\\n\"Id\": \"sha256:bd3d4369ae.......fa2645f5699037d7d8c6b415a10\",\\n\"RepoTags\": [\\n\"node:latest\"\\n<Snip>\\n\"RootFS\": {\\n\"Type\": \"layers\",\\n\"Layers\": [\\n\"sha256:c8a75145fc...894129005e461a43875a094b93412\",\\n\"sha256:c6f2b330b6...7214ed6aac305dd03f70b95cdc610\",\\n\"sha256:055757a193...3a9565d78962c7f368d5ac5984998\",\\n\"sha256:4837348061...12695f548406ea77feb5074e195e3\",\\n\"sha256:0cad5e07ba...4bae4cfc66b376265e16c32a0aae9\"\\n]\\n}\\n}\\n]\\nThe trimmed output shows the five layers. However, it shows their SHA256 hashes,\\nwhich are different from the short IDs shown in the docker pull output.\\nThe docker inspect command is great for getting detailed image information.\\nYou can also use the docker history command to inspect an image and see its layer\\ndata. However, this command shows the build history of an image and is not a strict list'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 62}, page_content='6: Working with Images\\n56\\nof layers in the final image. For example, some Dockerfile instructions (ENV, EXPOSE, CMD,\\nand ENTRYPOINT) only add metadata and don’t create layers.\\nBase layers\\nAll Docker images start with a base layer, and every time you add new content, Docker\\nadds a new layer.\\nConsider the following oversimplified example of building a simple Python application.\\nYour corporate policy mandates all applications be built on top of the official Ubuntu\\n24:04 image. This means the official Ubuntu 24:04 image will be the base layer for this\\napp. Installing your company’s approved version of Python will add a second layer, and\\nyour application source code will add a third. The final image will have three layers, as\\nshown in Figure 6.8. Remember, this is an oversimplified example for demonstration\\npurposes.\\nFigure 6.8\\nIt’s important to understand that an image is the combination of all layers stacked in the\\norder they were built. Figure 6.9 shows an image with two layers. Each layer has three\\nfiles, meaning the image has six files.\\nIt also shows that the layers are stored as independent objects, and the image is just\\nmetadata identifying the required layers and explaining how to stack them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 63}, page_content='6: Working with Images\\n57\\nFigure 6.9\\nIn the slightly more complex example of the three-layer image in Figure 6.10, the overall\\nimage only presents six files in the unified view. This is because File 7 in the top layer\\nis an updated version of File 5 directly below (inline). In this situation, the file in the\\nhigher layer obscures the file directly below it. This means you update files and make\\nother changes to images by adding new layers containing the changes.\\nFigure 6.10 - Stacking layers\\nUnder the hood, Docker uses storage drivers to stack layers and present them as a\\nunified filesystem and image. Almost all Docker setups use the overlay2 driver, but zfs,\\nbtrfs, and vfs are alternative options. However, whichever storage driver you use, the\\ndeveloper and user experience are always the same.\\nFigure 6.11 shows how the three-layer image from Figure 6.10 will appear on the system\\n— all three layers stacked and merged into a single unified view.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 64}, page_content='6: Working with Images\\n58\\nFigure 6.11 - Unified view of multi-layer image\\nSharing image layers\\nAs previously mentioned, images can share layers, leading to efficiencies in space and\\nperformance.\\nOne of the earlier docker pull commands generated an Already exists message for one\\nof the layers it pulled. This occurred because one of my Docker Desktop extensions had\\nalready pulled an image that used the exact same layer. As a result, Docker skipped that\\nlayer as it already had a local copy.\\nHere’s the code from earlier, and Figure 6.12 shows two images sharing the same layer.\\n$ docker pull redis:latest\\nlatest: Pulling from library/redis\\n25d3892798f8: Download complete\\ne5d458cf0bea: Download complete\\n4f4fb700ef54: Already exists\\n<<---- This line\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 65}, page_content='6: Working with Images\\n59\\nFigure 6.12 - Two images sharing a layer\\nLayers are also shared on the registry side. This means you can store lots of similar\\nimages in a registry, and the registry will save space by never storing more than a single\\ncopy of any layer.\\nPulling images by digest\\nSo far, you’ve seen how to pull and work with images using names (tags). While this\\nis the most common method, it has a problem — tags are arbitrary and mutable. This\\nmeans it’s possible to tag an image incorrectly or give a new image the same tag as an\\nolder one. An extremely common example is the latest tag. For example, pulling the\\nalpine:latest tag a year ago will not pull the same image as pulling the same tag today.\\nConsider a quick example outlining one potential implication of trusting mutable tags.\\nImagine you have an image called golftrack:1.5 and you get a warning that it has a\\ncritical vulnerability. You build a new image containing the fix and push the new image\\nto the same repository with the same tag.\\nTake a moment to consider what just happened and the implications.\\nYou have an image called golftrack:1.5 that’s being used by lots of containers in your\\nproduction environment, and it has a critical bug. You create a new version containing\\nthe fix. So far, so good, but then you make the mistake. You push the new image to\\nthe same repository with the same tag as the vulnerable image. This overwrites the\\noriginal image and leaves you without a great way of knowing which of your production'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 66}, page_content='6: Working with Images\\n60\\ncontainers are using the vulnerable image and which are using the fixed image — both\\nimages have the same tag!\\nThis is where image digests come to the rescue.\\nDocker uses a content addressable storage model where every image gets a cryptographic\\ncontent hash that we usually call the digest. As these are hashes of an image’s contents,\\nit’s impossible for two different images to have the same digest. It’s also impossible to\\nchange an image without creating a new digest. Fortunately, Docker lets you work with\\nimage digests instead of just names.\\nIf you’ve already pulled an image by name, you can see its digest by running a docker\\nimages command with the --digests flag as shown.\\n$ docker images --digests alpine\\nREPOSITORY\\nTAG\\nDIGEST\\nIMAGE ID\\nCREATED\\nSIZE\\nalpine\\nlatest\\nsha256:c5b1261d...8e1ad6b\\nc5b1261d6d3e\\n2 weeks ago\\n11.8MB\\nIf you want to find an image’s digest before pulling it, you can use the docker buildx\\nimagetools command. The following example retrieves the image digest for the\\nnigelpoulton/k8sbook/latest image on Docker Hub.\\n$ docker buildx imagetools inspect nigelpoulton/k8sbook:latest\\nName:\\ndocker.io/nigelpoulton/k8sbook:latest\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\\nDigest:\\nsha256:13dd59a0c74e9a147800039b1ff4d61201375c008b96a29c5bd17244bce2e14b\\n<Snip>\\nYou can now use the digest to pull the image. I’ve trimmed the command and the output\\nfor readability.\\n$ docker pull nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b\\ndocker.io/nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b: Pulling from nigelpoulton/k8sbook\\n59f1664fb787: Download complete\\na052f1888b3e: Download complete\\n94a9f4dfa0e5: Download complete\\nbb7e600677fa: Download complete\\nedfb0c26f1fb: Download complete\\n5b1423465504: Download complete\\n2f232a362cd9: Download complete\\nDigest: sha256:13dd59a0...bce2e14b\\nStatus: Downloaded newer image for nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b\\ndocker.io/nigelpoulton/k8sbook:latest@sha256:13dd59a0...bce2e14b\\nIt’s also possible to directly query the registry API for image data, including digest. The\\nfollowing curl command queries Docker Hub for the digest of the same image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 67}, page_content='6: Working with Images\\n61\\n$ curl \"https://hub.docker.com/v2/repositories/nigelpoulton/k8sbook/tags/?name=latest\" \\\\\\n|jq \\'.results[].digest\\'\\n\"sha256:13dd59a0c74e9a147800039b1ff4d61201375c008b96a29c5bd17244bce2e14b\"\\nImage hashes and layer hashes\\nYou already know that images are just a loose collection of independent layers. This\\nmeans an image is just a manifest file with some metadata and a list of layers. The actual\\napplication and all its dependencies live in the layers that are fully independent and have\\nno concept of being part of an image.\\nWith this in mind, images and layers have their own digests as follows:\\n• Images digests are a crypto hash of the image’s manifest file\\n• Layer digests are a crypto hash of the layer’s contents\\nThis means all changes to layers or image manifests result in new hashes, giving us an\\neasy and reliable way to know if changes have been made.\\nContent hashes vs distribution hashes\\nDocker compares hashes before and after every push and pull to ensure no tampering\\noccurs while data is crossing the network. However, it also compresses images during\\npush and pull operations to save network bandwidth and storage space on the registry.\\nAs a result of this compression, the before and after hashes won’t match.\\nTo get around this, each layer gets two hashes:\\n• Content hash (uncompressed)\\n• Distribution hash (compressed)\\nEvery time Docker pushes or pulls a layer from a registry, it includes the layer’s distri-\\nbution hash and uses this to verify no tampering occurred. This is one reason why the\\nhashes in different CLI and registry outputs don’t always match — sometimes you’re\\nlooking at the content hash, and other times you’re looking at the distribution hash.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 68}, page_content='6: Working with Images\\n62\\nMulti-architecture images\\nOne of the best things about Docker is its simplicity. However, as technologies grow,\\nthey inevitably get more complex. This happened for Docker when it started supporting\\ndifferent platforms and architectures, such as Windows and Linux on variations of\\nARM, x64, PowerPC, s390x and more. Suddenly, there were multiple versions of\\nthe same image for all the different architectures, and developers and users had to\\nput in significant extra work to get the right version. This broke the smooth Docker\\nexperience.\\nMulti-architecture images to the rescue!\\nFortunately, Docker and the registry API adapted and became clever enough to hide\\nimages for multiple architectures behind a single tag. This means you can do a docker\\npull alpine on any architecture and get the correct version of the image. For example,\\nif you’re on an AMD64 machine, you’ll get the AMD64 image.\\nTo make this happen, the Registry API supports two important constructs:\\n• Manifest lists\\n• Manifests\\nThe manifest list is exactly what it sounds like — a list of architectures supported by an\\nimage tag. Each supported architecture then has its own manifest that lists the layers\\nused to build it.\\nRun the following command to see the different architectures supported behind the\\nalpine:latest tag.\\n$ docker buildx imagetools inspect alpine\\nName:\\ndocker.io/library/alpine:latest\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\\nDigest:\\nsha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nManifests:\\nName:\\ndocker.io/library/alpine:latest@sha256:6457d53f...628977d0\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/amd64\\nName:\\ndocker.io/library/alpine:latest@sha256:b229a851...d144c1d8\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm/v6\\nName:\\ndocker.io/library/alpine:latest@sha256:ec299a7b...33b4c6fe\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm/v7'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 69}, page_content='6: Working with Images\\n63\\nName:\\ndocker.io/library/alpine:latest@sha256:a0264d60...93467a46\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm64/v8\\nName:\\ndocker.io/library/alpine:latest@sha256:15c46ced...ab073171\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/386\\nName:\\ndocker.io/library/alpine:latest@sha256:b12b826d...ba52a3a2\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/ppc64le\\nYour output may include additional annotations, but if you look closely, you’ll see a\\nsingle manifest list pointing to six manifests.\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json is the\\nmanifest list.\\nEach MediaType: application/vnd.docker.distribution.manifest.v2+json line\\nrefers to a manifest for each specific architecture.\\nFigure 6.13 shows how manifest lists and manifests are related. On the left, you can see\\na manifest list with entries for the different architectures supported by the image. The\\narrows show that each entry in the manifest list points to a manifest defining the image\\nconfig and the list of layers making up the image for that architecture.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 70}, page_content='6: Working with Images\\n64\\nFigure 6.13 - Manifest lists and manifests\\nLet’s step through a quick example.\\nAssume you’re using Docker Desktop on an M4 Mac where Docker runs inside a\\nlinux/arm VM. You ask Docker to pull an image, and Docker makes the relevant calls to\\nthe Registry API to request the appropriate manifest list. Assuming it exists, Docker then\\nparses it for a linux/arm entry. If linux/arm entry exists, Docker retrieves its manifest,\\nparses it for the crypto IDs of its layers, pulls each layer, and assembles them into the\\nimage.\\nLet’s see it in action.\\nThe following examples are from Docker Desktop on an ARM-based Mac and Docker\\nDesktop on an AMD-based Windows machine running in Windows containers mode.\\nBoth start a new container based the official golang image and execute the go version\\ncommand. The outputs show the version of Go and the host’s platform and CPU\\narchitecture. Notice how both commands are exactly the same, and Docker takes care\\nof pulling the correct image.\\nBoth images are large and may take a while to download. You do not need to complete\\nthese commands yourself.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 71}, page_content='6: Working with Images\\n65\\nLinux on arm64 example:\\n$ docker run --rm golang go version\\n<Snip>\\ngo version go1.23.4 linux/arm64\\nWindows on x64 example:\\n> docker run --rm golang go version\\n<Snip>\\ngo version go1.23.4 windows/amd64\\nYou’ve already seen how to use the docker buildx imagetools command to see the\\nmanifest list and manifests for an image. You can get similar information from the\\ndocker manifest command. The following example inspects the manifest list for\\nthe official golang image on Docker Hub. You can see it has images for Linux and\\nWindows on a variety of CPU architectures. You can run the same command without\\nthe grep filter to see the full JSON manifest list. Windows users should replace the grep\\ncommand with Select-String architecture,os\\n$ docker manifest inspect golang | grep \\'architecture\\\\|os\\'\\n\"architecture\": \"amd64\",\\n\"os\": \"linux\"\\n\"architecture\": \"arm\",\\n\"os\": \"linux\",\\n\"architecture\": \"arm64\",\\n\"os\": \"linux\",\\n\"architecture\": \"386\",\\n\"os\": \"linux\"\\n\"architecture\": \"mips64le\",\\n\"os\": \"linux\"\\n\"architecture\": \"ppc64le\",\\n\"os\": \"linux\"\\n\"architecture\": \"s390x\",\\n\"os\": \"linux\"\\n\"architecture\": \"amd64\",\\n\"os\": \"windows\",\\n\"os.version\": \"10.0.20348.2227\"\\n\"architecture\": \"amd64\",\\n\"os\": \"windows\",\\n\"os.version\": \"10.0.17763.5329\"\\nPulling the right image for your system is one thing, but what about building images for\\nall these different architectures?\\nThe docker buildx command makes it easy to create multi-architecture images. For\\nexample, you can use Docker Desktop on linux/arm to build images for linux/amd'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 72}, page_content='6: Working with Images\\n66\\nand possibly other architectures. We’ll perform builds like these in future chapters, but\\ndocker buildx offers two ways to create multi-architecture images:\\n• Emulation\\n• Build Cloud\\nEmulation mode performs builds for different architectures on your local machine by\\nrunning the build inside a QEMU virtual machine emulating the target architecture. It\\nworks most of the time but is slow and doesn’t have a shared cache.\\nBuild Cloud is a service from Docker, Inc. that performs builds in the cloud on native\\nhardware without requiring emulation. It’s very fast, lets you share a common build\\ncache with teammates, and is seamlessly integrated into Docker Desktop and any\\nversion of the Docker Engine using a version of buildx supporting the cloud driver.\\nIt also integrates with GitHub actions and other CI solutions. At the time of writing,\\nDocker Build Cloud is a subscription service you have to pay for.\\nWe’ll use both in future chapters, but I ran the following command to build AMD and\\nARM versions of the nigelpoulton/tu-demo image using Docker Build Cloud.\\n$ docker buildx build \\\\\\n--builder=cloud-nigelpoulton-ddd-cloud \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/tu-demo:latest --push .\\nVulnerability scanning with Docker Scout\\nLots of tools and plugins exist that scan images for known vulnerabilities.\\nWe’ll look at Docker Scout, as it’s built into almost every level of Docker, including the\\nCLI, Docker Desktop, Docker Hub, and the scout.docker.com portal. It’s a very slick\\nservice, but it requires a paid subscription. Other similar products and services exist, but\\nmost require paid subscriptions.\\nRecent versions of Docker Desktop have the Scout CLI plugin pre-installed and ready\\nto go. If you’re running a different version of Docker, you may be able to install the CLI\\nplugin from the GitHub repo14.\\nYou can use the docker scout quickview command to get a quick vulnerability\\noverview of an image. The following command analyses the nigelpoulton/tu-\\ndemo:latest image. If a local copy doesn’t exist, it pulls it from Docker Hub and\\nperforms the analysis locally.\\n14https://github.com/docker/scout-cli'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 73}, page_content='6: Working with Images\\n67\\n$ docker scout quickview nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\n│\\n0C\\n1H\\n1M\\n0L\\ndigest\\n│\\nb4210d0aa52f\\n│\\nBase image\\n│\\npython:3-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\nUpdated base image │\\npython:3.11-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\n│\\n│\\nThe output shows zero critical vulnerabilities (0C), one high (1H), one medium (1M),\\nand zero low (0L).\\nYou can use the docker scout cves command to get more detailed information,\\nincluding remediation advice.\\n$ docker scout cves nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\n\\uffffDetected 1 vulnerable package with 2 vulnerabilities\\n## Overview\\n│\\nAnalyzed Image\\n────────────────────┼────────────────────────────────\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64/v8\\nvulnerabilities │\\n0C\\n1H\\n1M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2\\npkg:apk/alpine/expat@2.5.0-r2?os_name=alpine&os_version=3.19\\n\\uffffHIGH CVE-2023-52425\\nhttps://scout.docker.com/v/CVE-2023-52425\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n<Snip>\\nI’ve snipped the output so it only shows the critical and high vulnerabilities, but several\\nthings are clear:\\n• It has detected one vulnerable package containing two vulnerabilities\\n• The affected package is called expat and the vulnerable version we’re running is\\n2.5.0-r2\\n• It lists the vulnerability as CVE-2023-52425'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 74}, page_content='6: Working with Images\\n68\\n• It includes a link to a Scout report containing more info\\n• It suggests we update to version 2.6.0-r0 which contains the fix\\nFigure 6.14 shows how this looks in Docker Desktop, and you get similar integrations\\nand views in Docker Hub.\\nFigure 6.14 - Docker Scout integration with Docker Desktop\\nThe scout.docker.com portal provides an overview dashboard, allows you to configure\\npolicies, and lets you set up integrations with Docker Hub and other registries to\\nremotely scan and monitor multiple repositories.\\nDeleting Images\\nYou can delete images using the docker rmi command. rmi is short for remove image.\\nDeleting images removes them from your local repository and they’ll no longer show up\\nin your docker images commands. The operation also deletes all directories on your\\nlocal filesystem containing layer data. However, Docker won’t delete layers shared by\\nmultiple images until you delete all images that reference them.\\nYou can delete images by name, short ID, or SHA. You can also delete multiple images\\nwith the same command.\\nThe following command deletes three images — one by name, one by short ID, and one\\nby SHA. I’ve trimmed the output for easier reading.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 75}, page_content='6: Working with Images\\n69\\n$ docker rmi redis:latest af111729d35a sha256:c5b1261d...f8e1ad6b\\nUntagged: redis:latest\\nDeleted: sha256:76d5908f5e19fcdd73daf956a38826f790336ee4707d9028f32b24ad9ac72c08\\nUntagged: nigelpoulton/tu-demo:v2\\nDeleted: sha256:af111729d35a09fd24c25607ec045184bb8d76e37714dfc2d9e55d13b3ebbc67\\nUntagged: alpine:latest\\nDeleted: sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nDocker will prevent the delete operation if the image is being used by a container or\\nreferenced by more than one tag. However, you can force the operation with the -f\\nflag, but you should do so with caution, as forcing Docker to delete an image in use by\\na container will untag the image and leave it on the system as a dangling image.\\nA handy way to delete all images is to pass a list of all local image IDs to the docker rmi\\ncommand. You should use this command with caution, and if you’re following along on\\nWindows, it will only work in a PowerShell terminal.\\n$ docker rmi $(docker images -q) -f\\nTo understand how this works, download a couple of images and then run docker\\nimages -q.\\n$ docker pull alpine\\n<Snip>\\n$ docker pull ubuntu\\n<Snip>\\n$ docker images -q\\n44dd6f223004\\n3f5ef9003cef\\nSee how the docker images -q returns a list of local image IDs. Passing this list to\\ndocker rmi will delete all images on the system as shown next.\\n$ docker rmi $(docker images -q) -f\\nUntagged: alpine:latest\\nUntagged: alpine@sha256:02bb6f428431fb...a33cb1af4444c9b11\\nDeleted: sha256:44dd6f2230041...09399391535c0c0183b\\nDeleted: sha256:94dd7d531fa56...97252ba88da87169c3f\\nUntagged: ubuntu:latest\\nUntagged: ubuntu@sha256:dfd64a3b4296d8...9ee20739e8eb54fbf\\nDeleted: sha256:3f5ef9003cefb...79cb530c29298550b92\\nDeleted: sha256:b49483f6a0e69...f3075564c10349774c3\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nLet’s remind ourselves of some of the commands we’ve used.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 76}, page_content='6: Working with Images\\n70\\nImages – The commands\\n• docker pull is the command to download images from remote registries. It\\ndefaults to Docker Hub but works with other registries. The following command\\nwill pull the image tagged as latest from the alpine repository on Docker Hub:\\ndocker pull alpine:latest.\\n• docker images lists all the images in your Docker host’s local repository (image\\ncache). You can add the --digests flag to see the SHA256 hashes.\\n• docker inspect gives you a wealth of image-related metadata in a nicely format-\\nted view.\\n• docker manifest inspect lets you inspect the manifest list of images stored\\nin registries. The following command will show the manifest list for the regctl\\nimage on GitHub Container Registry (GHCR): docker manifest inspect\\nghcr.io/regclient/regctl.\\n• docker buildx is a Docker CLI plugin that works with Docker’s latest build\\nengine features. You saw how to use the imagetools sub-command to query\\nmanifest-related data from images.\\n• docker scout is a Docker CLI plugin that integrates with the Docker Scout\\nbackend to perform image vulnerability scanning. It scans images, provides\\nreports on vulnerabilities, and even suggests remediation actions.\\n• docker rmi is the command to delete images. It deletes all layer data stored in the\\nlocal filesystem, and you cannot delete images that are in use by containers.\\nChapter summary\\nThis chapter taught you the important theory and fundamentals of images.\\nYou learned that images contain everything needed to run an application as a container.\\nThis includes just enough OS, source code, dependencies, and metadata.\\nYou can start one or more containers from a single image.\\nUnder the hood, Docker constructs images by stacking one or more read-only layers\\nand presenting them as a unified object. Every image has a manifest that lists the layers\\nthat make up the image and how to stack them.\\nYou learned that image names are also called tags, they’re mutable, and they don’t always\\npull the same image. For example, pulling the alpine:latest tag today will not pull\\nthe same image as it will a year from now. Fortunately, every image gets an immutable\\ndigest that you can use to guarantee you always pull the intended image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 77}, page_content='6: Working with Images\\n71\\nDocker Hub has the notion of curated official images that should be safer to use than\\nunofficial images. However, you should always exercise caution when downloading\\nsoftware from the internet, even official images from Docker Hub.\\nImages can share layers for efficiency, and Docker makes it easy to build and pull images\\nfor lots of different CPU architectures, such as ARM and AMD.\\nDocker Scout scans images for known vulnerabilities and provides remediation advice.\\nIt requires a Docker subscription and is integrated into the docker CLI, Docker Hub,\\nand Docker Desktop.\\nIn the next chapter, we’ll take a similar tour of containers — the run-time sibling of\\nimages.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 78}, page_content='7: Working with containers\\nDocker implements the Open Container Initiative (OCI) specifications. This means\\nsome of the things you’ll learn in this chapter will apply to other container runtimes and\\nplatforms that implement the OCI specifications.\\nI’ve divided the chapter into the following sections:\\n• Container – The TLDR\\n• Containers vs VMs\\n• Images and containers\\n• Check Docker is running\\n• Starting a container\\n• How containers start apps\\n• Connecting to a running container\\n• Inspecting container processes\\n• The docker inspect command\\n• Writing data to a container\\n• Stopping, restarting, and deleting a container\\n• Killing a container’s main process\\n• Debugging slim images and containers with Docker Debug\\n• Self-healing containers with restart policies\\n• The commands\\nContainers – The TLDR\\nContainers are run-time instances of images, and you can start one or more containers\\nfrom a single image.\\nFigure 7.1 shows multiple containers started from a single image. The shared image is\\nread-only, but you can write to the containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 79}, page_content='7: Working with containers\\n73\\nFigure 7.1\\nYou can start, stop, restart, and delete containers just like you can with VMs. However,\\ncontainers are smaller, faster, and more portable than VMs. They’re also designed to\\nbe stateless and ephemeral, whereas VMs are designed to be long-running and can be\\nmigrated with their state and data.\\nContainers are also designed to be immutable. This means you shouldn’t change them\\nafter you’ve deployed them — if a container fails, you replace it with a new one instead\\nof connecting to it and making a live fix.\\nContainers should only run a single process and we use them to build microservices\\napps. For example, an application with four features, such as a web server, auth, catalog,\\nand store, will have four containers — one running the web server, one running the auth\\nservice, one running the catalog, and another running the store.\\nContainers vs VMs\\nContainers and VMs are both virtualization technologies for running applications. They\\nboth work on your laptop, bare metal servers, in the cloud, and more. However, the\\nways they virtualize are very different:\\n• VMs virtualize hardware\\n• Containers virtualize operating systems\\nIn the VM model, you power on a server and a hypervisor boots. When the hypervisor\\nboots, it claims all hardware resources such as CPU, RAM, storage, and network\\nadapters. To deploy an app, you ask the hypervisor to create a virtual machine. It does\\nthis by carving up the hardware resources into virtual versions, such as virtual CPUs\\nand Virtual RAM, and packaging them into a VM that looks exactly like a physical\\nserver. Once you have the VM, you install an OS and then an app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 80}, page_content='7: Working with containers\\n74\\nIn the container model, you power on the same server and an OS boots and claims all\\nhardware resources. You then install a container runtime such as Docker. To deploy\\nan app, you ask Docker to create a container. It does this by carving up OS resources\\nsuch as process trees and filesystems into virtual versions and then packaging them as a\\ncontainer that looks exactly like a regular OS. You then tell Docker to run the app inside\\nthe container.\\nFigure 7.2 shows the two models side by side and attempts to demonstrate the more\\nefficient nature of containers with the same server running 3x more containers than\\nVMs.\\nFigure 7.2\\nIn summary, hypervisors perform hardware virtualization where they divide hardware\\nresources into virtual versions and package them as VMs. Container runtimes perform\\nOS virtualization where they divide OS resources into virtual versions and package them\\nas containers. VMs look and feel exactly like physical servers. Containers look and feel\\nexactly like regular operating systems.\\nThe VM tax\\nOne of the biggest problems with the virtual machine model is that you need to\\ninstall an OS on every VM — every OS consumes CPU, RAM, and storage and takes a\\nrelatively long time to boot.\\nContainers get around all of this by sharing a single OS on the host they’re running on.\\nThis gives containers all of the following benefits over VMs:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 81}, page_content='7: Working with containers\\n75\\n• Containers are smaller and more portable\\n• You can run more containers on your infrastructure\\n• Containers start faster\\n• Containers reduce the number of operating systems you need to manage (patch,\\nupdate, etc.)\\n• Containers present a smaller attack surface\\nLet’s briefly expand on each point.\\nContainers are smaller than VMs because they only contain application code and a\\nminimal set of OS-related constructs such as essential filesystem objects. Because of this,\\nthey’re typically only a few megabytes in size. On the other hand, every VM needs a full\\nOS, meaning they’re usually hundreds or thousands of megabytes.\\nBecause containers don’t contain their own OS, you can run a lot more containers\\nthan VMs. For example, deploying 100 applications as VMs will require 100 operating\\nsystems, each consuming CPU, memory, and storage, and each needing to be patched\\nand managed. However, deploying the same 100 applications as containers requires no\\nadditional operating systems. This drastically reduces your OS management overhead\\nand allows you to allocate more system resources to applications instead of operating\\nsystems.\\nContainers also start faster than VMs because they use the host’s OS which is already\\nbooted. On the other hand, VMs need to go through a full OS bootstrapping process\\nbefore starting the app.\\nOne of the early concerns about containers centered around the shared kernel model\\nwhere all containers on the same host share the host’s kernel. While this offers perfor-\\nmance and portability benefits, it’s less secure than the VM model where every VM has\\nits own dedicated kernel. For example, a rogue container that exploits a vulnerability\\nin the host’s kernel might be able to impact every other container on the same host.\\nFortunately, this is much less of a concern now that container platforms have matured\\nand ship with class-leading tools that can make them more secure than non-container\\nplatforms. For example, most container engines and platforms implement sensible\\ndefaults for security-related technologies such as SELinux, AppArmor, seccomp, capabilities,\\nand more. You can even configure these to make containers more secure than VMs.\\nOther technologies, such as image vulnerability scanning, give you more control over\\nthe security of your software than you ever had before.\\nAt the time of writing, containers are the go-to solution for the vast majority of new\\napplications.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 82}, page_content='7: Working with containers\\n76\\nPre-reqs\\nYou’ll need a working Docker environment to follow along with the examples, and I\\nrecommend Docker Desktop. Other Docker setups should work, but you may have\\nto manually install the Docker Debug plugin if you want to follow along with those\\nexamples.\\nImages and Containers\\nAs previously mentioned, you can start multiple containers from a single image. The\\nimage is read-only in this relationship, but each container is read-write. As shown\\nin Figure 7.3, Docker accomplishes this by creating a thin read-write layer for each\\ncontainer and placing it on top of the shared image.\\nFigure 7.3 - Container R/W layers\\nIn this example, each container has its own thin R/W layer but shares the same image.\\nThe containers can see and access the files and apps in the image through their own R/W\\nlayer, and if they make any changes, these get written to their R/W layer. When you stop\\na container, Docker keeps the R/W layer and restores it when you restart the container.\\nHowever, when you delete a container, Docker deletes its R/W layer. This way, each\\ncontainer can make and keep its own changes without requiring write access to the\\nshared image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 83}, page_content='7: Working with containers\\n77\\nCheck Docker is running\\nRun a docker version to check Docker is running. It’s a good command because it\\nchecks the CLI and engine components.\\n$ docker version\\nClient:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49\\nOS/Arch:\\ndarwin/arm64\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nOS/Arch:\\nlinux/arm64\\n<Snip>\\nAs long as you get a response from the Client and Server, you’re good to go and can\\nskip to the next section.\\nIf you get an error code in the Server section, this usually means your Docker daemon\\n(server) isn’t running or your user account doesn’t have permission to access it. If\\nyou’re running on Linux, you’ll need to ensure your user account is a member of the\\nlocal docker Unix group. If it isn’t, you can add it by running usermod -aG docker\\n<username> and restarting your shell. Alternatively, you can prefix all docker commands\\nwith sudo.\\nYour account needs to be a member of the docker group so it can access the API, which\\nis exposed on a privileged local Unix socket at /var/run/docker.sock. It’s also possible\\nto expose the API over the network.\\nIf your user account is already a member of the local docker group and you still get an\\nerror from the daemon, there’s a good chance the Docker daemon isn’t running. Run\\none of the following commands to check the status of the daemon.\\nLinux systems not using Systemd.\\n$ service docker status\\ndocker start/running, process 29393\\nLinux systems using Systemd.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 84}, page_content=\"7: Working with containers\\n78\\n$ systemctl is-active docker\\nactive\\nIf the daemon isn’t running, start it with the appropriate command for your system.\\nStarting a container\\nThe docker run command is the simplest and most common way to start a new\\ncontainer.\\nRun the following command to start a new container called webserver.\\n$ docker run -d --name webserver -p 5005:8080 nigelpoulton/ddd-book:web0.1\\nUnable to find image 'nigelpoulton/ddd-book:web0.1' locally\\nweb0.1: Pulling from nigelpoulton/ddd-book\\n4f4fb700ef54: Already exists\\ncf2a607f33f7: Download complete\\n0a1f0c111e9a: Download complete\\nc1af4b5db242: Download complete\\nDigest: sha256:3f5b281b914b1e39df8a1fbc189270a5672ff9e98bfac03193b42d1c02c43ef0\\nStatus: Downloaded newer image for nigelpoulton/ddd-book:web0.1\\nb5594b3b8b3fdce544d2ca048e4340d176bce9f5dc430812a20f1852c395e96b\\nLet’s take a closer look at the command and the output.\\ndocker run tells Docker to run a new container\\nThe -d flag tells Docker to run it in the background as a daemon process and detached\\nfrom your local terminal\\nThe name flag tells Docker to name this container webserver.\\nThe -p 5005:8080 flag maps port 5005 on your local system to port 8080 inside the\\ncontainer. This works because the container’s web server is listening on port 8080.\\nThe nigelpoulton/ddd-book:web0.1 argument tells Docker which image to use to start\\nthe container.\\nWhen you hit Return, the Docker client converted the command into an API request\\nand posted it to the Docker API exposed by the Docker daemon. The Docker daemon\\naccepted the command and searched its local image repository for a copy of the\\nnigelpoulton/ddd-book:web0.1 image. It didn’t find one, so it searched Docker Hub.\\nIn the example, it found one on Docker Hub and pulled a local copy.\\nOnce it had a local copy of the image, the daemon made a request to containerd asking\\nfor a new container. containerd then instructed runc to create the container and start\\nthe app. It also performed the port mapping.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 85}, page_content='7: Working with containers\\n79\\nRun the following commands to verify Docker pulled the image and started the\\nwebserver container.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nweb0.1\\n3f5b281b914b\\n12 minutes ago\\n159MB\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\nb5594b3b8b3f\\nnigelpoulton...\\n\"node ./app.js\"\\nUp 2 mins\\n0.0.0.0:80->8080/tcp\\nwebserver\\nYou can also test the app by connecting a browser to port 5005 on your Docker host.\\nIf you’re using Docker Desktop, point your browser to localhost:5005. If you’re not\\nrunning Docker Desktop, you may need to substitute localhost with the name or IP of\\nthe host Docker is running on.\\nFigure 7.4 - Web app running in container\\nCongratulations. Docker pulled a local copy of the image and started a container\\nrunning the app shown in the image.\\nHow containers start apps\\nIn the previous section, you created a container running a web app. But how did the\\ncontainer know to start a web app?\\nThere are three ways you can tell Docker how to start an app in a container:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 86}, page_content='7: Working with containers\\n80\\n1. An Entrypoint instruction in the image\\n2. A Cmd instruction in the image\\n3. A CLI argument\\nYou’ll learn more about these in the next chapter, but the Entrypoint and Cmd instruc-\\ntions are optional image metadata where you can store the command you want Docker\\nto run to start the default app. Then, whenever you start a container from the image,\\nDocker checks the Entrypoint or Cmd instruction and executes the stored command.\\nEntrypoint instructions cannot be overridden on the CLI, and anything you pass in via\\nthe CLI will be appended to the Entrypoint instruction as an argument.\\nCmd instructions are overridden by CLI arguments.\\nRun the following command to see if the nigelpoulton/ddd-book:web0.1 image has\\nan Entrypoint instruction. The command searches the image metadata and returns any\\nlines containing the word “Entrypoint” as well as the three lines immediately following it.\\nWindows users will need to replace the grep command with Select-String -Pattern\\n\\'Entrypoint\\' -Context 0,3.\\n$ docker inspect nigelpoulton/ddd-book:web0.1 | grep Entrypoint -A 3\\n<Snip>\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"\\n],\\nThis image has an Entrypoint instruction that translates into the following command\\n— node ./app.js. If you’re not familiar with Node.js, it’s a simple command telling the\\nNode.js runtime to execute the code in the app.js file.\\nIf an image doesn’t have an Entrypoint instruction, you can search for the presence of a\\nCmd instruction.\\nIf an image doesn’t have either, you’ll need to pass an argument on the CLI.\\nThe format of the docker run command is:\\ndocker run <arguments> <image> <command>\\nAs mentioned, the <command> is optional; you don’t need it if the image has a Cmd or\\nEntrypoint instruction. If you specify a <command>, it will override a Cmd instruction\\nbut will be appended to an Entrypoint instruction.\\nThe following command starts a new background container based on the Alpine image\\nand tells it to run the sleep 60 command, causing it to run for 60 seconds and then exit.\\nThe --rm flag cleans up the exited container so you don’t have to delete it manually.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 87}, page_content='7: Working with containers\\n81\\n$ docker run --rm -d alpine sleep 60\\nIf you run a docker ps command before the 60-second sleep timer expires, you’ll see\\nthe container in the output. If you run it after 60 seconds, the container will be gone.\\nThe --rm argument automatically cleans up the exited container.\\nMost production images will specify an Entrypoint or Cmd instruction.\\nConnecting to a running container\\nYou can use the docker exec command to execute commands in running containers,\\nand it has two modes:\\n• Interactive\\n• Remote execution\\nInteractive exec sessions connect your terminal to a shell process in the container and\\nbehave like remote SSH sessions. Remote execution mode lets you send commands to a\\nrunning container and prints the output to your local terminal.\\nRun the following command to start an interactive exec session by creating a new\\nshell process (sh) inside the webserver container that is already running. The -it flag\\nmakes it an interactive exec session, and the sh argument starts a new sh process inside the\\ncontainer. sh is a minimal shell program installed in the container.\\n$ docker exec -it webserver sh\\n/src #\\nNotice how your shell prompt changed. This proves your terminal is connected to the\\nshell process inside the container.\\nTry executing a few common Linux commands. Some will work, and some won’t. This\\nis because container images are usually optimized to be lightweight and don’t have all of\\nthe normal commands and packages installed. The following example shows a couple of\\ncommands — one succeeds, and the other one fails.\\nThe examples list the contents of your current directory and try to edit the app.js file\\nwith the vim editor.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 88}, page_content='7: Working with containers\\n82\\n/src # ls -l\\ntotal 100\\n-rw-r--r--\\n1 root\\nroot\\n324 Feb 20 12:35 Dockerfile\\n-rw-r--r--\\n1 root\\nroot\\n377 Feb 20 12:35 README.md\\n-rw-r--r--\\n1 root\\nroot\\n341 Feb 20 12:35 app.js\\ndrwxr-xr-x\\n183 root\\nroot\\n4096 Feb 20 12:41 node_modules\\n-rw-r--r--\\n1 root\\nroot\\n74342 Feb 20 12:41 package-lock.json\\n-rw-r--r--\\n1 root\\nroot\\n404 Feb 20 12:38 package.json\\ndrwxr-xr-x\\n2 root\\nroot\\n4096 Feb 20 12:35 views\\n<Snip>\\n/src # vim app.js\\nsh: vim: not found\\nThe vim command fails because it isn’t installed in the container.\\nInspecting container processes\\nMost containers only run a single process. This is the container’s main app process and\\nis always PID 1.\\nRun a ps command to see the processes running in your container. You’ll need to be\\nconnected to the exec session from the previous section for these commands to work.\\n/src # ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n13 root\\n0:00 sh\\n22 root\\n0:00 ps\\nThe output shows three processes:\\n• PID 1 is the main application process running the Node.js web app\\n• PID 13 is the shell process your interactive exec session is connected to\\n• PID 22 is the ps command you just ran\\nThe ps process terminated as soon as it displayed the output, and the sh process will\\nterminate when you exit the exec session. This means the only long-running process is\\nPID 1 running the Node app.\\nIf you kill the container’s main process (PID 1), you’ll also kill the container. This is\\nbecause containers only run while their main process is executing — when that process\\nis no longer running, there’s no reason for the container to run. We’ll demonstrate this\\nlater.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 89}, page_content='7: Working with containers\\n83\\nType exit to quit the exec session and return to your local terminal.\\nRun another docker exec command without specifying the -it flags. This will\\nremotely execute the command without creating an interactive session. The format of\\nthe command is docker exec <container> <command>, and it will only work if the\\ncontainer has the command you’re trying to execute.\\n$ docker exec webserver ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n42 root\\n0:00 ps\\nThis time, only two processes are running because you terminated the sh process when\\nyou typed exit to quit the previous interactive exec session.\\nThe docker inspect command\\nYou’ll love the docker inspect command as it’s a treasure trove of detailed information\\nabout images and containers.\\nThe following command retrieves full details of the running webserver container, and\\nI’ve snipped the output to highlight a few interesting things. However, I recommend\\nrunning the command on your system and studying the output.\\n$ docker inspect webserver\\n<Snip>\\n\"State\": {\\n\"Status\": \"running\"\\n},\\n\"Name\": \"/webserver\",\\n\"PortBindings\": {\\n\"8080/tcp\": [\\n{\\n\"HostIp\": \"\",\\n\"HostPort\": \"5005\"\\n}\\n]\\n},\\n\"RestartPolicy\": {\\n\"Name\": \"no\",\\n\"MaximumRetryCount\": 0\\n\"Image\": \"nigelpoulton/ddd-book:web0.1\",\\n\"WorkingDir\": \"/src\",\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 90}, page_content='7: Working with containers\\n84\\n],\\n}\\n<Snip>\\nThe snipped output shows the container is running, is called webserver, is binding port\\n8080 in the container to 5005 on the host, has no restart policy, and is based on the\\nnigelpoulton/ddd-book:web0.1 image. The Entrypoint block lists the command that\\nautomatically runs every time the container starts.\\nWe’ll cover this in more detail later, but this container inherited its Entrypoint instruc-\\ntion from the image you started it from. You can verify this by running the following\\ndocker inspect command against the image. I’ve snipped the output to highlight the\\nrelevant section.\\n$ docker inspect nigelpoulton/ddd-book:web0.1\\n<Snip>\\n\"Config\": {\\n\"WorkingDir\": \"/src\",\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"\\n],\\n<Snip>\\nI recommend you take time to investigate the output of docker inspect commands.\\nYou’ll learn a lot.\\nWriting data to a container\\nIn this section, you’ll exec onto the webserver container and edit the web server\\nconfiguration to display a new message on the home page. In the next section, you’ll\\nstop and restart the container and verify your changes aren’t lost.\\nWARNING: This section is for demonstration purposes only. In the real\\nworld, you shouldn’t change live containers like this. Any time you need to\\nchange a live container, you should create and test a new container with the\\nrequired changes and then replace the existing container with the new one.\\nOpen a new interactive exec session to the webserver container with the following\\ncommand.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 91}, page_content='7: Working with containers\\n85\\n$ docker exec -it webserver sh\\n/src #\\nThe container runs a simple Node.js web app that uses the views/home.pug file to build\\nthe app’s home page.\\nRun the following command to open the home.pug file in the vi editor. Windows users\\ncan use Notepad or another editor.\\n/src # vi views/home.pug\\nIf you know how to use vi, you can go ahead and change the text on line 8 after the h1\\ntag to anything you like and save your changes.\\nCarefully follow these steps if you’re not familiar with vi:\\n1. Press the i key to put vi into insert mode\\n2. Use the arrow keys to navigate to line 8\\n3. Use your delete key to delete the text after the h1 tag on line 8\\n4. Type a new message of your choice\\n5. Press the escape key to exit insert mode and return to command mode\\n6. type :wq and press enter save your changes and exit (:wq is short for write and\\nquit)\\nOnce you’ve saved your changes, refresh your browser to see the updates.\\nType exit to quit the exec session and return to your local terminal.\\nCongratulations, you’ve updated the web server config.\\nStopping, restarting, and deleting a container\\nIn this section, you’ll execute the typical container lifecycle events and see how they\\nimpact the changes you’ve made to the container.\\nThe following commands will only work if you’ve quit the interactive exec session.\\nCheck your container is still running.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 92}, page_content='7: Working with containers\\n86\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\nb5594b3b8b3f\\nnigelpoulton...\\n\"node ./app.js\"\\nUp 51 mins\\n0.0.0.0:80->8080\\nwebserver\\nStop it with the docker stop command. It will take up to 10 seconds to gracefully stop.\\n$ docker stop webserver\\nwebserver\\nRun another docker ps command.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nThe container no longer shows in the list of running containers. However, you can see it\\nif you run the same command with the -a flag to show all containers, including stopped\\nones.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nb5594b3b8b3f\\nnigelpou...\\n\"node ./app.js\"\\nExited (137) About a minute ago\\nwebserver\\nAs you can see in the output, it still exists but is in the Exited state. Restart it with the\\nfollowing command.\\n$ docker restart webserver\\nwebserver\\nIf you run another docker ps, you’ll see it in the Up state.\\nRefresh your browser to see if Docker has saved your changes to the home page or\\nreverted to the original.\\nDocker has saved your changes!\\nYou can also run the following command to return the contents of the file directly from\\nthe container’s filesystem.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 93}, page_content=\"7: Working with containers\\n87\\n$ docker exec webserver cat views/home.pug\\nhtml\\nhead\\ntitle='Docker FTW'\\nlink(rel='stylesheet', href='https://stackpath.bootstrapcdn.com/....\\nbody\\ndiv.container\\ndiv.jumbotron\\nh1 Everybody loves containers!\\n<<---- I changed this line\\n<Snip>\\nSo far, you’ve seen that starting and stopping containers doesn’t lose changes. You also\\nsaw that restarting them is very fast.\\nRun the following command to delete the container. The -f flag forces the operation\\nand doesn’t allow the app the usual 10-second grace period to flush buffers and grace-\\nfully quit. Be careful forcing operations like this, as Docker doesn’t ask you to confirm.\\n$ docker rm webserver -f\\nwebserver\\nRun a docker ps -a to see if there’s any sign of the container.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nAll signs of the container are gone and you cannot restart it. You can start a new\\ninstance by executing another docker run command and specifying the same image,\\nbut it won’t have the changes you made.\\nWARNING: As previously mentioned, changing live containers like this is an\\nanti-pattern and you shouldn’t do it. We only showed it here to demonstrate\\nhow containers work and how changes to the container’s filesystem (made\\nto the container’s own thin R/W layer) persist across restarts. An anti-pattern\\nis something that works but isn’t a good practice as it can have unintended\\nconsequences.\\nKilling a container’s main process\\nEarlier in the chapter, we learned that containers are designed to run a single process,\\nand we said that killing this process also kills the container.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 94}, page_content='7: Working with containers\\n88\\nLet’s test if that’s true.\\nRun the following command to start a new interactive container called ddd-ctr based on\\nthe Ubuntu image and tell it to run a Bash shell as its main process.\\n$ docker run --name ddd-ctr -it ubuntu:24.04 bash\\nUnable to find image \\'ubuntu:24.04\\' locally\\n24.04: Pulling from library/ubuntu\\n51ae9e2de052: Download complete\\nDigest: sha256:ff0b5139e774bb0dee9ca8b572b4d69eaec2795deb8dc47c8c829becd67de41e\\nStatus: Downloaded newer image for ubuntu:24.04\\nroot@d3c892ad0eb3:/#\\nThe command pulls the Ubuntu image and attaches your terminal to the container’s\\nBash shell process.\\nRun a ps command to list all running processes.\\nroot@d3c892ad0eb3:/# ps\\nPID TTY\\nTIME CMD\\n1 pts/0\\n00:00:00 bash\\n9 pts/0\\n00:00:00 ps\\nPID 1 is the container’s main process and is the Bash shell you told the container to run.\\nThe other one is the ps command and has already exited. This means the Bash process is\\nthe only process running in the container.\\nIf you type exit, you’ll terminate the Bash process and kill the container. This is because\\ncontainers only run while their main process executes.\\nTest this by typing exit to return to your local terminal and then running a docker ps\\n-a command to see if the container terminated.\\nroot@d3c892ad0eb3:/# exit\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nd3c892ad0eb3\\nubuntu:24.04\\n\"bash\"\\nExited (0) 3 secs ago\\nddd-ctr\\nAs expected, the container is in the exited state and not running. However, you can run\\nthe following two commands to restart it and attach your shell to its main process.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 95}, page_content='7: Working with containers\\n89\\n$ docker restart ddd-ctr\\nddd-ctr\\n$ docker attach ddd-ctr\\nroot@d3c892ad0eb3:/#\\nYour terminal is once again attached to the Bash shell in the container.\\nYou can type Ctrl PQ to exit a container without killing the process you’re attached to.\\nType Ctrl PQ to exit the container and run another docker ps command to verify the\\ncontainer is still running this time.\\nroot@d3c892ad0eb3:/# <Ctrl PQ>\\nread escape sequence\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nd3c892ad0eb3\\nubuntu:24.04\\n\"bash\"\\nUp 27 seconds\\nddd-ctr\\nThe container is still up.\\nNow that you know how to exit containers without killing them, let’s switch focus and\\nsee how to use Docker Debug to debug slim containers and images.\\nDebugging slim images and containers with Docker\\nDebug\\nAt the time of writing, Docker Debug is only included as part of Docker Desktop and\\nrequires a Pro, Team, or Business subscription.\\nIt’s a widely accepted good practice to deploy slim images that only contain app code and\\ndependencies. This means no shell or debugging tools and is a big part of making images\\nand containers small and secure. However, it also makes it difficult to debug them when\\nthings go wrong.\\nThis is where Docker Debug comes to the rescue by allowing you to get shell access\\nto images and containers that don’t include a shell and seamlessly inject powerful\\ndebugging tools into them.\\nAt a high level, Docker Debug works by attaching a shell to a container and mounting a\\ntoolbox loaded with debugging tools. This toolbox is mounted as a directory called /nix\\nand is available during your debugging session but is never visible to the container. As\\nsoon as you exit the Docker Debug session, the /nix directory is removed. If you’re\\ndebugging a running container, any changes you make are immediately visible to the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 96}, page_content='7: Working with containers\\n90\\ncontainer and persist across container restarts. For example, updating an index.html\\nduring a Docker Debug session will immediately update the running web app, and the\\nchanges will persist if the container is stopped and restarted. If you’re debugging an\\nimage or stopped container, the Docker Debug session creates a debug sandbox and\\nadds it to the image as a R/W layer to make it feel like a running container. However,\\nchanges you make while debugging an image or stopped container are not persisted and\\nare lost as soon as you quit the debug session.\\nIf you’ve been following along, you’ll have a running container called ddd-ctr. If you\\ndon’t, you can start one by running docker run --name ddd-ctr -it ubuntu:24.04\\nbash.\\nRun the following commands to attach to the container and see if it has any debugging\\ntools. The following docker attach command is similar to the docker exec commands\\nyou learned earlier but automatically connects to a container’s main process. You don’t\\nneed to run the docker attach command if you’re already connected to the container.\\n$ docker attach ddd-ctr\\nroot@d3c892ad0eb3:/#\\nroot@d3c892ad0eb3:/# ping nigelpoulton.com\\nbash: ping: command not found\\nroot@d3c892ad0eb3:/# nslookup nigelpoulton.com\\nbash: nslookup: command not found\\nroot@d3c892ad0eb3:/# vim\\nbash: vim: command not found\\nThe commands all failed because none of the tools are installed in this container. This\\nwould make debugging this container difficult without Docker Debug.\\nType Ctrl PQ to gracefully disconnect from the container without killing the Bash\\nprocess.\\nIn the following steps, you’ll use Docker Debug to get a shell session to the container\\nand run commands that aren’t installed in the container. You can even use Docker\\nDebug to get shell access to containers and images that don’t include a shell.\\nYou need to log in to Docker to use Docker Debug, and it only works if you have a Pro,\\nTeam, or Business license.\\n$ docker login\\nAuthenticating with existing credentials...\\nLogin Succeeded\\nRun the following command to check if you have the Docker Debug CLI plugin. All\\nmodern versions of Docker Desktop include this by default. Other Docker installations\\nmay not have it, but you may be able to install it manually.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 97}, page_content='7: Working with containers\\n91\\n$ docker info\\nClient:\\nVersion:\\n26.1.1\\nContext:\\ndesktop-linux\\nDebug Mode: false\\nPlugins:\\ndebug: Get a shell into any image or container. (Docker Inc.)\\nVersion:\\n0.0.29\\nPath:\\n/Users/nigelpoulton/.docker/cli-plugins/docker-debug\\n<Snip>\\nOnce you’re logged in and have the plugin installed, you’re ready to continue.\\nThe format of the command is docker debug <image>|<container>. We’ll open a\\nDocker Debug session to the running container called ddd-ctr.\\n$ docker debug ddd-ctr\\nThis is an attach shell, i.e.:\\n- Any changes to the container filesystem are visible to the container directly.\\n- The /nix directory is invisible to the actual container.\\nVersion: 0.0.37 (BETA)\\nroot@d3c892ad0eb3 / [ddd-ctr]\\ndocker >\\nYou’ve successfully connected to the running container and got a new shell prompt\\n(docker >). You also got some helpful info displaying the short ID and name of the\\ncontainer you’re debugging, as well as a reminder that any changes you make will be\\nvisible to the container.\\nTry running the ping, nslookup, and vim commands that failed in the previous section.\\nIf you get stuck in the vim session, just type :q and press Enter.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 98}, page_content=\"7: Working with containers\\n92\\ndocker > ping nigelpoulton.com\\nPING nigelpoulton.com (192.124.249.126) 56(84) bytes of data.\\n64 bytes from cloudproxy10126.sucuri.net (192.124.249.126): icmp_seq=1 ttl=63 time=211 ms\\n64 bytes from cloudproxy10126.sucuri.net (192.124.249.126): icmp_seq=2 ttl=63 time=58.3 ms\\n^C\\ndocker > nslookup nigelpoulton.com\\nzsh: command not found: nslookup\\ndocker > vim\\n~\\nVIM\\n- Vi IMproved\\n~\\nversion 9.0.1441\\n~\\nby Bram Moolenaar et al.\\n~\\nVim is open source and freely distributable\\n<Snip>\\n:q\\nThe ping and vim commands worked, but the nslookup still failed. This is because the\\ndefault Docker Debug toolbox includes ping and vim but doesn’t include nslookup. Don’t\\nworry, though. You can use Docker Debug’s built-in install command to add any\\npackage listed on search.nixos.org.\\nRun the following command to install the bind package (which includes the nslookup\\ntool), and then run the nslookup command again.\\ndocker > install bind\\nTip: You can install any package available at: https://search.nixos.org/packages.\\ninstalling 'bind-9.18.19'\\n<Snip>\\ndocker > nslookup nigelpoulton.com\\nServer:\\n192.168.65.7\\nAddress:\\n192.168.65.7#53\\nNon-authoritative answer:\\nName:\\nnigelpoulton.com\\nAddress:\\n192.124.249.126\\nThe command worked, and nslookup is now installed in your toolbox and will be\\navailable in future Docker Debug sessions.\\nCongratulations, you’ve used Docker Debug to attach to a running container and run\\ntroubleshooting commands that aren’t part of the container. You’ve also seen how to\\ninstall additional tools to your Docker Debug toolbox. Remember, any changes you\\nmake to running containers are immediately visible to the container and persist after\\nyou close the session.\\nType exit to terminate the debug session and return to your local shell.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 99}, page_content='7: Working with containers\\n93\\nRun the following command to create a new Docker Debug session that debugs the\\nnigelpoulton/ddd-book:web0.1 image. Docker will automatically pull the image from\\nDocker Hub if you don’t have a local copy.\\n$ docker debug nigelpoulton/ddd-book:web0.1\\nNote: This is a sandbox shell. All changes will not affect the actual image.\\nVersion: 0.0.37 (BETA)\\nroot@3f5b281b914b /src [nigelpoulton/ddd-book:web0.1]\\ndocker >\\nNotice the different message this time. Debugging images creates a sandbox shell and\\nchanges won’t affect the actual image. This reminds you that debugging images and\\nstopped containers behaves differently from debugging running containers:\\n• Changes made while debugging a live container are persisted\\n• Changes made while debugging images or stopped containers are deleted when\\nyou quit the debug session\\nRun an nslookup command to prove the tool is saved to your toolbox and available for\\nuse without re-installing.\\ndocker > nslookup craigalanson.com\\nServer:\\n192.168.65.7\\nAddress:\\n192.168.65.7#53\\nNon-authoritative answer:\\nName:\\ncraigalanson.com\\nAddress:\\n198.185.159.144\\n<Snip>\\nDocker Debug has a built-in entrypoint command that lets you print, lint, and test an\\nimage or container’s Entrypoint or Cmd command. These are the commands Docker\\nexecutes to start the container’s app.\\nRun the following entrypoint command to reveal the default command this container\\nwill run when it starts.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 100}, page_content='7: Working with containers\\n94\\ndocker > entrypoint --print\\nnode ./app.js\\nThe entrypoint command is clever enough to look for Entrypoint and Cmd instruc-\\ntions.\\nType exit to quit the debug session.\\nIn summary, Docker Debug is a fantastic tool for debugging slim images and containers.\\nIt gets you shell access to containers and images that don’t include a shell, and you can\\nrun troubleshooting tools that aren’t available in the container or image. Any changes\\nyou make to running containers take immediate effect and persist across stop and restart\\noperations. However, changes made while debugging images and stopped containers are\\nlost when you close the session. In all cases, the tools you install and use are never part\\nof the container or image.\\nSelf-healing containers with restart policies\\nContainer restart policies are a simple form of self-healing that allows the local Docker\\nEngine to automatically restart failed containers.\\nYou apply restart policies per container, and Docker supports the following four policies:\\n• no (default)\\n• on-failure\\n• always\\n• unless-stopped\\nThe following table shows how each policy reacts to different scenarios. A Y indicates\\nthe policy will attempt a container restart, whereas an N indicates it won’t.\\nRestart\\nRestart\\nNon-zero\\nZero\\ndocker stop\\nwhen Daemon\\npolicy\\nexit code\\nexit code\\ncommand\\nrestarts\\nno\\nN\\nN\\nN\\nN\\non-failure\\nY\\nN\\nN\\nY\\nalways\\nY\\nY\\nN\\nY\\nunless-stopped\\nY\\nY\\nN\\nN\\nNon-zero exit codes indicate a failure occurred. Zero exit codes indicate the container\\nexited normally without an error.\\nWe’ll demo some examples, but you should also do your own testing.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 101}, page_content='7: Working with containers\\n95\\nLet’s demonstrate the always policy by starting a new interactive container with the --\\nrestart always flag and telling it to run a shell process. We’ll then type exit to kill the\\nshell process and the container to see what happens.\\nRun the following command to start an interactive container called neversaydie with\\nthe always restart policy.\\n$ docker run --name neversaydie -it --restart always alpine sh\\n/#\\nYour terminal will automatically connect to the shell process inside the container.\\nType exit to kill the shell process and return to your local terminal. This will cause the\\ncontainer to exit with a zero exit code, indicating a normal exit without any failures.\\nAccording to the previous table, the always restart policy should automatically restart\\nthe container.\\nRun a docker ps command to see if this happened.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\n1933623830bb\\nalpine\\n\"sh\"\\n35 seconds ago\\nUp 2 seconds\\nneversaydie\\nThe container is running as expected. However, you can see it was created 35 seconds\\nago but has only been running for 2 seconds. This is because you forced it to exit\\nwhen you killed the shell process, and then Docker automatically restarted it. It’s also\\nimportant to know that Docker restarted the same container and didn’t create a new\\none. In fact, if you run a docker inspect against it, you’ll see the RestartCount has\\nbeen incremented to 1. Remember to replace grep with Select-String -Pattern\\n\\'RestartCount\\' if you’re on Windows using PowerShell.\\n$ docker inspect neversaydie | grep RestartCount\\n\"RestartCount\": 1,\\nAn interesting feature of the --restart always policy is that if you stop a container\\nwith docker stop and then restart the Docker daemon, Docker will restart the con-\\ntainer when the daemon comes up. To be clear:\\n1. You start a new container with the --restart always policy\\n2. You manually stop it with the docker stop command\\n3. You restart Docker (or an event causes Docker to restart)\\n4. When Docker comes back up, it starts the stopped container\\nIf you don’t want this behavior, you should try the unless-stopped policy.\\nIf you are working with Docker Compose or Docker Stacks, you can apply restart\\npolicies to services as follows. We’ll cover these in more detail in later chapters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 102}, page_content='7: Working with containers\\n96\\nservices:\\nmyservice:\\n<Snip>\\nrestart_policy:\\ncondition: always | unless-stopped | on-failure\\nClean up\\nYou can run docker images and docker ps -a commands to see the images you pulled\\nand the containers you created as part of this chapter. Your output will be similar to this.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nweb0.1\\n3f5b281b914b\\n4 days ago\\n159MB\\nubuntu\\n24.04\\nff0b5139e774\\n13 days ago\\n138MB\\nalpine\\nlatest\\nc5b1261d6d3e\\n4 weeks ago\\n11.8MB\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\nac165419214f\\nalpine\\n\"sh\"\\n33 secs ago\\nUp 24 seconds\\nneversaydie\\n5bd3741185fa\\nubuntu:24.04\\n\"bash\"\\n3 mins ago\\nExited (0) ~1min ago\\nddd-ctr\\nYou can delete individual containers with the docker rm <container> -f command\\nand images with the docker rmi command, and you should always delete containers\\nbefore images.\\nYou can also delete all containers and all images with the following two commands. Be\\nwarned though, Docker will not prompt you for confirmation.\\n$ docker rm $(docker ps -aq) -f\\nac165419214f\\n5bd3741185fa\\n$ docker rmi $(docker images -q)\\nUntagged: nigelpoulton/ddd-book:web0.1\\nDeleted: sha256:3f5b281b914b1e39df8a1fbc189270a5672ff9e98bfac03193b42d1c02c43ef0\\nUntagged: ubuntu:24.04\\nDeleted: sha256:ff0b5139e774bb0dee9ca8b572b4d69eaec2795deb8dc47c8c829becd67de41e\\nUntagged: alpine:latest\\nDeleted: sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nBoth commands work by passing a list of all container/image IDs to the delete com-\\nmand.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 103}, page_content='7: Working with containers\\n97\\nContainers – The commands\\n• docker run is the command to start new containers. You give it the name of an\\nimage and it starts a container from it. This example starts an interactive container\\nfrom the Ubuntu image and tells it to run the Bash shell: docker run -it ubuntu\\nbash.\\n• Ctrl-PQ is how you detach from a container without killing the process you’re\\nattached to. You’ll use it frequently to detach from running containers without\\nkilling them.\\n• docker ps lists all running containers, and you can add the -a flag to also see\\ncontainers in the stopped (Exited) state.\\n• docker exec allows you to run commands inside containers. The following\\ncommand will start a new Bash shell inside a running container and connect\\nyour terminal to it: docker exec -it <container-name> bash. This next\\ncommand runs a ps command inside a running container without opening an\\ninteractive shell session: docker exec <container-name> ps. For these to work,\\nthe container must include the Bash shell.\\n• docker stop stops a running container and puts it in the Exited (137) state. It\\nissues a SIGTERM to the container’s PID 1 process and allows the container 10\\nseconds to gracefully quit. If the process hasn’t cleaned up and stopped within 10\\nseconds, it sends a SIGKILL to force the container to terminate immediately.\\n• docker restart restarts a stopped container.\\n• docker rm deletes a stopped container. You can add the -f flag to delete the\\ncontainer without having to stop it first.\\n• docker inspect shows you detailed configuration and run-time information\\nabout a container.\\n• docker debug attaches a debug shell to a container or image and lets you run\\ncommands that aren’t available inside the container or image. It requires a Pro,\\nTeam, or Business Docker subscription.\\nChapter summary\\nIn this chapter, you learned some of the major differences between VMs and containers,\\nincluding that containers are smaller, faster, and more portable.\\nYou learned how to start, stop, and restart containers with the docker CLI, and you saw\\nthat changes to a container’s filesystem persist across restarts.\\nYou learned that containers run a single process and terminate if this process is killed.\\nYou also saw the three ways of telling a container which app to run and how to start it —\\nvia Entrypoint or Cmd instructions in the image metadata or via the docker run CLI.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 104}, page_content='7: Working with containers\\n98\\nYou learned about Docker Debug and how it allows you to get a shell to slim containers\\nand run troubleshooting commands that don’t exist in the container.\\nFinally, you learned how to attach restart policies to containers and how the different\\nrestart policies work.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 105}, page_content='8: Containerizing an app\\nDocker makes it easy to package applications as images and run them as containers.\\nWe call this process containerization, and this chapter will walk you through the entire\\nprocess.\\nI’ve divided the chapter as follows:\\n• Containerizing an app – The TLDR\\n• Containerize a single-container app\\n• Moving to production with multi-stage-builds\\n• Buildx, BuildKit, drivers, and Build Cloud\\n• Multi-architecture builds\\n• A few good practices\\nContainerizing an app – The TLDR\\nDocker aims to make it easy to build, share, and run applications. We call this containeriza-\\ntion and the process looks like this:\\n1. Write your applications and create the list of dependencies\\n2. Create a Dockerfile that tells Docker how to build and run the app\\n3. Build the app into an image\\n4. Push the image to a registry (optional)\\n5. Run a container from the image\\nYou can see these five steps in Figure 8.1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 106}, page_content='8: Containerizing an app\\n100\\nFigure 8.1 - Basic flow of containerizing an app\\nContainerize a single-container app\\nIn this section, you’ll complete the following steps to containerize a simple Node.js app:\\n• Get the application code from GitHub\\n• Create the Dockerfile\\n• Containerize the app\\n• Run the app\\n• Test the app\\n• Look a bit closer\\nI recommend you follow along with Docker Desktop. This is because we’ll be using\\nthe new docker init command, which might not be installed on other versions of\\nDocker. Don’t worry if your Docker installation doesn’t have docker init, we include\\ninstructions for you as well.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 107}, page_content=\"8: Containerizing an app\\n101\\nGet the application code\\nThe application we’ll use is a Node.js web app that serves a web page on port 8080.\\nYou’ll need a copy of the book’s GitHub repo containing the application code. If you\\ndon’t already have it, run the following command to get it. You’ll need git installed, and\\nthe command will create a new directory called ddd-book.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nCloning into 'ddd-book'...\\nremote: Enumerating objects: 47, done.\\nremote: Counting objects: 100% (47/47), done.\\nremote: Compressing objects: 100% (32/32), done.\\nremote: Total 47 (delta 11), reused 44 (delta 11), pack-reused 0\\nReceiving objects: 100% (47/47), 167.30 KiB | 1.66 MiB/s, done.\\nResolving deltas: 100% (11/11), done.\\nChange into the ddd-book/node-app directory and list its contents.\\n$ cd ddd-book/node-app\\n$ ls -l\\ntotal 98\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n341 20 Feb 12:35 app.js\\ndrwxr-xr-x\\n103 nigelpoulton\\nstaff\\n3296 12 Mar 16:18 node_modules\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n39975 12 Mar 16:18 package-lock.json\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n355\\n8 Mar 10:10 package.json\\ndrwxr-xr-x\\n3 nigelpoulton\\nstaff\\n96 20 Feb 12:35 views\\nThis directory is your build context because it contains the application source code and\\nthe files listing dependencies.\\nFor Docker to containerize it, it needs a Dockerfile with build instructions. Let’s create it.\\nCreate the Dockerfile\\nIn the past, you had to create Dockerfiles manually. Fortunately, newer versions of\\nDocker support the docker init command that reads your build context, analyzes your\\napplication, and automatically creates a Dockerfile implementing good practices.\\nRun the following command to create a Dockerfile for the app. If your Docker installa-\\ntion doesn’t have the docker init plugin, you’ll have to skip this step.\\nFeel free to accept a newer version of Node.js, but complete all other prompts as shown.\\nYou’ll need to run it from the node-app directory.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 108}, page_content='8: Containerizing an app\\n102\\n$ docker init\\nWelcome to the Docker Init CLI!\\n<Snip>\\n? What application platform does your project use? Node\\n? What version of Node do you want to use? 23.3.0\\n<<---- Newer versions are OK\\n? Which package manager do you want to use? npm\\n? What command do you want to use to start the app? node app.js\\n? What port does your server listen on? 8080\\nCREATED: .dockerignore\\nCREATED: Dockerfile\\nCREATED: compose.yaml\\nCREATED: README.Docker.md\\n\\uffffYour Docker files are ready!\\nThe process created a new Dockerfile and placed it in your current directory. It looks\\nlike this.\\n1. ARG NODE_VERSION=20.8.0\\n2. FROM node:${NODE_VERSION}-alpine\\n3. ENV NODE_ENV production\\n4. WORKDIR /usr/src/app\\n5. RUN --mount=type=bind,source=package.json,target=package.json \\\\\\n--mount=type=bind,source=package-lock.json,target=package-lock.json \\\\\\n--mount=type=cache,target=/root/.npm \\\\\\nnpm ci --omit=dev\\n6. USER node\\n7. COPY . .\\n8. EXPOSE 8080\\n9. CMD node app.js\\nLines 1 and 2 tell Docker to pull the node:23.3.0-alpine image and use it as the base\\nfor the new image.\\nLine 3 tells Node to run in production mode. This is a Node.js optimization that increases\\nperformance while minimizing logging and other common development features.\\nLine 4 sets the working directory for the remaining steps. For example, the RUN and COPY\\ninstructions on lines 5 and 7 will run against the WORKDIR directory, as will the node\\napp.js command on line 9.\\nLine 5 bind mounts the dependency files and installs them with the npm ci --omit-dev\\ncommand.\\nLine 6 ensures Node.js runs the app as a non-root user.\\nLine 7 copies the application’s source code from your build context (the first period)\\ninto the WORKDIR directory (the second period) inside the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 109}, page_content='8: Containerizing an app\\n103\\nLine 8 documents the application’s network port.\\nLine 9 is the command Docker will execute whenever it starts a container from the\\nimage.\\nYou now have everything Docker needs to build the application into a container image\\n— source code, dependencies, and a Dockerfile.\\nContainerize the app\\nIn this section, you’ll build the application into a container image.\\nIf your Docker installation doesn’t have the docker init plugin and you didn’t follow\\nthe previous step, you’ll need to rename the sample-Dockerfile to Dockerfile before\\ncontinuing.\\nRun the following command to build a new image called ddd-book:ch8.node. Be sure to\\ninclude the trailing period (.) as this tells Docker to use your current working directory\\nas the build context. Remember, the build context is the directory where your app files live.\\n$ docker build -t ddd-book:ch8.node .\\n[+] Building 16.2s (12/12) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n=> => transferring dockerfile: 1.21kB\\n0.0s\\n=> => transferring context: 659B\\n0.0s\\n=> [stage-0 1/4] FROM docker.io/library/node:20.8.0-alpine\\n3s\\n<<---- Base layer\\n=> [stage-0 2/4] WORKDIR /usr/src/app\\n0.2s\\n<<---- New layer\\n=> [stage-0 3/4] RUN --mount=type=bind,source=package...\\n1.1s\\n<<---- New layer\\n=> [stage-0 4/4] COPY . .\\n0.1s\\n<<---- New layer\\n=> exporting to image\\n0.2s\\n=> => exporting layers\\n0.2s\\n=> => writing image sha256:f282569b8bd0f0...016cc1adafc91\\n0.0s\\n=> => naming to docker.io/library/ddd-book:ch8.node\\nI’ve snipped the output, but you can see four numbered steps creating four image layers.\\nThese map to the instructions in the Dockerfile.\\nCheck the image exists in your Docker host’s local repository.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nddd-book\\nch8.node\\n24dd040fa06b\\n18 minutes ago\\n242MB\\nCongratulations, you’ve containerized the app as an OCI image!\\nRun a docker inspect ddd-book:ch8.node command to verify the image and see the\\nsettings from the Dockerfile. You should be able to see the image layers and metadata\\nsuch as the Exposed Ports, WorkingDir, and Entrypoint values.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 110}, page_content='8: Containerizing an app\\n104\\n$ docker inspect ddd-book:ch8.node\\n[\\n{\\n\"Id\": \"sha256:24dd040fa06baf6e40144c5a59f99a749159a932ecebb737751f7f862963527a\",\\n\"RepoTags\": [\\n\"ddd-book:ch8.node\"\\n<Snip>\\n\"ExposedPorts\": {\\n\"8080/tcp\": {}\\n\"WorkingDir\": \"/usr/src/app\",\\n\"Cmd\": [\\n\"/bin/sh\",\\n\"-c\",\\n\"node app.js\"\\n],\\n<Snip>\\n\"Layers\": [\\n\"sha256:5f4d9fc4d98de91820d2a9c81e501c8cc6429bc8758b43fcb2cd50f4cab9a324\",\\n\"sha256:6b20c4e93dbab9786f96268bbe32c208d385f2c4490a278ad3b1e55cc79480e4\",\\n\"sha256:012c308a78ec993a47fdb7c4c6d17b53d8ce2649a463be28ae5c48ab1af2e039\",\\n\"sha256:35a839ac7cc922afd896a0297e692141c77ed6e03eff6a70db13bb23f6cd4f8f\",\\n\"sha256:918caa8070410ccfb2c5b3b4d62ca66742c46bf21fe0bd433738b7796c530e68\",\\n\"sha256:a48b3b3d0c5a693840e7e4abd7971f130b4447573483628bcb996091e1e8e8b8\",\\n\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n<Snip>\\nYou might wonder why the image has seven layers when only four Dockerfile instruc-\\ntions created layers. This is because the node:20.8.0-alpine base image already had\\nfour layers. Therefore, the FROM instruction pulled a base image with four layers, and\\nthen the WORKDIR, RUN and COPY instructions added three more layers. You can see this\\nin Figure 8.2.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 111}, page_content='8: Containerizing an app\\n105\\nFigure 8.2 - Dockerfile and image layers\\nPush the image to Docker Hub\\nThis is an optional section, and you’ll need a Docker Hub account to follow along. Go to\\nhub.docker.com and sign up for a free one now.\\nYou’ll complete the following steps:\\n1. Login to Docker Hub\\n2. Re-tag the image\\n3. Push the image\\nAfter creating images, you’ll normally push them to a registry where you can keep them\\nsafe and make them accessible to teammates and clients. Lots of registries exist, but\\nDocker Hub is the most common public registry and is where Docker pushes images\\nby default.\\nLog in to Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 112}, page_content=\"8: Containerizing an app\\n106\\n$ docker login\\nUSING WEB-BASED LOGIN\\nTo sign in with credentials on the command line, use 'docker login -u <username>'\\nYour one-time device confirmation code is: PNXK-SGJG\\nPress ENTER to open your browser or submit your device code here: https://login.docker.com/activate\\nLogin Succeeded\\nOnce logged in, you need to re-tag the image. This is because Docker uses the image tag\\nto determine which registry and repository to push it to.\\nIf you run a docker images command, you’ll see an image tagged as ddd-book:ch8.node.\\nIf you push this image, Docker will try to push it to a repository called ddd-book on\\nDocker Hub. However, no such repository exists, and the command will fail.\\nRun the following command to re-tag the image to include your Docker ID. The format\\nof the command is docker tag <current-tag> <new-tag>, and it creates an additional\\ntag for the same image.\\n$ docker tag ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\\nRun another docker images command to see the image with both tags. Notice how\\neverything is identical except the REPO column. This is because it’s the same image with\\ndifferent names.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nch8.node\\n24dd040fa06b\\n38 minutes ago\\n268MB\\nddd-book\\nch8.node\\n24dd040fa06b\\n38 minutes ago\\n268MB\\nPush it to Docker Hub. You’ll need to be logged in with your Docker ID for this to work,\\nand you’ll need to use your Docker ID instead of mine.\\n$ docker push nigelpoulton/ddd-book:ch8.node\\nThe push refers to repository [docker.io/nigelpoulton/ddd-book]\\ne4ef261755c8: Pushed\\nd25f74b85615: Pushed\\n7e1aebde141d: Pushed\\n7b3f8039e3c4: Pushed\\n2a2799ae89a2: Mounted from library/node\\n4927cb899c33: Mounted from library/node\\n579b34f0a95b: Pushed\\nced319b3ffb5: Pushed\\nch8.node: digest: sha256:24dd040fa06baf...1f7f862963527a size: 856\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 113}, page_content='8: Containerizing an app\\n107\\nFigure 8.3 shows how Docker figured out where to push the image.\\nFigure 8.3\\nNow that you’ve pushed the image to a registry, you can access it from anywhere with\\nan internet connection. You can also grant other people access to pull it and push\\nchanges.\\nRun the app\\nAs previously mentioned, the application is a web server listening on port 8080.\\nRun the following command to start it as a container. You’ll have to delete the\\nnigelpoulton image prefix or replace it with your ID.\\n$ docker run -d --name c1 \\\\\\n-p 5005:8080 \\\\\\nnigelpoulton/ddd-book:ch8.node\\nThe -d flag runs the container in the background, and the --name flag calls it c1. The\\n-p 5005:8080 maps port 5005 on your Docker host to port 8080 inside the container,\\nwhich means you’ll be able to point a browser to port 5005 and reach the app. The last\\nline tells Docker to base the container on the nigelpoulton/ddd-book:ch8.node image\\nyou just built.\\nDocker will use the local copy of the image from the previous steps. It only pulls a copy\\nfrom Docker Hub if it doesn’t have a local copy.\\nCheck the container is running and verify the port mapping.\\n$ docker ps\\nID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\n49..\\nddd-book:ch8.node\\n\"node ./app.js\"\\nUP 6 secs\\n0.0.0.0:5005->8080/tcp\\nc1\\nI’ve snipped the output for readability, but the container is running, and port 5005 on\\nthe Docker host maps to port 8080 in the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 114}, page_content='8: Containerizing an app\\n108\\nTest the app\\nOpen a web browser and point it to the DNS name or IP address of your Docker host\\non port 5005. If you’re using Docker Desktop or a similar local environment, you can\\nconnect to localhost:5005. Otherwise, use the IP or DNS of the Docker host on port\\n5005.\\nYou should see the app as shown in Figure 8.4.\\nFigure 8.4\\nYou can try the following if it doesn’t work:\\n1. Run a docker ps command to ensure the c1 container is running\\n2. Check port mapping is correct — 0.0.0.0:5005->8080/tcp\\n3. Check that firewall and other network security settings aren’t blocking traffic to\\nyour Docker host on port 5005\\nCongratulations, the application is containerized and running as a container!\\nLooking a bit closer\\nNow that you’ve containerized the application let’s take a closer look at how some of the\\nmachinery works.\\nThe docker build command parses the Dockerfile one line at a time, starting from the\\ntop.\\nYou can insert comments by starting a line with the # character, and the builder will\\nignore them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 115}, page_content='8: Containerizing an app\\n109\\nAll non-comment lines are called instructions or steps and take the format <INSTRUCTION>\\n<arguments>. Instruction names are not case-sensitive, but it’s common to write them in\\nUPPERCASE to make the file easier to read.\\nSome instructions create new layers, whereas others add metadata.\\nExamples of instructions that create new layers are FROM, RUN, COPY and WORKDIR.\\nExamples that create metadata include EXPOSE, ENV, CMD, and ENTRYPOINT. The premise\\nis this:\\n• Instructions that add content, such as files and programs, create new layers\\n• Instructions that don’t add content don’t add layers and only create metadata\\nYou can run a docker history command against any image to see the instructions that\\ncreated it.\\n$ docker history ddd-book:ch8.node\\nIMAGE\\nCREATED BY\\nSIZE\\nCOMMENT\\n24dd...a06b\\nCMD [\"/bin/sh\" \"-c\" \"node app.js\"]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nEXPOSE map[8080/tcp:{}]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nCOPY . . # buildkit\\n98kB\\nbuildkit.dockerfile.v0\\n<missing>\\nUSER node\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nRUN /bin/sh -c npm ci --omit=dev # buildkit\\n13.6MB\\nbuildkit.dockerfile.v0\\n<missing>\\nWORKDIR /usr/src/app\\n16.4kB\\nbuildkit.dockerfile.v0\\n<missing>\\nENV NODE_ENV=production\\n0B\\nbuildkit.dockerfile.v0\\n<Snip>\\n<missing>\\nADD alpine-minirootfs-3.21.0-aarch64.tar.gz\\n8.84MB\\n8.35MB\\nA few things are worth noting from the output.\\nThe bottom few lines that I’ve snipped from the book related to the history of the\\nnode:23.3.0-alpine base image that was pulled by the FROM instruction.\\nAll lines ending with buildkit.dockerfile.v0 relate to instructions from the Docker-\\nfile used to build the image.\\nThe CREATED BY column lists the exact Dockerfile instruction that created the layer or\\nmetadata.\\nLines with a non-zero value in the SIZE column created new layers, whereas the lines\\nwith 0B only added metadata. In this example, three lines/instructions created layers.\\nRun a docker inspect to see the list of image layers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 116}, page_content='8: Containerizing an app\\n110\\n$ docker inspect ddd-book:ch8.node\\n<Snip>\\n},\\n\"RootFS\": {\\n\"Type\": \"layers\",\\n\"Layers\": [\\n\"sha256:5f4d9fc4d98de91820d2a9c81e501c8cc6429bc8758b43fcb2cd50f4cab9a324\",\\n\"sha256:6b20c4e93dbab9786f96268bbe32c208d385f2c4490a278ad3b1e55cc79480e4\",\\n\"sha256:012c308a78ec993a47fdb7c4c6d17b53d8ce2649a463be28ae5c48ab1af2e039\",\\n\"sha256:35a839ac7cc922afd896a0297e692141c77ed6e03eff6a70db13bb23f6cd4f8f\",\\n\"sha256:918caa8070410ccfb2c5b3b4d62ca66742c46bf21fe0bd433738b7796c530e68\",\\n\"sha256:a48b3b3d0c5a693840e7e4abd7971f130b4447573483628bcb996091e1e8e8b8\",\\n\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n},\\nAs previously mentioned, the output shows seven layers because the base image had four\\nlayers, and the Dockerfile added three more.\\nFigure 8.5 maps the Dockerfile instructions to image layers. The bold instructions with\\narrows create layers; the others create metadata. The layer IDs will be different in your\\nenvironment.\\nFigure 8.5\\nNote: Older builders didn’t create a layer for WORKDIR instructions. However,\\nthe instruction modifies filesystem permissions and the current builder\\ncreates a very small layer. This behavior may change in the future.\\nIt’s generally considered a good practice to use Docker Official Images and Verified Pub-\\nlisher images as the base layer for new images you create. This is because they maintain a'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 117}, page_content='8: Containerizing an app\\n111\\nhigh standard and quickly implement fixes for known vulnerabilities.\\nMoving to production with multi-stage builds\\nWhen it comes to container images… big is bad! For example:\\n• Big means slow\\n• Big means more potential vulnerabilities\\n• Big means a larger attack surface\\nFor these reasons, your container images should only contain the stuff needed to run\\nyour applications in production.\\nThis is where multi-stage builds come into play.\\nAt a high level, multi-stage builds use a single Dockerfile with multiple FROM instructions\\n— each FROM instruction represents a new build stage. This allows you to have a stage\\nwhere you do the heavy lifting of building the app inside a large image with compilers\\nand other build tools, but then you have another stage where you copy the compiled app\\ninto a slim image for production. The builder can even run different stages in parallel for\\nfaster builds.\\nNote: A slim image is a very small image intended for production use that\\nonly contains files and apps that are absolutely necessary to run the applica-\\ntion. They do not include shells, package managers, or troubleshooting tools.\\nFigure 8.6 shows a high-level workflow. Stage 1 builds an image with all the required\\nbuild and compilation tools. Stage 2 copies the app code into the image and builds it.\\nStage 3 creates a small production-ready image containing only the compiled app and\\nanything needed to run it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 118}, page_content='8: Containerizing an app\\n112\\nFigure 8.6\\nLet’s look at an example!\\nWe’ll work with the code in the multi-stage folder of the book’s GitHub repo. It’s a\\nsimple Go app with a client and server borrowed from the Docker samples buildme repo\\non GitHub. Don’t worry if you’re not a Go programmer; you don’t need to be. You only\\nneed to know that it compiles the client and server apps into executable files that do not\\nneed the Go language or any other tools or runtimes to execute.\\nHere’s the Dockerfile:\\nFROM golang:1.23.4-alpine AS base\\n<<---- Stage 0\\nWORKDIR /src\\nCOPY go.mod go.sum .\\nRUN go mod download\\nCOPY . .\\nFROM base AS build-client\\n<<---- Stage 1\\nRUN go build -o /bin/client ./cmd/client\\nFROM base AS build-server\\n<<---- Stage 2\\nRUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod\\n<<---- Stage 3\\nCOPY --from=build-client /bin/client /bin/\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]\\nThe first thing to note is that there are four FROM instructions. Each of these is a distinct\\nbuild stage, and Docker numbers them starting from 0. However, we’ve given each stage a\\nfriendly name:\\n• Stage 0 is called base and builds an image with compilation tools, etc'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='8: Containerizing an app\\n113\\n• Stage 1 is called build-client and compiles the client executable\\n• Stage 2 is called build-server and compiles the server executable\\n• Stage 3 is called prod and copies the client and server executables into a slim image\\nEach stage outputs an intermediate image that later stages can use. However, Docker\\ndeletes them when the final stage completes.\\nThe goal of the base stage is to create a reusable build image with all the tools stages\\n1 and 2 need to build the client and server applications. The image created by this\\nstage is only used to compile the executables and not for production. It pulls the\\ngolang:1.23.4-alpine image, which is over 350MB when uncompressed. It sets the\\nworking directory to /src and copies in the go.mod and go.sum files from your working\\ndirectory. These files list the application dependencies and hashes. After that, it uses the\\nRUN instruction to install the dependencies and then the COPY instruction to copy the\\napplication source code into the image. All of this creates a large image with three layers\\ncontaining a lot of build stuff but not much app stuff. When this build stage completes, it\\noutputs a large image that later stages can use.\\nThe build-client stage doesn’t pull a new image. Instead, it uses the FROM base AS\\nbuild-client instruction to use the intermediate image created by the base stage. It\\nthen issues a RUN instruction to compile the client app into a binary executable. The goal\\nof this stage is to create an image with the compiled client binary that later stages can\\nreference.\\nThe build-server stage does the same for the server component and outputs a similar\\nimage for use by later stages.\\nThe prod stage pulls the minimal scratch image. It then runs two COPY --from instruc-\\ntions to copy the compiled client app from the build-client stage and the compiled\\nserver app from the build-server stage. It then tells Docker to run the server app when\\nit’s started as a container. This stage outputs the final production image containing just\\nthe client and server binaries inside a tiny scratch image and the metadata telling Docker\\nhow to start the app.\\nThe builder will run the base stage first, then run the build-client and build-server\\nstages in parallel, and finally run the prod stage.\\nIt will always attempt to run stages in parallel, but it can only do this when no depen-\\ndencies exist. For example, the build-client and build-server stages both start with\\nFROM base..., meaning they depend on the base stage and cannot run until that stage\\nis built. However, the build-client and build-server can run in parallel because they\\ndon’t depend on each other. To work out if build stages can run in parallel, start reading\\nthe Dockerfile from the top and check if the FROM instructions reference other FROM\\ninstructions immediately before or after — if they do, they can’t run in parallel.\\nLet’s see it in action.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 120}, page_content='8: Containerizing an app\\n114\\nChange into the multi-stage directory and verify the Dockerfile and associated app\\nfiles exist.\\n$ ls -l\\ntotal 28\\n-rw-rw-r-- 1 ubuntu ubuntu\\n368 Mar 25 10:09 Dockerfile\\n-rw-rw-r-- 1 ubuntu ubuntu\\n433 Mar 25 10:09 Dockerfile-final\\n-rw-rw-r-- 1 ubuntu ubuntu\\n305 Mar 25 10:09 README.md\\ndrwxrwxr-x 4 ubuntu ubuntu 4096 Mar 25 10:09 cmd\\n-rw-rw-r-- 1 ubuntu ubuntu 1013 Mar 25 10:09 go.mod\\n-rw-rw-r-- 1 ubuntu ubuntu 5631 Mar 25 10:09 go.sum\\nBuild the image and watch the build-client and build-server stages execute in\\nparallel. This can significantly improve the performance of large builds.\\n$ docker build -t multi:full .\\n[+] Building 14.6s (15/15) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n=> => transferring dockerfile: 736B\\n0.0s\\n<Snip>\\n=> [build-client 1/1] RUN go build -o /bin/client ./cmd/client\\n5.1s\\n<<---- parallel\\n=> [build-server 1/1] RUN go build -o /bin/server ./cmd/server\\n5.1s\\n<<---- parallel\\n<Snip>\\nRun a docker images to see the new image.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nmulti\\nfull\\na7a01440f2b5\\n5 seconds ago\\n26.7MB\\nThe final production image is only 26MB, much smaller than the 350MB+ base image\\npulled by the base stage to build and compile the app. This is because the final prod\\nstage extracted the compiled client and server binaries and placed them in a tiny new\\nscratch image.\\nRun a docker history to see the final production image. It only has two layers — one\\ncreated by copying in the client binary and the other by copying in the server binary.\\nNone of the previous build stages are included in the final production image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 121}, page_content='8: Containerizing an app\\n115\\n$ docker history multi:full\\nIMAGE\\nCREATED\\nCREATED BY\\nSIZE\\na7a01440f2b5\\n2 minutes ago\\nENTRYPOINT [\"/bin/server\"]\\n0B\\n<missing>\\n2 minutes ago\\nCOPY /bin/server /bin/ # buildkit\\n8.64MB\\n<missing>\\n2 minutes ago\\nCOPY /bin/client /bin/ # buildkit\\n8.53MB\\nMulti-stage builds and build targets\\nYou can also build multiple images from a single Dockerfile.\\nThe previous example compiled client and server apps and copied both into the same\\nimage. However, Docker makes it easy to create a separate image for each by splitting\\nthe final prod stage into two stages as follows:\\nFROM golang:1.20-alpine AS base\\nWORKDIR /src\\nCOPY go.mod go.sum .\\nRUN go mod download\\nCOPY . .\\nFROM base AS build-client\\nRUN go build -o /bin/client ./cmd/client\\nFROM base AS build-server\\nRUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod-client\\n<<---- New stage\\nCOPY --from=build-client /bin/client /bin/\\nENTRYPOINT [ \"/bin/client\" ]\\nFROM scratch AS prod-server\\n<<---- New stage\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]\\nI’ve pre-created the Dockerfile and called it Dockerfile-final in the multi-stage\\nfolder, but you can see the only change is splitting the final prod stage into two stages\\n— one for the client build and the other for the server build. With a Dockerfile like this,\\nyou tell a docker build command which of the two final stages to target for the build.\\nLet’s do it.\\nRun the following two commands to create two different images from the same\\nDockerfile-final file. Both commands use the -f flag to tell Docker to use the\\nDockerfile-final file. They also use the --target flag to tell the builder which stage\\nto build from.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 122}, page_content='8: Containerizing an app\\n116\\n$ docker build -t multi:client --target prod-client -f Dockerfile-final .\\n<Snip>\\n$ docker build -t multi:server --target prod-server -f Dockerfile-final .\\n<Snip>\\nCheck the builds and image sizes.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nmulti\\nfull\\na7a01440f2b5\\n4 minutes ago\\n26.7MB\\nmulti\\nserver\\na75778df1b9c\\n4 seconds ago\\n11.7MB\\nmulti\\nclient\\n02b621e9415f\\n12 seconds ago\\n11.9MB\\nYou now have three images, and the client and server images are each about half the\\nsize of the full image. This makes sense because the full image contains the client and\\nserver binaries, whereas the others only include one.\\nBuildx, BuildKit, drivers, and Build Cloud\\nThis section takes a quick look at the major build components.\\nBehind the scenes, Docker’s build system has a client and server:\\n• Client: Buildx\\n• Server: BuildKit\\nBuildx is Docker’s latest and greatest build client. It’s implemented as a CLI plugin and\\nsupports all the latest features of BuildKit, such as multi-stage builds, multi-architecture\\nimages, advanced caching, and more. It’s been the default build client since Docker v23.0\\nand Docker Desktop v4.19. This means every time you run a docker build command,\\nyou’re automatically using the Buildx builder.\\nYou can configure Buildx to talk to multiple BuildKit instances, and we call each\\ninstance of BuildKit a builder. Builders can run on your local machine, in your cloud or\\ndatacenter, or Docker’s Build Cloud.\\nIf you point buildx at a local builder, image builds will be done on your local machine.\\nIf you point it at a remote builder, such as Docker Build Cloud, builds will be done on\\nremote infrastructure.\\nFigure 8.7 shows a Docker environment configured to talk to a local and a remote\\nbuilder.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 123}, page_content='8: Containerizing an app\\n117\\nFigure 8.7 - Docker build architecture\\nIn the diagram, the local builder uses the docker-container driver to create a local\\nBuildKit instance inside a dedicated container. All builds using this driver will run in the\\ndedicated container. The other option uses the cloud driver to send builds to Docker’s\\nBuild Cloud service. Build Cloud offers fast builds and a shared cache but requires a\\npaid subscription.\\nWhen you run a docker build command, buildx interprets the command and sends\\nthe build request to the selected builder. This includes the Dockerfile, command line\\narguments, caching options, export options, and the build context (app and dependency\\nlist). The builder performs the build and exports the image. The Buildx client monitors\\nthe build and reports on progress.\\nRun the following command to see the builders you have configured on your system.\\nI’ve trimmed the output in the book, but you can see a local and a remote builder.\\n$ docker buildx ls\\nNAME/NODE\\nDRIVER/ENDPOINT\\nPLATFORMS\\nbuilder *\\ndocker-container\\nbuilder0\\ndesktop-linux\\nlinux/arm64, linux/amd64, linux/amd64/v2,\\nlinux/riscv64, linux/ppc64le, linux/s390x,\\nlinux/386, linux/mips64le, linux/mips64,\\nlinux/arm/v7, linux/arm/v6\\ncloud-nigelpoulton-ddd\\ncloud\\nlinux-arm64\\ncloud://nigel...arm64\\nlinux/arm64*\\nlinux-amd64\\ncloud://nigel...amd64\\nlinux/amd64*, linux/amd64/v2,\\nlinux/amd64/v3,linux/amd64/v4\\n<Snip>\\nNotice how the first builder supports more platforms than the cloud builder. This is\\nbecause the docker-container driver utilizes QEMU to emulate target hardware. It\\nusually works but can be slow.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 124}, page_content='8: Containerizing an app\\n118\\nThe second builder is Docker’s Build Cloud, which only supports AMD and ARM builds.\\nBuilds running in Build Cloud run on native hardware and offer a shared cache so that\\nteammates can share a common cache for even faster builds. Complex builds can be\\nmuch quicker when executed on native hardware such as Build Cloud.\\nRun a docker buildx inspect command against one of your builders.\\n$ docker buildx inspect cloud-nigelpoulton-ddd\\nName:\\ncloud-nigelpoulton-ddd\\nDriver:\\ncloud\\nNodes:\\nName:\\nlinux-arm64\\nEndpoint:\\ncloud://nigelpoulton/ddd_linux-arm64\\nStatus:\\nrunning\\nBuildkit:\\nv0.16.0\\nPlatforms: linux/arm64*, linux/arm/v6, linux/arm/v7\\nLabels:\\norg.mobyproject.buildkit.worker.executor:\\noci\\norg.mobyproject.buildkit.worker.hostname:\\nnigelpoulton_ddd-cloud_linux-arm64\\norg.mobyproject.buildkit.worker.network:\\nhost\\norg.mobyproject.buildkit.worker.oci.process-mode: sandbox\\norg.mobyproject.buildkit.worker.selinux.enabled:\\nfalse\\norg.mobyproject.buildkit.worker.snapshotter:\\noverlayfs\\nGC Policy rule#0:\\nAll:\\ntrue\\nKeep Bytes: 25GiB\\n<Snip>\\nLet’s see how to perform multi-architecture builds.\\nMulti-architecture builds\\nYou can use the docker build command to build images for multiple platforms and\\nCPU architectures, including ones different from your local machine. For example:\\n• Docker on an AMD machine can build ARM images\\n• Docker on an ARM machine can build AMD images\\nYou also have the option to perform builds locally or in the cloud. Both work with the\\nstandard docker build command and only require minimal backend configuration.\\nRun the following command to list your current builders. Remember, a builder is an\\ninstance of BuildKit that will perform builds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 125}, page_content='8: Containerizing an app\\n119\\n$ docker buildx ls\\nNAME/NODE\\nDRIVER/ENDPOINT\\nPLATFORMS\\nbuilder *\\ndocker-container\\nbuilder0\\ndesktop-linux\\nlinux/arm64, linux/amd64, linux/amd64/v2,\\nlinux/riscv64, linux/ppc64le, linux/s390x,\\nlinux/386, linux/mips64le, linux/mips64,\\nlinux/arm/v7, linux/arm/v6\\ncloud-nigelpoulton-ddd\\ncloud\\nlinux-arm64\\ncloud://nigel...arm64\\nlinux/arm64*\\nlinux-amd64\\ncloud://nigel...amd64\\nlinux/amd64*, linux/amd64/v2, linux/amd64/v3,\\nlinux/amd64/v4\\n<Snip>\\nThe book’s output shows two builders; the one with the asterisk (*) is the default builder.\\nIn this example, the default builder is called builder and uses the docker-container\\ndriver to perform builds inside a local build container. Unless you specify a different\\nbuilder, all builds will run inside this build container. It supports multiple architectures,\\nincluding AMD, ARM, RISC-V, s390x, and more.\\nIf you don’t already have one, create a new builder called container that uses the docker-\\ncontainer driver with the following command.\\n$ docker buildx create --driver=docker-container --name=container\\nRun another docker buildx ls to show the new builder. Don’t worry if it shows as\\npresent but inactive.\\nMake it the default builder.\\n$ docker buildx use container\\nChange into the web-app directory and run the following command to build the app\\ninto AMD and ARM images and export them directly to Docker Hub.\\nBe sure to substitute your Docker ID as the command pushes directly to Docker Hub\\nand will fail if you try to push it to my repositories. If you don’t have a Docker Hub\\naccount or don’t want to push the images, you can replace the --push with --load.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 126}, page_content='8: Containerizing an app\\n120\\n$ docker buildx build --builder=container \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n[+] Building 79.3s (26/26) FINISHED\\n<Snip>\\n=> [linux/arm64 2/5] RUN apk add --update nodejs npm curl\\n19.0s\\n=> [linux/amd64 2/5] RUN apk add --update nodejs npm curl\\n17.4s\\n=> [linux/amd64 3/5] COPY . /src\\n0.0s\\n=> [linux/amd64 4/5] WORKDIR /src\\n0.0s\\n=> [linux/amd64 5/5] RUN\\nnpm install\\n7.3s\\n=> [linux/arm64 3/5] COPY . /src\\n0.0s\\n=> [linux/arm64 4/5] WORKDIR /src\\n0.0s\\n=> [linux/arm64 5/5] RUN\\nnpm install\\n5.6s\\n=> exporting to image\\n<Snip>\\n=> => pushing layers\\n31.5s\\n=> => pushing manifest for docker.io/nigelpoulton/ddd-book:web0.2@sha256:8fc61...\\n3.6s\\n=> [auth] nigelpoulton/ddd-book:pull,push token for registry-1.docker.io\\n0.0s\\nI’ve snipped the output, but you can still see two important things:\\n• Each Dockerfile instruction executed twice — once for AMD and once for ARM\\n• The last few lines show the image layers being pushed directly to Docker Hub\\nNow that you’ve performed a build, the builder will show as active and list the architec-\\ntures it supports.\\nFigure 8.8 shows how the images for both architectures appear on Docker Hub under\\nthe same repository and tag.\\nFigure 8.8 - Multi-platform image\\nYou can also perform the builds using Docker Build Cloud. This is a cloud-based service\\nthat offers fast builds and lets you share your build cache with teammates. It requires a\\npaid subscription.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 127}, page_content='8: Containerizing an app\\n121\\nIf you have a Docker subscription that grants you access to Build Cloud, you can go to\\nbuild.docker.com and configure your first cloud builder. You can also create cloud\\nbuilders from the CLI as follows. If you’re following along, you’ll need to give yours a\\ndifferent name.\\n$ docker buildx create --driver cloud nigelpoulton/ddd\\nOnce you have a cloud builder, you can either make it your default builder with a\\ndocker buildx use <builder> command, or you can specify it when performing\\nindividual builds.\\nThe following command uses the --builder flag to use the cloud-nigelpoulton-ddd\\ncloud builder to build the same images as in the previous steps. Remember to use your\\nown cloud builder if you’re following along.\\n$ docker buildx build \\\\\\n--builder=cloud-nigelpoulton-ddd \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n=> [internal] connected to docker build cloud service\\n0.0s\\n<Snip>\\nAt the time of writing, Build Cloud supports various AMD and ARM architectures,\\nwhereas the docker-container driver supports more but is slower and less reliable.\\nA few good practices\\nLet’s finish the chapter with a few best practices. This isn’t a full list, and the advice\\napplies to local builds and cloud builds.\\nLeverage the build cache\\nBuildKit uses a cache to speed up builds. The best way to see the impact is to build a\\nnew image on a clean Docker host and then repeat the same build immediately after.\\nThe first build will pull images and take time to build layers. The second build will\\ninstantly complete because the layers and other artifacts from the first build are cached\\nand leveraged by later builds.\\nIf you use a local builder, the cache is only available to other builds you execute on the\\nsame system. However, your entire team can share the cache on Docker Build Cloud.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 128}, page_content='8: Containerizing an app\\n122\\nFor each build, the builder iterates through the Dockerfile one line at a time, starting\\nfrom the top. For each line, it checks if it already has the layer in its cache. If it does,\\na cache hit occurs, and it uses the cached layer. If it doesn’t, a cache miss occurs, and it\\nbuilds a new layer from the instruction. Cache hits are one of the best ways to make\\nbuilds faster.\\nLet’s take a closer look.\\nAssume the following Dockerfile:\\nFROM alpine\\nRUN apk add --update nodejs npm\\nCOPY . /src\\nWORKDIR /src\\nRUN npm install\\nEXPOSE 8080\\nENTRYPOINT [\"node\", \"./app.js\"]\\nThe first instruction tells Docker to use the alpine:latest image as its base image. If\\nyou already have a copy of this image, the builder moves on to the next instruction. If\\nyou don’t have a copy, it pulls it from Docker Hub.\\nThe next instruction (RUN apk...) runs a command to update package lists and install\\nnodejs and npm. Before executing the instruction, Docker checks the build cache for a\\nlayer built from the same base image using the same instruction. In this case, it’s looking\\nfor a layer built by executing the RUN apk add --update nodejs npm instruction\\ndirectly on top of the alpine:latest image.\\nIf it finds a matching layer, it links to that layer and continues the build with the cache\\nintact. If it does not find a matching layer, it invalidates the cache and builds the\\nlayer. Invalidating the cache means the builder must execute all remaining Dockerfile\\ninstructions in full and cannot use the cache.\\nLet’s assume Docker had a cached layer for the RUN instruction and that the layer’s ID is\\nAAA.\\nThe next instruction runs a COPY . /src command to copy the app code into the image.\\nThe previous instruction scored a cache hit, meaning Docker can check if it has a cached\\nlayer built by running a COPY . /src against the AAA layer. If it has a cached layer for\\nthis, it links to the layer and proceeds to the next instruction. If it doesn’t have a cached\\nlayer, it builds it and invalidates the cache for the rest of the build.\\nThis process continues for the rest of the Dockerfile.\\nIt’s important to understand a few things.\\nAny time an instruction results in a cache miss, the cache is invalidated and no longer\\nchecked for the rest of the build. This means you should write your Dockerfiles so that'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 129}, page_content='8: Containerizing an app\\n123\\ninstructions most likely to invalidate the cache go near the end of the Dockerfile. This\\nallows builds to benefit from the cache for as long as possible.\\nYou can force a build to ignore the cache by running docker build with the --no-cache\\noption.\\nIt’s also important to understand that COPY and ADD instructions include logic to ensure\\nthe content you’re copying into the image hasn’t changed since the last build. For exam-\\nple, you might have a cached layer that Docker built by running a COPY . /src against\\nthe AAA image. However, if the files that the COPY . /src instruction copies into the\\nlayer have changed since the cached layer was built, you cannot use the cached layer as\\nyou’d get old versions of the files. To protect against this, Docker performs checksums\\nagainst each file it copies. If the checksums don’t match, the cache is invalidated, and\\nDocker builds a new layer.\\nOnly install essential packages\\nWe often joke that we install the entire internet when we build apps. As a quick example,\\nthe simple Node.js app used earlier in the chapter depends on two packages:\\n• Express\\n• Pug\\nHowever, these packages depend on other packages, which in turn depend on others.\\nAt the time of writing, building this simple application with two dependencies actually\\ndownloads over 110 packages!\\nFortunately, some package managers provide a way for you to only download and install\\nessential packages instead of the entire internet. One example is the apt package manager\\nthat lets you specify the no-install-recommends flag so that it only installs packages\\nin the depends field and not every recommended and suggested package. Each package\\nmanager does this differently, but it’s worth investigating as it can massively impact the\\nsize of your images.\\nClean up\\nIf you’ve followed along, you’ll have one running container and several images in your\\nlocal image repository. You should delete the running container and, optionally, the\\nlocal images.\\nRun the following command to delete the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 130}, page_content='8: Containerizing an app\\n124\\n$ docker rm c1 -f\\nOptionally delete the local images with the following command. Be sure to use the\\nnames of the images in your environment.\\n$ docker rmi \\\\\\nmulti:full multi:client multi:server ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\\nContainerizing an app – The commands\\n• docker build containerizes applications. It reads a Dockerfile and follows the\\ninstructions to create an OCI image. The -t flag tags the image, and the -f flag\\nlets you specify the name and location of the Dockerfile. The build context is where\\nyour application files exist and can be a directory on your local Docker host or a\\nremote Git repo.\\n• The Dockerfile FROM instruction specifies the base image. It’s usually the first\\ninstruction in a Dockerfile, and it’s considered a good practice to build from\\nDocker Official Images or images from Verified Publishers. FROM is also used to\\nidentify new build stages in multi-stage builds.\\n• The Dockerfile RUN instruction lets you run commands during a build. It’s com-\\nmonly used to update packages and install dependencies. Every RUN instruction\\ncreates a new image layer.\\n• The Dockerfile COPY instruction adds files to images, and you’ll regularly use it to\\ncopy your application code into a new image. Every COPY instruction creates an\\nimage layer.\\n• The Dockerfile EXPOSE instruction documents an application’s network port.\\n• The Dockerfile ENTRYPOINT and CMD instructions tell Docker how to run the app\\nwhen starting a new container.\\n• Some other Dockerfile instructions include LABEL, ENV, ONBUILD, HEALTHCHECK and\\nmore.\\nChapter summary\\nThis chapter taught you how to containerize an application. This is the process of\\nbuilding an app into a container image and running it as a container.\\nYou pulled some application source code from GitHub and used the docker init\\ncommand to auto-generate a Dockerfile with instructions telling Docker how to build'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 131}, page_content='8: Containerizing an app\\n125\\nthe app into a container image. You then used docker build to create the image, docker\\npush to push it to Docker Hub, and docker run to run it as a container.\\nAlong the way, you learned that some Dockerfile instructions add content to an\\nimage and therefore create new layers. Instructions that don’t add content only create\\nmetadata.\\nAfter that, you learned how multi-stage builds allow you to create small and efficient\\nproduction images without the bloat carried over from compiling the app.\\nAfter that, you learned that buildx is the default build client that integrates with the\\nlatest features of the BuildKit build engine. You learned how to create local and remote\\nbuilders (BuildKit instances) and how to use them to perform multi-architecture builds.\\nYou also learned the importance of the build cache for speeding up builds and how to\\noptimize Dockerfiles to leverage the build cache.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 132}, page_content='9: Multi-container apps with Compose\\nIn this chapter, you’ll deploy and manage a multi-container application using Docker\\nCompose. When talking about Docker Compose, we usually shorten it to Compose and\\nalways write it with a capital “C”.\\nI’ve organized the chapter as follows:\\n• Docker Compose – The TLDR\\n• Compose background\\n• Installing Compose\\n• The sample app\\n• Compose files\\n• Deploying apps with Compose\\n• Managing apps with Compose\\nDocker Compose – The TLDR\\nWe create modern cloud-native applications by combining lots of small services that\\nwork together to form a useful app. We call them microservices applications, and they\\nbring a lot of benefits, such as self-healing, autoscaling, and rolling updates. However,\\nthey can be complex.\\nFor example, you might have a microservices app with the following services:\\n• Web front-end\\n• Ordering\\n• Catalog\\n• Back-end datastore\\n• Logging\\n• Authentication\\n• Authorization'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 133}, page_content='9: Multi-container apps with Compose\\n127\\nInstead of hacking together complex scripts and long docker commands, Compose lets\\nyou describe the application in a simple YAML file called a Compose file. You then use the\\nCompose file with the docker compose command to deploy and manage the entire app.\\nThis makes Compose files important parts of your applications that you should host in a\\nversion control system such as Git.\\nThat’s the basics. Let’s dig deeper.\\nCompose background\\nWhen Docker was new, a company called Orchard Labs built a tool called Fig that made\\ndeploying and managing multi-container apps easy. It was a Python tool that ran on\\ntop of Docker and let you define complex multi-container microservices apps in a\\nsimple YAML file. You could even use the fig command-line tool to manage the entire\\napplication lifecycle.\\nBehind the scenes, Fig would read the YAML file and call the appropriate Docker\\ncommands to deploy and manage the app.\\nFig was so good that Docker, Inc. acquired Orchard Labs and rebranded Fig as Docker\\nCompose. They renamed the command-line tool from fig to docker-compose, and\\nthen, more recently, they folded it into the main docker CLI with its own compose sub-\\ncommand. You can now run simple docker compose commands to easily manage multi-\\ncontainer microservices apps.\\nThere is also a Compose Specification15 driving Compose as an open standard for multi-\\ncontainer microservices apps. The specification is community-led and kept separate\\nfrom the Docker implementation to maintain better governance and demarcation.\\nHowever, Docker Compose is the reference implementation, and you should expect Docker\\nto implement the full spec.\\nReading the spec is a great way to learn the details.\\nInstalling Compose\\nAll modern versions of Docker come with Docker Compose pre-installed, and you no\\nlonger need to install it as a separate application.\\nTest it with the following command.\\n15https://www.compose-spec.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 134}, page_content=\"9: Multi-container apps with Compose\\n128\\n$ docker compose version\\nDocker Compose version v2.35.1\\nThe sample app\\nWe’ll use the sample app shown in Figure 9.1 with two services, a network, and a\\nvolume.\\nFigure9.1 - Sample app\\nThe web-fe service runs a web server that increments a counter in the redis service\\nevery time it receives a request for the web page. Both services are connected to the\\ncounter-net network and use it to communicate. The redis service mounts the\\ncounter-vol volume.\\nThis is all defined in the compose.yaml file in the multi-container folder of the book’s\\nGitHub repo.\\nIf you haven’t already done so, clone the repo so you have a local copy of everything\\nyou’ll need. You’ll need git installed, and the command will create a new directory\\ncalled ddd-book.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nCloning into 'ddd-book'...\\nremote: Enumerating objects: 67, done.\\nremote: Counting objects: 100% (67/67), done.\\nremote: Compressing objects: 100% (47/47), done.\\nremote: Total 67 (delta 17), reused 63 (delta 16), pack-reused 0\\nReceiving objects: 100% (67/67), 173.61 KiB | 1.83 MiB/s, done.\\nResolving deltas: 100% (17/17), done.\\nChange into the ddd-book/multi-container directory and list its contents.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 135}, page_content='9: Multi-container apps with Compose\\n129\\n$ cd ddd-book/multi-container/\\n$ ls -l\\ntotal 20\\ndrwxrwxr-x 4 ubuntu ubuntu 4096 May 21 15:53 app\\n-rw-rw-r-- 1 ubuntu ubuntu\\n288 May 21 15:53 Dockerfile\\n-rw-rw-r-- 1 ubuntu ubuntu\\n18 May 21 15:53 requirements.txt\\n-rw-rw-r-- 1 ubuntu ubuntu\\n355 May 21 15:53 compose.yaml\\n-rw-rw-r-- 1 ubuntu ubuntu\\n332 May 21 15:53 README.md\\nThis directory is your build context and contains all the app code and configuration files\\nDocker needs to deploy and manage the app.\\n• The app folder contains the application code, views, and templates\\n• The Dockerfile describes how to build the image for the web-fe service\\n• The requirements.txt file lists the application dependencies for the web-fe\\nservice\\n• The compose.yaml file tells Docker how to deploy the app\\nFigure 9.2 shows the app in more detail.\\nFigure 9.2 - Detailed view of sample app\\nWhen you deploy the app, you’ll use the docker compose command to send the\\ncompose.yaml file to Docker, where Docker parses the file and completes the necessary\\nsteps to deploy the app. These steps include creating the network, volume, image, and\\nservices, and connecting the services to the appropriate network and volume.\\nAs you’ll see later, Docker assigns the app a project name based on the name of your build\\ncontext’s directory. In our example, the build context is the multi-container directory,\\nso Docker will use “multi-container” as the project name. You’ll see why this matters later.\\nNow that you know what the app looks like, let’s take a closer look at the Compose file.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 136}, page_content='9: Multi-container apps with Compose\\n130\\nCompose files\\nCompose uses YAML files to define microservices applications. We call them Compose\\nfiles, and Compose expects you to name them compose.yaml or compose.yml. However,\\nyou can specify a different filename with the -f flag.\\nHere is the Compose file we’ll be using. It’s called compose.yaml from the multi-\\ncontainer folder.\\nservices:\\n<<--- Microservices are defined in the \"services\" block\\nweb-fe:\\n----┐\\ndeploy:\\n|\\nreplicas: 1\\n|\\nbuild: .\\n| This block\\ncommand: python app.py\\n| defines the\\nports:\\n| *web-fe*\\n- target: 8080\\n| microservice\\npublished: 5001\\n|\\nnetworks:\\n|\\n- counter-net\\n----┘\\nredis:\\n----┐\\ndeploy:\\n|\\nreplicas: 1\\n|\\nimage: \"redis:alpine\"\\n|\\nnetworks:\\n| The *redis*\\ncounter-net\\n| service\\nvolumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\ntarget: /app\\n----┘\\nnetworks:\\n<<--- Networks are defined in this block\\ncounter-net:\\nvolumes:\\n<<--- Volumes are defined in this block\\ncounter-vol:\\nThe first thing to note is that the file has three top-level keys with a block of code\\nbeneath each:\\n• services\\n• networks\\n• volumes\\nMore top-level keys exist, but this app only uses the three in the list.\\nThe top-level services key is mandatory and is where you define application microser-\\nvices. This app has two microservices called web-fe and redis. The web-fe service runs\\nthe application’s web server and the redis service runs a database backend.\\nLet’s look at both, starting with the web-fe service.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 137}, page_content='9: Multi-container apps with Compose\\n131\\nservices:\\nweb-fe:\\n<<--- Service name. Containers will inherit this name\\ndeploy:\\nreplicas: 1\\n<<--- Deploy a single container for this service\\nbuild: .\\n<<--- Build from the Dockerfile in the current directory\\ncommand: python app/app.py <<-- Execute this command when starting containers\\nports:\\n- target: 8080\\n----┐Map port 8080 in the container\\npublished: 5001\\n----┘to port 5001 on the Docker host\\nnetworks:\\n- counter-net\\n<<--- Attach the service\\'s containers to the \"counter-net\" network\\nLet’s step through it.\\n• web-fe: is the service’s name, and all containers Docker creates for this service\\nwill inherit “web-fe” as part of their names.\\n• deploy.replicas: 1 tells Docker to deploy a single container for this service. You\\ncan specify a different number of replicas to deploy multiple identical containers\\nfor the service. However, you’ll only be able to deploy a single replica on Docker\\nDesktop as only one container can bind to the port in the ports field.\\n• build: . tells Docker to build the image for this service from the Dockerfile in the\\ncurrent directory.\\n• command: python app/app.py is the command Docker executes inside every\\ncontainer it creates for this service. The app.py file must exist in the image, and\\nthe image must have Python installed. The Dockerfile takes care of both of these\\nrequirements.\\n• ports: is where you map network ports from the service’s containers to the\\nDocker host. This example maps port 5001 on the Docker host to port 8080 inside\\nthe container and is why Docker Desktop readers can only deploy a single replica\\nfor this service.\\n• networks: tells Docker to attach this service’s containers to the counter-net\\nnetwork. The network should already exist or be defined in the networks top-level\\nkey.\\nIn summary, Compose will build a new image from the Dockerfile in the same directory\\nand start a single container from it. When it starts, the container will have web-fe in\\nits name and run the python app/app.py command. It will attach to the counter-net\\nnetwork, expose the web service on the host’s port 5001.\\nNow, let’s look at the redis service.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 138}, page_content='9: Multi-container apps with Compose\\n132\\nservices:\\n..\\nredis:\\n<<--- Service name. Containers will inherit this name\\nimage: \"redis:alpine\"\\n<<--- Pull the \"redis:alpine\" image for this service\\ndeploy:\\nreplicas: 1\\n<<--- Deploy a single container for this service\\nnetworks:\\ncounter-net:\\n<<--- Attach containers to the \"counter-net\" network\\nvolumes:\\n- type: volume\\nsource: counter-vol\\n----┐Mount the \"counter-vol\" volume\\ntarget: /app\\n----┘to \"/app\" in the containers for this service\\nLet’s step through this one.\\n• redis: is the service’s name, and all containers created as part of this service will\\ninherit “redis” as part of their names.\\n• image: redis:alpine tells Docker to pull the redis:alpine image from Docker\\nHub and use it to start the service’s containers.\\n• deploy.replicas: 1 tells Docker to deploy a single container for this service.\\n• networks: tells Docker to attach the service’s containers to the counter-net\\nnetwork.\\n• volumes: tells Docker to mount the counter-vol volume to the /data directory\\ninside all of the service’s containers. This is where Redis stores data and will mean\\nyou can stop and delete most of the app without losing data.\\nConnecting both services to the counter-net network means they can resolve each\\nother by name and communicate. This is important, as the following extract from the\\napp.py file shows the web app communicating with the redis service by name.\\nimport time\\nimport redis\\nfrom flask import Flask, render_template\\napp = Flask(__name__)\\ncache = redis.Redis(host=\\'redis\\', port=6379)\\n<<---- \"redis\" is the name of the service\\n<Snip>\\nThe network and volumes blocks are extremely simple and define a network called\\ncounter-net and a volume called counter-vol.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 139}, page_content='9: Multi-container apps with Compose\\n133\\nnetworks:\\n<<---- This block defines a new network called \"counter-net\"\\ncounter-net:\\nvolumes:\\n<<---- This block defines a new volume called \"counter-vol\"\\ncounter-vol:\\nNow that we understand the Compose file, let’s deploy the app.\\nDeploying apps with Compose\\nIn this section, you’ll use the app from the Compose file. You’ll need a local copy of the\\nbook’s GitHub repo, and you’ll need to run all commands from the multi-container\\nfolder.\\nRun the following command to deploy the app. By default, it deploys the app defined in\\nthe compose.yaml file in the working directory.\\n$ docker compose up --detach\\n- redis 7 layers [||||||]\\n0B/0B\\nPulled\\n5.2s\\n- b0dd12c8e070: Pull complete\\n<Snip>\\n- 4f4fb700ef54: Pull complete\\n- redis Pulled\\n<Snip>\\n=> [web-fe internal] load build definition from Dockerfile\\n[+] Building 613s (11/11) FINISHED\\n<Snip>\\n[+] Running 5/5\\n- web-fe\\nBuilt\\n0.0s\\n- Network multi-container_counter-net\\nCreated\\n0.0s\\n- Volume \"multi-container_counter-vol\"\\nCreated\\n0.0s\\n- Container multi-container-redis-1\\nCreated\\n0.0s\\n- Container multi-container-web-fe-1\\nCreated\\n0.0s\\nIt’ll take a few seconds to build the web-fe image, pull the redis image, and then\\nstart the app. We’ll review what happened in a second, but let’s talk about the docker\\ncompose command first.\\nRunning a docker compose up command is the most common way to deploy a\\nCompose app. It reads through the Compose file in the local directory and runs the\\nDocker commands required to deploy the app. This includes building and pulling\\nimages, creating required networks and volumes, and starting all containers.\\nThe command you executed didn’t specify the name or location of the Compose file, so\\nDocker assumed it was called compose.yaml in the local directory. However, you can use\\nthe -f flag to point to a Compose file with a different name in a different directory. For'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 140}, page_content='9: Multi-container apps with Compose\\n134\\nexample, the following command will deploy the application defined in a Compose file\\ncalled sample-app.yml in the apps/ddd-book directory.\\n$ docker compose -f apps/ddd-book/sample-app.yml up --detach\\nNow that you’ve deployed the app, you can run regular docker commands to see the\\nimages, containers, networks, and volumes that Compose created.\\nRun the following command to see the image created for the web-fe service and the\\nimage pulled for the redis service.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nalpine\\nf773b35a95e1\\n8 days ago\\n61.4MB\\nmulti-container-web-fe\\nlatest\\n811f22c9edb7\\n2 minutes ago\\n99.7MB\\nDocker pulled the redis:alpine image from Docker Hub, but it used the Dockerfile to\\nbuild the multi-container-web-fe:latest image.\\nIf you look at the Dockerfile, you’ll see it pulls the python:alpine image, copies in the\\napp code, installs requirements, and sets the command to start the app.\\nFROM python:alpine\\n<<---- Base image\\nCOPY . /app\\n<<---- Copy app code into image\\nWORKDIR /app\\n<<---- Set working directory\\nRUN pip install -r requirements.txt\\n<<---- Install requirements\\nENTRYPOINT [\"python\", \"app/app.py\"]\\n<<---- Set the default app\\nNotice how the newly built image’s name is a combination of the project name and the\\nservice name. The project name is the name of the build context directory, which in our\\nexample is multi-container, and the service name is web-fe. Compose uses this format\\nto name all resources, and the following table shows the names it will give the resources\\nfor our sample app.\\nResource type\\nResource\\nName\\nService\\nweb-fe\\nmulti-container-web-fe-1\\nService\\nredis\\nmulti-container-redis-1\\nNetwork\\ncounter-net\\nmulti-container_counter-net\\nVolume\\ncounter-vol\\nmulti-container_counter-vol\\nList running containers to see the containers Compose created for the app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 141}, page_content='9: Multi-container apps with Compose\\n135\\n$ docker ps\\nID\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\n61..\\n\"python app/app.py\"\\nUp 35 mins\\n0.0.0.0:5001->8080/tcp..\\nmulti-container-web-fe-1\\n80..\\n\"docker-entrypoint..\"\\nUp 35 mins\\n6379/tcp\\nmulti-container-redis-1\\nAs you can see, the multi-container-web-fe-1 container is running the Python web\\napp and is mapped to port 5001 on all interfaces on the Docker host. We’ll connect to\\nthis later.\\nThe number at the end of the container names allows each service to have multiple\\nreplicas. For example, if the web-fe service had three replicas they would be called\\nmulti-container-web-fe-1, multi-container-web-fe-2, and multi-container-web-\\nfe-3.\\nRun the following commands to see the counter-net network and counter-vol\\nvolume.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n46100cae7441\\nmulti-container_counter-net\\nbridge\\nlocal\\n<Snip>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmulti-container_counter-vol\\n<Snip>\\nWith the application deployed, you can point a web browser at your Docker host on port\\n5001 to view it. You can connect to localhost:5001 if you’re running Docker Desktop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 142}, page_content='9: Multi-container apps with Compose\\n136\\nRefresh the page a few times and watch the counter increment. This is the app counting\\npage refreshes and storing the value on the volume in the Redis service.\\nCongratulations. You’ve successfully deployed a multi-container application using\\nDocker Compose!\\nManaging apps with Compose\\nIn this section, you’ll see how to stop, restart, delete, and get the status of Compose apps.\\nMake a note of how many times you’ve refreshed the page, and then run the following\\ncommand to shut the app down.\\n$ docker compose down\\n[+] Running 3/3\\n- Container multi-container-redis-1\\nRemoved\\n0.2s\\n- Container multi-container-web-fe-1\\nRemoved\\n0.2s\\n- Network multi-container_counter-net\\nRemoved\\n0.2s\\nThe output shows Docker deleting both containers and the network. However, it\\ndoesn’t mention the volume.\\nRun a docker volumes ls command to see if the volume still exists.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 143}, page_content='9: Multi-container apps with Compose\\n137\\n$ docker volume ls\\n<Snip>\\nlocal\\nmulti-container_counter-vol\\nThe volume still exists because Docker knows we store important information in\\nvolumes that we might want to keep when stopping and restarting apps. In our example,\\nthe redis service stored the refresh count in the volume, meaning we’ll see the same\\ncount when we redeploy the app in a later step.\\nDocker also keeps the images it built and pulled when it started the app. Feel free to run\\na docker images command to prove the images still exist.\\nLet’s explore a few other docker compose commands.\\nRun the following command to redeploy the app.\\n$ docker compose up --detach\\n<Snip>\\n[+] Running 3/3\\n- Network multi-container_counter-net\\nCreated\\n0.2s\\n- Container multi-container-redis-1\\nStarted\\n0.2s\\n- Container multi-container-web-fe-1\\nStarted\\n0.2s\\nNotice how it started much faster this time. This is because the images and volume\\nalready exist.\\nGo back to your browser and refresh the app. The refresh count should continue from\\nwhere you left it. This is because Redis stores the count in the /data directory, which\\nuses the volume Docker didn’t delete.\\nSwitch back to the CLI and check the current state of the app with a docker compose\\nps command.\\n$ docker compose ps\\nNAME\\nCOMMAND\\nSERVICE\\nSTATUS\\nPORTS\\nmulti-container-redis-1\\n\"docker-entrypoint..\"\\nredis\\nUp 33 sec\\n6379/tcp\\nmulti-container-web-fe-1\\n\"python app/app.py\"\\nweb-fe\\nUp 33 sec\\n0.0.0.0:5001->8080\\nThe output shows both containers, the commands they’re executing, their current state,\\nand the network ports they’re listening on.\\nRun a docker compose top to list the processes inside each container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 144}, page_content='9: Multi-container apps with Compose\\n138\\n$ docker compose top\\nmulti-container-redis-1\\nUID\\nPID\\nPPID\\n... CMD\\nlxd\\n12023\\n11980\\nredis-server *:6379\\nmulti-container-web-fe-1\\nUID\\nPID\\nPPID\\n... CMD\\nroot\\n12024\\n12002\\n0\\npython app/app.py python app/app.py\\nroot\\n12085\\n12024\\n0\\n/usr/local/bin/python app/app.py python app/app.py\\nThe PID numbers returned are the PID numbers as seen from the Docker host (not from\\nwithin the containers).\\nRun the following commands to stop the app and recheck its status.\\n$ docker compose stop\\n[+] Running 2/2\\n- Container multi-container-redis-1\\nStopped\\n0.4s\\n- Container multi-container-web-fe-1\\nStopped\\n0.5\\n$ docker compose ps -a\\nNAME\\nCOMMAND\\nSERVICE\\nSTATUS\\nPORTS\\nNAME\\nIMAGE\\n...\\nSERVICE\\nSTATUS\\nmulti-container-redis-1\\nredis:alpine\\n...\\nredis\\nExited (0) 25 seconds ago\\nmulti-container-web-fe-1\\nmulti-container-web-fe\\n...\\nweb-fe\\nExited (0) 25 seconds ago\\nThe app is down, but Docker hasn’t deleted the containers — it’s only stopped them.\\nRestart the app with the docker compose restart command.\\n$ docker compose restart\\n[+] Running 2/2\\n- Container multi-container-redis-1\\nStarted\\n0.1s\\n- Container multi-container-web-fe-1\\nStarted\\n0.1s\\nCheck the status of the app.\\n$ docker compose ls\\nNAME\\nSTATUS\\nCONFIG FILES\\nmulti-container\\nrunning(2)\\n/Users/nigelpoulton/temp/ddd-book/multi-container/compose.yaml\\nGo back to your browser and refresh the page again. The counter will continue from\\nwhere you left it because Docker didn’t delete the containers or the volumes. Even if\\nyour app doesn’t use volumes, it won’t lose data across container restarts.\\nCongratulations. You’ve deployed and managed a multi-container microservices app\\nusing Docker Compose.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 145}, page_content='9: Multi-container apps with Compose\\n139\\nBefore cleaning up and reviewing the commands, it’s important to understand that\\nthis was a simple example and that Docker Compose can deploy and manage far more\\ncomplex applications.\\nClean up\\nRun the following command to stop and delete the app. The --volumes flag will delete\\nall of the app’s volumes, and the --rmi all will delete all of its images.\\n$ docker-compose down --volumes --rmi all\\n[+] Running 6/6\\n- Container multi-container-web-fe-1\\nRemoved\\n0.2s\\n- Container multi-container-redis-1\\nRemoved\\n0.1s\\n- Volume multi-container_counter-vol\\nRemoved\\n0.0s\\n- Image multi-container-web-fe:latest\\nRemoved\\n0.1s\\n- Image redis:alpine\\nRemoved\\n0.1s\\n- Network multi-container_counter-net\\nRemoved\\n0.1s\\nDeploying apps with Compose – The commands\\n• docker compose up is the command to deploy a Compose app. It creates all\\nimages, containers, networks, and volumes the app needs. It expects you to call\\nthe Compose file compose.yaml, but you can specify a custom filename with the -f\\nflag. You’ll normally start the app in the background with the --detach flag.\\n• docker compose stop will stop all containers in a Compose app without deleting\\nthem. You can easily restart them with docker compose restart, and you\\nshouldn’t lose any data.\\n• docker compose restart will restart a stopped Compose app. If you make\\nchanges to the Compose file while it’s stopped, these changes will not appear in\\nthe restarted app. You need to redeploy the app to see any changes you made in the\\nCompose file.\\n• docker compose ps lists each container in the Compose app. It shows the current\\nstate, the command each container is running, and network ports.\\n• docker compose down will stop and delete a running Compose app. By default, it\\ndeletes containers and networks but not volumes and images.\\nChapter Summary\\nIn this chapter, you learned how to deploy and manage multi-container applications\\nusing Docker Compose.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 146}, page_content='9: Multi-container apps with Compose\\n140\\nCompose is fully integrated into the Docker toolset with its own docker compose sub-\\ncommand. It lets you define multi-container applications in declarative configuration\\nfiles and deploy them with a single command.\\nCompose files define all the containers, networks, volumes, secrets, and other configu-\\nrations an application needs. You then use the docker compose command to post the\\nCompose file to Docker, and Docker deploys it.\\nOnce you’ve deployed the app, you can manage its entire lifecycle using docker\\ncompose sub-commands.\\nDocker Compose is popular with developers, and the Compose file is an excellent\\nsource of application documentation as it defines all the services that make up the app,\\nthe images they use, the ports they expose, the networks and volumes they use, and\\nmuch more. As such, it can help bridge the gap between development and operations\\nteams. You should also treat Compose files as code and store them in version control\\nsystems.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 147}, page_content='10: Docker and AI\\nDocker offers two ways of deploying and running AI apps:\\n1. Docker Model Runner (preferred)\\n2. Containers\\nBoth methods run AI apps locally, making them suitable for companies with privacy\\nconcerns, that do not want unpredictable cloud costs, have latency-sensitive require-\\nments, and require full control over things like prompt customization and fine-tuning.\\nHowever, Docker Model Runner is the preferred method and will be the focus of this\\nchapter.\\nI’ve organized the chapter as follows:\\n• Docker Model Runner background\\n• Docker Model Runner architecture\\n• Install Docker Model Runner\\n• Explore Docker Model Runner\\n• Use Docker Model Runner with Compose\\n• Use Docker Model Runner with 3rd-party apps\\n• Running models in containers\\nThroughout the chapter, we’ll use the terms “LLMs”, “models, “AI models”, and “AI apps” to\\nmean the same thing.\\nDocker Model Runner background\\nDocker Model Runner (DMR) is a new technology, fully integrated with the Docker\\ntoolchain, that executes AI models directly on host machines rather than inside\\ncontainers. Yes… Docker Model Runner executes AI models outside of containers! This\\nis because containers cannot access the majority of AI acceleration hardware like GPUs,\\nNPUs, and TPUs that make AI models fast. This is because most AI acceleration devices\\nare proprietary, with their own drivers and SDKs, and it’s extremely hard for Docker\\nand the wider ecosystem to develop and maintain support for them all.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 148}, page_content='10: Docker and AI\\n142\\nYes, it’s possible for containers to access modern NVIDIA GPUs if you install the\\nNVIDIA Container Toolkit. However, this is complex to install and only works for CUDA-\\ncapable NVIDIA GPUs. By executing models outside of containers, Docker Model\\nRunner gives you the best of both worlds:\\n• Integration with Docker tools and the wider cloud native ecosystem\\n• Easier access to AI acceleration hardware\\nThe early releases of DMR work with NVIDIA GPUs on Windows hosts and the built-\\nin GPUs on Macs with Apple silicon. Future releases will support a broader range of AI\\nacceleration hardware.\\nNow that you know the background, let’s look at Docker Model Runner’s architecture.\\nDocker Model Runner Architecture\\nDMR executes models directly on host hardware, exposes them via OpenAI-compatible\\nendpoints, and integrates with the wider Docker toolchain and cloud native ecosystem.\\nFigure 10.1 shows the high-level architecture and major components.\\nFigure 10.1 - Docker Model Runner Architecture\\nYou can see Docker Model Runner at the bottom of the diagram in the center. It’s a host\\nprocess that wraps one or more runtimes, provides models with direct access to host'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 149}, page_content='10: Docker and AI\\n143\\nhardware, dynamically loads and unloads models based on demand, and serves them\\nvia OpenAI-compatible endpoints that applications can access from inside containers or\\nvia the network. The Docker CLI can pull and push models from Docker Hub and DMR\\nstores them in a local store for fast access.\\nLet’s dig a little deeper.\\nDMR is a host process separate from the Docker Engine. For Mac users, this means it runs\\noutside the Docker Desktop VM with direct access to hardware. It wraps a pluggable\\nruntime layer that allows you to choose the best runtime for your requirements. Runtime\\nis another word for the core inference engine that loads and executes models and provides\\ninference. Early releases use llama.cpp as the runtime, but future releases will support\\nadditional runtimes.\\nDMR exposes several API endpoints for model management and inference. The\\nmodel management endpoints allow you to query and manage models, whereas the\\ninference endpoints are OpenAI-compatible. Containers on the same host can access\\nthe endpoints via the special http://model-runner.docker.internal/ hostname, non-\\ncontainerized apps on the same host can reach them via the local Docker socket or the\\nhost’s loopback address on port 12434, and apps running on different hosts can access\\nthem via the DMR host’s IP or DNS name on port 12434.\\nThe initial versions of DMR use a Docker CLI plugin that provides the docker model\\ncommand. Docker Desktop automatically installs the plugin when you enable DMR,\\nbut future versions may integrate DMR functionality into core Docker commands\\nlike docker pull and docker run. If this happens, commands like docker pull and\\ndocker run will read the object manifest to know they’re working with models instead\\nof images or containers.\\nDocker Hub maintains a catalog of verified models below the ai namespace16. You can pull\\nthese in the same way you pull images, and DMR will store them in a local model store in\\nyour filesystem below ∼/.docker/models. As is normal for AI models, they are usually\\nseveral gigabytes in size. You can even push your own models to Docker Hub where they\\nare stored as a new (proposed) OCI artifact type called a model.\\nWe’ll get into more details and see all of this in action as you progress through the\\nchapter. However, a quick word on how DMR compares with other popular model\\nservers.\\nDocker Model Runner vs Ollama vs LM Studio\\nIf you’re already running local models, you’ll recognize similarities with tools like LM\\nStudio and Ollama.\\n16https://hub.docker.com/u/ai'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 150}, page_content='10: Docker and AI\\n144\\nFor example, they can all use llama.cpp as their core inference engine and can expose\\nmodels via OpenAI-style endpoints. This means they all offer similar core functionality\\nand performance. However, Docker Model Runner offers seamless integration with\\nDocker tools and the wider cloud native ecosystem.\\nWith these points in mind, you should seriously consider DMR if you’re:\\n• An existing Docker user who already runs local models\\n• An existing Docker user with plans to start running local models\\n• Already running local models and about to start using Docker for containers\\nIn all of these cases, switching to Docker Model Runner allows you to consolidate tools\\nand ecosystems.\\nHowever, early versions of Docker Model Runner may offer fewer features than some\\nof the alternatives, and you should always test new products against your current and\\nfuture requirements.\\nInstalling Docker Model Runner\\nYou’ll need all of the following to complete the examples:\\n• A Mac or Windows machine, preferably with Apple or NVIDIA GPUs\\n• Docker Desktop v4.41 or newer (includes Docker Compose v2.35)\\n• A clone of the book’s GitHub repo\\nDocker Model Runner also works on CPUs, meaning you can still use it if you don’t\\nhave a machine with supported GPUs. Models will just run slower.\\nYou can run the following command to clone the book’s GitHub repo:\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nChange into the dmr directory.\\n$ cd ddd-book/dmr\\nOpen Docker Desktop’s Settings page, click the Features in development tab, and\\ncheck the Enable Docker Model Runner and Enable host-side TCP support check-\\nboxes. Accept the default port of 12434 and then click the blue Apply & restart button\\nto activate your changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 151}, page_content='10: Docker and AI\\n145\\nChecking the Enable host-side TCP support option maps DMR to port 12434 on the\\nhost’s network interface so that local apps can access it on localhost:12434 and remote\\napps can access it from the network on the same port.\\nOnce you’ve enabled DMR, switch to the command line and verify it’s working.\\n$ docker model status\\nDocker Model Runner is running\\nStatus:\\nllama.cpp: running llama.cpp latest-metal (sha256:ad58230f548...) version: a0f7016\\nDMR is running and you can see it’s using llama.cpp as its core inference engine (run-\\ntime) which, in turn, is using Apple’s Metal API to give models access to my MacBook’s\\nGPUs. Future versions of DMR may support Apple’s MLX framework so that models\\ncan leverage Apple’s Neural Engine for even better performance. As the runtime layer is\\npluggable, things like MLX and support for other hardware can come through the use of\\ndifferent runtimes.\\nCongratulations. You’ve enabled Docker Model Runner and are ready to start using it.\\nExplore Docker Model Runner\\nIn this section, you’ll learn how to:\\n• Pull models from Docker Hub\\n• List and inspect models\\n• Test models\\n• Inspect the DMR APIs\\nPull models from Docker Hub\\nDocker maintains a catalog of models below the ai namespace17 on Docker Hub. These\\nare part of the Docker Verified Publisher Program, meaning they should be high quality and\\nup to date.\\nPoint your browser at https://hub.docker.com/catalogs/models and click through\\nthe available models. Clicking a particular model shows its model card with detailed\\nmodel info. Figure 10.2 shows the model card for the Mistral model. We’ll look more\\nclosely later in the chapter, but you can see it’s a verified model, you can see the model\\n17https://hub.docker.com/u/ai'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 152}, page_content='10: Docker and AI\\n146\\narchitecture, training cut-off date, model variants, and even benchmark info. However,\\nbenchmark info is from the original model publisher, and you should always perform\\nyour own testing to see how well a model performs for your specific requirements.\\nFigure 10.2 - Model info card\\nRun the following command to download a quantized version of a Gemma3 4B model.\\nQuantization is a way to reduce model size without losing too much model accuracy or\\nperformance. However, even quantized can be several gigabytes and can take a while to\\ndownload. Feel free to download a newer quantized version if available.\\n$ docker model pull ai/gemma3:4B-Q4_K_M\\nDownloaded: 18.10 MB...\\n<Snip>\\nModel pulled successfully\\nOnce the pull operation is complete, list your local models to see the one you down-\\nloaded.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 153}, page_content='10: Docker and AI\\n147\\n$ docker model ls\\nMODEL NAME\\nPARAMS\\nQUANTIZATION\\nARCHITECTURE\\nMODEL ID\\nSIZE\\nai/gemma3:4B-Q4_K_M\\n3.88 B\\nIQ2_XXS/Q4_K_M\\ngemma3\\n0b329b335467\\n2.31G\\nInspecting models\\nDMR automatically pulls images from Docker Hub where it stores and distributes them\\nas a new type of OCI artifact called a model. This model-spec18 is currently in draft and\\nmay change slightly.\\nRun the following command to inspect the manifest of the Gemma3 model you just\\npulled. The command connects to Docker Hub and inspects the manifest from Docker\\nHub and not the local copy you pulled.\\n$ docker manifest inspect ai/gemma3:4B-Q4_K_M | jq\\n{\\n\"schemaVersion\": 2,\\n\"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\\n<<--- Image manifest\\n\"config\": {\\n----┐\\n\"mediaType\": \"application/vnd.docker.ai.model.config.v0.1+json\", | Model config\\n\"size\": 372,\\n| descriptor\\n\"digest\": \"sha256:22273fdf4e6dbaf...af0e6569be41539\"\\n----┘\\n},\\n\"layers\": [\\n{\\n\"mediaType\": \"application/vnd.docker.ai.gguf.v3\",\\n----┐\\n\"size\": 2489757856,\\n| GGUF descriptor\\n\"digest\": \"sha256:09b370de51ad3...fc96ab2dc1adaa7\"\\n----┘\\n},\\n{\\n\"mediaType\": \"application/vnd.docker.ai.license\",\\n----┐\\n\"size\": 8346,\\n| License descriptor\\n\"digest\": \"sha256:a4b03d96571f0...dc90e3f960823e5\"\\n----┘\\n}\\n]\\n}\\nThe output shows three descriptors relating to the model config and its two layers, and\\nyou’ll recognize it if you’re familiar with the structure of OCI images.\\nWhen you pulled the model, DMR queried Docker Hub (OCI registry) for the requested\\nmodel, read its manifest, pulled the config and two layers, and stored them in the local\\nmodel store with filenames matching the SHAs. This means the config file and layer\\nfiles are in your local filesystem below ∼/.docker/models/blobs/sha256 and you can\\ninspect them with your favorite tools.\\n18https://github.com/docker/model-spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 154}, page_content='10: Docker and AI\\n148\\n$ ls -lh ~/.docker/models/blobs/sha256\\ntotal 13609568\\n-rw-r--r--@ 1\\n2.3G\\n09b370de51ad3bde8c3aea...667ddbafc96ab2dc1adaa7\\n<<---- model file (GGUF)\\n-rw-r--r--@ 1\\n372B\\n22273fd2f4e6dbaf5b5dae...308eb0faf0e6569be41539\\n<<---- model config JSON\\n-rw-r--r--@ 1\\n8.2K\\na4b03d96571f0ad98b1253...328909bdc90e3f960823e5\\n<<---- License\\nThe following command prints the model’s configuration from the local copy of the\\nconfig file. It shows the model format, quantization, parameters, architecture, size, and\\nmore. Yours may have a different SHA and filename.\\n$ cat ~/.docker/models/blobs/sha256/22273fdf4e6dbaf...af0e6569be41539 | jq\\n{\\n\"config\": {\\n\"format\": \"gguf\",\\n\"quantization\": \"IQ2_XXS/Q4_K_M\",\\n\"parameters\": \"3.88 B\",\\n\"architecture\": \"gemma3\",\\n\"size\": \"2.31 GiB\"\\n},\\n\"descriptor\": {\\n\"created\": \"2025-03-26T09:57:32.086694+01:00\"\\n},\\n\"rootfs\": {\\n\"type\": \"rootfs\",\\n\"diff_ids\": [\\n\"sha256:09b370de51ad3bde8c3aea3559a769a59e7772e813667ddbafc96ab2dc1adaa7\",\\n\"sha256:a4b03d96571f0ad98b1253bb134944e508a4e9b9de328909bdc90e3f960823e5\"\\n]\\n}\\n}\\nYou can see the same information with the docker model inspect command.\\nYou can also inspect the model’s GGUF file and license file. However, model files can be\\nlarge, and although they have a header with readable metadata, they also have a large\\nbody with the tensors that represent model parameters, including the weights and\\nbiases, which are not human-readable.\\nPackaging and storing models as OCI artifacts allows you to leverage the huge number\\nof existing public and private OCI registries that most companies already use to store all\\nof the following:\\n• Container images\\n• Signatures\\n• SBOMs\\n• OPA Policies'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 155}, page_content='10: Docker and AI\\n149\\n• Helm charts\\n• Wasm modules\\n• MCP tools\\nAdding AI models to this growing list reduces registry sprawl and makes AI models more\\naccessible to existing cloud-native tools and workflow pipelines.\\nTest your model\\nDMR offers two easy ways to test your models:\\n• The CLI\\n• Docker Desktop UI\\nThe CLI offers very basic testing capabilities with zero conversational history.\\nThe following example opens an interactive REPL (Read, Evaluate, Print, Loop) envi-\\nronment and asks the model two related questions. However, there’s no conversational\\nhistory, and it treats each question independently. I’ve clipped the responses as they can\\nbe quite long.\\n$ docker model run ai/gemma3:4B-Q4_K_M\\nInteractive chat mode started. Type \\'/bye\\' to exit.\\n> How long is a day on Mars?\\nA day on Mars, also known as a \"sol,\" is about **24 hours, 39 minutes, and 35 seconds** long...\\n> What about Venus?\\nOkay, let\\'s talk about Venus! It\\'s a truly fascinating and incredibly hostile planet, often\\ncalled Earth\\'s \"sister planet\" due to its similar size and composition. However, that\\'s\\nwhere the similarities largely end. Here\\'s a breakdown of key information about Venus:...\\nType /bye to return to your shell.\\nDocker Desktop offers a slightly better way to test.\\nOpen the Docker Desktop UI and click the Models tab in the left navigation bar. Click\\nthe model you want to test to open a chat session and then ask it the same questions.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 156}, page_content='10: Docker and AI\\n150\\nFigure 10.3 - Docker Desktop’s Model Chat Window\\nThis time, the environment has realized the two questions are related.\\nInspect the DMR API\\nDocker Model Runner exposes a set of native endpoints for model management and a\\nset of OpenAI-compatible endpoints for model interaction.\\nDMR endpoints\\n/models\\n<<---- GET\\n/models/create\\n<<---- POST\\n/models/{namespace}/{name}\\n<<---- GET and DELETE\\nOpenAI-compatible endpoints'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 157}, page_content='10: Docker and AI\\n151\\n/engines/llama.cpp/v1/models\\n<<---- GET\\n/engines/llama.cpp/v1/chat/completions\\n<<---- POST\\n/engines/llama.cpp/v1/completions\\n<<---- POST\\n/engines/llama.cpp/v1/embeddings\\n<<---- POST\\nLet’s craft an API request to DMR’s OpenAI-compatible chat/completions endpoint so\\nthat it asks the Gemma3 model we pulled earlier how long a Martian day is.\\nThe first thing we need to do is get the list of available models. We already pulled the\\nai/gemma3:4B-Q4_K_M, but it’s always worth querying DMR to ensure the OpenAI\\nendpoints refer to it by the same name.\\nRun the following curl command to get the list of local models and see their names.\\n$ curl -s localhost:12434/engines/v1/models | jq\\n{\\n\"object\": \"list\",\\n\"data\": [\\n{\\n\"id\": \"ai/gemma3:4B-Q4_K_M\",\\n\"object\": \"model\",\\n\"created\": 1742979452,\\n\"owned_by\": \"docker\"\\n}\\n]\\n}\\nGreat, DMR refers to it as ai/gemma3:4B-Q4_K_M.\\nNow, POST your question to DMR’s chat/completions endpoint.\\n$ curl -s http://localhost:12434/engines/v1/chat/completions \\\\\\n-H \"Content-Type: application/json\" \\\\\\n-d \\'{\\n\"model\": \"ai/gemma3:4B-Q4_K_M\",\\n\"messages\": [\\n{\\n\"role\": \"system\",\\n\"content\": \"Keep your responses to one sentence only.\"\\n},\\n{\\n\"role\": \"user\",\\n\"content\": \"How long is a day on Mars?\"\\n}\\n],\\n\"temperature\": 0.7,\\n\"max_tokens\": 500\\n}\\' | jq -r \\'.choices[0].message.content\\'\\nA day on Mars, also known as a sol, is approximately 24.6 hours long.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 158}, page_content='10: Docker and AI\\n152\\nIt worked. Let’s quickly step through the command.\\nThe curl command targets DMR’s /engines/v1/chat/completions endpoint. If your\\nDMR has multiple runtimes, you can target a specific one by including it between the\\nbase path and API version. For example, you’d use the following path to explicitly call\\nthe llama.cpp runtime:\\n/engines/llama.cpp/v1/chat/completions\\nThe -d flag indicates the data to send in the request body and includes all of the\\nfollowing:\\n• model: This is the name of the desired model\\n• messages: Includes the system prompt telling the model to give short answers, as\\nwell as the user prompt with the question\\n• temperature: Tells the model how creative to be (usually between 0-1, with 0\\nbeing predictable and 1 being very creative)\\n• max_tokens: Restricts the length of responses\\nNow that you understand how DMR works, let’s see how to integrate it with a Com-\\npose-based chatbot app.\\nUse Docker Model Runner with Compose\\nIn this section, you’ll use Compose to deploy a chatbot app that uses DMR as its\\ninference server.\\nYou’ll need Docker Desktop v4.41 or newer with Docker Model Runner enabled.\\nThe app is a multi-tier application with three services:\\n• frontend: Chat interface\\n• backend: Backend API\\n• dmr: Model server (DMR)\\nFigure 10.4 shows the chatbot architecture. The fronted service implements a Remix-\\nbased chatbot interface that you access on port 3000. This communicates with a FastAPI\\nbackend server over the project’s default network on port 8000. The backend API\\nserver calls DMR’s OpenAI-compatible chat/completions API with streaming enabled\\nand streams responses to the frontend.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 159}, page_content='10: Docker and AI\\n153\\nFigure 10.4 - Chatbot architecture\\nThe app’s Compose file is in the dmr folder and defines the three services from Figure\\n10.4.\\nservices:\\nfrontend:\\n----┐\\nbuild: ./frontend\\n|\\nports:\\n|\\n- \"3000:3000\"\\n| Frontend\\nenv_file:\\n| service\\n- .env\\n|\\ndepends_on:\\n|\\n- backend\\n----┘\\nbackend:\\n----┐\\nbuild: ./backend\\n|\\nports:\\n|\\n- \"8000:8000\"\\n| Backend\\nenv_file:\\n| service\\n- .env\\n|\\ndepends_on:\\n|\\n- dmr\\n----┘\\ndmr:\\n----┐\\nprovider:\\n|\\ntype: model\\n| DMR\\noptions:\\n|\\nmodel: ${LLM_MODEL_NAME} ----┘\\nLet’s step through the file.\\nThe frontend service builds an image from the Dockerfile and application code in the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 160}, page_content='10: Docker and AI\\n154\\n./frontend folder, exposes port 3000, loads environment variables from the local .env\\nfile, and will only start when the backend service is running.\\nThe backend service builds an image from the Dockerfile and code in the ./backend\\nfolder, listens on port 8000, loads the same environment variables from the same .env\\nfile, and will only start when the dmr service is running.\\nThe dmr service declares Docker Model Runner as part of the Compose app and uses\\nthe provider extension to tell DMR to download and use the model defined in the LLM_-\\nMODEL_NAME variable from the local .env file. You need Docker Compose v2.35 or newer\\nto leverage DMR like this.\\nThe local .env file defines the following two variables that tell the app how to connect to\\nDMR and which model to use:\\nMODEL_HOST=http://model-runner.docker.internal/engines/v1\\nLLM_MODEL_NAME=ai/gemma3:4B-Q4_K_M\\nYou can integrate with remote DMR instances by changing the MODEL_HOST variable\\nto point to your remote DMR instance like this: http://<host>:12434/engines/v1.\\nHowever, the provider extension doesn’t support remote instances yet, so you won’t be\\nable to declare dependencies on DMR. This may change in the future.\\nWhen you deploy the app, Docker will automatically create a network for the project\\ncalled default, build the images for the frontend and backend, and start all three ser-\\nvices. The dependencies ensure the dmr service will start first, then the backend service,\\nand finally the frontend. Docker will connect the frontend and backend services to\\nthe project’s default network so the frontend can send requests to the backend on port\\n8000. The backend will connect to the dmr service (the local instance of Docker Model\\nRunner) via HTTP requests to http://model-runner.docker.internal/engines/v1.\\nThis is a special hostname that all containers can use to access DMR.\\nChange into the dmr folder and run the following commands.\\nDeploy the app.\\n$ docker compose up --build --detach\\n[+] Building 3.3s (25/25) FINISHED\\n[+] Running 6/6\\n- backend\\nBuilt\\n0.0s\\n- frontend\\nBuilt\\n0.0s\\n- Network dmr_default\\nCreated\\n0.0s\\n- dmr\\nCreated\\n1.5s\\n- Container dmr-backend-1\\nStarted\\n0.4s\\n- Container dmr-frontend-1\\nStarted\\n0.2s\\nYou can see it’s built the frontend and backend images, created the project’s network,\\nand started the services in the expected order.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 161}, page_content='10: Docker and AI\\n155\\nOpen your browser to http://localhost:3000 and ask your chatbot some questions.\\nFigure 10.5 - Working chatbot\\nThe example proves the chatbot maintains a conversation history and infers context\\nfrom previous questions.\\nThe small text below the message box displays the name of the model DMR is using and\\nwill match the value of the LLM_MODEL_NAME environment variable in the .env file.\\nCongratulations. You used Compose to deploy a chatbot app that leverages an LLM via\\nDocker Model Runner!\\nUse Docker Model Runner with Open WebUI\\nIn theory, any OpenAI-compatible third-party app can leverage Docker Model Runner\\nvia its OpenAI-compatible endpoints.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 162}, page_content='10: Docker and AI\\n156\\nIn this section, you’ll combine Open WebUI19 with Docker Model Runner to create a\\npowerful and customizable local chatbot experience that looks and feels like commer-\\ncial-grade chatbots such as ChatGPT and Claude.\\nYou’ll need Docker Desktop v4.41 or newer with Docker Model Runner enabled. The\\nexample uses the gemma3:4B-Q4_K_M that you pulled earlier. If you haven’t pulled\\nthe model, DMR will pull it when you deploy the app. You can also experiment with\\ndifferent models.\\nYou’ll complete all of the following steps:\\n1. Check DMR status and local models\\n2. Install Open WebUI as a container\\n3. Connect to Open WebUI and use it\\nCheck DMR status and pull models\\nRun the following command to check the status of DMR.\\n$ docker model status\\nDocker Model Runner is running\\nStatus:\\nllama.cpp: running llama.cpp latest-metal (sha256:af30fb4847b...)\\nDownload a small quantized Qwen model.\\n$ docker model pull ai/qwen3:0.6B-Q4_K_M\\nDownloaded: 0.00 MB\\nModel pulled successfully\\nList models to make sure you have at least two models so you can switch between them\\nin the app.\\n$ docker model ls\\nMODEL NAME\\nPARAMS\\nQUANTIZATION\\nARCH\\nMODEL ID\\nSIZE\\nai/gemma3:4B-Q4_K_M\\n3.88 B\\nIQ2_XXS/Q4_K_M\\ngemma3\\n0b329b335467\\n2.3G\\nai/qwen3:0.6B-Q4_K_M\\n751.63 M\\nIQ2_XXS/Q4_K_M\\nqwen3\\n18e5114fc13b\\n456.11 MiB\\nFeel free to pull additional models.\\n19https://www.openwebui.com/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 163}, page_content='10: Docker and AI\\n157\\nInstall Open WebUI as a container\\nOpen WebUI is a popular AI platform that integrates with Ollama and OpenAI-\\ncompatible model servers to create powerful chatbot experiences. You can install it via\\npip or as a Docker container. We’ll use the following Compose file from the openwebui\\nfolder to install it as a container.\\nvolumes:\\nopen-webui:\\nservices:\\nopen-webui:\\nimage: ghcr.io/open-webui/open-webui:main\\nenvironment:\\n- DEFAULT_MODELS=${MODEL_NAME}\\n- WEBUI_AUTH=False\\n- OPENAI_API_KEY=${OPENAI_KEY}\\n- OPENAI_API_BASE_URL=${MODEL_HOST}\\nvolumes:\\n- open-webui:/app/backend/data\\nports:\\n- \"3001:8080\"\\nrestart: always\\ndepends_on:\\n- dmr\\ndmr:\\nprovider:\\ntype: model\\noptions:\\nmodel: ${MODEL_NAME}\\nThe open-webui service pulls the official Open WebUI image from GitHub Container\\nRegistry, configures it with four environment variables, mounts a volume so you don’t\\nlose your configuration every time you restart it, exposes the web interface on port 3001,\\nand declares a dependency on the dmr service.\\nThe dmr service tells Docker Model Runner to use the model defined in the MODEL_NAME\\nvariable. In our example, this will be the Qwen model you pulled earlier and DMR will\\nautomatically pull it if needed.\\nThere’s a local .env file defining the following variables:\\n• MODEL_HOST: Docker Model Runner base URL\\n• MODEL_NAME: Default model to use\\n• OPENAI_KEY: OpenAI API key (set to “na” as DMR doesn’t require it)\\nChange into the openwebui directory and deploy the app with the following command.\\nThe Open WebUI image is nearly 6GB in size and may take a while to download on a\\nslow internet connection.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 164}, page_content='10: Docker and AI\\n158\\n$ docker compose up\\n[+] Running 16/16\\n- open-webui Pulled\\n227.8s\\n<Snip>\\n[+] Running 4/4\\n- Network open-webui_default\\nCreated\\n0.0s\\n- Volume \"open-webui_open-webui\"\\nCreated\\n0.0s\\n- dmr\\nCreated\\n1.3s\\n- Container open-webui-open-webui-1\\nStarted\\n1.7s\\nAttaching to open-webui-1\\nopen-webui-1\\n| Loading...\\n<Snip>\\nFetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 278481.02it/s]\\n<Snip>\\nThe first time you start Open WebUI it downloads important files before serving the\\napp. You need to wait for these to download before connecting to the app.\\nCongratulations. You’ve installed Open WebUI as a Docker container and can connect\\nto it on http://localhost:3001. A 500: Internal Error message usually means\\nOpen WebUI is still downloading files in the background.\\nConnect to Open WebUI and use it\\nOpen a new browser tab to http://localhost:3001.\\nYou’ll need to create an admin account the first time you access it. Don’t worry though,\\neverything is stored locally and nothing leaves your computer.\\nOnce you’ve created your account, you’ll be automatically logged in and will see the\\nOpen WebUI interface as shown in Figure 10.6'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 165}, page_content='10: Docker and AI\\n159\\nFigure 10.6 - Open WebUI interface\\nOpen WebUI is a powerful tool, and I encourage you to investigate its features after\\nyou’ve completed the chapter. For now, Figure 10.6 highlights three important elements.\\nClicking the model selector dropdown lets you select from the models you’ve already\\ndownloaded to Docker Model Runner. If you download new models, they’ll appear in\\nthe list. Changing the model will update the active model shown in the middle of the\\nscreen. Finally, you talk with the chatbot via the prompt box.\\nHowever, before asking your chatbot any questions, I recommend you give it a cus-\\ntomized system prompt so that it responds in a way that’s useful to you. A system prompt\\nis a set of instructions you give the AI model to help it respond in ways that are helpful\\nto you.\\nTo do this, click your user in the bottom left corner, choose Settings > General, and\\nenter a new system prompt. I used the following:\\nGive simple answers. Limit responses to two sentences. Never ask if you can help with anything\\nelse.\\nBe sure to click Save to apply your changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 166}, page_content='10: Docker and AI\\n160\\nNow, ask your chatbot some questions to see if it’s useful and maintains a conversational\\nhistory.\\nFigure 10.7 shows a very brief conversation asking how far away the moon is and then\\nthe sun. I phrased the second question to test if the chatbot is intelligent enough to rec-\\nognize it as a follow-up to the previous question. You can see the chatbot remembered\\nthe first question and gave a contextually appropriate answer for the second question.\\nFigure 10.7 - Conversational history\\nYou can also see that Open WebUI saved the conversation in the left navigation pane\\nand that the prompt box has options for executing code, voice recording, and much\\nmore. As previously mentioned, I recommend you play around with Open WebUI’s\\nadvanced features, as you can easily create a powerful local chatbot with many of the\\nfeatures of ChatGPT, Claude, and other advanced chatbot apps.\\nRunning models in containers\\nRunning models in containers is no longer recommended, and I’ve only included this\\nshort section for reference. I do not recommend you complete the example.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 167}, page_content='10: Docker and AI\\n161\\nAs previously stated, AI models run fastest on AI acceleration hardware like GPUs and\\nNPUs. However, exposing them inside containers is very difficult. So much so that\\nDocker containers can only access modern CUDA-capable NVIDIA GPUs, and even\\nthese require the complex installation of the NVIDIA Container Toolkit.\\nIn summary, if you run Docker on a host with CUDA-capable NVIDIA GPUs and install\\nthe NVIDIA Container Toolkit, you can run models inside containers and leverage\\nthe GPUs. If your host has NPUs, TPUs, or GPUs from another manufacturer, models\\ninside containers will run slowly on the host’s CPUs.\\nThe ai-compose folder has two Compose files to deploy a three-tier chatbot like the\\none you deployed in the Use Docker Model Runner with Compose section. The biggest\\ndifference is that this version talks to a containerized Ollama server instead of Docker\\nModel Runner. The two Compose files are:\\n• compose.yaml: Runs the model on CPUs\\n• gpu-compose.yaml: Runs the model on NVIDIA GPUs if you have NVIDIA GPUs\\nand have installed the NVIDIA Container Toolkit (outside of the scope of this\\nbook)\\nThe ollama service, shown below, replaces Docker Model Runner. It pulls a pre-created\\nimage that runs an Ollama server, executes a script to pull a Mistral model into the\\ncontainer, and provides inference. It stores the pulled model in the volume, defines a\\nhealthcheck, and sets some resource limits.\\nollama:\\nimage: nigelpoulton/gsd-book:chat-model\\nvolumes:\\n- ollama_data:/root/.ollama\\nenvironment:\\n- MODEL=${MODEL:-mistral:latest}\\nhealthcheck:\\n<Snip>\\ndeploy:\\nresources:\\nlimits:\\nmemory: 8G\\nYou can start and manage the app with the usual docker compose commands. However,\\nthe app maps to port 3000 on your host and will conflict with the chatbot from earlier in\\nthe chapter. If you want to run this app (not recommended), manually edit the Compose\\nfile to map it to a different port.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 168}, page_content='10: Docker and AI\\n162\\nClean up\\nCongratulations on completing the examples and running local models with Docker\\nModel Runner.\\nIf you followed the examples, you’ll have all of the following running and downloaded.\\n• Docker Model Runner and at least one downloaded model\\n• Two Compose apps (Open WebUI chatbot, and Remix chatbot)\\nRunning the following command from within the openwebui directory will delete the\\nOpen WebUI chatbot app along with its images, networks, and volumes. It will not stop\\nDMR or delete any local models.\\n$ docker compose down --rmi all --volumes\\n[+] Running 2/2\\n- Container openwebui-open-webui-1\\nRemoved\\n1.4s\\n- dmr\\nRemoved\\n0.0s\\n- Image ghcr.io/open-webui/open-webui:main\\nRemoved\\n1.0s\\n- Volume openwebui_open-webui\\nRemoved\\n0.1s\\n- Network openwebui_default\\nRemoved\\n0.2s\\nDon’t worry about the line saying dmr is removed. It’s removing the dmr Compose\\nservice and not disabling Docker Model Runner on the host.\\nChange into the dmr directory and run the same command if you want to delete the\\nRemix chatbot app from the Use Docker Model Runner with Compose section.\\nYou can list your downloaded models with docker model ls and delete them with\\ndocker model rm.\\nFinally, you can disable DMR in Docker Desktop by going to the Settings page, clicking\\nFeatures in development, and then unchecking the Enable Docker Model Runner\\ncheckbox.\\nDocker Model Runner – The commands\\n• docker model status shows if DMR is running and prints basic runtime\\ninformation\\n• docker model pull downloads models from Docker Hub or other OCI-compliant\\nregistries that support models as a mediaType\\n• docker model push pushes models to Docker Hub and other OCI-compliant\\nregistries that support models as a mediaType'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 169}, page_content='10: Docker and AI\\n163\\n• docker model ls lists the models pulled to your local model store\\n• docker model inspect shows detailed model information, including tag, format,\\narchitecture, quantization, and more\\n• docker model rm deletes models from your local store\\nChapter Summary\\nIn this chapter, you learned that Docker Model Runner (DMR) is the best way to run\\nlocal AI models with Docker. It runs as a host process outside of the Docker Engine and\\nexecutes models directly on host hardware rather than inside containers. This gives\\nit access to a wider range of AI acceleration hardware than containers. It dynamically\\nloads and unloads models based on demand and serves them via OpenAI-compatible\\nendpoints. It has a pluggable runtime layer that defaults to llama.cpp.\\nRight now, DMR is a feature of Docker Desktop and works on Mac and Windows.\\nHowever, it will soon be integrated with Docker CE so that we can use it on Linux and\\nas part of CI/CD pipelines.\\nDMR is tightly integrated with the Docker CLI, the Docker API, Docker Hub, Docker\\nCompose, the Docker MCP Toolkit, and more. You learned how to pull models from\\nDocker Hub, list and inspect models, run models, and integrate DMR with Compose\\nand 3rd-party off-the-shelf apps.\\nYou can still run model servers like Ollama inside of containers, but these will usually\\nbe slower than DMR as they have access to a smaller pool of supported AI acceleration\\nhardware.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 170}, page_content='11: Docker and Wasm\\nWasm (WebAssembly) is driving the third wave of cloud computing, and Docker is\\nevolving to take advantage.\\nWe built the first wave on virtual machines (VMs), the second on containers, and\\nwe’re building the third on Wasm. Each wave drives smaller, faster, and more secure\\nworkloads, and all three are working together to drive the future of cloud computing.\\nIn this chapter, you’ll write a simple Wasm application and use Docker to containerize\\nand run it in a container. The goal is to introduce you to Wasm and show you how easy\\nit is to work with Docker and Wasm together.\\nThe terms Wasm and WebAssembly mean the same thing, and we’ll use the term Wasm.\\nI’ve divided the chapter as follows:\\n• Pre-reqs\\n• Intro to Wasm\\n• Write a Wasm app\\n• Containerize a Wasm app\\n• Deploy a Wasm app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 171}, page_content='11: Docker and Wasm\\n165\\nPre-reqs\\nYou’ll need all of the following if you plan on following along:\\n• Docker Desktop 4.37+ with Wasm enabled\\n• Rust 1.82+ with the Wasm target installed\\n• Spin 3.1+\\nAt the time of writing, support for Wasm is a beta feature in Docker Desktop and doesn’t\\nwork with Multipass Docker VMs. This may change in the future. It also means there’s a\\nhigher risk of bugs. I’ve tested the examples in this chapter on Docker Desktop 4.37.0.\\nConfigure Docker Desktop for Wasm\\nOpen the Docker Desktop UI, click the Settings icon at the top right, and make sure Use\\ncontainerd for pulling and storing images is selected on the General tab. Next, click\\nthe Features in development tab, select the Enable Wasm option and click the blue\\nApply & restart button.\\nfigure 11.2 shows some of the settings.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 172}, page_content=\"11: Docker and Wasm\\n166\\nFigure 11.2 - Docker Desktop Wasm settings\\nInstall Rust and configure for Wasm\\nSearch the web for how to install Rust and follow the instructions for your platform.\\nOnce you’ve installed Rust, run the following command to install the wasm32-wasip1\\ntarget so that Rust can compile to Wasm.\\n$ rustup target add wasm32-wasip1\\ninfo: downloading component 'rust-std' for 'wasm32-wasip1'\\ninfo: installing component 'rust-std' for 'wasm32-wasip1'\\nInstall Spin\\nSpin is a Wasm framework and runtime that makes building and running Wasm apps\\neasy.\\nSearch the web for how to install Fermyon spin and follow the instructions for your\\nsystem.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 173}, page_content='11: Docker and Wasm\\n167\\nRun the following command to verify the installation.\\n$ spin --version\\nspin 3.1.0 (1aa89da 2024-12-18)\\nYou’re ready to build and run Wasm apps on your local machine.\\nIntro to Wasm and Wasm containers\\nWasm is a new type of application that is smaller, faster, and more portable than tradi-\\ntional Linux containers. However, traditional Linux containers can do a lot more than\\nWasm apps. For example, Wasm apps are currently great for AI workloads, serverless\\nfunctions, plugins, and edge devices, but not so good for complex networking or heavy\\nI/O.\\nHowever, Wasm is evolving fast and may become better at other workloads in the\\nfuture.\\nDigging a little deeper…\\nAs we’re about to see, Wasm is a new virtual machine architecture that programming\\nlanguages compile to. So, instead of compiling apps to Linux on ARM or Linux on\\nAMD, you compile them to Wasm and they’ll run on any system with a Wasm runtime.\\nFortunately, Docker Desktop ships with several Wasm runtimes.\\nRun the following command to see the list of Wasm runtimes installed as part of your\\nDocker Desktop environment. The first time you run the command, it will download\\nthe image.\\n$ docker run --rm -i --privileged --pid=host jorgeprendes420/docker-desktop-shim-manager:latest\\nio.containerd.wasmtime.v1\\nio.containerd.wws.v1\\nio.containerd.slight.v1\\nio.containerd.wasmer.v1\\nio.containerd.spin.v2\\nio.containerd.lunatic.v1\\nio.containerd.wasmedge.v1\\nMy installation has seven Wasm runtimes, including the io.containerd.spin.v2\\nruntime we’ll use in the examples.\\nThese Wasm runtimes allow containerd to deploy and manage Wasm containers. A Wasm\\ncontainer is a Wasm binary running inside a minimal scratch container so that you can\\nbuild, ship, and run them with familiar Docker tools such as the docker run command\\nand Docker Hub.\\nTalk is cheap, though. Let’s see it in action.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 174}, page_content='11: Docker and Wasm\\n168\\nWrite a Wasm app\\nIn this step, you’ll use spin to create a simple web server and compile it as a Wasm app.\\nIn a later step, you’ll build, share, and run the app as a Wasm container.\\nChange into a new directory and then run the following command to create a new\\nWasm app called hello-world. Respond to the prompts as shown in the example.\\n$ spin new hello-world -t http-rust\\nDescription: Wasm app\\nHTTP path: /hello\\nThe command creates a new hello-world directory and scaffolds a simple Rust-based\\nweb app. Change into this directory and inspect the app files. If you don’t have the tree\\ncommand, you can run an ls -l for similar results.\\n$ cd hello-world\\n$ tree\\n.\\n├──Cargo.toml\\n├──spin.toml\\n└──src\\n└──lib.rs\\nWe’re only interested in the spin.toml and src/lib.rs files.\\nEdit the src/lib.rs file and change the text inside the double quotes as shown in the\\nfollowing snippet. This configures the app to display Docker loves Wasm.\\nuse spin_sdk::http::{IntoResponse, Request, Response};\\n<Snip>\\nOk(http::Response::builder()\\n.status(200)\\n.header(\"content-type\", \"text/plain\")\\n.body(\"Docker loves Wasm\")?)\\n<<---- Change text inside quotes\\n.build())\\n}\\nOnce you’ve saved your changes, run a spin build command to compile the app as a\\nWasm binary.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 175}, page_content='11: Docker and Wasm\\n169\\n$ spin build\\nBuilding component hello-world with `cargo build --target wasm32-wasip1 --release`\\n<Snip>\\nFinished building all Spin components\\nIf you look at the first line of the output, you’ll see it’s running a more complex cargo\\nbuild command that compiles the app as a Wasm binary.\\nRun another tree command to see the Wasm binary.\\n$ tree\\n<Snip>\\n└──target\\n└──wasm32-wasip1\\n└──release\\n└──hello_world.wasm\\nThe output is much longer this time, and I’ve trimmed the example in the book so you\\nonly see the hello_world.wasm binary. This is the Wasm app, and it will run on any\\nsystem with the spin Wasm runtime.\\nYou’ll containerize the app in the next section, but you should test it works before\\nproceeding.\\nRun a spin up command to start the app using the local spin runtime you installed\\nearlier.\\n$ spin up\\nLogging component stdio to \".spin/logs/\"\\nServing http://127.0.0.1:3000\\nAvailable Routes:\\nhello-world: http://127.0.0.1:3000/hello\\nPoint your browser to http://127.0.0.1:3000/hello and make sure the app works.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 176}, page_content='11: Docker and Wasm\\n170\\nFigure 11.3 - Wasm app running locally\\nCongratulations. You just built a simple web server, compiled it to Wasm, and executed\\nit locally using spin! In the next section, you’ll containerize it and run it in Docker.\\nPress Ctrl-C to kill the app.\\nContainerize a Wasm app\\nDocker Desktop lets you containerize Wasm apps so you can use familiar Docker tools\\nto push and pull them to OCI registries and run them inside containers.\\nAs always, you need a Dockerfile that tells Docker how to package the app as an image.\\nCreate a new file called Dockerfile in your current directory and populate it with the\\nfollowing three lines.\\nFROM scratch\\nCOPY /target/wasm32-wasip1/release/hello_world.wasm .\\nCOPY spin.toml .\\nThe file references the scratch empty base image because Wasm containers don’t need a\\nLinux OS.\\nThe two COPY instructions copy the hello_world.wasm Wasm app and the spin.toml\\nfile into the image.\\nIf you look closely, you’ll see that the spin.toml file expects the Wasm app to be in the\\ntarget/wasm32-wasip1/release/ directory. However, the second COPY instruction'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 177}, page_content='11: Docker and Wasm\\n171\\nplaces it in the root folder. This means we’ll need to update the spin.toml file so\\nit knows where to find the app after the Dockerfile copies it into the image’s root\\ndirectory.\\nEdit the spin.toml file and remove the leading path for the source line as shown.\\n<Snip>\\n[component.hello-world]\\nsource = \"hello_world.wasm\"\\n<<---- Remove any leading directories so it looks like this\\n<Snip>\\nSave your changes.\\nRun the following command to containerize the Wasm app. Be sure to tag the image\\nwith your own Docker Hub username instead of mine.\\n$ docker build \\\\\\n--platform wasi/wasm \\\\\\n--provenance=false \\\\\\n-t nigelpoulton/ddd-book:wasm .\\nThe --platform wasi/wasm flag sets the image as a Wasm image.\\nSome older versions of Docker have an older builder and will fail. If this happens, try\\nrunning the same command, but change the first line to docker buildx build \\\\.\\nList the images on your system.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nwasm\\n7b55889f1006\\n28 seconds ago\\n104kB\\nSee how the Wasm image looks like a regular image, just smaller.\\nYou can push and pull the image to Docker Hub and other OCI registries as normal.\\nThe following command pushes the image to one of my repos in Docker Hub. Be sure to\\ntag the image with your own Docker username.\\n$ docker push nigelpoulton/ddd-book:wasm\\nThe push refers to repository [docker.io/nigelpoulton/ddd-book]\\n301823195c36: Pushed\\n8966226af76a: Pushed\\nwasm: digest: sha256:7b55889f1006285ed6c394dcc7a56aca8955c107587b2216340e592299b8ae4c size: 695'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 178}, page_content='11: Docker and Wasm\\n172\\nIf you look at Docker Hub, you can see it’s recognized it as a wasi/wasm image. You’ll\\nalso see there’s no vulnerability analysis data. This is because image scanning tools can’t\\nanalyze Wasm images yet.\\nFigure 11.4 - Wasm image on Docker Hub\\nRun a Wasm container\\nNow that you’ve packaged the Wasm app as an OCI image and pushed it to a registry,\\nyou can run it as a container.\\nThe following command runs it in a new container called wasm-ctr and maps it to\\nport 5556 on your Docker host. The --runtime flag makes sure Docker executes the\\ncontainer with the spin Wasm runtime. Older versions of Docker Desktop may not have\\nthe spin runtime and will fail.\\n$ docker run -d --name wasm-ctr \\\\\\n--runtime=io.containerd.spin.v2 \\\\\\n--platform=wasi/wasm \\\\\\n-p 5556:80 \\\\\\nnigelpoulton/ddd-book:wasm /\\nYou can check it’s running with a regular docker ps command.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 179}, page_content='11: Docker and Wasm\\n173\\nConnect your browser to http://localhost:5556/hello to see the app.\\nFigure 11.5 - Wasm app running in container\\nCongratulations, your Wasm app is running inside a Wasm container.\\nClean up\\nRun the following commands to delete the container and the local image. Use your own\\nimage name when deleting the image.\\n$ docker rm wasm-ctr -f\\nwasm-ctr\\n$ docker rmi nigelpoulton/ddd-book:wasm\\nUntagged: nigelpoulton/ddd-book:wasm\\nDeleted: sha256:7b55889f1006285ed6c394dcc7a56aca8955c107587b2216340e592299b8ae4c\\nYou’ll still have a copy of the image on Docker Hub and the spin app in your local\\nfilesystem. Feel free to delete these as well.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 180}, page_content='11: Docker and Wasm\\n174\\nChapter summary\\nIn this chapter, you containerized a Wasm app and ran it in a Wasm container.\\nWasm is a new technology driving a new wave of cloud computing. Wasm apps are\\nsmaller, faster, more secure, and more portable than traditional Linux containers.\\nHowever, they’re not as flexible. For example, at the time of writing, Wasm apps aren’t\\ngreat for apps with heavy I/O requirements or complex networking. This will change\\nquickly as the Wasm ecosystem is evolving fast.\\nFortunately, Docker already works with Wasm, and Docker Desktop ships with a\\nfew popular Wasm runtimes. This means you can use industry-standard tools such as\\ndocker build and docker run to containerize and run Wasm apps. You can even push\\nthem to OCI registries such as Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 181}, page_content='12: Docker Swarm\\nThis chapter that shows you how to deploy a multi-node Swarm cluster and how to run\\napps on it.\\nIt’s a smaller chapter than in previous editions because Swarm is declining in popularity\\nand is no longer core to modern Docker workflows. If you need more of a deep dive,\\nyou can access the longer version in the swarm-chapters folder of the book’s GitHub\\nrepo. I’ve rewritten this shorter chapter to make way for adding the Docker and AI\\nchapter without increasing the cost of the book.\\nI’ve divided this chapter as follows:\\n• Swarm primer\\n• Build a swarm\\n• Deploy a Swarm app\\nThroughout the chapter, we’ll use Swarm with a capital “S” to refer to the Docker Swarm\\norchestration technology, and we’ll use swarm with a lower case “s” to refer to a cluster\\nof Docker nodes.\\nSwarm primer\\nThe orchestration wars were back in the mid-2010s when technologies like Docker\\nSwarm, HashiCorp Nomad, Mesosphere DC/OS, and Kubernetes battled it out to see\\nwhich would be crowned the de facto container orchestration platform. Fast forward to\\nnow, and it’s clear that Kubernetes came out on top and has the largest and most vibrant\\necosystem. However, Docker Swarm continues to have small followings and can be\\nbetter than Kubernetes for certain use cases. For example, Docker Swarm can be a great\\nsolution for small businesses with small requirements that don’t need the steep learning\\ncurve and overheads of a full Kubernetes environment.\\nWith this in mind, Docker Swarm is two things:\\n1. A secure cluster of Docker nodes (swarm with a little “s”)\\n2. An intelligent application orchestrator (Swarm with a big “S”)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 182}, page_content='12: Docker Swarm\\n176\\nAs you’re about to see, a swarm is a cluster of Docker nodes with one or more manager\\nnodes and optional worker nodes. Managers run the control plane services that secure\\nthe cluster and provide the orchestration intelligence. Workers run user apps. Both\\ntypes of nodes can be physical machines, VMs, cloud instances, and more. The only\\nrequirements are that they run Docker and can communicate over reliable networks.\\nBy default, swarm managers run user apps and control plane services. This is fine for lab\\nenvironments, but you should probably dedicate them to control plane services in busy\\nproduction environments.\\nBuild a swarm\\nIn this section, you’ll build two or more Docker nodes into a highly available swarm.\\nI recommend you go to http://https://labs.play-with-docker.com/ and spin up a\\nfew Docker nodes to follow along. You can also use tools like Multipass and VirtualBox\\nto create local VMs and install Docker on them. However, I do not recommend Docker\\nDesktop for this chapter as it only gives you a single Docker node.\\nI’ll build the swarm shown in Figure 12.1 with three managers and two workers.\\nYour swarm can be different, but you should consider the following for production\\nenvironments:\\n• Three managers spread across availability zones for high availability\\n• Enough workers to handle application requirements\\nFigure 12.1 - Five-node swarm'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 183}, page_content='12: Docker Swarm\\n177\\nI’ve configured DNS name resolution so that nodes can communicate via name, and I’ve\\nensured port 2377 isn’t blocked on my network.\\nYou’ll complete the following steps to build your swarm:\\n• Initialize the first swarm manager\\n• Add workers (optional)\\n• Add additional managers\\nIf you only have a small lab, you can build a swarm with just two managers.\\nInitialize your swarm\\nLog on to the node you want to make your first manager and run the following com-\\nmand. If the node has multiple IPs, you’ll be prompted to use the --advertise-addr flag.\\nIf this happens, use the node’s primary IP address.\\n$ docker swarm init\\nSwarm initialized: current node (b8slc7l29tgdetxgy8acy1k1q) is now a manager.\\nTo add a worker to this swarm, run the following command:\\ndocker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nCongratulations. You have a single-node swarm.\\nAdd workers\\nAdding worker nodes is optional, as your managers will also run user apps. Only add\\nworkers if your lab has enough nodes and resources.\\nIf you want to add workers, copy the docker swarm join command from the previous\\noutput and paste it into the nodes you want as workers. Be sure to copy the entire\\ncommand, including the join token.\\nwrkr-1\\n$ docker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nThis node joined a swarm as a worker.\\nwrkr-2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 184}, page_content='12: Docker Swarm\\n178\\n$ docker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nThis node joined a swarm as a worker.\\nSwitch back to your manager node and run the following command to see your swarm.\\n$ docker node ls\\nMANAGER\\nENGINE\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nSTATUS\\nVERSION\\nb8slc7l29tgdetxgy8acy1k1q *\\nnode1\\nReady\\nActive\\nLeader\\n27.3.1\\nw3e321uxty2quuqnsk1w19kfc\\nnode4\\nReady\\nActive\\n27.3.1\\nkbodotf68tz8dne2ktk1g5mt4\\nnode5\\nReady\\nActive\\n27.3.1\\nGreat. You’ve got one manager and two workers. Managers have either Leader or\\nReachable in the MANAGER STATUS column, whereas workers leave this column empty.\\nAdd managers for high availability\\nMost production swarms run three managers for high availability. This means one\\nmanager can fail and Swarm operations will continue via the surviving managers.\\nHowever, this is cluster availability and not application availability. For example, if the\\nfailed manager was running the only instance of a database, that database will be\\nunavailable.\\nRun the following command from your manager node to extract the command for\\nadding more managers.\\n$ docker swarm join-token manager\\nTo add a manager to this swarm, run the following command:\\ndocker swarm join --token SWMTKN-1-2f4s47lja0z1ddkgv...6ytm3qnq9bu8uei9stiu 172.31.40.192:2377\\nCopy the long docker swarm join command and run it on the nodes you want to add\\nas additional managers.\\nOnce you’ve added all your managers and workers, run another docker node ls to see\\nyour swarm. You can run it from any manager node.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 185}, page_content='12: Docker Swarm\\n179\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\nENGINE VER\\nb8slc7l29tgdetxgy8acy1k1q *\\nnode1\\nReady\\nActive\\nLeader\\n27.3.1\\ny43jr1d754pbjv3arlhpn9pqw\\nnode2\\nReady\\nActive\\nReachable\\n27.3.1\\nk1npnfxr7ykueac4jovmyiv0b\\nnode3\\nReady\\nActive\\nReachable\\n27.3.1\\nw3e321uxty2quuqnsk1w19kfc\\nnode4\\nReady\\nActive\\n27.3.1\\nkbodotf68tz8dne2ktk1g5mt4\\nnode5\\nReady\\nActive\\n27.3.1\\nNotice how one of the managers is showing as the Leader and the other two as Reach-\\nable. This is because Swarm operates an active/passive multi-manager high-availability\\nmodel where one manager controls the cluster and the others provide backup. The\\nasterisk (*) indicates the manager you executed the command from.\\nYour swarm is ready to run apps.\\nDeploy Swarm app\\nIn this section, you’ll deploy an app to your swarm and see Swarm’s orchestration\\ncapabilities. These include scheduling apps across cluster nodes, scaling apps up and\\ndown, self-healing from app failures, and performing rolling updates.\\nThe app\\nFigure 12.2 shows the application you’ll deploy. It’s a multi-container microservices\\napplication with:\\n• Two services (web-fe and redis)\\n• An encrypted overlay network (counter-net)\\n• A volume (counter-vol)\\n• A published port (5001)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 186}, page_content='12: Docker Swarm\\n180\\nFigure 12.2 - The sample app\\nTerminology: Throughout the remainder of the chapter, we’ll use the\\nterm service to refer to the Docker service object that manages one or more\\nidentical containers in a Swarm app. We’ll use the terms container and replica\\ninterchangeably.\\nLog on to a swarm manager and clone the book’s GitHub repo.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nChange into the ddd-book/swarm-new directory.\\n$ cd ddd-book/swarm-new\\nThe application’s Compose file defines a network called counter-net, a volume called\\ncounter-vol, and two services called web-fe and redis.\\nI’ve annotated the listing to draw your attention to the major parts.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 187}, page_content='12: Docker Swarm\\n181\\nnetworks:\\n----┐\\ncounter-net:\\n|\\ndriver: overlay\\n| Deploy an encrypted overlay network called *counter-net*\\ndriver_opts:\\n|\\nencrypted: \\'yes\\'\\n----┘\\nvolumes:\\ncounter-vol:\\n<<--- Create a volume called *counter-vol*\\nservices:\\nweb-fe:\\n----┐\\nimage: nigelpoulton/ddd-book:swarm-app\\n|\\ncommand: python app.py\\nw\\ndeploy:\\ne\\nreplicas: 4\\nb\\n<<---- Deploy four replicas\\nupdate_config:\\n-\\n<<---- Next 3 lines define how to update the app\\nparallelism: 2\\nf\\n<<---- Update two replicas at a time\\ndelay: 10s\\ne\\n<<---- Wait 10 seconds after each pair\\nfailure_action: rollback\\n<<---- Rollback if there\\'s a failure\\nrestart_policy:\\ns\\ncondition: on-failure\\ne\\n<<---- Restart replicas if they fail\\ndelay: 5s\\nr\\n<<---- Wait five seconds between restart attempts\\nmax_attempts: 3\\nv\\n<<---- Only try three restarts\\nwindow: 120s\\ni\\n<<---- Give up after trying for two minutes\\nnetworks:\\nc\\n- counter-net\\ne\\n<<---- Attach to the *counter-net* network\\nports:\\n|\\n- \"5001:8080\"\\n----┘\\n<<---- Map the app to 5001 on the host\\nredis:\\n----┐\\n<<---- Redis service\\nimage: \"redis:alpine\"\\n|\\nnetworks:\\n|\\ncounter-net:\\n|\\n<<---- Join the *counter-net* network\\nvolumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\n<<---- Mount the *counter-vol* volume to\\ntarget: /app\\n----┘\\n<<---- /data in the container\\nLet’s step through it.\\nThe networks key defines an encrypted overlay network called counter-net, the\\nvolumes key defines a volume called counter-vol, and the services block defines two\\nservices.\\nThe web-fe service pulls an image from Docker Hub, sets the start command for\\neach replica, and tells Swarm to deploy four identical containers for this service. The\\ndeploy.update_config block tells Swarm how to perform updates whenever a new\\nimage or config change occurs. This file tells Swarm to update two replicas in parallel,\\nwait 10 seconds before updating the next two, and perform a rollback if it encounters\\nfailures. The deploy.restart_policy block tells Swarm to restart replicas if they fail,\\nto wait five seconds after each restart attempt, to attempt a maximum of three restarts,\\nand to stop trying after two minutes. It joins all replicas to the counter-net network and\\nmaps port 8080 on each replica to 5001 on the host the replica is running on.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 188}, page_content='12: Docker Swarm\\n182\\nThe redis service pulls an image from Docker Hub, joins the counter-net network,\\nand mounts the counter-vol volume to /data in its container.\\nEncrypting the network keeps application traffic private but incurs a performance\\npenalty that varies based on factors such as traffic type and traffic flow. However, it’s\\nusually around 10%, but you should perform your own testing.\\nDeploy the app\\nA vital part of Swarm is the concept of desired state. This is jargon for what your app\\nshould look like and is defined in the Compose file. In our example, desired state can be\\nsummarised as four replicas of the web-fe service, a single replica of the redis service,\\nand all the networks, volumes, and port mappings.\\nYou’ll need to run the commands in this section from the ddd-book/swarm-new folder of\\nthe manager you downloaded the book’s GitHub repo to.\\nRun the following command to deploy the app and call it ddd.\\n$ docker stack deploy -c compose.yaml ddd\\nCreating network ddd_counter-net\\nCreating volume ddd_counter-vol\\nCreating service ddd_web-fe\\nCreating service ddd_redis\\nSwarm has deployed the app and observed state matches desired state — you asked for four\\nreplicas of the web-fe service and a single replica of the redis service, and that’s what\\nyou’ve got.\\nRun the following commands to confirm this.\\n$ docker stack ps ddd\\nDESIRED\\nCURRENT\\nID\\nNAME\\nIMAGE\\nNODE\\nDESIRED\\nSTATE\\npgeupeqyqg5t\\nddd_redis.1\\nredis:alpine\\nwrk2\\nRunning\\nRunning 8 min\\nqbtkiz1p9v1n\\nddd_web-fe.1\\nnigelpoulton/ddd-book:swarm-app\\nwrk1\\nRunning\\nRunning 8 min\\nwbs2ndy22xhh\\nddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nRunning\\nRunning 8 min\\nskqz1mbreluo\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 min\\nsg5u9b6t8m44\\nddd_web-fe.4\\nnigelpoulton/ddd-book:swarm-app\\nmgr3\\nRunning\\nRunning 8 min\\n$ docker stack services ddd\\nID\\nNAME\\nMODE\\nREPLICAS\\nIMAGE\\nPORTS\\notr7927s9m1s\\nddd_redis\\nrepl\\n1/1\\nredis:alpine\\nrsm3x02o9fwc\\nddd_web-fe\\nrepl\\n4/4\\nnigelpoulton/ddd-book:swarm-app\\n*:5001->8080\\nIf you look closely, you’ll see that Swarm has evenly balanced the four web-fe replicas\\nacross your nodes. You can also see the web-fe service is publishing port 5001.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 189}, page_content='12: Docker Swarm\\n183\\nPoint your browser to the IP address of one of your Swarm nodes on port 5001.\\nFigure 12.3\\nManage the app\\nYou can manage Swarm apps in two ways:\\n• Imperatively\\n• Declaratively\\nThe imperative method is where you run Docker CLI commands to make changes. For\\nexample, you can use the docker service scale command to increase and decrease the\\nnumber of service replicas.\\nThe declarative method is the preferred method, where you make all changes via the\\nCompose file. For example, if you want to change the number of replicas for a service,\\nyou edit the Compose file and run another docker stack deploy command.\\nThe following example demonstrates why you should manage Swarm apps declaratively.\\nImagine you’ve deployed an app from a Compose file that defines reporting and catalog services.\\nIt’s currently running one replica of the reporting service, but it’s year-end and demand on the\\nreporting service has gone through the roof. A colleague decides to run an imperative docker\\nservice scale command to increase the number of reporting replicas to 10. This fixes the\\nissue, but the observed state of the app no longer matches the desired state defined in its Compose\\nfile — the Compose file only defines one replica, but there are 10 on the cluster. Later in the\\nday, you roll out a new version of the catalog service by specifying a new image version in\\nthe Compose file and running a docker stack deploy command. This pushes the updated\\nCompose file to Swarm as your new desired state, and Swarm compares it to the observed state of'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 190}, page_content='12: Docker Swarm\\n184\\nthe cluster. When it does this, it sees you’ve requested a new version of the app and schedules the\\nupdates. However, it will also reduce the number of replicas from 10 down to 1, as the Compose\\nfile wasn’t used to increase the count to 10. This will cause the reporting service to start running\\nslowly again.\\nThis is why you should make all changes declaratively via your Compose files, and you\\nshould manage your Compose files in a version control system.\\nWith this in mind, let’s complete the following as a single task:\\n• Increase the number of web-fe replicas from 4 to 10\\n• Update the web-fe service to the newer swarm-appv2 image\\nYou know you should do this declaratively, so let’s edit the following lines in the Com-\\npose file.\\n<Snip>\\nservices:\\nweb-fe:\\nimage: nigelpoulton/ddd-book:swarm-appv2\\n<<---- changed to swarm-appv2\\ncommand: python app.py\\ndeploy:\\nreplicas: 10\\n<<---- Changed from 4 to 10\\n<Snip>\\nSave your changes and redeploy the app. This will send the updated Compose file to the\\nswarm manager, and Swarm will roll out a new version of the web-fe service with all 10\\nreplicas running the new image.\\n$ docker stack deploy -c compose.yaml ddd\\nUpdating service ddd_web-fe (id: rsm3x02o9fwcftt3a87fqcabq)\\nUpdating service ddd_redis (id: otr7927s9m1s5mkz326243kv3)\\nRun a docker stack ps to see the rollout’s progress.\\n$ docker stack ps ddd\\nNAME\\nIMAGE\\nNODE\\nDESIRED\\nCURRENT STATE\\nddd_web-fe.1\\nnigelpoulton/ddd-book:swarm-app\\nwrk1\\nRunning\\nRunning 8 mins ago\\nddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-appv2\\nmgr1\\nRunning\\nRunning 13 secs ago\\n\\\\_ddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nShutdown\\nShutdown 26 secs ago\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 mins ago\\n<Snip>\\nI’ve trimmed the output, and I’ve only listed some of the replicas. However, you can see a\\nfew things.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 191}, page_content='12: Docker Swarm\\n185\\nSwarm has evenly balanced the six new replicas across both worker nodes (not shown in\\nthe book).\\nThe top line shows the ddd_web-fe.1 replica running the old image for the last 8\\nminutes. The next two lines show the ddd_web-fe.2 replica. You can see that the\\nold replica was running the old image and that it was shut down 26 seconds ago and\\nreplaced with a new replica running the new image. The new replica has been running\\nfor 13 seconds.\\nThe last line shows the ddd_web-fe.3 replica is still running the old version.\\nSwarm immediately adds the six new replicas, but honors the update settings in the\\ndeploy.update_config section of your Compose file for existing replicas. This means\\nit updates the four original replicas two at a time and waits 10 seconds before updating\\nanother two.\\nBefore moving on, it’s important to clarify the reconciliation process that just happened.\\nThe application was running four web-fe replicas, all based on the swarm-app image,\\nand this was recorded on the Swarm as desired state. We edited the Compose file and\\nchanged all web-fe replicas to use the newer swarm-appv2 image and increased the\\nreplica count from four to ten. We saved our changes and ran a docker stack deploy\\ncommand to push this new desired state to Swarm. Shortly after, Swarm compared\\nthe observed state of the cluster with the new desired state and noticed it had four\\nweb-fe replicas running the swarm-app image but should actually have ten web-fe\\nreplicas running the swarm-appv2 image. As such, it deleted the existing four replicas\\nand replaced them with ten new replicas. It even followed rules you defined in the\\ndeploy.update_config section of the Compose file.\\nRefresh your browser to see the updated version of the app.\\nFigure 12.4 - The updated app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 192}, page_content='12: Docker Swarm\\n186\\nCongratulations, you’ve deployed and managed a Swarm app.\\nClean up\\nIf you’ve been following along, you’ve deployed a Swarm app with two services, a\\nnetwork, and a volume.\\nRun the following command to delete the app. Be warned though, it deletes it without\\nrequesting confirmation.\\n$ docker stack rm ddd\\nRemoving service ddd_redis\\nRemoving service ddd_web-fe\\nRemoving network ddd_counter-net\\nThe command deleted the network and services, but not the volume. This is because\\nSwarm decouples volume lifecycles from containers and services.\\nRun the following command on the node that hosted the redis replica. It will delete the\\nvolume.\\n$ docker volume rm ddd_counter-vol\\nddd_counter-vol\\nYou can delete your Swarm by running a docker swarm leave command on all swarm\\nnodes. You should remove the leader node last, and you may have to use the --force\\nflag.\\nDocker Swarm – The Commands\\n• docker swarm init initializes a new Swarm and makes the node the first manager\\nof the Swarm.\\n• docker stack deploy is the command you’ll run to deploy and update Swarm\\napps. You need to specify the Compose file and the name of the app.\\n• docker stack ls lists all Swarm apps and shows the number of services in each.\\n• docker stack ps gives you detailed information about a Swarm app. It tells you\\nwhich node each replica is running on, which images they’re based on, and shows\\nthe desired state and current state of each replica.\\n• docker stack services gives you a line of information for each application\\nservice and includes useful information such as replication mode, how many\\nreplicas, and port mappings.\\n• docker stack rm deletes a Swarm app and doesn’t ask for confirmation.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 193}, page_content='12: Docker Swarm\\n187\\nChapter Summary\\nDocker Swarm lets you group multiple Docker nodes into a secure, highly available\\ncluster and provides advanced application orchestration services similar to Kubernetes.\\nWorking with Swarm is a good way to kick-start your Kubernetes learning.\\nYou built a multi-node swarm, deployed an app to it, scaled the app, and performed a\\nlive rollout. And you did it all declaratively via a Compose file.\\nIf you want to learn Kubernetes, check out my Kubernetes books:\\n• Quick Start Kubernetes: The fastest way to master Kubernetes fundamentals.\\n• The Kubernetes Book: The best-selling Kubernetes book that goes into all the\\ndetail.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 194}, page_content='13: Docker Networking\\nIt’s always the network!\\nAny time we experience infrastructure issues, we always blame the network. One of the\\nreasons we do this is that networks are at the center of everything. With this in mind, it’s\\nimportant you have a strong understanding of Docker networking.\\nIn the early days of Docker, networking was hard. Fortunately, these days it’s almost a\\npleasure ;-)\\nThis chapter will get you up to speed with the fundamentals of Docker networking.\\nYou’ll learn all the theory behind the Container Network Model (CNM) and libnetwork, and\\nyou’ll get your hands dirty with lots of examples. You’ll learn about overlay networks in\\nthe next chapter.\\nI’ve divided the chapter into the following sections:\\n• Docker networking – the TLDR\\n• Docker networking theory\\n• Single-host bridge networks\\n• External access via port mappings\\n• Connecting to existing networks and VLANs\\n• Service Discovery\\n• Ingress load balancing\\nA few quick things before we start.\\nEverything we’ll cover relates to Linux containers, and I recommend you follow along\\nusing something like Multipass or Play with Docker, as they give you easy access to\\nsome of the Linux commands we’ll use. I don’t recommend following along on Docker\\nDesktop as it runs everything inside a Linux VM and you won’t have access to the Linux\\ncommands.\\nSome of the examples explain how networking works on a swarm. You’ll only be able to\\nfollow these if you’re following along with a Swarm cluster.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 195}, page_content='13: Docker Networking\\n189\\nDocker Networking – The TLDR\\nDocker runs microservices applications comprised of many containers that work\\ntogether to form the overall app. These containers need to be able to communicate,\\nand some will have to connect with external services, such as physical servers, virtual\\nmachines, or something else.\\nFortunately, Docker has solutions for both of these requirements.\\nDocker networking is based on libnetwork, which is the reference implementation of an\\nopen-source architecture called the Container Network Model (CNM).\\nFor a smooth out-of-the-box experience, Docker ships with everything you need\\nfor the most common networking requirements, including multi-host container-to-\\ncontainer networks and options for plugging into existing VLANs. However, the model\\nis pluggable, and the ecosystem can extend Docker’s networking capabilities via drivers\\nthat plug into libnetwork.\\nLast but not least, libnetwork also provides native service discovery and basic load\\nbalancing.\\nThat’s the big picture. Let’s get into the detail.\\nDocker networking theory\\nAt the highest level, Docker networking is based on the following three components:\\n• The Container Network Model (CNM)\\n• Libnetwork\\n• Drivers\\nThe CNM is the design specification and outlines the fundamental building blocks of a\\nDocker network.\\nLibnetwork is a real-world implementation of the CNM. It’s open-sourced as part of\\nthe Moby project20 and used by Docker and other platforms.\\nDrivers extend the model by implementing specific network topologies such as VXLAN\\noverlay networks.\\nFigure 13.1 shows all three.\\n20https://mobyproject.org/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 196}, page_content='13: Docker Networking\\n190\\nFigure 13.1\\nLet’s take a closer look at each.\\nThe Container Network Model (CNM)\\nEverything starts with a design.\\nThe design guide for Docker networking is the CNM that outlines the fundamental\\nbuilding blocks of a Docker network.\\nI recommend you read the specification document21, but at a high level, it defines three\\nbuilding blocks:\\n• Sandboxes\\n• Endpoints\\n• Networks\\nA sandbox is an isolated network stack inside a container. It includes Ethernet interfaces,\\nports, routing tables, DNS configuration, and everything else you’d expect from a\\nnetwork stack.\\nEndpoints are virtual network interfaces that look, smell, and feel like regular network\\ninterfaces. They connect sandboxes to networks.\\nNetworks are virtual switches (usually software implementations of an 802.1d bridge). As\\nsuch, they group together and isolate one or more endpoints that need to communicate.\\nFigure 13.2 shows how all three connect and relate to familiar infrastructure compo-\\nnents. Using CNM terminology, endpoints connect sandboxes to networks. Every container\\nyou create will have a sandbox with at least one endpoint connecting it to a network.\\n21https://github.com/moby/moby/blob/master/libnetwork/docs/design.md'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 197}, page_content='13: Docker Networking\\n191\\nFigure 13.2 - The Container Network Model (CNM)\\nAs the name suggests, the Container Network Model is all about providing networking\\nfor containers. Figure 13.3 shows how CNM components relate to containers —\\neach container gets its own sandbox which hosts the container’s entire network stack,\\nincluding one or more endpoints that act as Ethernet interfaces and can be connected to\\nnetworks.\\nFigure 13.3\\nContainer A has a single interface (endpoint) and is only connected to Network A.\\nHowever, Container B has two interfaces connected to Network A and Network B.\\nThe containers can communicate with each other because they are both connected to\\nNetwork A. However, the two endpoints inside of Container B cannot communicate\\nwith each other as they’re on different networks.\\nIt’s also important to understand that endpoints behave exactly like regular network\\nadapters, meaning you can only connect them to a single network. This is why Con-\\ntainer B needs two endpoints if it wants to connect to both networks.\\nFigure 13.4 extends the diagram further by adding the Docker host. Even though both\\ncontainers are running on the same host this time, their network stacks are completely\\nisolated and can only communicate via a network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 198}, page_content='13: Docker Networking\\n192\\nFigure 13.4\\nLibnetwork\\nLibnetwork is the reference implementation of the CNM. It’s open-source, cross-\\nplatform (Linux and Windows), maintained by the Moby project, and used by Docker.\\nBefore Docker created libnetwork, it implemented all of its networking code inside\\nthe daemon. However, over time, the daemon became bloated and difficult for other\\nprojects to use. As a result, Docker removed the networking code from the daemon and\\nrefactored it as an external library called libnetwork based on the CNM design. Today,\\nDocker implements all of its core networking in libnetwork.\\nAs well as implementing the core components of the CNM, libnetwork also implements\\nthe network control plane, including management APIs, service discovery, and ingress-\\nbased container load balancing.\\nDrivers\\nLibnetwork implements the control plane, but it relies on drivers to implement the data\\nplane. For example, drivers are responsible for creating networks and ensuring isolation\\nand connectivity.\\nDocker ships with several built-in drivers that we sometimes call native drivers or local\\ndrivers. These include bridge, overlay, and macvlan, and they build the most common\\nnetwork topologies. Third parties can also write network drivers to implement other\\nnetwork topologies and more advanced configurations.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 199}, page_content='13: Docker Networking\\n193\\nFigure 13.5 shows the roles of libnetwork and drivers and how they relate to control\\nplane and data plane responsibilities.\\nFigure 13.5\\nEvery network you create is owned by a driver, and the driver creates and manages\\neverything about the network. For example, if you create an overlay network called\\nprod-fe-cuda, Docker will invoke the overlay driver to create the network and its\\nresources.\\nTo meet the demands of complex, highly fluid environments, a single Docker host or\\nSwarm cluster can have multiple heterogeneous networks managed by different drivers.\\nLet’s look at single-host bridge networks and connecting to existing networks. You’ll\\nlearn about overlay networks in the next chapter.\\nSingle-host bridge networks\\nThe simplest type of Docker network is the single-host bridge network.\\nThe name tells us two things:\\n• Single-host tells us the network only spans a single Docker host\\n• Bridge tells us that it’s an implementation of an 802.1d bridge (layer 2 switch)\\nDocker creates single-host bridge networks with the built-in bridge driver. If you run\\nWindows containers you’ll need to use the nat driver, but for all intents and purposes they\\nwork the same.\\nFigure 13.6 shows two Docker hosts with identical local bridge networks, both called\\nmynet. Even though the networks are identical, they are independent and isolated,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 200}, page_content='13: Docker Networking\\n194\\nmeaning the containers in the picture cannot communicate, even if the nodes are part\\nof the same swarm.\\nFigure 13.6\\nEvery new Docker host gets a default single-host bridge network called bridge that\\nDocker connects new containers to unless you override it with the --network flag.\\nThe following commands show the output of a docker network ls command on\\nDocker installation.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\nc7464dce29ce\\nbridge\\nbridge\\nlocal\\n<<---- Default on all Docker hosts\\nc65ab18d0580\\nhost\\nhost\\nlocal\\n42a783df0fbe\\nnone\\nnull\\nlocal\\nAs always, you can run docker inspect commands to get more information. I highly\\nrecommend running the command on your own system and studying the output.\\n$ docker network inspect bridge\\n[\\n{\\n\"Name\": \"bridge\",\\n\"Id\": \"c7464dce2...ba2e3b8\",\\n\"Scope\": \"local\",\\n\"Driver\": \"bridge\",\\n\"EnableIPv6\": false,\\n\"IPAM\": {\\n\"Driver\": \"default\",\\n\"Options\": null,\\n\"Config\": [\\n{\\n\"Subnet\": \"172.17.0.0/16\",\\n\"Gateway\": \"172.17.0.1\"\\n}'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 201}, page_content='13: Docker Networking\\n195\\n]\\n},\\n\"Internal\": false,\\n\"Attachable\": false,\\n\"Ingress\": false,\\n\"ConfigFrom\": {\\n\"Network\": \"\"\\n},\\n<Snip>\\n}\\n]\\nAll bridge networks are based on the battle-hardened Linux bridge technology that has\\nexisted in the Linux kernel for over 20 years. This means they’re high-performance and\\nhighly stable. It also means you can inspect them using standard Linux utilities.\\nThe default bridge network on all Linux-based Docker hosts is called bridge and maps to\\nan underlying Linux bridge in the host’s kernel called docker0. This is shown in Figure\\n13.7.\\nFigure 13.7 - Mapping the default Docker “bridge” network to the “docker0” bridge in the host’s kernel\\nYou can run a docker network inspect command to confirm that the bridge network\\nis based on the docker0 bridge in the host’s kernel. If you’re on Windows using Power-\\nShell, you’ll need to replace grep with SelectString.\\n$ docker network inspect bridge | grep bridge.name\\n\"com.docker.network.bridge.name\": \"docker0\",\\nNow run these Linux commands to inspect the docker 0 bridge from the Linux host.\\nYou might need to manually install the brctl utility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 202}, page_content='13: Docker Networking\\n196\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\ndocker0\\n8000.0242aff9eb4f\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\n$ ip link show docker0\\n3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc...\\nlink/ether 02:42:af:f9:eb:4f brd ff:ff:ff:ff:ff:ff\\nThe first command lists all the bridges on your Docker host and shows if they have any\\ndevices connected to them. The example in the book shows the docker0 bridge with no\\ndevices connected in the interfaces column. You’ll only see the docker_gwbridge if\\nyour host is a member of a swarm cluster.\\nThe second command shows the configuration and state of the docker0 bridge.\\nFigure 13.8 shows the complete stack with containers connecting to the bridge\\nnetwork, which, in turn, maps to the docker0 Linux bridge in the host’s kernel. It also\\nshows how you can use port mappings to publish connected devices on the Docker\\nhost’s interface. More on port mappings later.\\nFigure 13.8\\nIn the next few steps, you’ll complete all of the following:\\n1. Create a new Docker bridge network\\n2. Connect a container to the new network'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 203}, page_content='13: Docker Networking\\n197\\n3. Inspect the new network\\n4. Test name-based discovery\\nRun the following command to create a new single-host bridge network called local-\\nnet.\\n$ docker network create -d bridge localnet\\nf918f1bb0602373bf949615d99cb2bbbef14ede935fbb2ff8e83c74f10e4b986\\nThe long number returned by the command is the network’s ID and you’ll need it in the\\nnext step.\\nAs expected, the command creates a new Docker bridge network called localnet that\\nyou can list and inspect with the usual docker commands. However, behind the scenes,\\nit also creates a new Linux bridge in the host’s kernel.\\nRun another brctl show command to see it.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\ndocker0\\n8000.024258ee84bc\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\nThe example in the book shows a new bridge called br-f918f1bb0602 with no devices\\nconnected. If you look closely at the name, you’ll recognize f918f1bb0602 as the first 12\\ncharacters from the ID of the new localnet network you just created.\\nAt this point, the bridge configuration on the host looks like Figure 13.9, with three\\nDocker networks and three associated bridges in the host’s kernel.\\nFigure 13.9\\nLet’s create a new container called c1 and attach it to the new localnet bridge network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 204}, page_content='13: Docker Networking\\n198\\n$ docker run -d --name c1 \\\\\\n--network localnet \\\\\\nalpine sleep 1d\\nOnce you’ve created the container, inspect the localnet network and verify the\\ncontainer is connected to it. You’ll need the jq utility installed for the command to work.\\nLeave off the \"| jq\" if it doesn’t work.\\n$ docker network inspect localnet --format \\'{{json .Containers}}\\' | jq\\n{\\n\"09c5f4926c87da12039b3b510a5950b3fe9db80e13431dc17d870450a45fd84a\": {\\n\"Name\": \"c1\",\\n\"EndpointID\": \"27770ac305773b352d716690fb9f8e05c1b71e10dc66f67b88e93cb923ab9749\",\\n\"MacAddress\": \"02:42:ac:15:00:02\",\\n\"IPv4Address\": \"172.21.0.2/16\",\\n\"IPv6Address\": \"\"\\n}\\n}\\nThe output shows the c1 container and its IP address. This proves Docker connected it\\nto the network.\\nIf you run another brctl show command, you’ll see the c1 container’s interface\\nconnected to the br-1597657726bc bridge.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\nveth833aaf9\\ndocker0\\n8000.024258ee84bc\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\nFigure 13.10 shows the updated configuration. Your veth IDs will be different, but the\\nimportant thing to understand is that every veth is like a cable with an interface on\\neither end. One end is connected to the Docker network, and the other end is connected\\nto the associated bridge in the kernel.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 205}, page_content='13: Docker Networking\\n199\\nFigure 13.10\\nIf you add more containers to the localnet network, they’ll all be able to communicate\\nusing names. This is because Docker automatically registers container names with an\\ninternal DNS service and allows containers on the same network to find each other by\\nname. The exception to this rule is the built-in bridge network that does not support\\nDNS resolution.\\nLet’s test name resolution by creating a new container called c2 on the same localnet\\nnetwork and seeing if it can ping the c1 container.\\nRun the following command to create the c2 container on the localnet network. You’ll\\nneed to type exit if you’re still logged in to the c1 container.\\n$ docker run -it --name c2 \\\\\\n--network localnet \\\\\\nalpine sh\\nYour terminal will switch into the c2 container.\\nTry to ping the c1 container by name.\\n# ping c1\\nPING c1 (172.21.0.2): 56 data bytes\\n64 bytes from 172.21.0.2: seq=0 ttl=64 time=1.564 ms\\n64 bytes from 172.21.0.2: seq=1 ttl=64 time=0.338 ms\\n64 bytes from 172.21.0.2: seq=2 ttl=64 time=0.248 ms\\n<Control-c>\\nIt works! This is because all containers run a DNS resolver that forwards name lookups\\nto Docker’s internal DNS server that holds name-to-IP mappings for all containers\\nstarted with the --name or --net-alias flag.\\nType exit to log out of the container and return to your local shell.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 206}, page_content='13: Docker Networking\\n200\\nExternal access via port mappings\\nSo far, we’ve said that containers on bridge networks can only communicate with\\nother containers on the same network. However, you can get around this by mapping\\ncontainers to ports on the Docker host. It’s a bit clunky and has a lot of limitations, but it\\nmight be useful for occasional testing and development work.\\nFigure 13.11 shows a single Docker host running two containers. The web container on\\nthe right is running a web server on port 80 that is mapped to port 5005 on the Docker\\nhost. The client container on the left is sending requests to the Docker host on port\\n5005 and the external client at the bottom is doing the same. Both requests will hit the\\nhost’s IP on port 5005 and be redirected to the web server running in the web container.\\nFigure 13.11\\nLet’s test the setup to see if it works.\\nCreate a new container called web running NGINX on port 80 and map it to port 5005\\non the Docker host. If you’re still logged on to the container from the previous example,\\nyou’ll need to type exit first.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 207}, page_content='13: Docker Networking\\n201\\n$ docker run -d --name web \\\\\\n--network localnet \\\\\\n--publish 5005:80 \\\\\\nnginx\\nVerify the port mapping.\\n$ docker port web\\n80/tcp -> 0.0.0.0:5005\\n80/tcp -> [::]:5005\\nThe output shows the port mapping exists on all interfaces on the Docker host.\\nYou can test external access by pointing a web browser to the Docker host on port 5005.\\nYou’ll need to know the IP or DNS name of your Docker host (if you’re following along\\non Multipass it will probably be your Multipass VM’s 192.168.x.x address). You’ll see\\nthe Welcome to nginx! page.\\nLet’s create another container and see if it can reach the web container via the port\\nmapping.\\nRun the following command to create a new container called client on the bridge\\nnetwork.\\n$ docker run -it --name client --network bridge alpine sh\\n#\\nThe command will log you into the container and your prompt will change.\\nInstall the curl utility.\\n# apk add curl\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/aarch64/APKINDEX.tar.gz\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/community/aarch64/APKINDEX.tar.gz\\n(1/8) Installing ca-certificates (20240226-r0)\\n<Snip>\\nNow connect to the IP of your Docker host on port 5005 to see if you can reach the\\ncontainer.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 208}, page_content='13: Docker Networking\\n202\\n# curl 192.168.64.69:5005\\n<!DOCTYPE html>\\n<html>\\n<head>\\n<title>Welcome to nginx!</title>\\n...\\n</html>\\nYou’ve reached the NGINX web server running on the c1 container via a port mapping\\nto the Docker host’s IP.\\nEven though this works, it’s clunky and doesn’t scale. For example, no other containers\\nor host processes will be able to use port 5005 on the host. This is one of the reasons\\nthat single-host bridge networks are only useful for local development or very small\\napplications.\\nConnecting to existing networks and VLANs\\nThe ability to connect containerized apps to external systems and physical networks is\\nimportant. A common example is partially containerized apps where the parts running\\nin containers need to be able to communicate with the parts not running in containers.\\nThe built-in MACVLAN driver (transparent if you’re using Windows containers) was\\ncreated with this in mind. It gives every container its own IP and MAC address on the\\nexternal physical network, making each one look, smell, and feel like a physical server or\\nVM. This is shown in Figure 13.12.\\nFigure 13.12 - MACVLAN driver making containers visible on external networks\\nOn the positive side, MACVLAN performance is good as it doesn’t require port\\nmappings or additional bridges. However, you need to run your host NICs in promis-\\ncuous mode, which isn’t allowed on many corporate networks and public clouds. So,\\nMACVLAN will work on your data center networks if your network team allows\\npromiscuous mode, but it probably won’t work on your public cloud.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 209}, page_content='13: Docker Networking\\n203\\nLet’s dig a bit deeper with the help of some pictures and a hypothetical example. This\\nexample will only work if your host NIC is in promiscuous mode on a network that\\nallows it. It also requires an existing VLAN 100. You can adapt it if the VLAN config on\\nyour physical network is different. You can follow along without the VLANs, but you\\nwon’t get the full experience.\\nAssume you have the network shown in Figure 13.13 with two VLANs:\\nFigure 13.13\\nNext, you add a Docker host and connect it to the network.\\nFigure 13.14\\nNow comes the requirement to attach a container to VLAN 100. To do this, you create a\\nnew Docker network with the macvlan driver and configure it with all of the following:\\n• Subnet info\\n• Gateway\\n• Range of IPs it can assign to containers\\n• Which of the host’s interfaces or sub-interfaces to use\\nRun the following command to create a new MACVLAN network called macvlan100\\nthat will connect containers to VLAN 100. You may need to change the name of the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 210}, page_content='13: Docker Networking\\n204\\nparent interface to match the parent interface name on your system. For example,\\nchanging -o parent=eth0.100 to -o parent=enp0s1.100. The parent interface must\\nbe connected to the VLAN, and you’ll need to type exit if you’re still logged on to the\\ncontainer from the previous example.\\n$ docker network create -d macvlan \\\\\\n--subnet=10.0.0.0/24 \\\\\\n--ip-range=10.0.0.0/25 \\\\\\n--gateway=10.0.0.1 \\\\\\n-o parent=eth0.100 \\\\\\n<<---- Make sure this matches your system\\nmacvlan100\\nDocker will create the macvlan100 network and a new sub-interface on the host called\\neth0.100@eth0. The config now looks like this.\\nFigure 13.15\\nThe MACVLAN driver creates standard Linux sub-interfaces and tags them with the ID\\nof the VLAN they will connect to. In this example, we’re connecting to VLAN 100, so we\\ntag the sub-interface with .100 (-o parent=eth0.100).\\nWe also used the --ip-range flag to tell the new network which sub-set of IP addresses\\nit can assign to containers. It’s vital that you reserve this range of addresses for Docker,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 211}, page_content='13: Docker Networking\\n205\\nas the MACVLAN driver has no management plane feature to check if IPs are already in\\nuse.\\nIf you inspect the network, you’ll be able to see the important configuration information.\\nI’ve snipped the output to show the most relevant parts.\\n$ docker network inspect macvlan100\\n[\\n{\\n\"Name\": \"macvlan100\",\\n\"Driver\": \"macvlan\",\\n\"IPAM\": {\\n\"Config\": [\\n{\\n\"Subnet\": \"10.0.0.0/24\",\\n\"IPRange\": \"10.0.0.0/25\",\\n\"Gateway\": \"10.0.0.1\"\\n}\\n]\\n},\\n\"Options\": {\\n\"parent\": \"enp0s1.100\"\\n},\\n}\\n]\\nOnce you’ve created the macvlan100 network, you can connect containers to it and\\nDocker will assign the IP and MAC addresses on the underlying VLAN so they’ll be\\nvisible to other systems.\\nThe following command creates a new container called mactainer1 and connects it to\\nthe macvlan100 network.\\n$ docker run -d --name mactainer1 \\\\\\n--network macvlan100 \\\\\\nalpine sleep 1d\\nThe config now looks like Figure 13.16.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 212}, page_content='13: Docker Networking\\n206\\nFigure 13.16\\nHowever, remember that the underlying network (VLAN 100) does not see any of\\nthe MACVLAN magic, it only sees the container with its MAC and IP addresses,\\nmeaning the mactainer1 container will be able to communicate with every other system\\nconnected to VLAN 100!\\nNote: If you can’t get this to work, it might be because your host NIC isn’t\\nin promiscuous mode. Also, remember that public cloud platforms normally\\nblock promiscuous mode.\\nAt this point, you’ve got a MACVLAN network and used it to connect a new container\\nto an existing VLAN. If you have the complete setup, with the existing VLAN, you can\\ntest that the container is reachable form other system on the VLAN.\\nHowever, it doesn’t stop there. The Docker MACVLAN driver supports VLAN trunking.\\nThis means you can create multiple MACVLAN networks that connect to different\\nVLANs. Figure 13.17 shows a single Docker host running two MACVLAN networks\\nconnecting containers to two different VLANs.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 213}, page_content='13: Docker Networking\\n207\\nFigure 13.17\\nTroubleshooting connectivity problems\\nA quick note on troubleshooting connectivity issues before moving on to service\\ndiscovery.\\nDaemon logs and container logs can be useful when troubleshooting connectivity issues.\\nIf you’re running Windows containers, you can view them in the Windows Event\\nViewer or directly in ∼\\\\AppData\\\\Local\\\\Docker. For Linux containers, it depends on\\nwhich init system you’re using. If you’re running a systemd, Docker will post logs to\\njournald and you can view them with the journalctl -u docker.service command.\\nIf you’re using a different init system, you might want to check the following locations:\\n• Ubuntu systems running upstart: /var/log/upstart/docker.log\\n• RHEL-based systems: /var/log/messages\\n• Debian: /var/log/daemon.log\\nYou can also tell Docker how verbose you want daemon logging to be. To do this, edit\\nthe daemon config file at /etc/docker/daemon.json and set \"debug\" to \"true\" and\\n\"log-level\" to one of the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 214}, page_content='13: Docker Networking\\n208\\n• debug – the most verbose option\\n• info – the default value and second-most verbose option\\n• warn – third most verbose option\\n• error – fourth most verbose option\\n• fatal – least verbose option\\nThe following snippet from a daemon.json enables debugging and sets the level to\\ndebug. It will work on all Docker platforms.\\n{\\n<Snip>\\n\"debug\":true,\\n\"log-level\":\"debug\",\\n<Snip>\\n}\\nIf your daemon.json file doesn’t exist, create it. Also, be sure to restart Docker after\\nmaking any changes to the file.\\nThat was the daemon logs. What about container logs?\\nYou can normally view container logs with the docker logs command. If you’re\\nrunning Swarm, you should use the docker service logs command. However,\\nDocker supports a few different log drivers, and they don’t all work with native Docker\\ncommands. For some of them, you might have to view logs using the platform’s native\\ntools.\\njson-file and journald are probably the easiest to configure and they both work with\\nthe docker logs and docker service logs commands.\\nThe following snippet from a daemon.json shows a Docker host configured to use\\njournald.\\n{\\n\"log-driver\": \"journald\"\\n}\\nYou can also start a container or a service with the --log-driver and --log-opts flags\\nto override the settings in daemon.json.\\nContainer logs work on the premise that your application runs as PID 1 and sends logs\\nto STDOUT and errors to STDERR. The logging driver then forwards everything to the\\nlocations configured via the logging driver.\\nThe following is an example of running the docker logs command against a container\\ncalled vantage-db that is configured with the json-file logging driver.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 215}, page_content='13: Docker Networking\\n209\\n$ docker logs vantage-db\\n1:C 2 Feb 09:53:22.903 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\\n1:C 2 Feb 09:53:22.904 # Redis version=4.0.6, bits=64, commit=00000000, modified=0, pid=1\\n1:C 2 Feb 09:53:22.904 # Warning: no config file specified, using the default config.\\n1:M 2 Feb 09:53:22.906 * Running mode=standalone, port=6379.\\n1:M 2 Feb 09:53:22.906 # WARNING: The TCP backlog setting of 511 cannot be enforced...\\n1:M 2 Feb 09:53:22.906 # Server initialized\\n1:M 2 Feb 09:53:22.906 # WARNING overcommit_memory is set to 0!\\nThere’s a good chance you’ll find network connectivity errors in the daemon logs or\\ncontainer logs.\\nService discovery\\nAs well as core networking, libnetwork also provides service discovery that allows all\\ncontainers and Swarm services to locate each other by name. The only requirement is\\nthat the containers be on the same network.\\nUnder the hood, Docker implements a native DNS server and configures every con-\\ntainer to use it for name resolution.\\nFigure 13.18 shows a container called c1 pinging another container called c2 by name.\\nThe same principle applies to Swarm service replicas.\\nFigure 13.18\\nLet’s step through the process.\\n• Step 1: The c1 container issues a ping c2 command. The container’s local DNS\\nresolver checks its cache to see if it has an IP address for c2. All Docker containers\\nhave a local DNS resolver.\\n• Step 2: The local resolver doesn’t have an IP address for c2, so it initiates a\\nrecursive query to the embedded Docker DNS server. All Docker containers are\\npre-configured to know how to send queries to the embedded DNS server.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 216}, page_content='13: Docker Networking\\n210\\n• Step 3: The Docker DNS server maintains name-to-IP mappings for every\\ncontainer you create with the --name or --net-alias flags. This means it knows\\nthe IP address of the c2 container.\\n• Step 4: The DNS server returns the IP address of the c2 container to the local\\nresolver in the c1 container. If c1 and c2 are on different Docker networks it won’t\\nreturn the IP address — name resolution only works for containers on the same\\nnetwork.\\n• Step 5: The c1 container sends the ping request (ICMP echo request) to the IP\\naddress of c2.\\nJust to confirm a few points.\\nDocker will automatically register the name and IP of every container you create\\nwith the --name or net-alias flag with the embedded Docker DNS service. It also\\nautomatically configures every container to use the embedded DNS service to convert\\nnames to IPs. And name resolution (service discovery) is network scoped, meaning it only\\nworks for containers and services on the same network.\\nOne last point on service discovery and name resolution…\\nYou can use the --dns flag to start containers and services with a customized list of\\nDNS servers, and you can use the --dns-search flag to add custom search domains\\nfor queries against unqualified names (i.e., when the application doesn’t specify fully\\nqualified DNS names for services they consume). You’ll find both of these useful if your\\napplications query names outside of your Docker environment such as internet services.\\nBoth of these options work by adding entries to the container’s /etc/resolv.conf file.\\nRun the following command to start a new container with the infamous 8.8.8.8\\nGoogle DNS server and nigelpoulton.com as a search domain for unqualified queries.\\n$ docker run -it --name custom-dns \\\\\\n--dns=8.8.8.8 \\\\\\n--dns-search=nigelpoulton.com \\\\\\nalpine sh\\nYour shell prompt will change to indicate you’re connected to the container.\\nInspect its /etc/resolv.conf file.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 217}, page_content='13: Docker Networking\\n211\\n# cat /etc/resolv.conf\\nGenerated by Docker Engine.\\nThis file can be edited; Docker Engine will not make further changes once it\\nhas been modified.\\nnameserver 8.8.8.8\\nsearch nigelpoulton.com\\nThe file’s contents might be slightly different if you connect the container to a custom\\nnetwork, but the options work the same.\\nType exit to return to your local terminal.\\nIngress load balancing\\nThis section only applies to Docker Swarm.\\nSwarm supports two ways of publishing services to external clients:\\n• Ingress mode (default)\\n• Host mode\\nExternal clients can access ingress mode services via any swarm node — even nodes not\\nhosting a service replica. However, they can only access host mode services via nodes\\nrunning replicas. Figure 13.19 shows both modes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 218}, page_content='13: Docker Networking\\n212\\nFigure 13.19\\nIngress mode is the default, meaning any time you create a service with -p or --publish,\\nDocker will publish it in ingress mode. If you want to publish a service in host mode, you’ll\\nneed to use the --publish flag with the mode=host option. The following example\\npublishes a service in host mode and will only work on a swarm.\\n$ docker service create -d --name svc1 \\\\\\n--publish published=5005,target=80,mode=host \\\\\\nnginx\\nA few notes about the command. docker service create lets you publish services\\nusing either long form syntax or short form syntax.\\nThe short form looks like -p 5005:80 and you’ve seen it a few times already. However,\\nyou cannot publish a service in host mode using the short form.\\nLong form looks like this: --publish published=5005,target=80,mode=host. It’s a\\ncomma-separated list with no whitespace after the commands, and the options work as\\nfollows:\\n• published=5005 makes the service available to external clients via port 5005\\n• target=80 makes sure requests hitting the published port get mapped back to port\\n80 on service replicas'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 219}, page_content='13: Docker Networking\\n213\\n• mode=host makes sure requests will only reach the service if they arrive on nodes\\nrunning a service replica\\nYou’ll almost always use ingress mode.\\nBehind the scenes, ingress mode uses a layer 4 routing mesh that Docker calls the\\nservice mesh or the swarm-mode service mesh. Figure 13.20 shows the basic traffic\\nflow when an external request hits the cluster for a service exposed in ingress mode.\\nFigure 13.20\\nLet’s quickly walk through the diagram.\\nThe command at the top deploys a new Swarm service called svc1 with one replica,\\nattaches it to the overnet network and publishes it on port 5005 on the ingress network.\\nDocker automatically creates the ingress network when you create the swarm, and\\nit attaches every node to it. The act of publishing the service on port 5005 makes it\\naccessible via port 5005 on every swarm node because every node is connected to the\\ningress network. Docker also creates a swarm-wide rule to route all traffic hitting nodes\\non port 5005 to port 80 in the svc1 replicas via the ingress network.\\nNow let’s track that external request.\\n1. The external client sends a request to Node 1 on port 5005\\n2. Node 1 receives the request and knows to forward traffic arriving on port 5005 to\\nthe ingress network\\n3. The ingress network forwards the request to Node 2 which is running a replica\\n4. Node 2 receives the request and passes it to the replica on port 80'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 220}, page_content='13: Docker Networking\\n214\\nIf the service has multiple replicas, swarm is clever enough to balance requests across\\nthem all.\\nClean up\\nIf you’ve been following along, you’ll have a lot of containers, networks, and services\\nthat you probably want to clean up.\\nRun the following command to delete the services you created.\\n$ docker service rm svc1\\nNow, delete the standalone containers you created.\\n$ docker rm c1 c2 client web mactainer1 -f\\nFinally, delete the networks you created.\\n$ docker network rm localnet macvlan100\\nDocker Networking – The Commands\\nDocker networking has its own docker network sub-command, and the main com-\\nmands include:\\n• docker network ls lists all the Docker networks available to the host.\\n• docker network create is how you create a new Docker network. You have\\nto give the network a name and you can use the -d flag to specify which driver\\ncreates it.\\n• docker network inspect provides detailed configuration information about\\nDocker networks.\\n• docker network prune deletes all unused networks on a Docker host.\\n• docker network rm Deletes specific networks on a Docker host or swarm.\\nYou also ran some native Linux commands.\\n• brctl show prints a list of all kernel bridges on the Docker host and shows if any\\ncontainers are connected.\\n• ip link show prints bridge configuration data. You ran an ip link show\\ndocker0 to see the configuration of the docker0 bridge on your Docker host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 221}, page_content='13: Docker Networking\\n215\\nChapter Summary\\nThe Container Network Model (CNM) is the design document for Docker networks\\nand defines the three major constructs — sandboxes, endpoints, and networks.\\nLibnetwork is the reference implementation of the CMN and is an open-source project\\nmaintained by the Moby project. Docker uses it to implement its core networking,\\nincluding control plane services such as service discovery.\\nDrivers extend the capabilities of libnetwork by implementing specific network topolo-\\ngies, such as bridge and overlay networks. Docker ships with built-in drivers, but you\\ncan also use third-party drivers.\\nSingle-host bridge networks are the most basic type of Docker network but are only\\nsuitable for local development and very small applications. They do not scale, and you\\nneed to map containers to host ports if you want to publish services outside of the\\nnetwork.\\nOverlay networks are all the rage and are excellent container-only multi-host networks.\\nWe’ll talk about them in-depth in the next chapter.\\nThe macvlan driver lets you create Docker networks that connect containers to existing\\nphysical networks and VLANs. They make containers first-class citizens on external\\nnetworks by giving them their own MAC and IP addresses. Unfortunately, you have to\\nrun your host NICs in promiscuous mode, meaning they won’t work in public clouds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 222}, page_content='14: Docker overlay networking\\nOverlay networks are at the center of most cloud-native microservices apps, and this\\nchapter will get you up to speed on how they work in Docker.\\nI’ve divided the chapter into the following sections:\\n• Docker overlay networking – The TLDR\\n• Docker overlay networking history\\n• Building and testing overlay networks\\n• Overlay networks explained\\nLet’s do some networking magic!\\nDocker overlay networking – The TLDR\\nReal-world containers need a reliable and secure way to communicate without caring\\nwhich host they’re running on or which networks those hosts are connected to. This\\nis where overlay networks come into play — they create flat, secure, layer 2 networks\\nthat span multiple hosts. Containers on different hosts can connect to the same overlay\\nnetwork and communicate directly.\\nDocker offers native overlay networking that is simple to configure and secure by\\ndefault.\\nBehind the scenes, Docker builds overlay networking on top of libnetwork and the native\\noverlay driver. Libnetwork is the canonical implementation of the Container Network\\nModel (CNM), and the overlay driver implements all of the machinery to build overlay\\nnetworks.\\nDocker overlay networking history\\nIn March 2015, Docker, Inc. acquired a container networking startup called Socket Plane\\nwith two goals in mind:\\n1. Bring overlay networking to Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 223}, page_content='14: Docker overlay networking\\n217\\n2. Make container networking simple for developers\\nThey accomplished both goals, and overlay networking continues to be at the heart of\\ncontainer networking in 2024 and the foreseeable future.\\nHowever, there’s a lot of complexity hiding behind the simple Docker commands.\\nKnowing the commands is probably enough if you’re a casual Docker user. However,\\nif you plan to use Docker in production, especially if you plan to use Swarm and Docker\\nnetworking, then the things we’ll cover will be vital.\\nBuilding and testing Docker overlay networks\\nYou’ll need at least two Docker nodes configured in a swarm to follow along. The\\nexamples in the book show the two nodes on different networks connected by a router,\\nbut yours can be on the same network. You can follow along with two Multipass VMs\\non the same laptop or computer, but any Docker configuration will work as long as the\\nnodes can communicate. I don’t recommend using Docker Desktop as you only get a\\nsingle node and won’t get the full experience.\\nFigure 14.1 shows the initial lab configuration. Remember, your nodes can be on\\nthe same network, this will just mean your underlay network is simpler. We’ll explain\\nunderlay networks later.\\nFigure 14.1'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 224}, page_content='14: Docker overlay networking\\n218\\nBuild a Swarm\\nIf you’re following along, you’ll need a swarm because overlay networks leverage the\\nswarm’s key-value store and other security features.\\nThis section builds a two-node swarm with two Docker nodes called node1 and node2.\\nIf you already have a swarm, you can skip this section.\\nYou’ll need to substitute the IP addresses and names with the values from your environ-\\nment. You’ll also need to ensure the following network ports are open between the two\\nnodes:\\n• 2377/tcp for management plane comms\\n• 7946/tcp and 7946/udp for control plane comms (SWIM-based gossip)\\n• 4789/udp for the VXLAN data plane\\nRun the following command on node1.\\n$ docker swarm init\\nSwarm initialized: current node (1ex3...o3px) is now a manager.\\nThe command output includes a docker swarm join command. Copy this command\\nand run it node2.\\n$ docker swarm join \\\\\\n--token SWMTKN-1-0hz2ec...2vye \\\\\\n172.31.1.5:2377\\nThis node joined a swarm as a worker.\\nYou now have a two-node Swarm with node1 as a manager and node2 as a worker.\\nCreate a new overlay network\\nLet’s create a new encrypted overlay network called uber-net.\\nRun the following command from your manager node (node1).\\n$ docker network create -d overlay -o encrypted uber-net\\nvdu1yly429jvt04hgdm0mjqc6'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 225}, page_content='14: Docker overlay networking\\n219\\nThat’s it. You’ve created a brand-new encrypted overlay network. The network spans\\nboth nodes in the swarm and Docker uses TLS to encrypt it (AES in GCM mode). It also\\nrotates the encryption keys every 12 hours.\\nIf you don’t specify the -o encrypted flag, Docker will still encrypt the control plane\\n(management traffic) but won’t encrypt the data plane (application traffic). This can\\nbe important, as encrypting the data plane can decrease network performance by\\napproximately 10%.\\nList the networks on node1.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n65585dda7500\\nbridge\\nbridge\\nlocal\\n7e368a1105c7\\ndocker_gwbridge\\nbridge\\nlocal\\na38083cdab1c\\nhost\\nhost\\nlocal\\n4dsqo7jc36ip\\ningress\\noverlay\\nswarm\\nd97e92a23945\\nnone\\nnull\\nlocal\\nvdu1yly429jv\\nuber-net\\noverlay\\nswarm\\n<<---- New overlay network\\nThe new network is at the bottom of the list called uber-net and is scoped to the entire\\nswarm (SCOPE = swarm). This means it spans every node in the swarm. However, if you\\nlist networks on node2 you won’t see the uber-net network. This is because Docker\\nonly extends overlay networks to worker nodes when they need them. In our example,\\nDocker will extend the uber-net network to node2 when it runs a container that needs\\nit. This lazy approach to network deployment improves scalability by reducing the\\namount of network gossip on the swarm.\\nAttach a container to the overlay network\\nNow that you have an overlay network let’s connect a container to it.\\nBy default, you can only attach containers that are part of swarm services to overlay\\nnetworks. If you want to add standalone containers, you need to create the overlay with\\nthe --attachable flag.\\nThe example will create a swarm service called test with two replicas on the uber-net\\nnetwork. One replica will be deployed to node1 and the other to node2, causing Docker\\nto extend the overlay network to node2.\\nRun the following commands from node1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 226}, page_content='14: Docker overlay networking\\n220\\n$ docker service create --name test \\\\\\n--network uber-net \\\\\\n--replicas 2 \\\\\\nubuntu sleep infinity\\nCheck the status of the service.\\n$ docker service ps test\\nID\\nNAME\\nIMAGE\\nNODE\\nDESIRED STATE\\nCURRENT STATE\\nsm1...1nw\\ntest.1\\nubuntu:latest\\nnode1\\nRunning\\nRunning\\ntro...kgk\\ntest.2\\nubuntu:latest\\nnode2\\nRunning\\nRunning\\nThe NODE column shows one replica running on each node.\\nSwitch over to node2 and run a docker network ls to verify it can now see the uber-\\nnet network.\\nCongratulations. You’ve created a new overlay network spanning two nodes on separate\\nunderlay networks and attached two containers to it. You’ll appreciate the simplicity\\nof what you’ve done when we reach the theory section and learn about the outrageous\\ncomplexity going on behind the scenes!\\nTest the overlay network\\nFigure 14.2 shows the current setup with two containers running on different Docker\\nhosts but connected to the same overlay.\\nFigure 14.2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 227}, page_content='14: Docker overlay networking\\n221\\nThe following steps will walk you through obtaining the container names and IP\\naddresses and then seeing if they can ping each other.\\nSwitch back to node1 and run a docker network inspect to see the overlay network’s\\nsubnet information and any IP addresses it’s assigned to service replicas.\\n$ docker network inspect uber-net\\n[\\n{\\n\"Name\": \"uber-net\",\\n\"Id\": \"vdu1yly429jvt04hgdm0mjqc6\",\\n\"Scope\": \"swarm\",\\n\"Driver\": \"overlay\",\\n\"EnableIPv6\": false,\\n\"IPAM\": {\\n\"Driver\": \"default\",\\n\"Options\": null,\\n\"Config\": [\\n{\\n\"Subnet\": \"10.0.0.0/24\",\\n<<---- Subnet info\\n\"Gateway\": \"10.0.0.1\"\\n<<---- Subnet info\\n}\\n\"Containers\": {\\n\"Name\": \"test.1.tro80xqwm7k1bsyn3mt1fjkgk\",\\n<<---- Replica ID\\n\"IPv4Address\": \"10.0.0.3/24\",\\n<<---- Container IP\\n<Snip>\\n},\\n<Snip>\\nI’ve snipped the output and highlighted the subnet info and the IPs of connected con-\\ntainers. One thing to note is that Docker only shows you the IP addresses of containers\\nrunning on the local node. For example, the output in the book only shows the IP of the\\nfirst replica called test.1.tro...kgk. If you run the same command on node2, you’ll\\nsee the name and IP of the other replica.\\nRun the following commands on both nodes to get the local container names, IDs, and\\nIP addresses of both replicas and make a note of them.\\nThe ID at the end of the second command (d7766923a5a7) is the container ID as\\nreturned by the docker ps command. You’ll need to substitute the value from your\\nenvironment.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 228}, page_content='14: Docker overlay networking\\n222\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAME\\nd7766923a5a7\\nubuntu:latest\\n\"sleep infinity\"\\n2 hrs ago\\nUp 2 hrs\\ntest.1.tro...kgk\\n$ docker inspect \\\\\\n--format=\\'{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\\' d7766923a5a7\\n10.0.0.3\\nI have the following in my environment :\\n• replica 1: ID=d7766923a5a7, Name=test.1.tr0...kgk, IP=10.0.0.3\\n• replica 2: ID=b6c897d1186d, Name=test.2.sm1...1nw, IP=10.0.0.4\\nFigure 14.3 shows the configuration so far. Subnet and IP addresses may be different in\\nyour lab.\\nFigure 14.3\\nAs you can see, a layer 2 overlay network spans both nodes, and each container is\\nconnected to it with its own IP. This means the container on node1 can ping the\\ncontainer on node2 even though both nodes are on different underlay networks.\\nLet’s test it. You’ll need the names and IPs of your containers.\\nLog on to either of the containers and install the ping utility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 229}, page_content='14: Docker overlay networking\\n223\\n$ docker exec -it d7766923a5a7 bash\\n# apt update && apt-get install iputils-ping -y\\n<Snip>\\nReading package lists... Done\\nBuilding dependency tree\\nReading state information... Done\\n<Snip>\\nSetting up iputils-ping (3:20190709-3) ...\\nProcessing triggers for libc-bin (2.31-0ubuntu9) ...\\nNow ping the remote container by IP and then by replica ID.\\n# ping 10.0.0.4\\nPING 10.0.0.4 (10.0.0.4) 56(84) bytes of data.\\n64 bytes from 10.0.0.4: icmp_seq=1 ttl=64 time=1.06 ms\\n64 bytes from 10.0.0.4: icmp_seq=2 ttl=64 time=1.07 ms\\n64 bytes from 10.0.0.4: icmp_seq=3 ttl=64 time=1.03 ms\\n64 bytes from 10.0.0.4: icmp_seq=4 ttl=64 time=1.26 ms\\n^C\\n# ping test.2.sm180xqwm7k1bsyn3mt1fj1nw\\nPING test.2.sm180xqwm7k1bsyn3mt1fj1nw (10.0.0.4) 56(84) bytes of data.\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=1 ttl=64 time=2.83 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=2 ttl=64 time=8.39 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=3 ttl=64 time=5.88 ms\\n^C\\nCongratulations. The containers can ping each other via the overlay network, and all the\\ntraffic is encrypted.\\nYou can also trace the route of the ping command. This will report a single hop, proving\\nthat the containers are communicating directly via the overlay network — blissfully\\nunaware of any underlay networks being traversed.\\nYou’ll need to install traceroute in the container for this to work.\\n# apt install traceroute\\n<Snip>\\n# traceroute 10.0.0.4\\ntraceroute to 10.0.0.4 (10.0.0.4), 30 hops max, 60 byte packets\\n1\\ntest-svc.2.sm180xqwm7k1bsyn3mt1fj1nw.uber-net (10.0.0.4)\\n1.110ms\\n1.034ms\\n1.073ms\\nSo far, you’ve created an overlay network and a swarm service that connected two\\ncontainers to it. Swarm scheduled the containers to two different nodes and you proved\\nthey could ping each other via the overlay network.\\nNow that you’ve seen how easy it is to build and use secure overlay networks, let’s find\\nout how Docker builds them behind the scenes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 230}, page_content='14: Docker overlay networking\\n224\\nOverlay networks explained\\nFirst and foremost, Docker uses VXLAN tunnels to create virtual layer 2 overlay net-\\nworks. So, let’s do a quick VXLAN primer.\\nVXLAN primer\\nAt the highest level, Docker uses VXLANs to create layer 2 networks on top of existing\\nlayer 3 infrastructure. That’s a lot of jargon that means you can create simple networks\\non top of complex networks. The hands-on example in the previous sections created\\na new 10.0.0.0/24 layer 2 network that abstracted a more complex network topology\\nbelow. See Figure 14.4 and remember that your underlay network configuration was\\nprobably different.\\nFigure 14.4\\nFortunately, VXLAN is an encapsulation technology and, therefore, transparent to exist-\\ning routers and network infrastructure. This means the routers and other infrastructure\\nin the underlay network see the VXLAN/overlay traffic as regular IP/UDP packets and\\nhandle it without requiring changes.\\nTo create the overlay, Docker creates a VXLAN tunnel through the underlay networks,\\nand this tunnel is what allows the overlay traffic to flow freely without having to\\ninteract with the complexity of the underlay networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 231}, page_content='14: Docker overlay networking\\n225\\nTerminology: We use the terms underlay networks or underlay infrastructure to\\nrefer to the networks the overlay tunnels through.\\nEach end of the VXLAN tunnel is terminated by a VXLAN Tunnel Endpoint (VTEP), and\\nit’s this VTEP that encapsulates and de-encapsulates the traffic entering and exiting the\\ntunnel. See Figure 14.5.\\nFigure 14.5\\nThe image shows the layer 3 infrastructure as a cloud for two reasons:\\n• It can be a lot more complex than the two networks and a single router from the\\nprevious diagrams\\n• The VXLAN tunnel abstracts the complexity and makes it opaque\\nIn reality, the VXLAN tunnel traverses the underlay network. However, I don’t show\\nthis in the diagram to keep the diagram simple.\\nTraffic flow example\\nThe hands-on examples from earlier had two hosts connected via an IP network. You\\ndeployed an overlay network across both hosts, connected two containers to it, and did\\na ping test. Let’s explain some of the things that happened behind the scenes.\\nDocker created a new sandbox (network namespace) on each host with a new switch\\ncalled Br0. It also created a VTEP with one end connected to the Br0 virtual switch and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 232}, page_content='14: Docker overlay networking\\n226\\nthe other end connected to the host’s network stack. The end in the host’s network stack\\ngot an IP address on the underlay network that the host is connected to and was bound\\nto UDP port 4789. Finally, the two VTEPs on each host created a VXLAN tunnel as the\\nbackbone for the overlay network.\\nFigure 14.6 shows the configuration. Remember, the VXLAN tunnel goes through the\\nnetworks at the bottom of the diagram; I’ve just drawn it higher up for readability.\\nFigure 14.6\\nAt this point, you’ve created the VXLAN overlay, and you’re ready to connect contain-\\ners.\\nDocker now creates a virtual Ethernet adapter (veth) in each container and connects it\\nto the local Br0 virtual switch. The final topology looks like Figure 14.7, and although\\nit’s complex, you should now see how the containers communicate over the VXLAN\\noverlay despite their hosts being on two separate networks — the overlay is a virtual\\nnetwork tunneled through the underlay networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 233}, page_content='14: Docker overlay networking\\n227\\nFigure 14.7\\nNow that you know how Docker creates overlay networks, let’s see how the two\\ncontainers communicate.\\nWarning! This section is very technical, and you don’t need to understand it\\nall for day-to-day operations.\\nFor this example, we’ll call the container on node1 “C1” and the container on node2\\n“C2”. We’ll also assume C1 wants to ping C2 like we did in the practical example earlier.\\nFigure 14.8 shows the full configuration with container names and IPs added.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 234}, page_content='14: Docker overlay networking\\n228\\nFigure 14.8\\nC1 initiates a ping request to 10.0.0.4 — the IP address of C2.\\nC1 doesn’t have an entry for 10.0.0.4 in its local MAC address table (ARP cache), so\\nit floods the packet on all interfaces, including the veth interface connected to the Br0\\nbridge. The Br0 bridge knows it can forward traffic for 10.0.0.4 to the connected\\nVTEP interface and sends a proxy ARP reply to the container. This results in the veth\\nlearning how to forward the packet by updating its own MAC table to send all future\\npackets for 10.0.0.4 directly to the local VTEP. The Br0 switch knew about the C2\\ncontainer because Docker propagates details of all new containers to every swarm node\\nvia the network’s built-in gossip protocol.\\nNext, the veth in the C1 container sends the ping to the VTEP interface which encapsu-\\nlates it for transmission through the VXLAN tunnel. The encapsulation adds a VXLAN\\nheader containing a VXLAN network ID (VNID) that maps traffic from VLANs to\\nVXLANs and vice versa — each VLAN gets mapped to its own VNID so that packets\\ncan be de-encapsulated on the receiving end and forwarded to the correct VLAN. This\\nmaintains network isolation.\\nThe encapsulation also wraps the frame in a UDP packet and adds the IP of the remote\\nVTEP on node2 in the destination IP field. It also adds the UDP/4789 socket information.\\nThis encapsulation allows the packets to be routed across the underlay networks\\nwithout the underlays knowing anything about VXLAN.\\nWhen the packet arrives at node2, the host’s kernel sees it’s addressed to UDP port\\n4789 and knows it has a VTEP bound to this socket. This means it sends the packet to\\nthe VTEP, which reads the VNID, de-encapsulates it, and sends it to its own local Br0\\nswitch on the VLAN corresponding to the VNID. From there, it delivers it to the C2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 235}, page_content='14: Docker overlay networking\\n229\\ncontainer.\\nAnd that, my friends, is how Docker uses VXLAN to build and operate overlay networks\\n— a whole load of mind-blowing complexity beautifully hidden behind a single Docker\\ncommand.\\nI’m hoping that’s enough to get you started and help you when talking to your network-\\ning team about the networking aspects of your Docker infrastructure. On the topic of\\ntalking to your networking team… don’t approach them thinking that you now know\\neverything about VXLAN. If you do, you’ll probably embarrass yourself. I’m speaking\\nfrom experience ;-)\\nOne final thing. Docker also supports layer 3 routing within an overlay network. For\\nexample, you can create a single overlay network with two subnets, and Docker will\\nhandle the routing. The following command will create a new overlay called prod-net\\nwith two subnets. Docker will automatically create two virtual switches called Br0 and\\nBr1 inside the sandbox and handle all the routing.\\n$ docker network create --subnet=10.1.1.0/24 --subnet=11.1.1.0/24 -d overlay prod-net\\nClean up\\nIf you followed along, you’ll have created an overlay network called uber-net and\\ndeployed a service called test. You may also have created a swarm.\\nRun the following command to delete the test service.\\n$ docker service rm test\\nDelete the uber-net network with the following command. You may have to wait a few\\nseconds while Docker deletes the service using it.\\n$ docker network rm uber-net\\nIf you no longer need the swarm, you can run a docker swarm leave -f command on\\nboth nodes. You should run it on node2 first.\\nDocker overlay networking – The commands\\n• docker network create tells Docker to create a new network. You use the -d\\noverlay flag to use the overlay driver to create an overlay network. You can also\\npass the -o encrypted flag to tell Docker to encrypt network traffic. However,\\nperformance may drop in the region of 10%.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 236}, page_content='14: Docker overlay networking\\n230\\n• docker network ls lists all the container networks visible to a Docker host.\\nDocker hosts running in swarm mode only see overlay networks if they run\\ncontainers attached to the network. This keeps network-related management\\ntraffic to a minimum.\\n• docker network inspect shows detailed information about a particular container\\nnetwork. You can find out the scope, driver, IPv4 and IPv6 info, subnet configura-\\ntion, IP addresses of connected containers, VXLAN network ID, encryption state,\\nand more.\\n• docker network rm deletes a network.\\nChapter Summary\\nIn this chapter, you created a new Docker overlay network and learned about the\\ntechnologies Docker uses to build them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 237}, page_content='15: Volumes and persistent data\\nStateful applications that create and manage data are a big part of modern cloud-native\\napps. This chapter explains how Docker volumes help stateful applications manage their\\ndata.\\nI’ve split the chapter into the following parts:\\n• Volumes and persistent data – The TLDR\\n• Containers without volumes\\n• Containers with volumes\\n• The commands\\nVolumes and persistent data – The TLDR\\nThere are two main types of data — persistent and non-persistent.\\nPersistent data is the stuff you care about and need to keep. It includes things like cus-\\ntomer records, financial data, research results, audit data, and even some types of logs.\\nNon-persistent data is the stuff you don’t care about and don’t need to keep. We call\\napplications that create and manage persistent data stateful apps, and applications that\\ndon’t create or manage persistent data stateless apps.\\nBoth are important, and Docker has solutions for both.\\nFor stateless apps, Docker creates every container with an area of non-persistent local\\nstorage that’s tied to the container lifecycle. This storage is suitable for scratch data\\nand temporary files, but you’ll lose it when you delete the container or the container\\nterminates.\\nDocker has volumes for stateful apps that create and manage important data. Volumes are\\nseparate objects that you mount into containers, and they have their own lifecycles. This\\nmeans you don’t lose the volumes or the data on them when you delete containers. You\\ncan even mount volumes into different containers.\\nThat’s the TLDR. Let’s take a closer look.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 238}, page_content='15: Volumes and persistent data\\n232\\nContainers without volumes\\nIn the early days of Docker, containers were only good for stateless applications that\\ndidn’t generate important data. However, despite being stateless, many of these apps still\\nneeded a place to write temporary scratch data. So, as shown in Figure 15.1, Docker\\ncreates containers by stacking read-only image layers and placing a thin layer of local\\nstorage on top. The same technology allows multiple containers to share the same read-\\nonly image layers.\\nFigure 15.1 - Ephemeral container storage\\nThis thin layer of local storage is integral to the read-write nature of containers. For\\nexample, if an application needs to update existing files or add new files, it makes\\nthe changes in the local storage layer, and Docker merges them into the view of the\\ncontainer. However, the local storage is coupled to the container’s lifecycle, meaning it\\ngets created when you create the container, and deleted when you delete it. This means\\nit’s not a good place for data that you need to keep (persist).\\nDocker keeps the local storage layer on the Docker host’s filesystem, and you’ll hear it\\ncalled various names such as the thin writeable layer, ephemeral storage, read-write storage,\\nand graphdriver storage. It’s usually located in the following locations on your Docker\\nhosts:\\n• Linux containers: /var/lib/docker/<storage-driver>/...\\n• Windows containers: C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\...\\nEven though the local storage layer allows you to update live containers, you should\\nnever do this. Instead, you should treat containers as immutable objects and never change\\nthem once deployed. For example, if you need to fix or change the configuration of a live\\ncontainer, you should create and test a new container with the changes and then replace\\nthe live container with the new one.\\nTo be clear, applications like databases can change the data they manage. But users\\nand configuration tools should never change the container’s configuration, such as its\\nnetwork or application configuration. You should always make changes like these in a\\nnew container and then replace the old container with the new one.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 239}, page_content='15: Volumes and persistent data\\n233\\nIf your containers don’t create persistent data, this thin writable layer of local storage\\nwill be fine, and you’ll be good to go. However, if your containers create persistent data,\\nyou need to read the next section.\\nContainers with volumes\\nThere are three main reasons you should use volumes to handle persistent data in\\ncontainers:\\n• Volumes are independent objects that are not tied to the lifecycle of a container\\n• You can map volumes to specialized external storage systems\\n• Multiple containers on different Docker hosts can use volumes to access and share\\nthe same data\\nAt a high level, you create a volume, then create a container, and finally mount the\\nvolume into the container. When you mount it into the volume, you mount it into a\\ndirectory in the container’s filesystem, and anything you write to that directory gets\\nstored in the volume. If you delete the container, the volume and data will still exist.\\nYou’ll even be able to mount the surviving volume into another container.\\nFigure 15.2 shows a Docker volume outside the container as a separate object. The\\nvolume is mounted into the container’s filesystem at /data, and anything you write to\\nthat directory will be stored on the volume and exist after you delete the container.\\nFigure 15.2 - High-level view of volumes and containers\\nThe image also shows that you can map the volume to an external storage system\\nor a directory on the Docker host. External storage systems can be cloud services or\\ndedicated storage appliances, but either way, the volume’s lifecycle is decoupled from\\nthe container. All of the container’s other directories use the thin writable layer in the\\nlocal storage area on the Docker host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 240}, page_content='15: Volumes and persistent data\\n234\\nCreating and managing Docker volumes\\nVolumes are first-class objects in Docker. This means there’s a docker volume sub-\\ncommand, and a volume resource in the API.\\nRun the following command to create a new volume called myvol.\\n$ docker volume create myvol\\nmyvol\\nBy default, Docker creates new volumes with the built-in local driver. And, as the name\\nof the driver suggests, these volumes are only available to containers on the same node\\nas the volume. You can use the -d flag to specify a different driver, but you’ll need to\\ninstall the driver first.\\nThird-party drivers22 provide advanced features and access to external storage systems\\nsuch as cloud storage services and on-premises storage systems such as SAN and NAS.\\nFigure 15.3 shows a Docker host connected to an external storage system via a plugin\\n(driver).\\nFigure 15.3 - Plugging external storage into Docker\\nOnce you’ve created the volume, you can see it with the docker volume ls command\\nand inspect it with the docker volume inspect command.\\n22https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 241}, page_content='15: Volumes and persistent data\\n235\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmyvol\\n$ docker volume inspect myvol\\n[\\n{\\n\"CreatedAt\": \"2024-05-15T12:23:14Z\",\\n\"Driver\": \"local\",\\n\"Labels\": null,\\n\"Mountpoint\": \"/var/lib/docker/volumes/myvol/_data\",\\n\"Name\": \"myvol\",\\n\"Options\": null,\\n\"Scope\": \"local\"\\n}\\n]\\nNotice that the Driver and Scope fields are both set to local. This means you created\\nthe volume with the local driver, and it’s only available to containers on this Docker\\nhost. Mountpoint tells you where the volume exists in the Docker host’s filesystem.\\nBy default, Docker gives every volume created with the local driver its own directory\\non the host under /var/lib/docker/volumes. This means anyone with access to the\\nDocker host can bypass the container and access the volume’s contents directly in the\\nhost’s filesystem. You saw this in the Docker Compose chapter when we copied a file\\ndirectly into a volume’s directory on the Docker host, and the file immediately appeared\\nin the volume inside the container. However, that’s not a recommended practice.\\nNow that you’ve created a volume, you can create containers to use it. However, before\\nyou do that, there are two ways to delete Docker volumes:\\n• docker volume prune\\n• docker volume rm\\nThe docker volume prune --all command deletes all volumes not mounted into a\\ncontainer or service replica, so use it with caution!\\nThe docker volume rm command is more precise and lets you specify which volumes to\\ndelete.\\nNeither command will delete a volume in use by a container or service replica.\\nThe myvol volume you created isn’t used by a container, so you can delete it with either\\ncommand. Be careful if you use the prune command, as it may also delete other volumes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 242}, page_content='15: Volumes and persistent data\\n236\\n$ docker volume prune --all\\nWARNING! This will remove all local volumes not used by at least one container.\\nAre you sure you want to continue? [y/N] y\\nDeleted Volumes:\\nmyvol\\nTotal reclaimed space: 0B\\nCongratulations. You’ve created, inspected, and deleted a Docker volume, and none\\nof the actions involved a container. This proves that volumes are decoupled from\\ncontainers.\\nAt this point, you know all the commands to create, list, inspect, and delete Docker\\nvolumes. You’ve even seen how to deploy them via Compose files in the Compose and\\nSwarm stacks chapters. However, you can also deploy volumes via Dockerfiles by using\\nthe VOLUME instruction. The format is VOLUME <container-mount-point>. Interestingly,\\nyou cannot specify a host directory when you define volumes in a Dockerfile. This is\\nbecause host directories can differ depending on your host OS, and you could easily\\nbreak your builds if you specified a directory that doesn’t exist on a host. As a result,\\ndefining a volume in a Dockerfile requires you to specify host directories at deployment\\ntime.\\nUsing volumes with containers\\nLet’s see how to use volumes with containers.\\nRun the following command to create a new standalone container called voltainer that\\nmounts a volume called bizvol.\\n$ docker run -it --name voltainer \\\\\\n--mount source=bizvol,target=/vol \\\\\\nalpine\\nThe command specified the --mount flag, telling Docker to mount a volume called\\nbizvol into the container at /vol. The command completed successfully even though\\nyou didn’t have a volume called bizvol. This raises an important point:\\n• If you specify a volume that already exists, Docker will use it\\n• If you specify a volume that does not exist, Docker will create it\\nIn our case, bizvol didn’t exist, so Docker created it and mounted it into the container.\\nType Ctrl PQ to return to your local shell, and then list volumes to make sure Docker\\ncreated it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 243}, page_content='15: Volumes and persistent data\\n237\\n# <Ctrl-PQ>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nbizvol\\nEven though volumes are decoupled from containers, Docker won’t let you delete this\\none because it’s in use by the voltainer container.\\nTry to delete it.\\n$ docker volume rm bizvol\\nError response from daemon: remove bizvol: volume is in use - [b44d3f82...dd2029ca]\\nAs expected, you can’t delete it.\\nThe volume is brand new, so it doesn’t have any data. Let’s exec onto the container and\\nwrite some data to it.\\n$ docker exec -it voltainer sh\\n# echo \"I promise to write a book review on Amazon\" > /vol/file1\\nThe command writes some text to a file called file1 in the /vol directory where the\\nvolume is mounted.\\nRun a few commands to make sure the file and data exist.\\n# ls -l /vol\\ntotal 4\\n-rw-r--r-- 1 root\\nroot\\n50 May 23 08:49 file1\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nType exit to return to your Docker host’s shell, and then delete the container with the\\nfollowing commands.\\n# exit\\n$ docker rm voltainer -f\\nvoltainer\\nCheck that Docker deleted the container but kept the volume.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 244}, page_content='15: Volumes and persistent data\\n238\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nbizvol\\nAs the volume still exists, you can view its contents in the Docker host’s local filesystem.\\nRemember, though, that it’s not recommended to access volumes directly via the host’s\\nfilesystem. We’re just showing you how to do it for demonstration and educational\\nreasons.\\nRun the following commands from your Docker host terminal. They’ll show the\\ncontents of the volume’s directory on your Docker host. The first command will show\\nthat the file still exists, and the second will show its contents.\\nThis step won’t work on Docker Desktop, as Docker Desktop runs inside a VM. You\\nmay have to prefix the commands with sudo.\\n$ ls -l /var/lib/docker/volumes/bizvol/_data/\\ntotal 4\\n-rw-r--r-- 1 root root 50 Jan 12 14:25 file1\\n$ cat /var/lib/docker/volumes/bizvol/_data/file1\\nI promise to write a book review on Amazon\\nGreat, the volume and the data still exist.\\nLet’s see if you can mount the existing bizvol volume into a new service or container.\\nRun the following command to create a new container called newctr that mounts bizvol\\nat /vol.\\n$ docker run -it \\\\\\n--name newctr \\\\\\n--mount source=bizvol,target=/vol \\\\\\nalpine sh\\nYour terminal is now attached to the newctr container. Check to see if the volume and\\ndata are mounted as expected.\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nCongratulations. You’ve created a volume, written some data to it, deleted the original\\ncontainer, mounted it in a second container, and verified the data still exists.\\nType exit to leave the container and jump over to Amazon to leave the book review you\\npromised to write.\\nIf you left a review, thanks! If you didn’t, I’ll cry, but I’ll live ;-)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 245}, page_content='15: Volumes and persistent data\\n239\\nSharing storage across cluster nodes\\nIntegrating Docker with external storage systems lets you present shared storage to\\nmultiple nodes so that the containers running on different nodes can share the same\\nvolumes. These external systems can be cloud storage services or enterprise storage\\nsystems in your on-premises data centers. For example, you can present a single storage\\nLUN or NFS share (shared volume) to multiple Docker hosts so that any container on\\nthose hosts can access and share the volume. Figure 15.4 shows an external storage\\nsystem presenting a shared volume to two Docker nodes. The Docker nodes use the\\nappropriate driver for the external system to make the shared volume available to either\\nor both containers.\\nFigure 15.4\\nBuilding a shared setup like this requires a lot of things. You need access to specialized\\nstorage systems and knowledge of how they work. You also need a volume driver/plugin\\nthat works with the external storage system. Finally, you need to know how your\\napplications read and write to the shared storage to avoid potential data corruption.\\nPotential data corruption\\nData corruption is a major concern for any shared storage configuration.\\nAssume the following example based on Figure 15.4.\\nThe application running in ctr1 writes an update to the shared volume. However,\\ninstead of directly committing the update, it keeps it in a local cache for faster recall. At\\nthis point, the application in ctr1 thinks it’s written data to the volume. However, before\\nctr1 flushes its cache and commits the data to the volume, the app in ctr2 updates the\\nsame data with a different value and commits it directly to the volume. At this point,\\nboth applications think they’ve updated the data in the volume, but in reality, only'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 246}, page_content='15: Volumes and persistent data\\n240\\nthe application in ctr2 has. A few seconds later, ctr1 flushes the data to the volume\\nand overwrites the changes made by the application in ctr2. However, neither of the\\napplications is aware of the changes the other has made.\\nThis is why you need to design applications that share data to coordinate updates to\\nshared volumes.\\nClean up\\nIf you’ve been following along, you’ll have a container and a volume.\\nRun the following command to delete the container.\\n$ docker rm\\nNow, run this command to delete the volume.\\n$ docker volume rm bizvol\\nVolumes and persistent data – The Commands\\n• docker volume create creates new volumes. By default, it creates them with the\\nlocal driver, but you can use the -d flag to specify a different driver.\\n• docker volume ls lists all volumes on your Docker host.\\n• docker volume inspect shows you detailed volume information. You can use this\\ncommand to see where a volume exists in the Docker host’s filesystem.\\n• docker volume prune deletes all volumes not in use by a container or service\\nreplica. Use with caution!\\n• docker volume rm deletes specific volumes that are not in use.\\nChapter Summary\\nThere are two main types of data: persistent and non-persistent.\\nPersistent data is data you need to keep, and non-persistent data is data you don’t need\\nto keep.\\nBy default, all containers get a layer of writable non-persistent storage that lives and dies\\nwith the container. We sometimes call this local storage, and it’s ideal for non-persistent'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 247}, page_content='15: Volumes and persistent data\\n241\\ndata. However, if your apps create data you need to keep, you should store the data in a\\nDocker volume.\\nDocker volumes are first-class objects in the Docker API, and you manage them\\nindependently of containers using their own docker volume sub-command. This means\\ndeleting containers doesn’t delete the data in their volumes.\\nA few third-party plugins exist that provide Docker with access to specialized external\\nstorage systems.\\nVolumes are the recommended way to work with persistent data in Docker environ-\\nments.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 248}, page_content='16: Docker security\\nIf security is hard, we’re less likely to implement it. Fortunately, most of the security\\nin Docker is easy and pre-configured with sensible defaults. This means you get a\\nmoderately secure experience with zero effort. The defaults are not perfect, but they’re a\\ngood starting point.\\nDocker supports all major Linux security technologies and adds some of its own. As\\nsuch, I’ve divided the chapter so we cover the Linux security technologies first and\\nfinish the chapter covering the Docker technologies:\\n• Docker security – The TLDR\\n• Linux security technologies\\n– Kernel namespaces\\n– Control Groups\\n– Capabilities\\n– Mandatory Access Control\\n– seccomp\\n• Docker security technologies\\n– Swarm security\\n– Docker Scout and vulnerability scanning\\n– Docker Content Trust\\n– Docker secrets\\nThe chapter focuses heavily on Linux, but the sections relating to Docker security\\ntechnologies apply to Linux and Windows containers.\\nDocker security – The TLDR\\nGood security is about layers and defence in depth, and more layers is always better.\\nFortunately, Docker offers a lot of security layers, including the ones shown in Figure\\n16.1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 249}, page_content='16: Docker security\\n243\\nFigure 16.1\\nAs you can see, Docker leverages the common Linux security and workload isolation\\ntechnologies, including namespaces, control groups, capabilities, mandatory access control\\n(MAC), and seccomp. It ships with sensible defaults for each one, but you can customize\\nthem to your specific requirements.\\nDocker also has its own security technologies, including Docker Scout and Docker\\nContent Trust.\\nDocker Scout offers class-leading vulnerability scanning that scans your images, provides\\ndetailed reports on known vulnerabilities, and recommends solutions. Docker Content\\nTrust (DCT) lets you cryptographically sign and verify images.\\nIf you use Docker Swarm, you’ll also get all of the following that Docker automatically\\nconfigures: cryptographic node IDs, mutual authentication (TLS), automatic CA\\nconfiguration and certificate rotation, secure cluster join tokens, an encrypted cluster\\nstore, encrypted networks, and more.\\nOther security-related technologies also exist, but the important thing to know is that\\nDocker works with the major Linux security technologies and adds a few of its own.\\nSometimes, the Linux security technologies can be complex and challenging to work\\nwith, but the native Docker ones are always easy.\\nKernel Namespaces\\nKernel namespaces, usually shortened to namespaces, are the main technology for building\\ncontainers.\\nLet’s quickly compare namespaces and containers with hypervisors and virtual ma-\\nchines (VM).'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 250}, page_content='16: Docker security\\n244\\nNamespaces virtualize operating system constructs such as process trees and filesystems,\\nwhereas hypervisors virtualize physical resources such as CPUs and disks. In the VM model,\\nhypervisors create virtual machines by grouping virtual CPUs, virtual disks, and virtual\\nnetwork cards so that every VM looks, smells, and feels like a physical machine. In the\\ncontainer model, namespaces create virtual operating systems (containers) by grouping\\nvirtual process trees, virtual filesystems, and virtual network interfaces so that every\\ncontainer looks, smells, and feels exactly like a regular OS.\\nAt a very high level, namespaces provide lightweight isolation but do not provide a\\nstrong security boundary. Compared with VMs, containers are more efficient, but\\nvirtual machines are more secure.\\nDon’t worry, though. Platforms like Docker implement additional security technologies,\\nsuch as cgroups, capabilities, and seccomp, to improve container security.\\nNamespaces are a tried and tested technology that’s existed in the Linux kernel for\\na very long time. However, they were complex and hard to work with until Docker\\ncame along and hid all the complexity behind the simple docker run command and a\\ndeveloper-friendly API.\\nAt the time of writing, every Docker container gets its own instance of the following\\nnamespaces:\\n• Process ID (pid)\\n• Network (net)\\n• Filesystem/mount (mnt)\\n• Inter-process Communication (ipc)\\n• User (user)\\n• UTS (uts)\\nFigure 16.2 shows a single Docker host running two containers. The host OS has its\\nown collection of namespaces we call the root namespaces, and each container has its own\\ncollection of equivalent isolated namespaces. Applications in containers think they’re\\nrunning on their own host and are unaware of the root namespaces or namespaces in\\nother containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 251}, page_content='16: Docker security\\n245\\nFigure 16.2\\nLet’s briefly look at how Docker uses each namespace:\\n• Process ID namespace: Docker uses the pid namespace to give each container\\nits own isolated process tree. This means every container gets its own PID 1 and\\ncannot see or access processes running in other containers. Nor can any container\\nsee or access processes running on the host.\\n• Network namespace: Docker uses the net namespace to provide each container\\nwith an isolated network stack. This stack includes interfaces, IP addresses,\\nport ranges, and routing tables. For example, every container gets its own eth0\\ninterface with its own unique IP and range of ports.\\n• Mount namespace: Every container has its own mnt namespace with its own\\nunique isolated root (/) filesystem. This means every container can have its own\\n/etc, /var, /dev, and other important filesystem constructs. Processes inside a\\ncontainer cannot access the host’s filesystem or filesystems in other containers.\\n• Inter-process Communication namespace: Docker uses the ipc namespace\\nfor shared memory access within a container. It also isolates the container from\\nshared memory on the host and other containers.\\n• User namespace: Docker gives each container its own users that are only valid\\ninside the container. It also lets you map those users to different users on the\\nDocker host. For example, you can map a container’s root user to a non-root user\\non the host.\\n• UTS namespace: Docker uses the uts namespace to provide each container with\\nits own hostname.\\nRemember, a container is a collection of namespaces that Docker organizes to look like\\na regular OS. These namespaces provide isolation, but they are not a strong enough'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 252}, page_content='16: Docker security\\n246\\nsecurity boundary on their own. This is why Docker augments container security with\\nthe technologies we’re about to discuss.\\nControl Groups\\nIf namespaces are about isolation, control groups (cgroups) are about limits.\\nThink of containers as similar to rooms in a hotel. While each room might appear to be\\nisolated, they actually share a lot of things such as water supply, electricity supply, air\\nconditioning, swimming pool, gym, elevators, breakfast bar, and more. Containers are\\nsimilar — even though they’re isolated, they share a lot of common resources such as the\\nhost’s CPU, RAM, network I/O, and disk I/O.\\nDocker uses cgroups to limit a container’s use of these shared resources and prevent any\\ncontainer from consuming them all and causing a denial of service (DoS) attack.\\nCapabilities\\nThe Linux root user is extremely powerful, and you shouldn’t use it to run apps and\\ncontainers.\\nHowever, it’s not as simple as running them as non-root users, as most non-root users\\nare so powerless that they are practically useless. What’s needed is a way to run apps and\\ncontainers with the exact set of permissions they need — nothing more, nothing less.\\nThis is where capabilities come to the rescue.\\nUnder the hood, the Linux root user is a combination of a long list of capabilities. Some\\nof these capabilities include:\\n• CAP_CHOWN: lets you change file ownership\\n• CAP_NET_BIND_SERVICE: lets you bind a socket to low-numbered network\\nports\\n• CAP_SETUID: lets you elevate the privilege level of a process\\n• CAP_SYS_BOOT: lets you reboot the system.\\nThe list goes on and is long.\\nDocker leverages capabilities so that you can run containers as root but strip out\\nall the capabilities you don’t need. For example, suppose the only capability your\\ncontainer needs is the ability to bind to low-numbered network ports. In that case,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 253}, page_content='16: Docker security\\n247\\nDocker can start the container as root, drop all root capabilities, and then add back the\\nCAP_NET_BIND_SERVICE capability.\\nThis is a good example of implementing the principle of least privilege as you end up\\nwith a container that only has the capabilities it needs. Docker also sets restrictions to\\nprevent containers from re-adding dropped capabilities.\\nDocker ships with sensible out-of-the-box capabilities, but you should configure your\\nown for your production apps and containers. However, configuring your own requires\\nextensive effort and testing.\\nMandatory Access Control systems\\nDocker works with major Linux MAC technologies such as AppArmor and SELinux.\\nDepending on your Linux distribution, Docker applies default AppArmor or SELinux\\nprofiles to all new containers, and according to the Docker documentation, the default\\nprofiles are moderately protective while providing wide application compatibility.\\nYou can tell Docker to start containers without these policies, and you can configure\\nyour own. However, as with capabilities, configuring your own policies is very powerful\\nbut requires a lot of effort and testing.\\nseccomp\\nDocker uses seccomp to limit which syscalls a container can make to the host’s kernel.\\nSyscalls are how applications ask the Linux kernel to perform tasks. At the time of writ-\\ning, Linux has over 300 syscalls and the default Docker profile disables approximately\\n40-50.\\nAs per the Docker security philosophy, all new containers get a default seccomp profile\\nconfigured with sensible defaults designed to provide moderate security without impacting\\napplication compatibility.\\nAs always, you can customize your own seccomp profiles or tell Docker to start\\ncontainers without one. Unfortunately, the Linux syscall table is long, and configuring\\ncustom seccomp policies may be prohibitively complex for some users.\\nFinal thoughts on the Linux security technologies\\nDocker supports most of the important Linux security technologies and ships with\\nsensible defaults that add security without being too restrictive. Figure 16.3 shows how\\nDocker uses them to build a defence in depth security posture with multiple layers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 254}, page_content='16: Docker security\\n248\\nFigure 16.3 - Linux security defense in depth\\nSome of these technologies require knowledge of the Linux kernel and can be complex\\nto customize. Fortunately, many platforms, including Docker, ship with defaults that are\\na good place to start.\\nDocker security technologies\\nLet’s switch our focus to some of the security technologies Docker offers.\\nSwarm security\\nDocker Swarm lets you cluster multiple Docker hosts and manage applications declar-\\natively. Every Swarm comprises manager nodes and worker nodes that can be Linux or\\nWindows. Managers host the control plane and are responsible for configuring the\\ncluster and dispatching work tasks. Workers run application containers.\\nFortunately, swarm mode includes many security features that Docker automatically\\nconfigures with sensible defaults. These include:\\n• Cryptographic node IDs\\n• TLS for mutual authentication'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 255}, page_content='16: Docker security\\n249\\n• Secure join tokens\\n• CA configuration with automatic certificate rotation\\n• Encrypted cluster store\\n• Encrypted networks\\nLet’s walk through building a secure swarm and configuring some of the security\\naspects.\\nIf you’re following along, you’ll need three Docker hosts that can ping each other by\\nname. The examples use three hosts called mgr1, mgr2, and wrk1.\\nConfigure a secure Swarm\\nRun the following command from the node you want to be the first manager. We’ll run\\nthe example from mgr1.\\n$ docker swarm init\\nSwarm initialized: current node (7xam...662z) is now a manager.\\nThat’s it! You’ve configured a secure swarm with a cryptographic cluster ID, an en-\\ncrypted cluster store, a certificate authority (CA) with a 90-day certificate rotation\\npolicy, a set of secure join tokens to use when adding new managers and workers, and\\nconfigured the current manager with a client certificate for mutual TLS — all with a\\nsingle command!\\nThe CA is for internal Swarm security, and you should be careful using it for anything\\nelse.\\nFigure 16.4 shows the current swarm configuration. Some of the details may be\\ndifferent in your lab.\\nFigure 16.4'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 256}, page_content='16: Docker security\\n250\\nLet’s join mgr2 as an additional manager.\\nJoining new managers is a two-step process:\\n• Extract the secure join token\\n• Execute a docker swarm join command with the join token on the node you’re\\nadding\\nRun the following command from mgr1 to extract the manager join token.\\n$ docker swarm join-token manager\\nTo add a manager to this swarm, run the following command:\\ndocker swarm join --token \\\\\\nSWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz \\\\\\n172.31.5.251:2377\\nThe output gives you the full command and join token to run on mgr2. The join token\\nand IP address will be different in your lab.\\nThe format of the join command is:\\n• docker swarm join --token <manager-join-token> <ip-of-existing-\\nmanager>:<swarm-port>\\nThe format of the token is:\\n• SWMTKN-1-<hash-of-cluster-certificate>-<manager-join-token>\\nCopy the command and run it on mgr2:\\n$ docker swarm join --token SWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz 172.31.5.251:2377\\nThis node joined a swarm as a manager.\\nList the nodes in your swarm.\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\n7xamk...ge662z\\nmgr1\\nReady\\nActive\\nLeader\\ni0ue4...zcjm7f *\\nmgr2\\nReady\\nActive\\nReachable'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 257}, page_content='16: Docker security\\n251\\nYou now have a two-node swarm with mgr1 and mgr2 as managers. Both have access to\\nthe cluster store and are configured with client certificates for mutual TLS.\\nIn the real world, you’ll always run three or five managers for high availability.\\nFigure 16.5 shows the updated swarm with both managers.\\nFigure 16.5\\nAdding worker nodes is a similar two-step process — extract the join token and run the\\ncommand on the node.\\nRun the following command on either of the managers to expose the worker join\\ncommand and token.\\n$ docker swarm join-token worker\\nTo add a worker to this swarm, run the following command:\\ndocker swarm join --token \\\\\\nSWMTKN-1-1dmtw...17stb-ehp8g...w738q \\\\\\n172.31.5.251:2377\\nCopy the command and run it on wrk1:\\n$ docker swarm join --token SWMTKN-1-1dmtw...17stb-ehp8g...w738q 172.31.5.251:2377\\nThis node joined a swarm as a worker.\\nRun another docker node ls from either of your managers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 258}, page_content='16: Docker security\\n252\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\n7xamk...ge662z *\\nmgr1\\nReady\\nActive\\nLeader\\nailrd...ofzv1u\\nwrk1\\nReady\\nActive\\ni0ue4...zcjm7f\\nmgr2\\nReady\\nActive\\nReachable\\nYour swarm has two managers and a worker. The managers are configured for high\\navailability (HA) and the cluster store is replicated to both. The worker node is part of\\nthe swarm but cannot access the cluster store. Figure 16.6 shows the final configuration.\\nFigure 16.6\\nNow that you’ve built a secure Swarm, let’s examine some of the security aspects.\\nSwarm join tokens\\nThe only requirement for joining managers and workers is possession of the secure join\\ntoken. This means you should keep them safe and never post them on public repos or\\neven internal repos that are not restricted.\\nEvery swarm maintains two distinct join tokens:\\n• Manager token\\n• Worker token\\nEvery join token has four distinct fields separated by dashes (-):\\n• PREFIX - VERSION - SWARM ID - TOKEN\\nThe prefix is always SWMTKN and allows you to pattern-match against it to prevent people\\nfrom accidentally posting it publicly. The VERSION field indicates the version of the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 259}, page_content='16: Docker security\\n253\\nswarm. The Swarm ID field is a hash of the swarm’s certificate. The TOKEN field is the\\nworker or manager token.\\nAs you can see in the following table, the manager and worker tokens for any given\\nswarm are identical except for the final TOKEN field.\\nRole\\nPrefix\\nVersion\\nSwarm ID\\nToken\\nManager\\nSWMTKN\\n1\\n1dmtwusdc…r17stb\\n2axi53zjbs45lqxykaw8p7glz\\nWorker\\nSWMTKN\\n1\\n1dmtwusdc…r17stb\\nehp8gltji64jbl45zl6hw738q\\nIf you suspect either of your join tokens are compromised, you can revoke them and\\nissue new ones with a single command. The following example revokes the existing\\nmanager token and issues a new one.\\n$ docker swarm join-token --rotate manager\\nSuccessfully rotated manager join token.\\nExisting managers are unaffected, but you can only add new ones with the new token.\\nAs expected, the last field is the only difference between the old and new tokens.\\nDocker keeps a copy of join tokens in the encrypted cluster store.\\nTLS and mutual authentication\\nDocker issues every manager and worker with a client certificate that they use for\\nmutual authentication. It identifies the node, the swarm it’s a member of, and whether\\nit’s a manager or worker.\\nYou can inspect a node’s client certificate on Linux with the following command.\\n$ sudo openssl x509 \\\\\\n-in /var/lib/docker/swarm/certificates/swarm-node.crt \\\\\\n-text\\nCertificate:\\nData:\\nVersion: 3 (0x2)\\nSerial Number:\\n7c:ec:1c:8f:f0:97:86:a9:1e:2f:4b:a9:0e:7f:ae:6b:7b:b7:e3:d3\\nSignature Algorithm: ecdsa-with-SHA256\\nIssuer: CN = swarm-ca\\nValidity\\nNot Before: May 23 08:23:00 2024 GMT\\nNot After : Aug 21 09:23:00 2024 GMT\\nSubject: O = tcz3w1t7yu0s4wacovn1rtgp4, OU = swarm-manager,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 260}, page_content='16: Docker security\\n254\\nCN = 2gxz2h1f0rnmc3atm35qcd1zw\\nSubject Public Key Info:\\n<SNIP>\\nAs shown in Figure 16.7, the Subject field uses the standard O, OU, and CN fields to\\nspecify the Swarm ID, the node’s role, and the node ID:\\n• The Organization (O) field stores the Swarm ID\\n• The Organizational Unit (OU) field stores the node’s role in the swarm\\n• The Canonical Name (CN) field stores the node’s crypto ID.\\nYou can also see the certificate rotation period in the Validity section.\\nFigure 16.7\\nYou can match these values to the corresponding values from a docker info command.\\n$ docker info\\n<SNIP>\\nSwarm: active\\nNodeID: 2gxz2h1f0rnmc3atm35qcd1zw\\n<<---- Relates to the CN field\\nIs Manager: true\\n<<---- Relates to the OU field\\nClusterID: tcz3w1t7yu0s4wacovn1rtgp4\\n<<---- Relates to the O field\\n<SNIP>\\nCA Configuration:\\nExpiry Duration: 3 months\\n<<---- Relates to the validity block\\nForce Rotate: 0\\nRoot Rotation In Progress: false\\n<SNIP>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 261}, page_content='16: Docker security\\n255\\nSwarm CA configuration\\nYou can use the docker swarm update command to configure the certificate rotation\\nperiod. The following example changes it to 30 days.\\n$ docker swarm update --cert-expiry 720h\\nSwarm allows nodes to renew certificates early so that all nodes don’t update at exactly\\nthe same time.\\nYou can configure a new swarm to use an external CA by passing the --external-ca\\nflag to docker swarm init command, and you can use the docker swarm ca command\\nto manage other CA-related settings.\\n$ docker swarm ca --help\\nUsage:\\ndocker swarm ca [OPTIONS]\\nDisplay and rotate the root CA\\nOptions:\\n--ca-cert pem-file\\nPath to the PEM-formatted root CA certificate to use\\nfor the new cluster\\n--ca-key pem-file\\nPath to the PEM-formatted root CA key to use for the\\nnew cluster\\n--cert-expiry duration\\nValidity period for node certificates (ns|us|ms|s|m|h)\\n(default 2160h0m0s)\\n-d, --detach\\nExit immediately instead of waiting for the root rotation\\nto converge\\n--external-ca external-ca\\nSpecifications of one or more certificate signing endpoints\\n-q, --quiet\\nSuppress progress output\\n--rotate\\nRotate the swarm CA - if no certificate or key are\\nprovided, new ones will be generated\\nThe cluster store\\nThe cluster store is where Docker keeps the configuration and state of a swarm. It’s also\\ncritical to other Docker technologies, such as overlay networks and secrets. This is why\\noverlay networks and many other advanced security features only work in swarm mode.\\nThe cluster store is based on the popular etcd distributed database and is automatically\\nencrypted and replicated to all managers.\\nDocker handles day-to-day maintenance, but you should implement strong backup and\\nrecovery procedures for production clusters.\\nThat’s enough about swarm mode security for now. Let’s look at some Docker security\\ntechnologies that don’t require swarm mode.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 262}, page_content='16: Docker security\\n256\\nDocker Scout and vulnerability scanning\\nEvery container runs multiple software packages that are susceptible to bugs and\\nvulnerabilities that malicious actors can exploit.\\nImage scanning analyzes your images and produces a detailed list of all the software\\npackages it uses. We call this list a software bill of materials (SBOM), and the image\\nscanning system compares the SBOM against databases of known vulnerabilities and\\nprovides a report of vulnerabilities in your software. Most vulnerability scanners will\\nrank the vulnerabilities and provide advice on fixes.\\nVulnerability scanning is now an integral part of most software supply chains.\\nDocker Scout is Docker’s native scanning platform and works with Docker Hub,\\nDocker Desktop, the Docker CLI, and even has its own Docker Scout Dashboard.\\nHowever, it’s a subscription-based service.\\nOther scanning platforms are available, but most of these also require some form of\\nsubscription.\\nIf you’re using Docker Desktop, you can run the following command to see an example\\nof Docker Scout.\\n$ docker scout quickview nigelpoulton/tu-demo:latest\\n✓Provenance obtained from attestation\\n✓Pulled\\n✓Image stored for indexing\\n✓Indexed 66 packages\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\n│\\n0C\\n4H\\n2M\\n0L\\ndigest\\n│\\nb4210d0aa52f\\n│\\nBase image\\n│\\npython:3-alpine\\n│\\n0C\\n2H\\n1M\\n0L\\nUpdated base image │\\npython:3.11-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\n│\\n│\\nThe output shows zero critical vulnerabilities (0C), four high (4H), two medium (2M),\\nand zero low (0L).\\nYou can also run a docker scout cves command to get more detailed information,\\nincluding remediation advice.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 263}, page_content='16: Docker security\\n257\\n$ docker scout cves nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\n\\uffffDetected 6 vulnerable packages with a total of 8 vulnerabilities\\n## Overview\\n│\\nAnalyzed Image\\n────────────────────┼────────────────────────────────\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64\\nvulnerabilities │\\n0C\\n4H\\n2M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2\\npkg:apk/alpine/expat@2.5.0-r2?os_name=alpine&os_version=3.19\\n\\uffffHIGH CVE-2023-52425\\nhttps://scout.docker.com/v/CVE-2023-52425\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n\\uffffMEDIUM CVE-2023-52426\\nhttps://scout.docker.com/v/CVE-2023-52426\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n<Snip>\\nI’ve snipped the output, so it only shows some of the vulnerabilities. However, even\\nfrom the snipped output in the book, you can see:\\n• Scout has scanned 66 packages and detected several vulnerabilities\\n• We’re using version 2.5.0-r2 of the expat package which has one high (1H) and\\none medium (1M) vulnerability\\n• The high vulnerability is listed as CVE-2023-52425 and the medium as CVE-2023-\\n52426\\n• The report includes links to Scout reports containing more info on each vulnera-\\nbility\\n• Scout recommends updating to expat version 2.6.0-r0 which contains fixes for\\nboth\\nFigure 16.8 shows what it looks like in in Docker Desktop, and you get similar integra-\\ntions and views in Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 264}, page_content='16: Docker security\\n258\\nFigure 16.8 - Docker Scout integration with Docker Desktop\\nIf you subscribe to Docker Scout, you can use the scout.docker.com portal to configure\\npolicies and integrations with Docker Hub and other registries.\\nAs good as vulnerability scanning is, it only scans images and doesn’t detect security\\nproblems with networks, nodes, or orchestrators. Also, not all image scanners are equal.\\nFor example, the best ones perform deep binary-level scans, whereas others may just\\nlook at package names and do not inspect content closely.\\nIn summary, scanning tools are great for inspecting your images and detecting known\\nvulnerabilities. Beware though, with great knowledge comes great responsibility — once\\nyou’re aware of vulnerabilities, you’re responsible for mitigating or fixing them.\\nSigning and verifying images with Docker Content\\nTrust\\nDocker Content Trust (DCT) makes it simple for you to verify the integrity and pub-\\nlisher of images and is especially important when you’re pulling images over untrusted\\nnetworks such as the internet.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 265}, page_content='16: Docker security\\n259\\nAt a high level, DCT lets you sign your images when you push them to registries like\\nDocker Hub. It also lets you verify the images you pull and run as containers.\\nFigure 16.9 shows the high-level process.\\nFigure 16.9 - Docker Content Trust image signing and verification\\nYou can also use DCT to provide context, such as whether or not a developer has signed\\nan image for use in a particular environment such as prod or dev, or whether an image\\nhas been superseded by a newer version and is therefore stale.\\nThe following steps walk you through configuring Docker Content Trust, signing and\\npushing an image, and then pulling the signed image.\\nIf you plan on following along, you’ll need a cryptographic key pair. If you don’t already\\nhave one, you can run the following docker trust command to generate one. The\\ncommand generates a new key pair called nigel and loads it to the local trust store ready\\nfor use. It will prompt you to enter a passphrase; don’t forget it :-)\\n$ docker trust key generate nigel\\nGenerating key for nigel...\\nEnter passphrase for new nigel key with ID 1f78609:\\nRepeat passphrase for new nigel key with ID 1f78609:\\nSuccessfully generated and loaded private key.... key available: /Users/nigelpoulton/nigel.pub\\nIf you already have a key pair, you can import and load it with docker trust key load\\nkey.pem --name nigel.\\nThe next step is associating your key pair with the image repository to which you’ll push\\nsigned images. This example associates the nigel.pub key with the nigelpoulton/ddd-\\ntrust repo on Docker Hub. Your key file and repo will be different, and the repository\\ndoesn’t have to exist before you run the command.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 266}, page_content='16: Docker security\\n260\\n$ docker trust signer add --key nigel.pub nigel nigelpoulton/ddd-trust\\nAdding signer \"nigel\" to nigelpoulton/dct...\\nInitializing signed repository for nigelpoulton/dct...\\nEnter passphrase for root key with ID aee3314:\\nEnter passphrase for new repository key with ID 1a18dd1:\\nRepeat passphrase for new repository key with ID 1a18dd1:\\nSuccessfully initialized \"nigelpoulton/dct\"\\nSuccessfully added signer: nigel to nigelpoulton/dct\\nNow that you’ve loaded the key pair and associated it with a repository, the final step is\\nto sign an image and push it to the repo.\\nThe following command signs a local image called nigelpoulton/ddd-trust:signed\\nand pushes it to Docker Hub. Your image will have a different name and you’ll push it to\\na different repo.\\n$ docker trust sign nigelpoulton/ddd-trust:signed\\nSigning and pushing trust data for local image nigelpoulton/ddd-trust:signed may...\\nThe push refers to repository [docker.io/nigelpoulton/ddd-trust]\\n6495b414566f: Mounted from nigelpoulton/ddd-book\\n798676f7ef8b: Mounted from nigelpoulton/ddd-book\\nbca4290a9639: Mounted from nigelpoulton/ddd-book\\n28ad2149d870: Mounted from nigelpoulton/ddd-book\\n4f4fb700ef54: Mounted from nigelpoulton/ddd-book\\n5e1fc7f5df34: Mounted from nigelpoulton/ddd-book\\nsigned: digest: sha256:b65f9a1aa4e670bbafd0fbb91281ea95f9cdc5728aa546579e248dfbc0ea4bde\\nSigning and pushing trust metadata\\nEnter passphrase for nigel key with ID 92330ea:\\nSuccessfully signed docker.io/nigelpoulton/ddd-trust:signed\\nThe push operation creates the repo on Docker Hub and then signs and pushes the\\nimage. You can view the repo on Docker Hub, and you can run the following command\\nto inspect its signing data.\\n$ docker trust inspect nigelpoulton/ddd-trust:signed --pretty\\nSignatures for nigelpoulton/ddd-trust:signed\\nSIGNED TAG\\nDIGEST\\nSIGNERS\\nsigned\\n30e6d35703c578ee...4fcbbcbb0f281\\nnigel\\nList of signers and their keys for nigelpoulton/ddd-trust:signed\\nSIGNER\\nKEYS\\nnigel\\n4d6f1bf55702\\nAdministrative keys for nigelpoulton/ddd-trust:signed\\nRepository Key:\\n5e72e54afafb8444f...6b2744b32010ad22\\nRoot Key:\\n40418fc47544ca630...69a2cb89028c22092'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 267}, page_content='16: Docker security\\n261\\nYou can export the DOCKER_CONTENT_TRUST variable with a value of 1 to force a Docker\\nhost to sign and verify all images.\\n$ export DOCKER_CONTENT_TRUST=1\\nOnce enabled, you won’t be able to pull and work with unsigned images.\\nTest it by trying to pull an unsigned image.\\n$ docker pull nigelpoulton/ddd-book:web0.2\\nError: remote trust data does not exist for docker.io/nigelpoulton/ddd-book: notary.docker.io\\ndoes not have trust data for docker.io/nigelpoulton/ddd-book\\nYou can no longer pull images without trust data!\\nDelete the local copy of the image you just signed and pushed so that you can try pulling\\nit from Docker Hub. Your image name will be different.\\n$ docker rmi nigelpoulton/ddd-trust:signed\\nUntagged: nigelpoulton/ddd-trust:signed@sha256...\\n<Snip>\\nNow, try pulling the image.\\n$ docker pull nigelpoulton/ddd-trust:signed\\nPull (1 of 1): nigelpoulton/ddd-trust:signed@sha256:30e6...\\ndocker.io/nigelpoulton/ddd-trust@sha256:30e6... Pulling from nigelpoulton/ddd-trust\\n08409d417260: Pull complete\\nDigest: sha256:30e6d35703c578ee703230b9dc87ada2ba958c1928615ac8a674fcbbcbb0f281\\nStatus: Downloaded newer image for nigelpoulton/ddd-trust@sha256:30e6...\\nTagging nigelpoulton/ddd-trust@sha256:30e6d... as nigelpoulton/ddd-trust:signed\\ndocker.io/nigelpoulton/ddd-trust:signed\\nThe pull worked because the image has valid trust data.\\nIn summary, Docker Content Trust is an important technology that helps you verify the\\nintegrity of the images you pull and run. It’s simple to configure in its basic form, but\\nmore advanced features, such as context, can be more complex.\\nDocker Secrets\\nMost applications leverage sensitive data such as passwords, certificates, and SSH keys.\\nFortunately, Docker lets you wrap them inside secrets to keep them secure.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 268}, page_content='16: Docker security\\n262\\nNote: Secrets only work in swarm mode as they leverage the cluster store.\\nBehind the scenes, Docker encrypts secrets when they’re at rest in the cluster store and\\nwhile they’re in flight on the network. It also uses in-memory filesystems to mount secrets\\ninto containers and operates a least-privilege model, where secrets are only available\\nto services that have been explicitly granted access. There’s even a docker secret\\ncommand.\\nFigure 16.10 shows the high-level workflow of creating a secret and deploying it to\\nservice replicas:\\nFigure 16.10 - Secret workflow\\nLet’s go through the five steps in the diagram. I’ve used a key symbol to show the secret,\\nand it’s only available to the dark containers.\\n1. You create the secret\\n2. Docker stores it in the encrypted cluster store\\n3. You create a service (the dark containers) and grant it access to the secret\\n4. Docker encrypts the secret when sending it over the network to service replicas\\n5. Docker mounts the secret into service replicas as an unencrypted file in an in-\\nmemory filesystem\\nThe light-colored containers are part of a different service and cannot access the secret.\\nAs soon as replicas using the secret terminate, Docker destroys the in-memory filesys-\\ntem and flushes the secret from the node.\\nDocker mounts secrets in their unencrypted form so that applications can use them\\nwithout needing keys to decrypt them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 269}, page_content='16: Docker security\\n263\\nYou can create and manage secrets with the docker secret command and attach them\\nto services by passing the --secret flag to the docker service create command.\\nClean up\\nIf you’ve followed along, you’ve created a swarm, added a signer, created a new repo\\non Docker Hub, and exported an environment variable to sign and verify images\\nautomatically.\\nRun the following command to disable Docker Content Trust. You’ll need to run it on\\nevery node where you enabled Docker Content Trust.\\n$ unset DOCKER_CONTENT_TRUST\\nRemove the signer from the repository you created. Your signer and repository will have\\ndifferent names.\\n$ docker trust signer remove nigel nigelpoulton/ddd-trust\\nRemoving signer \"nigel\" from nigelpoulton/ddd-trust...\\nall signed tags are currently revoked, use docker trust sign to fix\\nYou may also want to delete the repositories you created on Docker Hub and delete the\\nlocal key files on your system (usually a .pub file in your home directory)\\nDelete the swarm by running the following command on all swarm nodes. You should\\nrun it on the swarm managers last.\\n$ docker swarm leave -f\\nChapter Summary\\nYou can configure Docker to be extremely secure. It supports all of the major Linux\\nsecurity technologies such as kernel namespaces, cgroups, capabilities, MAC, and\\nseccomp. It ships with sensible defaults for all of these, but you can customize and even\\ndisable them.\\nIn addition to the Linux security technologies, Docker includes an extensive set of\\nits own security technologies. Swarms are built on TLS and are secure out of the box.\\nDocker Scout performs binary-level image scans and provides detailed reports of\\nknown vulnerabilities and suggested fixes. Docker Content Trust lets you sign and\\nverify images, and Docker secrets allow you to share sensitive data with swarm services.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 270}, page_content='What next\\nThank you so much for reading my book. You’re on your way to mastering Docker and\\ncontainers, and you’ve learned some skills running local LLMs.\\nGet involved with the community\\nThere’s a vibrant cloud-native community full of helpful people. Get involved with\\nDocker groups and chats on the internet, and look up your local Docker or cloud-native\\nmeetup (search for “Docker meetup near me”).\\nKubernetes\\nNow that you understand Docker, Kubernetes is a great next step. It’s a lot like Swarm\\nbut has a larger scope and a more active community.\\nIf you liked this book, you’ll love my Kubernetes books.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 271}, page_content='What next\\n265\\nFeedback and reviews\\nBooks live and die by Amazon reviews and stars.\\nI live and breathe this book, ensuring you get the most up-to-date content that’s easy to\\nread and understand. So, please take a moment to leave a kind review on Amazon or\\nGoodreads.\\nAlso, ping me at ddd@nigelpoulton.com if you want to suggest content or fixes for\\nfuture editions.\\nConnect with me\\nFinally, thanks for reading my book. Feel free to connect with me on any of the usual\\nplatforms to discuss Docker, Kubernetes, Wasm, AI, and other technologies.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 272}, page_content='Terminology\\nThis glossary defines some of the most common Docker and container-related terms\\nused in the book.\\nIf you think I’ve missed anything important, ping me at ddd@nigelpoulton.com.\\nTerm\\nDefinition (according to Nigel)\\nAI acceleration hardware\\nHardware, such as GPUs, NPUs, and TPUs\\nthat speed up the execution (inference) of AI\\nmodels.\\nAPI\\nApplication Programming Interface. In the\\ncase of Docker, all resources are defined in\\nthe Docker API, which is RESTful and\\nexposed via the Docker Daemon.\\nBase image\\nThe first layer of all container images.\\nCreated by the Dockerfile FROM instruction\\nand usually contains a minimal set of OS\\nconstructs required by an application.\\nBuild\\nThe process of building a new container\\nimage. Docker builds images by stepping\\nthrough a set of instructions defined in a\\nDockerfile.\\nBuild Cloud\\nA subscription service that performs fast and\\nefficient image builds in Docker’s cloud\\ninfrastructure. It allows you to share a\\ncommon build cache among teams for very\\nfast builds.\\nBuildKit\\nDocker’s build engine that implements\\nadvanced build features such as advanced\\ncaching, multi-stage builds, and\\nmulti-architecture builds.\\nBuildx\\nDocker’s latest and greatest build client that\\nsupports all the latest features of BuildKit,\\nsuch as multi-stage builds and\\nmulti-architecture images. Buildx has been\\nDocker’s default build client since Docker\\nEngine v23.0 and Docker Desktop v4.19.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 273}, page_content='Terminology\\n267\\nTerm\\nDefinition (according to Nigel)\\nCapability\\nLinux kernel technology used by Docker to\\ncreate user accounts with the precise set of\\nsystem access they need.\\nChatbot\\nA computer program that can participate in\\ntext-based human conversations and is often\\nindistinguishable from a human.\\nCloud native\\nA loaded term that means different things to\\ndifferent people. Cloud native is a way of\\ndesigning, building, and working with\\nmodern applications and infrastructure. I\\nconsider an application to be cloud native if it\\ncan self-heal, scale on demand, perform\\nrolling updates, and versioned rollbacks.\\nCluster store\\nDocker Swarm’s distributed database that\\nholds the state of the cluster and apps. Based\\non the etcd distributed database, it is\\nautomatically encrypted and automatically\\ndistributed across all swarm managers for\\nhigh availability.\\nCompose\\nAn open specification for defining, deploying,\\nand managing multi-container microservices\\napps. Docker implements the Compose spec\\nand provides the docker compose command\\nto make it easy to work with Compose apps.\\nContainer\\nA container is a collection of kernel\\nnamespaces organized to look, smell, and feel\\nlike a regular operating system. Each\\ncontainer runs a single application, and\\ncontainers are smaller, faster, and more\\nportable than virtual machines. We\\nsometimes call them Docker containers or OCI\\ncontainers\\nContainer Network Model\\nPluggable interface enabling different\\nnetwork topologies and architectures. Third\\nparties provide CNM plugins for overlay\\nnetworks and BGP networks, as well as\\nvarious implementations of each.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 274}, page_content='Terminology\\n268\\nTerm\\nDefinition (according to Nigel)\\nContainer runtime\\nSoftware running on every Docker node\\nresponsible for pulling container images,\\nstarting containers, stopping containers, and\\nother low-level container operations. Docker\\nuses two runtimes that work together:\\ncontainerd is Docker’s high-level runtime\\nthat manages lifecycle events such as starting\\nand stopping containers, whereas runc is\\nDocker’s low-level runtime that interfaces\\nwith kernel constructs such as namespaces\\nand cgroups.\\ncontainerd\\nIndustry-standard container runtime used by\\nDocker and most Kubernetes clusters.\\nDonated to the CNCF by Docker, Inc.\\nPronounced “container dee”.\\nContainerize\\nThe process of packaging an application and\\nall dependencies into a container image.\\nControl Groups (cgroups)\\nLinux kernel feature that Docker uses to limit\\nthe amount of host CPU, RAM, disk, and\\nnetwork resources a container uses.\\nDesired state\\nHow your cluster and applications should be.\\nFor example, the desired state of an application\\nmicroservice might be five replicas of xyz\\ncontainer listening on port 8080/tcp. Vital to\\nreconciliation.\\nDocker\\nPlatform that makes it easy to work with\\ncontainerized apps. It allows you to build\\nimages, as well as run and manage standalone\\ncontainers and multi-container apps.\\nDocker Debug\\nDocker CLI plugin that lets you easily debug\\nslim images and containers that don’t ship\\nwith any debugging tools.\\nDocker Desktop\\nDesktop application for Linux, Mac, and\\nWindows that makes working with Docker\\neasy. It has a slick UI and many advanced\\nfeatures like image management, vulnerability\\nscanning, and Wasm support.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 275}, page_content='Terminology\\n269\\nTerm\\nDefinition (according to Nigel)\\nDocker Hub\\nHigh-performance OCI-compliant image\\nregistry. Docker Hub has over 57PB of\\nstorage and handles an average of 30K\\nrequests per second.\\nDocker, Inc.\\nUS-based technology company making it easy\\nfor developers to build, ship, and run\\ncontainerized applications. The company\\nbehind the Docker platform.\\nDocker init\\nA new Docker CLI plugin that creates\\nhigh-fidelity Dockerfiles and makes it easy to\\nscaffold Compose apps.\\nDocker Model Runner\\nDocker’s native tool for running local AI\\nmodels directly on host hardware (outside of\\ncontainers). Exposes OpenAI-compatible\\nendpoints.\\nDocker Scout\\nDocker’s native vulnerability scanning service.\\nScout is a subscription service that integrates\\nwith the Docker CLI, Docker Desktop,\\nDocker Hub, and other image registries.\\nDockerfile\\nPlain text file with instructions telling Docker\\nhow to build an application into a container\\nimage.\\netcd\\nThe open-source distributed database used by\\nDocker Swarm.\\nGGUF\\nBinary file format for storing LLM weights\\nand metadata.\\nGPU\\nGraphics Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nImage\\nArchive containing application code, all\\ndependencies, and the metadata required to\\nstart a single application as a container. We\\nsometimes call them OCI images, container\\nimages, or Docker images.\\nIngress network\\nHidden network on all Docker Swarm\\nclusters used to publish services to external\\nclients.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 276}, page_content='Terminology\\n270\\nTerm\\nDefinition (according to Nigel)\\nKernel namespace\\nFeature of the Linux kernel used by Docker to\\nisolate containers from processes running on\\nthe host and in other containers.\\nllama.cpp\\nPopular core inference engine (LLM runtime)\\nused by model servers like Docker Model\\nRunner and Ollama. Open source project that\\ncan run LLMs on low-grade consumer CPUs\\nas well as some high-performance GPUs.\\nLarge Language Model (LLM)\\nAn AI application that can participate in\\nhuman conversations and create human-like\\nanswers and ideas. The book’s AI chatbot app\\nuses an LLM that is trained as a coding\\nassistant that can help answer coding\\nquestions and provide coding samples.\\nLayer\\nImage layers contain modifications to the\\nbase image or the layer below them. Docker\\nbuilds images by stacking layers, each\\ncontaining changes to the layer below it. A\\nsimple example is a base layer that has basic\\nOS constructs, followed by a layer with the\\napplication. The two combined layers create\\nthe image with the OS and app.\\nlibcontainer\\nA Go library that uses namespaces, cgroups,\\nand capabilities to build containers. Docker\\nuses libcontainer via the runc low-level\\nruntime that is a CLI wrapper around\\nlibcontainer.\\nlibnetwork\\nThe Go library used by Docker to create and\\nmanage container networks.\\nManifest (OCI)\\nJSON document describing the configuration\\nand layers of OCI artifacts such as images and\\nmodels.\\nMicroservices\\nDesign pattern for modern applications.\\nIndividual application features are developed\\nas their own small applications\\n(microservices/containers) and communicate\\nvia APIs. They work together to form a useful\\napplication.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 277}, page_content='Terminology\\n271\\nTerm\\nDefinition (according to Nigel)\\nModel\\nAI program that has been pre-trained to\\naccept prompts and give human-like\\nresponses. We refer to AI programs as models.\\nMLX\\nApple’s machine learning framework that\\ngives AI models access to the unified memory\\narchitecture of Apple’s M series chips.\\nMulti-architecture builds (sometimes called\\nmulti-platform builds)\\nAllows you to build images for multiple\\narchitectures and platforms with a single\\ndocker build command. For example, you\\ncan run a single docker build command on\\nan AMD-based Windows system to build an\\nAMD image and an ARM image.\\nMulti-stage build\\nAllows you to create very small images (slim\\nimages). You build your images in stages and\\nonly carry forward the necessary artifacts for\\neach next stage. Each build stage is\\nrepresented by its own FROM instruction in\\nyour Dockerfile, and later build stages use the\\nCOPY --from instruction to use artifacts from\\nprevious stages and leave everything else\\nbehind.\\nNPU\\nNeural Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nObserved state\\nAlso known as current state or actual state. The\\nmost up-to-date view of the cluster and\\nrunning applications. Docker Swarm is\\nalways working to make observed state match\\ndesired state.\\nOllama\\nOpen-source runtime for running LLMs\\nlocally. A bit like Docker for LLMs — Ollama\\ncan pull and push LLMs and run them locally\\non your computer.\\nOpenAI-compatible endpoint\\nAPI service that accepts requests formatted\\naccording to OpenAI’s API specifications and\\nreturns responses in the same format.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 278}, page_content='Terminology\\n272\\nTerm\\nDefinition (according to Nigel)\\nOpen Container Initiative (OCI)\\nLightweight governance body responsible for\\ncreating and maintaining standards for\\nlow-level container technologies such as\\nimages, runtimes, and registries. Docker\\ncreates OCI-compliant images, implements\\nan OCI-compliant runtime, and Docker Hub\\nis an OCI-compliant registry.\\nOrchestrator\\nSoftware that deploys and manages apps.\\nDocker Swarm and Kubernetes are examples\\nof orchestrators that manage microservices\\napps, keep them healthy, scale them up and\\ndown, and more…\\nOverlay network\\nA large flat layer-2 network that spans\\nmultiple swarm nodes. All containers on the\\nsame overlay network can communicate with\\neach other, even if they’re on different Docker\\nhosts on different networks. The built-in\\noverlay driver creates overlay networks using\\nadvanced VXLAN technologies. Only used by\\nDocker Swarm.\\nPush\\nUpload an image to a registry.\\nPull\\nDownload an image from a registry.\\nQuantization\\nThe process of reducing the size and memory\\nrequirements of an AI model without\\nsacrificing too much performance and model\\naccuracy.\\nReconciliation\\nThe process of watching the state of an\\napplication and ensuring observed state\\nmatches desired state. Docker Swarm runs\\nreconciliation loops, ensuring applications\\nrun how you want them to.\\nRegistry\\nCentral place for storing and retrieving\\nimages. We sometimes call them OCI registries,\\ncontainer registries, or Docker registries.\\nRepository\\nAn area of a registry where you store related\\ncontainer images. You can set access controls\\nper repository.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 279}, page_content='Terminology\\n273\\nTerm\\nDefinition (according to Nigel)\\nREPL\\nRead, Evaluate, Print, Loop. CLI environment\\nfor testing and interacting with LLMs.\\nSeccomp\\nSecure computing Linux kernel feature used\\nby Docker to restrict the syscalls available to a\\ncontainer.\\nSecret\\nThe way Docker Swarm lets you inject\\nsensitive data into a container at run-time.\\nService\\nCapital “S” is a Docker Swarm feature that\\naugments containers with self-healing,\\nscaling, rollouts, and rollbacks.\\nSpin\\nFramework that makes it easy to build,\\ndeploy, and run Wasm apps. Docker Desktop\\nships with the spin runtime. Created by\\nFermyon Technologies, Inc.\\nSwarm (also known as Docker Swarm)\\nDocker’s native orchestration platform. A\\nlightweight and easy alternative to\\nKubernetes.\\nTPU\\nTensor Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nVolume\\nWhere containers store important data they\\nneed to keep. You can create and delete\\nvolumes independently from containers.\\nWasm (WebAssembly)\\nNew virtual machine architecture that is\\nsmaller, faster, more portable, and more\\nsecure than traditional containers. Wasm apps\\nrun anywhere with a Wasm runtime.\\nYAML\\nYet Another Markup Language. You write\\nCompose files in YAML. It’s a superset of\\nJSON.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cc54603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7985e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200,separators=[\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a5690a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 1}, page_content='Docker Deep Dive\\nZero to Docker in a single book!\\nNigel Poulton\\nThis book is available at https://leanpub.com/dockerdeepdive\\nThis version was published on 2025-05-12\\nISBN 9781916585133\\nThis is a Leanpub book. Leanpub empowers authors and publishers with the Lean\\nPublishing process. Lean Publishing is the act of publishing an in-progress ebook using\\nlightweight tools and many iterations to get reader feedback, pivot until you have the\\nright book and build traction once you do.\\n© 2016 - 2025 Nigel Poulton'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 2}, page_content='Huge thanks to my wife and kids for putting up with a geek in the house who genuinely thinks\\nhe’s a bunch of software running inside of a container on top of midrange biological hardware. It\\ncan’t be easy living with me!\\nMassive thanks as well to everyone who watches my Pluralsight videos. I love connecting with you\\nand really appreciate all the feedback I’ve gotten over the years. This was one of the major reasons\\nI decided to write this book! I hope it’ll be an amazing tool to help you drive your careers even\\nfurther forward.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 3}, page_content='Contents\\nAbout this edition\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n1\\nAbout the author\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n2\\n0: About the book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n3\\nPart 1: The big picture stuff . . . . . . . . . . . . . . . . . . . . .\\n6\\n1: Containers from 30,000 feet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nThe bad old days . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nHello VMware! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nVMwarts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nHello Containers! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nLinux containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 3}, page_content='7\\nHello Containers! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nLinux containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nHello Docker! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\nDocker and Windows . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\nWhat about Wasm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\nDocker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\nWhat about Kubernetes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n2: Docker and container-related standards and projects . . . . . . . . . . . . . . . . 13\\nDocker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nContainer-related standards and projects . . . . . . . . . . . . . . . . . . . . . . . . 15'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 3}, page_content='Docker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nContainer-related standards and projects . . . . . . . . . . . . . . . . . . . . . . . . 15\\n3: Getting Docker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nDocker Desktop\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nInstalling Docker with Multipass\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nInstalling Docker on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4: The big picture\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nThe Ops Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nThe Dev Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='CONTENTS\\nPart 2: The technical stuff . . . . . . . . . . . . . . . . . . . . . . . 35\\n5: The Docker Engine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\nDocker Engine – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\nThe Docker Engine\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\nThe influence of the Open Container Initiative (OCI) . . . . . . . . . . . . . . . . . 39\\nrunc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\ncontainerd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\nStarting a new container (example) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\\nWhat’s the shim all about? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nHow it’s implemented on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='What’s the shim all about? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nHow it’s implemented on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n6: Working with Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDocker images – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nIntro to images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nPulling images\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nImage registries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nImage naming and tagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nImages and layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\nPulling images by digest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nMulti-architecture images'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='Pulling images by digest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nMulti-architecture images\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nVulnerability scanning with Docker Scout . . . . . . . . . . . . . . . . . . . . . . . . 66\\nDeleting Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\\nImages – The commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\\n7: Working with containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nContainers – The TLDR\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nContainers vs VMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nImages and Containers\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\nCheck Docker is running . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nStarting a container'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\nCheck Docker is running . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nStarting a container\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\nHow containers start apps\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\\nConnecting to a running container . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\\nInspecting container processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\\nThe docker inspect command . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\nWriting data to a container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\nStopping, restarting, and deleting a container . . . . . . . . . . . . . . . . . . . . . . 85\\nKilling a container’s main process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nDebugging slim images and containers with Docker Debug'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='Killing a container’s main process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nDebugging slim images and containers with Docker Debug\\n. . . . . . . . . . . . . 89\\nSelf-healing containers with restart policies . . . . . . . . . . . . . . . . . . . . . . . 94\\nContainers – The commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\\n8: Containerizing an app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='CONTENTS\\nContainerizing an app – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\\nContainerize a single-container app\\n. . . . . . . . . . . . . . . . . . . . . . . . . . .100\\nMoving to production with multi-stage builds\\n. . . . . . . . . . . . . . . . . . . . . 111\\nBuildx, BuildKit, drivers, and Build Cloud . . . . . . . . . . . . . . . . . . . . . . . .116\\nMulti-architecture builds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .118\\nA few good practices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\nContainerizing an app – The commands . . . . . . . . . . . . . . . . . . . . . . . . . 124\\n9: Multi-container apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nDocker Compose – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\\nCompose background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='Docker Compose – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\\nCompose background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nInstalling Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nThe sample app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .128\\nCompose files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .130\\nDeploying apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .133\\nManaging apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .136\\nDeploying apps with Compose – The commands . . . . . . . . . . . . . . . . . . . .139\\n10: Docker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner background . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='10: Docker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner background . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . .142\\nInstalling Docker Model Runner . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nExplore Docker Model Runner\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .145\\nUse Docker Model Runner with Compose . . . . . . . . . . . . . . . . . . . . . . . .152\\nUse Docker Model Runner with Open WebUI\\n. . . . . . . . . . . . . . . . . . . . .155\\nRunning models in containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .160\\nDocker Model Runner – The commands . . . . . . . . . . . . . . . . . . . . . . . . .162\\nChapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .163'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='Docker Model Runner – The commands . . . . . . . . . . . . . . . . . . . . . . . . .162\\nChapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .163\\n11: Docker and Wasm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\\nPre-reqs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .165\\nIntro to Wasm and Wasm containers . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\\nWrite a Wasm app\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .168\\nContainerize a Wasm app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .170\\nRun a Wasm container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172\\nClean up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173\\nChapter summary\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='Clean up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173\\nChapter summary\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n12: Docker Swarm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nSwarm primer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175\\nBuild a swarm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .176\\nDeploy Swarm app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .179\\nDocker Swarm – The Commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='CONTENTS\\n13: Docker Networking\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nDocker Networking – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189\\nDocker networking theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189\\nSingle-host bridge networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .193\\nExternal access via port mappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . .200\\nDocker Networking – The Commands . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\n14: Docker overlay networking\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nDocker overlay networking – The TLDR\\n. . . . . . . . . . . . . . . . . . . . . . . .216\\nDocker overlay networking history . . . . . . . . . . . . . . . . . . . . . . . . . . . .216\\nBuilding and testing Docker overlay networks\\n. . . . . . . . . . . . . . . . . . . . . 217'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='Docker overlay networking history . . . . . . . . . . . . . . . . . . . . . . . . . . . .216\\nBuilding and testing Docker overlay networks\\n. . . . . . . . . . . . . . . . . . . . . 217\\nOverlay networks explained . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDocker overlay networking – The commands . . . . . . . . . . . . . . . . . . . . . .229\\n15: Volumes and persistent data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nVolumes and persistent data – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . 231\\nContainers without volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .232\\nContainers with volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .233\\nVolumes and persistent data – The Commands . . . . . . . . . . . . . . . . . . . . .240\\n16: Docker security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='Volumes and persistent data – The Commands . . . . . . . . . . . . . . . . . . . . .240\\n16: Docker security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nDocker security – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .242\\nKernel Namespaces\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\\nControl Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .246\\nCapabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .246\\nMandatory Access Control systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\nseccomp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\nDocker security technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nSwarm security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='Docker security technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nSwarm security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nDocker Scout and vulnerability scanning\\n. . . . . . . . . . . . . . . . . . . . . . . .256\\nSigning and verifying images with Docker Content Trust . . . . . . . . . . . . . . .258\\nDocker Secrets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nWhat next . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\\nTerminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 7}, page_content='CONTENTS\\n1\\nAbout this edition\\nThis edition was published in May 2025 and is up to date with the latest industry trends\\nand the latest enhancements to Docker.\\nMajor changes include:\\n• Brand new Docker Model Runner chapter with full AI LLM project\\n• Updates to BuildKit, buildx, and the new Docker Build Cloud\\n• Updates to Docker Debug content\\n• Updates to Wasm content\\n• Streamlined Swarm chapter\\nEnjoy the book, and get ready to master containers!\\n&copy 2025 Nigel Poulton Ltd.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 8}, page_content='About the author\\nNigel is a technology geek with a passion for learning new technologies and making\\nthem easier for others to learn. He’s the author of best-selling books on Docker and\\nKubernetes, as is the author of AI Explained: Facts, Fiction, and Future, a brutal read\\ninto the impacts of AI on society and the future of humanity.\\nNigel is a Docker Captain and has held senior technology roles at large and small\\nenterprises.\\nIn his free time, he listens to audiobooks and coaches youth football (soccer). He wishes\\nhe lived in the future and could understand the mysteries of life and the universe. He’s\\npassionate about learning, cars, and football (soccer). He lives in England with his\\nfabulous wife and three children.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 9}, page_content='0: About the book\\nThis May 2025 edition gets you up to speed with Docker and containers fast, no prior\\nexperience necessary.\\nIt has a brand-new chapter covering the latest and greatest Docker Model Runner\\ncontent for running local LLMs through Docker!\\nWhy should I read this book or care about Docker?\\nDocker has already changed how we build, share, and run applications, and it’s now\\nplaying a major role in emerging technologies such as Wasm and AI.\\nSo, if you want the best jobs working with the best technologies, you need a strong\\nDocker skillset.\\nHow I’ve organized the book\\nI’ve divided the book into two main sections:\\n1. The big picture stuff\\n2. The technical stuff\\nThe big picture stuff gets you up to speed with the basics, such as what Docker is, why we\\nuse containers, and fundamental jargon such as cloud-native, microservices, and orchestration.\\nThe technical stuff section covers everything you need to know about images, containers,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 9}, page_content='use containers, and fundamental jargon such as cloud-native, microservices, and orchestration.\\nThe technical stuff section covers everything you need to know about images, containers,\\nmulti-container microservices apps, orchestration, and the increasingly important topics of\\nWebAssembly, running local AI models, vulnerability scanning, debugging containers,\\nand more.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 10}, page_content='0: About the book\\n4\\nChapter breakdown\\n• Chapter 1: Summarizes the history and future of Docker and containers\\n• Chapter 2: Explains the most important container-related standards and projects\\n• Chapter 3: Shows you a few ways to get Docker\\n• Chapter 4: Walks you through deploying your first container\\n• Chapter 5: Deep dive into the Docker Engine architecture\\n• Chapter 6: Deep dive into images and image management\\n• Chapter 7: Deep dive into containers and container management\\n• Chapter 8: Deep dive into containerizing applications\\n• Chapter 9: Walks you through deploying and managing a multi-container AI\\nchatbot app with Docker Compose\\n• Chapter 10: Dives into the exciting new world of running local AI models with\\nDocker Model Runner\\n• Chapter 11: Walks you through building, containerizing, and running a Wasm app\\nwith Docker\\n• Chapter 12: Walks you through building a swarm cluster and deploying apps to it\\n• Chapter 13: Deep dive into Docker networking'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 10}, page_content='with Docker\\n• Chapter 12: Walks you through building a swarm cluster and deploying apps to it\\n• Chapter 13: Deep dive into Docker networking\\n• Chapter 14: Walks you through building and working with overlay networks\\n• Chapter 15: Introduces you to persistent and non-persistent data in Docker\\n• Chapter 16: Covers all the major Linux and Docker security technologies\\nEditions and updates\\nDocker, AI, and the cloud-native ecosystem are evolving fast, and 2-3-year-old books\\nare dangerously outdated. As a result, I’m committed to updating this book at least once\\nper year.\\nIf that sounds excessive, welcome to the new normal. For example, I released a big\\nupdate in January 2025. Then, less than three months later, I was writing a full new\\nchapter on Docker Model Runner for this May 2025 edition! This is hard work, but I’m\\ncommitted to keeping this the best Docker book in the world.\\nThe book is available in hardback, paperback, and e-book on all good book publishing\\nplatforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 11}, page_content='0: About the book\\n5\\nKindle updates\\nUnfortunately, Kindle readers cannot get updates. I have absolutely no control over\\nthis and was devastated when this change happened. Some people have successfully\\ncontacted Kindle Support and had the support team delete the old copy and push the\\nnew edition. However, this doesn’t always work. Please contact the Kindle Support team\\nfor updates, but if they can’t help, feel free to ping me at the book’s email address.\\nFeedback\\nIf you like the book and it helps your career, share the love by recommending it to a\\nfriend and leaving a review on Amazon or Goodreads.\\nIf you spot a typo or want to make a recommendation, drop me a quick email at\\nddd@nigelpoulton.com and I’ll do my best to respond.\\nThat’s everything. Let’s get rocking with Docker!'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 12}, page_content='Part 1: The big picture stuff'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 13}, page_content='1: Containers from 30,000 feet\\nContainers have taken over the world!\\nIn this chapter, you’ll learn why we have containers, what they do for us, and where we\\ncan use them.\\nThe bad old days\\nApplications are the powerhouse of every modern business. When applications break,\\nbusinesses break.\\nMost applications run on servers, and in the past, we were limited to running one\\napplication per server. As a result, the story went something like this:\\nEvery time a business needed a new application, it had to buy a new server. Unfor-\\ntunately, we weren’t very good at modeling the performance requirements of new\\napplications, and we had to guess. This resulted in businesses buying bigger, faster, and\\nmore expensive servers than necessary. After all, nobody wanted underpowered servers\\nincapable of handling the app, resulting in unhappy customers and lost revenue. As\\na result, we ended up with racks and racks of overpowered servers operating as low'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 13}, page_content='incapable of handling the app, resulting in unhappy customers and lost revenue. As\\na result, we ended up with racks and racks of overpowered servers operating as low\\nas 5-10% of their potential capacity. This was a tragic waste of company capital and\\nenvironmental resources.\\nHello VMware!\\nAmid all this, VMware, Inc. gave the world a gift — the virtual machine (VM) — a\\ntechnology that allowed us to run multiple business applications on a single server\\nsafely.\\nIt was a game-changer. Businesses could run new apps on the spare capacity of existing\\nservers, spawning a golden age of maximizing the value of existing assets.\\nVMwarts\\nBut, and there’s always a but! As great as VMs are, they’re far from perfect.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 14}, page_content='1: Containers from 30,000 feet\\n8\\nFor example, every VM needs its own dedicated operating system (OS). Unfortunately,\\nthis has several drawbacks, including:\\n• Every OS consumes CPU, RAM, and other resources we’d rather use on applica-\\ntions\\n• Every VM and OS needs patching\\n• Every VM and OS needs monitoring\\nVMs are also slow to boot and not very portable.\\nHello Containers!\\nWhile most of us were reaping the benefits of VMs, web scalers like Google had already\\nmoved on from VMs and were using containers.\\nA feature of the container model is that every container shares the OS of the host it’s\\nrunning on. This means a single host can run more containers than VMs. For example,\\na host that can run 10 VMs might be able to run 50 containers, making containers far\\nmore efficient than VMs.\\nContainers are also faster and more portable than VMs.\\nLinux containers\\nModern containers started in the Linux world and are the product of incredible work'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 14}, page_content='more efficient than VMs.\\nContainers are also faster and more portable than VMs.\\nLinux containers\\nModern containers started in the Linux world and are the product of incredible work\\nfrom many people over many years. For example, Google contributed many container-\\nrelated technologies to the Linux kernel. It’s thanks to many contributions like these\\nthat we have containers today.\\nSome of the major technologies underpinning modern containers include kernel\\nnamespaces, control groups (cgroups), and capabilities.\\nHowever, despite all this great work, containers were incredibly complicated, and it\\nwasn’t until Docker came along that they became accessible to the masses.\\nNote: I know that many container-like technologies pre-date Docker and\\nmodern containers. However, none of them changed the world the way\\nDocker has.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 15}, page_content='1: Containers from 30,000 feet\\n9\\nHello Docker!\\nDocker was the magic that made Linux containers easy and brought them to the masses.\\nWe’ll talk a lot more about Docker in the next chapter.\\nDocker and Windows\\nMicrosoft worked hard to bring Docker and container technologies to the Windows\\nplatform.\\nAt the time of writing, Windows desktop and server platforms support both of the\\nfollowing:\\n• Windows containers\\n• Linux containers\\nWindows containers run Windows apps and require a host system with a Windows kernel.\\nWindows 10, Windows 11, and all modern versions of Windows Server natively support\\nWindows containers.\\nWindows systems can also run Linux containers via the WSL 2 (Windows Subsystem for\\nLinux) subsystem.\\nThis means Windows 10 and Windows 11 are great platforms for developing and testing\\nWindows and Linux containers.\\nHowever, despite all the work developing Windows containers, almost all containers are'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 15}, page_content='Windows and Linux containers.\\nHowever, despite all the work developing Windows containers, almost all containers are\\nLinux containers. This is because Linux containers are smaller and faster, and more\\ntooling exists for Linux.\\nAll of the examples in this edition of the book are Linux containers.\\nWindows containers vs Linux containers\\nIt’s vital to understand that containers share the kernel of the host they’re running on.\\nThis means containerized Windows apps need a host with a Windows kernel, whereas\\ncontainerized Linux apps need a host with a Linux kernel. However, as mentioned, you\\ncan run Linux containers on Windows systems that have the WSL 2 backend installed.\\nTerminology: A containerized app is an application running as a container.\\nWe’ll cover this in a lot of detail later.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 16}, page_content='1: Containers from 30,000 feet\\n10\\nWhat about Mac containers?\\nThere is no such thing as Mac containers. However, Macs are great platforms for\\nworking with containers, and I do all of my daily work with containers on a Mac.\\nThe most popular way of working with containers on a Mac is Docker Desktop. It works\\nby running Docker inside a lightweight Linux VM on your Mac. Other tools, such as\\nPodman and Rancher Desktop, are also great for working with containers on a Mac.\\nWhat about Wasm\\nWasm (WebAssembly) is a modern binary instruction set that builds applications that are\\nsmaller, faster, more secure, and more portable than containers. You write your app in\\nyour favorite language and compile it as a Wasm binary that will run anywhere you have\\na Wasm runtime.\\nHowever, Wasm apps have many limitations, and we’re still developing many of\\nthe standards. As a result, containers remain the dominant model for cloud-native\\napplications.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 16}, page_content='a Wasm runtime.\\nHowever, Wasm apps have many limitations, and we’re still developing many of\\nthe standards. As a result, containers remain the dominant model for cloud-native\\napplications.\\nThe container ecosystem is also much richer and more mature than the Wasm ecosys-\\ntem.\\nAs you’ll see in the Wasm chapter, Docker and the container ecosystem are adapting\\nto work with Wasm apps, and you should expect a future where VMs, containers, and\\nWasm apps run side-by-side in most clouds and applications.\\nThis book is up-to-date with the latest Wasm and container developments.\\nDocker and AI\\nDevelopers and organizations are using more and more AI apps, and Docker is regularly\\nranked as the No. 1 most-desired and No. 1 most-used developer tool (Stack Overflow\\nAnnual Developer Survey).\\nUnfortunately, exposing GPUs and other AI acceleration hardware to apps running\\ninside containers is very hard. This is because they all have their own drivers and SDKs,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 16}, page_content='Annual Developer Survey).\\nUnfortunately, exposing GPUs and other AI acceleration hardware to apps running\\ninside containers is very hard. This is because they all have their own drivers and SDKs,\\nand it’s too much work for the industry to make them all work with containers. As\\na result, Docker has released Docker Model Runner as a way of running local LLMs\\noutside of containers so they have direct access to the host’s hardware.\\nChapter 10 is dedicated to running local AI models with Docker Model Runner, and it’s\\nvery exciting.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 17}, page_content='1: Containers from 30,000 feet\\n11\\nWhat about Kubernetes\\nKubernetes is the industry standard platform for deploying and managing containerized\\napps.\\nOlder versions of Kubernetes used Docker to start and stop containers. However, newer\\nversions use containerd, which is a stripped-down version of Docker optimized for use\\nby Kubernetes and other platforms.\\nThe important thing to know is that all Docker containers work on Kubernetes.\\nCheck out these books if you need to learn Kubernetes:\\n• Quick Start Kubernetes: This is ∼100 pages and will get you up-to-speed with\\nKubernetes in a single day!\\n• The Kubernetes Book. This is the ultimate book for mastering Kubernetes.\\nI update both books annually to ensure they’re up-to-date with the latest and greatest\\ndevelopments in the cloud native ecosystem.\\nChapter Summary\\nWe used to live in a world where every business application needed a dedicated, over-\\npowered server. VMware came along and allowed us to run multiple applications on'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 17}, page_content='Chapter Summary\\nWe used to live in a world where every business application needed a dedicated, over-\\npowered server. VMware came along and allowed us to run multiple applications on\\nnew and existing servers. However, following the success of VMware and hypervisors,\\na newer, more efficient, and portable virtualization technology called containers came'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 18}, page_content='1: Containers from 30,000 feet\\n12\\nalong. However, containers were complex and hard to implement until Docker came\\nalong and made them easy. Wasm and AI are powering new innovations, and the Docker\\necosystem is evolving to work with both. The book has entire chapters dedicated to\\nworking with AI apps and Wasm apps on Docker.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 19}, page_content='2: Docker and container-related\\nstandards and projects\\nThis chapter introduces you to Docker and some of the most important standards and\\nprojects shaping the container ecosystem. The goal is to lay some foundations that we’ll\\nbuild on in later chapters.\\nThis chapter has two main parts:\\n• Docker\\n• Container-related standards and projects\\nDocker\\nDocker is at the heart of the container ecosystem. However, the term Docker can mean\\ntwo things:\\n1. The Docker platform\\n2. Docker, Inc.\\nThe Docker platform is a neatly packaged collection of technologies for creating, manag-\\ning, and orchestrating containers. Docker, Inc. is the company that created the Docker\\nplatform and continues to be the driving force behind developing new features.\\nLet’s dive a bit deeper.\\nDocker, Inc.\\nDocker, Inc. is a technology company based out of Palo Alto and founded by French-\\nborn American developer and entrepreneur Solomon Hykes. Solomon is no longer at\\nthe company.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 19}, page_content='Docker, Inc.\\nDocker, Inc. is a technology company based out of Palo Alto and founded by French-\\nborn American developer and entrepreneur Solomon Hykes. Solomon is no longer at\\nthe company.\\nThe company started as a platform as a service (PaaS) provider called dotCloud. Behind the\\nscenes, dotCloud delivered its services on top of containers and had an in-house tool to\\nhelp them deploy and manage those containers. They called this in-house tool Docker.\\nThe word Docker is a British expression short for dock worker referring to someone who\\nloads and unloads cargo from ships.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 20}, page_content='2: Docker and container-related standards and projects\\n14\\nIn 2013, dotCloud dropped the struggling PaaS side of the business, rebranded as\\nDocker, Inc., and focused on bringing Docker and containers to the world.\\nThe Docker technology\\nThe Docker platform makes it easy to build, share, and run containers.\\nAt a high level, there are two major parts to the Docker platform:\\n• The CLI (client)\\n• The engine (server)\\nThe CLI is the familiar docker command-line tool for deploying and managing contain-\\ners. It converts simple commands into API requests and sends them to the engine.\\nThe engine comprises all the server-side components that run and manage containers.\\nFigure 2.1 shows the high-level architecture. The client and engine can be on the same\\nhost or connected over the network.\\nFigure 2.1 - Docker client and engine.\\nIn later chapters, you’ll see that the client and engine are complex and comprise a lot of'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 20}, page_content='host or connected over the network.\\nFigure 2.1 - Docker client and engine.\\nIn later chapters, you’ll see that the client and engine are complex and comprise a lot of\\nsmall specialized parts. Figure 2.2 gives you an idea of some of the complexity behind\\nthe engine. However, the client hides all this complexity so you don’t have to care. For\\nexample, you type friendly docker commands into the CLI, the CLI converts them to\\nAPI requests and sends them to the daemon, and the daemon takes care of everything\\nelse.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 21}, page_content='2: Docker and container-related standards and projects\\n15\\nFigure 2.2 - Docker CLI and daemon hiding complexity.\\nLet’s switch focus and briefly look at some standards and governance bodies.\\nContainer-related standards and projects\\nSeveral important standards and governance bodies influence container development\\nand the container ecosystem. Some of these include:\\n• The OCI\\n• The CNCF\\n• The Moby Project\\nThe Open Container Initiative (OCI)\\nThe Open Container Initiative (OCI)1 is a governance council responsible for low-level\\ncontainer-related standards.\\nIt operates under the umbrella of the Linux Foundation2 and was founded in the early\\ndays of the container ecosystem when some of the people at a company called CoreOS\\ndidn’t like the way Docker was dominating the ecosystem. In response, CoreOS created\\nan open standard called appc3 that defined specifications for things such as image\\nformat and container runtime. They also created a reference implementation called rkt\\n(pronounced “rocket”).'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 21}, page_content='an open standard called appc3 that defined specifications for things such as image\\nformat and container runtime. They also created a reference implementation called rkt\\n(pronounced “rocket”).\\nThe appc standard did things differently from Docker and put the ecosystem in an\\nawkward position with two competing standards.\\nWhile competition is usually a good thing, competing standards are generally bad, as they\\ngenerate confusion that slows down user adoption. Fortunately, the main players in the\\n1https://www.opencontainers.org\\n2https://www.linuxfoundation.org/projects\\n3https://github.com/appc/spec/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 22}, page_content='2: Docker and container-related standards and projects\\n16\\necosystem came together and formed the OCI as a vendor-neutral lightweight council\\nto govern container standards. This allowed us to archive the appc project and place all\\nlow-level container-related specifications under the OCI’s governance.\\nAt the time of writing, the OCI maintains three standards called specs:\\n• The image-spec4\\n• The runtime-spec5\\n• The distribution-spec6\\nWe often use a rail tracks analogy when explaining the OCI standards:\\nWhen the size and properties of rail tracks were standardized, it gave entrepreneurs\\nin the rail industry confidence the trains, carriages, signaling systems, platforms, and\\nother products they built would work with the standardized tracks — nobody wanted\\ncompeting standards for track sizes.\\nThe OCI specifications did the same thing for the container ecosystem and it’s flour-\\nished ever since. Docker has also changed a lot since the formation of the OCI, and all'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 22}, page_content='The OCI specifications did the same thing for the container ecosystem and it’s flour-\\nished ever since. Docker has also changed a lot since the formation of the OCI, and all\\nmodern versions of Docker implement all three OCI specs. For example:\\n• The Docker builder (BuildKit) creates OCI compliant-images\\n• Docker uses an OCI-compliant runtime to create OCI-compliant containers\\n• Docker Hub implements the OCI distribution spec and is an OCI-compliant registry\\nDocker, Inc. and many other companies have people serving on the OCI’s technical\\noversight board (TOB).\\nThe Cloud Native Computing Foundation (CNCF)\\nThe Cloud Native Computing Foundation (CNCF)7 is another Linux Foundation\\nproject that is influential in the container ecosystem. It was founded in 2015 with the\\ngoal of “…advancing container technologies… and making cloud native computing ubiquitous”.\\nInstead of creating and maintaining container-related specifications, the CNCF hosts'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 22}, page_content='goal of “…advancing container technologies… and making cloud native computing ubiquitous”.\\nInstead of creating and maintaining container-related specifications, the CNCF hosts\\nimportant projects such as Kubernetes, containerd, Notary, Prometheus, Cilium, and\\nlots more.\\nWhen we say the CNCF hosts these projects, we mean it provides a space, structure, and\\nsupport for projects to grow and mature. For example, all CNCF projects pass through\\nthe following three phases or stages:\\n4https://github.com/opencontainers/image-spec\\n5https://github.com/opencontainers/runtime-spec\\n6https://github.com/opencontainers/distribution-spec\\n7https://www.cncf.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 23}, page_content='2: Docker and container-related standards and projects\\n17\\n• Sandbox\\n• Incubating\\n• Graduated\\nEach phase increases a project’s maturity level by requiring higher standards of gov-\\nernance, documentation, auditing, contribution tracking, marketing, community\\nengagement, and more. For example, new projects accepted as sandbox projects may\\nhave great ideas and great technology but need help and resources to create strong\\ngovernance, etc. The CNCF helps with all of that.\\nGraduated projects are considered ready for production and are guaranteed to have strong\\ngovernance and implement good practices.\\nIf you look back to Figure 2.2, you’ll see that Docker uses at least two CNCF technolo-\\ngies — containerd and Notary.\\nThe Moby Project\\nDocker created the Moby project as a community-led place for developers to build\\nspecialized tools for building container platforms.\\nPlatform builders can pick the specific Moby tools they need to build their container'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 23}, page_content='specialized tools for building container platforms.\\nPlatform builders can pick the specific Moby tools they need to build their container\\nplatform. They can even compose their platforms using a mix of Moby tools, in-house\\ntools, and tools from other projects.\\nDocker, Inc. originally created the Moby project, but it now has members including\\nMicrosoft, Mirantis, and Nvidia.\\nThe Docker platform is built using tools from various projects, including the Moby\\nproject, the CNCF, and the OCI.\\nChapter summary\\nThis chapter introduced you to Docker and some of the major influences in the\\ncontainer ecosystem.\\nDocker, Inc., is a technology company based in Palo Alto that is changing how we do\\nsoftware. They were the first movers and instigators of the modern container revolution.\\nThe Docker platform focuses on running and managing application containers. It runs\\non Linux and Windows, can be installed almost anywhere, and offers a variety of free\\nand paid-for products.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 23}, page_content='The Docker platform focuses on running and managing application containers. It runs\\non Linux and Windows, can be installed almost anywhere, and offers a variety of free\\nand paid-for products.\\nThe Open Container Initiative (OCI) governs low-level container standards and\\nmaintains specifications for runtimes, image format, and registries.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 24}, page_content='2: Docker and container-related standards and projects\\n18\\nThe CNCF provides support for important cloud-native projects and helps them mature\\ninto production-grade tools.\\nThe Moby project hosts low-level tools developers can use to build container platforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 25}, page_content='3: Getting Docker\\nThere are lots of ways to get Docker and work with containers. This chapter will show\\nyou the following ways:\\n• Docker Desktop\\n• Multipass\\n• Server installs on Linux\\nI strongly recommend you install and use Docker Desktop. It’s the best way to work\\nwith Docker, and you’ll be able to use it to follow most of the examples in the book. I\\nuse it every day.\\nIf you can’t use Docker Desktop, we’ll show you how to install Docker in a Multipass\\nVM, as well as how to perform a simple installation on Linux. However, these installa-\\ntions don’t have all the features of Docker Desktop.\\nDocker Desktop\\nDocker Desktop is a desktop app from Docker, Inc. and is the best way to work with\\ncontainers. You get the Docker Engine, a slick UI, all the latest plugins and features,\\nand an extension system with a marketplace. You even get Docker Compose and a\\nKubernetes cluster if you want to learn Kubernetes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 25}, page_content='and an extension system with a marketplace. You even get Docker Compose and a\\nKubernetes cluster if you want to learn Kubernetes.\\nIt’s free for personal use and education, but you’ll have to pay a license fee if you use it\\nfor work and your company has over 250 employees or does more than $10M in annual\\nrevenue.\\nDocker Desktop on Windows 10 and Windows 11 Professional and Enterprise editions\\nsupports Windows containers and Linux containers. Docker Desktop on Mac, Linux, and\\nHome editions of Windows only support Linux containers. All of the examples in the\\nbook and almost all of the containers in the real world are Linux containers.\\nLet’s install Docker Desktop on Windows and MacOS.\\nWindows prereqs\\nDocker Desktop on Windows requires all of the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 26}, page_content='3: Getting Docker\\n20\\n• 64-bit version of Windows 10/11\\n• Hardware virtualization support must be enabled in your system’s BIOS\\n• WSL 2\\nBe very careful changing anything in your system’s BIOS.\\nInstalling Docker Desktop on Windows 10 and 11\\nSearch the internet for “install Docker Desktop on Windows”. This will take you to the\\nrelevant download page, where you can download the installer and follow the instruc-\\ntions. When prompted, you should install and enable the WSL 2 backend (Windows\\nSubsystem for Linux).\\nOnce the installation is complete, you need to manually start Docker Desktop from the\\nWindows Start menu. It may take a minute to start, but you can watch the start progress\\nvia the animated whale icon on the Windows taskbar at the bottom of the screen.\\nOnce it’s running, you can open a terminal and type some simple docker commands.\\n$ docker version\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nGo version:\\ngo1.23.8'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 26}, page_content='$ docker version\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nGo version:\\ngo1.23.8\\nOS/Arch:\\nlinux/amd64\\n<Snip>\\nCongratulations. You now have a working installation of Docker on your Windows\\nmachine.\\nNotice how the Server output shows OS/Arch: linux/amd64. This is because a default\\ninstallation assumes you’ll be working with Linux containers.\\nSome versions of Windows let you switch to Windows containers by right-clicking the\\nDocker whale icon in the Windows notifications tray and selecting Switch to Windows\\ncontainers…. Doing this keeps existing Linux containers running in the background,\\nbut you won’t be able to see or manage them until you switch back to Linux containers\\nmode.\\nMake sure you’re running in Linux containers mode so you can follow along with the\\nexamples later in the book.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 27}, page_content='3: Getting Docker\\n21\\nInstalling Docker Desktop on Mac\\nDocker Desktop for Mac is like Docker Desktop for Windows — a packaged product\\nwith a slick UI that gets you the full Docker experience on your laptop.\\nBefore proceeding with the installation, you need to know that Docker Desktop on\\nMac installs the daemon and server-side components inside a lightweight Linux VM\\nthat seamlessly exposes the API to your local Mac environment. This means you can\\nopen a terminal on your Mac and run docker commands without ever knowing it’s all\\nrunning in a hidden VM. This is also why Mac versions of Docker Desktop only work\\nwith Linux containers — everything’s running inside a Linux VM.\\nFigure 3.1 shows the high-level architecture for Docker Desktop on Mac.\\nFigure 3.1\\nThe simplest way to install Docker Desktop on your Mac is to search the web for “install\\nDocker Desktop on MacOS”, follow the links to the download, and then complete the\\nsimple installer.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 27}, page_content='Figure 3.1\\nThe simplest way to install Docker Desktop on your Mac is to search the web for “install\\nDocker Desktop on MacOS”, follow the links to the download, and then complete the\\nsimple installer.\\nWhen the installer finishes, you’ll have to start Docker Desktop from the MacOS\\nLaunchpad. It may take a minute to start, but you can watch the animated Docker whale\\nicon in the status bar at the top of your screen. Once it’s started, you can click the whale\\nicon to manage Docker Desktop.\\nOpen a terminal window and run some regular Docker commands. Try the following.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 28}, page_content='3: Getting Docker\\n22\\n$ docker version\\nClient:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49\\nOS/Arch:\\ndarwin/arm64\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nOS/Arch:\\nlinux/arm64\\ncontainerd:\\nVersion:\\n1.7.21\\nrunc:\\nVersion:\\n1.2.5\\ndocker-init:\\nVersion:\\n0.19.0\\n<Snip>\\nNotice that the OS/Arch: for the Server component shows as linux/amd64 or lin-\\nux/arm64. This is because the daemon runs inside the Linux VM mentioned earlier. The\\nClient component is a native Mac application and runs directly on the Mac OS Darwin\\nkernel. This is why it shows as darwin/amd64 or darwin/arm64.\\nYou can now use Docker on your Mac.\\nInstalling Docker with Multipass\\nOnly consider this section if you can’t use Docker Desktop.\\nMultipass installations don’t ship with out-of-the-box support for features such as\\ndocker scout, docker debug, and docker init.\\nMultipass is a free tool for creating cloud-style Linux VMs on your Linux, Mac, or'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 28}, page_content='docker scout, docker debug, and docker init.\\nMultipass is a free tool for creating cloud-style Linux VMs on your Linux, Mac, or\\nWindows machine and is incredibly easy to install and use. It’s an easy way to create\\nmulti-node production-like Docker clusters.\\nGo to https://multipass.run/install and install the right edition for your hardware\\nand OS.\\nOnce installed, you only need three commands:\\n$ multipass launch\\n$ multipass ls\\n$ multipass shell\\nRun the following command to create a new VM called node1 based on the docker\\nimage. The docker image has Docker pre-installed and ready to go.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 29}, page_content='3: Getting Docker\\n23\\n$ multipass launch docker --name node1\\nIt’ll take a minute or two to download the image and launch the VM.\\nList VMs to make sure yours launched properly.\\n$ multipass ls\\nName\\nState\\nIPv4\\nImage\\nnode1\\nRunning\\n192.168.64.37\\nUbuntu 24.04 LTS\\n172.17.0.1\\n172.18.0.1\\nYou’ll use the 192.168.x.x IP address when working with the examples later in the book.\\nConnect to the VM with the following command.\\n$ multipass shell node1\\nOnce connected, you can run the following commands to check your Docker version\\nand list installed CLI plugins.\\n$ docker --version\\nDocker version 26.1.0, build 9714adc\\n$ docker info\\nClient: Docker Engine - Community\\nVersion:\\n27.3.1\\nContext:\\ndefault\\nDebug Mode: false\\nPlugins:\\nbuildx: Docker Buildx (Docker Inc.)\\nVersion:\\nv0.17.1\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-buildx\\ncompose: Docker Compose (Docker Inc.)\\nVersion:\\nv2.29.7\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-compose\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 29}, page_content='Version:\\nv0.17.1\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-buildx\\ncompose: Docker Compose (Docker Inc.)\\nVersion:\\nv2.29.7\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-compose\\n<Snip>\\nYou can type exit to log out of the VM, and multipass shell node1 to log back in.\\nYou can also type multipass delete node1 and then multipass purge to delete it.\\nInstalling Docker on Linux\\nOnly consider this section if you can’t use Docker Desktop, as it doesn’t give you access\\nto docker scout, docker debug, or docker init.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 30}, page_content='3: Getting Docker\\n24\\nThese instructions show you how to install Docker on Ubuntu Linux 24.04 and are just\\nfor guidance purposes. Lots of other installation methods exist, and you should search\\nthe web for the latest instructions.\\n$ sudo snap install docker\\n<Snip>\\ndocker 27.2.0 from Canonical✓installed\\nRun some commands to test the installation. You’ll have to prefix them with sudo.\\n$ sudo docker --version\\nDocker version 27.2.0, build 3ab4256\\n$ sudo docker info\\n<Snip>\\nServer:\\nContainers: 0\\nRunning: 0\\nPaused: 0\\nStopped: 0\\nImages: 0\\nServer Version: 27.2.0\\n<Snip>\\nIf you don’t like adding sudo before Docker commands, you can run the following\\ncommands to create a docker group and add your user account to it.\\n$ sudo groupadd docker\\n$ sudo usermod -aG docker $(whoami)\\nYou’ll need to restart Docker for the changes to take effect. This is how you restart\\nDocker on many Ubuntu Linux distributions. Yours may be different.\\n$ sudo service docker start\\nChapter Summary'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 30}, page_content='You’ll need to restart Docker for the changes to take effect. This is how you restart\\nDocker on many Ubuntu Linux distributions. Yours may be different.\\n$ sudo service docker start\\nChapter Summary\\nYou can run Docker almost anywhere, and installing it’s easier than ever.\\nDocker Desktop gives you a fully functional Docker environment on your Linux, Mac,\\nor Windows machine and is the best way to get a Docker development environment on\\nyour local machine. It’s easy to install, includes the Docker Engine, has a slick UI, and\\nhas a marketplace with lots of extensions to extend its capabilities. It works with docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 31}, page_content='3: Getting Docker\\n25\\nscout, docker debug, and docker init, and it even lets you spin up a Kubernetes\\ncluster.\\nMultipass is a great way to spin up a local VM running Docker, and there are lots of\\nways to install Docker on Linux servers. These give you access to most of the free\\nDocker features but lack some of the features of Docker Desktop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 32}, page_content='4: The big picture\\nThis chapter will give you some hands-on experience and a high-level view of images\\nand containers. The goal is to prepare you for more detail in the upcoming chapters.\\nWe’ll break this chapter into two parts:\\n• The Ops perspective\\n• The Dev perspective\\nThe ops perspective focuses on starting, stopping, deleting containers, and executing\\ncommands inside them.\\nThe dev perspective focuses more on the application side of things and runs through\\ntaking application source code, building it into a container image, and running it as a\\ncontainer.\\nI recommend you read both sections and follow the examples, as this will give you the\\ndev and ops perspectives. DevOps anyone?\\nThe Ops Perspective\\nIn this section, you’ll complete all of the following:\\n• Check Docker is working\\n• Download an image\\n• Start a container from the image\\n• Execute a command inside the container\\n• Delete the container\\nA typical Docker installation installs the client and the engine on the same machine and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 32}, page_content='• Start a container from the image\\n• Execute a command inside the container\\n• Delete the container\\nA typical Docker installation installs the client and the engine on the same machine and\\nconfigures them to talk to each other.\\nRun a docker version command to ensure both are installed and running.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 33}, page_content='4: The big picture\\n27\\n$ docker version\\nClient:\\n<<--- Start of client response\\nVersion:\\n28.1.1\\n----┐\\nAPI version:\\n1.49\\n|\\nGo version:\\ngo1.23.8\\n| Client info block\\nOS/Arch:\\ndarwin/arm64\\n|\\nContext:\\ndesktop-linux\\n----┘\\nServer: Docker Desktop 4.42.0 (192140)\\n<<--- Start of server response\\nEngine:\\n----┐\\nVersion:\\n28.11\\n|\\nAPI version:\\n1.49 (minimum version 1.24) |\\nGo version:\\ngo1.23.8\\n|\\nOS/Arch:\\nlinux/arm64\\n|\\ncontainerd:\\n| Server block\\nVersion:\\n1.7.27\\n|\\nrunc:\\n|\\nVersion:\\n1.2.5\\n|\\ndocker-init:\\n|\\nVersion:\\n0.19.0\\n----┘\\nIf your response from the client and server looks like the output in the book, everything\\nis working as expected.\\nIf you’re on Linux and get a permission denied while trying to connect to the\\nDocker daemon... error, try again with sudo in front of the command — sudo docker\\nversion. If it works with sudo, you’ll need to prefix all future docker commands with\\nsudo.\\nDownload an image\\nImages are objects that contain everything an app needs to run. This includes an OS'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 33}, page_content='version. If it works with sudo, you’ll need to prefix all future docker commands with\\nsudo.\\nDownload an image\\nImages are objects that contain everything an app needs to run. This includes an OS\\nfilesystem, the application, and all dependencies. If you work in operations, they’re\\nsimilar to VM templates. If you’re a developer, they’re similar to classes.\\nRun a docker images command.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nIf you are working from a clean installation, you’ll have no images, and your output\\nwill be the same as the book. If you’re working with Multipass, you might see an image\\ncalled portainer/portainer-ce.\\nCopying new images onto your Docker host is called pulling. Pull the ubuntu:latest\\nimage.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 34}, page_content='4: The big picture\\n28\\n$ docker pull nginx:latest\\nlatest: Pulling from library/nginx\\nad5932596f78: Download complete\\ne4bc5c1a6721: Download complete\\n1bd52ec2c0cb: Download complete\\n411a98463f95: Download complete\\ndf25b2e5edb3: Download complete\\ne93f7200eab8: Download complete\\nDigest: sha256:fb197595ebe76b9c0c14ab68159fd3c08bd067ec62300583543f0ebda353b5be\\nStatus: Downloaded newer image for nginx:latest\\ndocker.io/library/nginx:latest\\nRun another docker images to confirm your pull command worked.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnginx\\nlatest\\nfb197595ebe7\\n10 days ago\\n280MB\\nWe’ll discuss where the image is stored and what’s inside it in later chapters. For now, all\\nyou need to know is that images contain enough of an operating system (OS) and all the\\ncode and dependencies required to run a desired application. The NGINX image you\\npulled includes a stripped-down version of Linux and the NGINX web server app.\\nStart a container from the image'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 34}, page_content='code and dependencies required to run a desired application. The NGINX image you\\npulled includes a stripped-down version of Linux and the NGINX web server app.\\nStart a container from the image\\nIf you’ve been following along, you’ll have a copy of the nginx:latest image and you\\ncan use the docker run command to start a container from it.\\nRun the following docker run command to start a new container called test from the\\nubuntu:latest image.\\n$ docker run --name test -d -p 8080:80 nginx:latest\\ne08c3535...30557225\\nThe long number confirms the container was created.\\nLet’s quickly examine that docker run command.\\ndocker run tells Docker to start a new container. The --name flag told Docker to\\ncall this container test and the -d flag told it to start the container in the background\\n(detached mode) so it doesn’t take over your terminal. The -p flag told Docker to map\\nport 80 in the container to port 8080 on your Docker host. Finally, the command told'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 34}, page_content='(detached mode) so it doesn’t take over your terminal. The -p flag told Docker to map\\nport 80 in the container to port 8080 on your Docker host. Finally, the command told\\nDocker to base the container on the nginx:latest image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 35}, page_content='4: The big picture\\n29\\nRun a docker ps command to see the running container.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\ne08c35352ff3\\nnginx:latest\\n\"/docker...\"\\n3 mins ago\\nUp 2 mins\\n0.0.0.0:8080->80/tcp\\ntest\\nYou should recognize the CONTAINER ID from the long number printed after the docker\\nrun command. You should also recognize the IMAGE, PORTS, and NAMES columns from\\nthe flags in the docker run command. The COMMAND field lists the command Docker\\nexecuted to start the NGINX app inside the container.\\nExecute a command inside the container\\nRun the following command to attach your shell to a new Bash process inside the\\ncontainer.\\n$ docker exec -it test bash\\nroot@e08c35352ff3:/#\\nYour shell prompt will change to indicate you’re connected to the container.\\nRun the following command to list files in your current directory.\\nroot@e08c35352ff3:/# ls -l\\ntotal 64\\nlrwxrwxrwx\\n1 root root\\n7 Jan\\n2 00:00 bin -> usr/bin\\ndrwxr-xr-x\\n2 root root 4096 Oct 31 11:04 boot\\ndrwxr-xr-x'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 35}, page_content='root@e08c35352ff3:/# ls -l\\ntotal 64\\nlrwxrwxrwx\\n1 root root\\n7 Jan\\n2 00:00 bin -> usr/bin\\ndrwxr-xr-x\\n2 root root 4096 Oct 31 11:04 boot\\ndrwxr-xr-x\\n5 root root\\n340 Jan 12 15:09 dev\\ndrwxr-xr-x\\n1 root root 4096 Jan\\n3 02:56 docker-entrypoint.d\\n-rwxr-xr-x\\n1 root root 1620 Jan\\n3 02:56 docker-entrypoint.sh\\ndrwxr-xr-x\\n1 root root 4096 Jan 12 15:09 etc\\n<Snip>\\nIf you’re familiar with Linux, you’ll recognize these are regular Linux files and directo-\\nries.\\nTry running a ps command to list running processes.\\nroot@e08c35352ff3:/# ps -elf\\nbash: ps: command not found\\nThe command is not found because most containers only ship with essential apps and\\ntools to keep them small and reduce attack vectors. Later in the book, we’ll show you'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 36}, page_content='4: The big picture\\n30\\nhow to use Docker Desktop and Docker Debug to connect to running containers and\\nexecute commands not included as part of the container.\\nType exit to terminate your bash process and connect your shell back to your local\\nterminal. Your shell prompt will revert.\\nRun the following command to verify the test container is still running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\ne08c35352ff3\\nnginx:latest\\n\"/docker...\"\\n7 mins ago\\nUp 7 mins\\n0.0.0.0:8080->80\\ntest\\nThe container is still running, and you can see it was created 7 minutes ago and has been\\nrunning for 7 minutes.\\nDelete the container\\nStop and kill the container using the docker stop and docker rm commands.\\n$ docker stop test\\ntest\\nIt can take a few seconds for the container to stop.\\n$ docker rm test\\ntest\\nVerify the container deleted properly by running the docker ps command with the -a\\nflag to list all containers, even those in the stopped state.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 36}, page_content='test\\nVerify the container deleted properly by running the docker ps command with the -a\\nflag to list all containers, even those in the stopped state.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nCongratulations, you’ve pulled a Docker image, started a container from it, logged in to\\nit, executed a command inside it, stopped it, and deleted it.\\nThe Dev Perspective\\nContainers are all about applications.\\nYou’ll complete all of the following steps in this section:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 37}, page_content=\"4: The big picture\\n31\\n• Clone an app from a GitHub repo\\n• Inspect the app’s Dockerfile\\n• Containerize the app\\n• Run the app as a container\\nRun the following command to make a local clone of the repo. This will copy the\\napplication code to your machine so you can containerize it in a future step. You’ll need\\nthe git CLI for this to work.\\n$ git clone https://github.com/nigelpoulton/psweb.git\\nCloning into 'psweb'...\\nremote: Enumerating objects: 63, done.\\nremote: Counting objects: 100% (34/34), done.\\nremote: Compressing objects: 100% (22/22), done.\\nremote: Total 63 (delta 13), reused 25 (delta 9), pack-reused 29\\nReceiving objects: 100% (63/63), 13.29 KiB | 4.43 MiB/s, done.\\nResolving deltas: 100% (21/21), done.\\nChange into the psweb directory and list its contents.\\n$ cd psweb\\n$ ls -l\\ntotal 32\\n-rw-r--r--@ 1 nigelpoulton\\nstaff\\n324\\n5 Feb 12:31 Dockerfile\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n378\\n5 Feb 12:31 README.md\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n341\\n5 Feb 12:31 app.js\\n-rw-r--r--@ 1 nigelpoulton\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 37}, page_content='-rw-r--r--@ 1 nigelpoulton\\nstaff\\n324\\n5 Feb 12:31 Dockerfile\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n378\\n5 Feb 12:31 README.md\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n341\\n5 Feb 12:31 app.js\\n-rw-r--r--@ 1 nigelpoulton\\nstaff\\n355\\n5 Feb 12:47 package.json\\ndrwxr-xr-x\\n3 nigelpoulton\\nstaff\\n96\\n5 Feb 12:31 views\\nThe app is a simple Node.js web app running some static HTML.\\nInspect the app’s Dockerfile\\nThe Dockerfile is a plain-text document that tells Docker how to build the app and\\ndependencies into an image.\\nList the contents of the application’s Dockerfile.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 38}, page_content='4: The big picture\\n32\\n$ cat Dockerfile\\nFROM alpine\\nLABEL maintainer=\"nigelpoulton@hotmail.com\"\\nRUN apk add --update nodejs npm curl\\nCOPY . /src\\nWORKDIR /src\\nRUN\\nnpm install\\nEXPOSE 8080\\nENTRYPOINT [\"node\", \"./app.js\"]\\nYou’ll learn more about Dockerfiles later in the book. Right now, all you need to know is\\nthat each line represents an instruction Docker executes to build the app into an image.\\nIf you’ve been following along, you’ve pulled the application code from a remote Git\\nrepo and looked at the application’s Dockerfile.\\nContainerize the app\\nRun the following docker build command to create a new image based on the instruc-\\ntions in the Dockerfile. It will create a new Docker image called test:latest.\\nBe sure to run the command from within the psweb directory and include the trailing\\nperiod.\\n$ docker build -t test:latest .\\n[+] Building 36.2s (11/11) FINISHED\\n=> [internal] load .dockerignore\\n0.0s\\n=> => transferring context: 2B\\n0.0s\\n=> [internal] load build definition from Dockerfile'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 38}, page_content='$ docker build -t test:latest .\\n[+] Building 36.2s (11/11) FINISHED\\n=> [internal] load .dockerignore\\n0.0s\\n=> => transferring context: 2B\\n0.0s\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n<Snip>\\n=> => naming to docker.io/library/test:latest\\n0.0s\\n=> => unpacking to docker.io/library/test:latest\\n0.7s\\nWhen the build completes, check that you have an image called test:latest.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\ntest\\nlatest\\n0435f2738cf6\\n21 seconds ago\\n160MB\\nCongratulations, you’ve containerized the app. That’s jargon for building it into a\\ncontainer image that contains the app and all dependencies.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 39}, page_content='4: The big picture\\n33\\nRun the app as a container\\nRun the following command to start a container called web1 from the image. If you’re\\non a Windows machine, you’ll need to replace the backslashes with backticks or run the\\ncommand on a single line without the backslashes.\\n$ docker run -d \\\\\\n--name web1 \\\\\\n--publish 8080:8080 \\\\\\ntest:latest\\nOpen a web browser and navigate to the DNS name or IP address of your Docker host\\non port 8080. If you’re following along on Docker Desktop, connect to localhost:8080\\nor 127.0.0.1:8080. If you’re following along on Multipass, connect to your Multipass\\nVM’s 192.168 address on port 8080. Run an ip a | grep 192 command from within\\nthe Multipass VM, or run a multipass ls from your local machine to find the address.\\nYou will see the following web page.\\nFigure 4.1\\nCongratulations. You’ve copied some application code from a remote Git repo, built it\\ninto a Docker image, and run it as a container. We call this containerizing an app.\\nClean up'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 39}, page_content='Figure 4.1\\nCongratulations. You’ve copied some application code from a remote Git repo, built it\\ninto a Docker image, and run it as a container. We call this containerizing an app.\\nClean up\\nRun the following commands to terminate the container and delete the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 40}, page_content='4: The big picture\\n34\\n$ docker rm web1 -f\\nweb1\\n$ docker rmi test:latest\\nUntagged: test:latest\\nDeleted: sha256:0435f27...cac8e2b\\nChapter Summary\\nIn the Ops section of the chapter, you downloaded a Docker image, launched a container\\nfrom it, logged into the container, executed a command inside of it, and then stopped\\nand deleted the container.\\nIn the Dev section, you containerized a simple application by pulling source code from\\nGitHub and building it into an image using instructions in a Dockerfile. You then ran\\nthe app as a container.\\nThe things you’ve learned in this chapter will help you in the upcoming chapters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 41}, page_content='Part 2: The technical stuff'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 42}, page_content='5: The Docker Engine\\nIn this chapter, we’ll look under the hood of the Docker Engine.\\nThis chapter has a strong operations focus, and you can use Docker without knowing\\neverything you’re about to learn. However, to truly master something, you need to\\nunderstand what’s going on under the hood. So, if you want to master Docker, you\\nshould read this chapter.\\nI’ve divided the chapter into the following sections:\\n• Docker Engine – The TLDR\\n• The Docker Engine\\n• The influence of the Open Container Initiative (OCI)\\n• runc\\n• containerd\\n• Starting a new container (example)\\n• What’s the shim all about\\n• How it’s implemented on Linux\\nLet’s learn about the Docker Engine.\\nDocker Engine – The TLDR\\nDocker Engine is jargon for the server-side components of Docker that run and manage\\ncontainers. If you’ve ever worked with VMware, the Docker Engine is similar to ESXi.\\nThe Docker Engine is modular and built from many small specialized components'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 42}, page_content='containers. If you’ve ever worked with VMware, the Docker Engine is similar to ESXi.\\nThe Docker Engine is modular and built from many small specialized components\\npulled from projects such as the OCI, the CNCF, and the Moby project.\\nIn many ways, the Docker Engine is like a car engine:\\n• A car engine is made from many specialized parts that work together to make a car\\ndrive — intake manifolds, throttle bodies, cylinders, pistons, spark plugs, exhaust\\nmanifolds, and more.\\n• The Docker Engine is made from many specialized tools that work together to\\ncreate and run containers — the API, image builder, high-level runtime, low-level\\nruntime, shims, etc.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 43}, page_content='5: The Docker Engine\\n37\\nFigure 5.1 shows the components of the Docker Engine that create and run containers.\\nOther components exist, but this simplified diagram focuses on the components that\\nstart and run containers.\\nFigure 5.1\\nThroughout the book, we’ll refer to runc and containerd with lowercase “r” and “c”, which\\nis how they’re both written in the official project documentation. This means sentences\\nstarting with either runc or containerd will not begin with a capital letter.\\nThe Docker Engine\\nWhen Docker was first released, the Docker Engine had two major components:\\n• The Docker daemon (sometimes referred to as just “the daemon”)\\n• LXC\\nThe daemon was a monolithic binary containing all the code for the API, image builders,\\ncontainer execution, volumes, networking, and more.\\nLXC did the hard work of interfacing with the Linux kernel and constructing the\\nrequired namespaces and cgroups to build and start containers.\\nReplacing LXC'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 43}, page_content='LXC did the hard work of interfacing with the Linux kernel and constructing the\\nrequired namespaces and cgroups to build and start containers.\\nReplacing LXC\\nRelying on LXC posed several problems for the Docker project.\\nFirst, LXC is Linux-specific, and Docker had aspirations of being multi-platform.\\nSecond, Docker was evolving fast, and there was no way of ensuring LXC evolved in the\\nways Docker needed.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 44}, page_content='5: The Docker Engine\\n38\\nTo improve the experience and help the project evolve more quickly, Docker replaced\\nLXC with its own tool, libcontainer. The goal of libcontainer was to be a platform-\\nagnostic tool that gave Docker access to the fundamental container building blocks in\\nthe host kernel.\\nLibcontainer replaced LXC in Docker a very long time ago.\\nBreaking up the monolithic Docker daemon\\nAs previously mentioned, the Docker Engine was originally a monolith with almost all\\nfunctionality coded into the daemon. However, as time passed, this became more and\\nmore problematic for the following reasons:\\n1. It got slower\\n2. It wasn’t what the ecosystem wanted\\n3. It’s hard to innovate on monolithic software\\nThe project recognized these challenges and began a long-running program to break\\napart and refactor the Engine so that every feature became its own small specialized tool.\\nPlatform builders could then re-use these tools to build other platforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 44}, page_content='apart and refactor the Engine so that every feature became its own small specialized tool.\\nPlatform builders could then re-use these tools to build other platforms.\\nThis work of breaking apart the Docker daemon is an ongoing process, and all of the\\ncode for building images and executing containers has been removed and refactored\\ninto small, specialized tools. Notable examples include removing the high-level and\\nlow-level runtime functionality and re-implementing them in separate tools called\\ncontainerd and runc, both of which are used by many different projects, including\\nDocker, Kubernetes, Firecracker, and Fargate. More recently (starting with Docker\\nDesktop 4.27.0), Docker has removed image management from the daemon and now\\nuses containerd’s image management capabilities.\\nFigure 5.2 shows another view of the Docker Engine components that are used to run\\ncontainers and lists the primary responsibilities of each component.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 45}, page_content='5: The Docker Engine\\n39\\nFigure 5.2 - Engine components and responsibilities\\nOther engine components exist.\\nThe influence of the Open Container Initiative (OCI)\\nAround the same time that Docker, Inc. was refactoring the Engine, the OCI8 was in the\\nprocess of defining two container-related standards:\\n1. Image Specification (image-spec)9\\n2. Runtime Specification (runtime-spec)10\\nBoth specifications were released as version 1.0 in July 2017 and are still vital today.\\nThey’ve even added a third specification called the Distribution Specification (distribu-\\ntion-spec) governing how images are distributed via registries.\\nAt the time of writing, the runtime-spec is at version 1.2.0, and the image-spec and\\ndistribution-spec are both at version 1.1.0. This demonstrates the slow-and-steady\\nnature of these low-level specifications that are heavily relied upon by so many other\\nprojects — stability is the name of the game for low-level OCI specs.\\n8https://www.opencontainers.org/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 45}, page_content='nature of these low-level specifications that are heavily relied upon by so many other\\nprojects — stability is the name of the game for low-level OCI specs.\\n8https://www.opencontainers.org/\\n9https://github.com/opencontainers/image-spec\\n10https://github.com/opencontainers/runtime-spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 46}, page_content='5: The Docker Engine\\n40\\nDocker, Inc. was a founding member of the OCI and was heavily involved in defining\\nthe original specifications. It continues to be involved by contributing code and helping\\nguide the future of the specifications.\\nAll versions of Docker since 2016 have implemented the OCI specifications. For\\nexample, Docker uses runc, the reference implementation of the OCI runtime-spec, to\\ncreate OCI-compliant containers (runtime-spec). It also uses BuildKit to build OCI-\\ncompliant images (image-spec), and Docker Hub is an OCI-compliant registry (registry-\\nspec).\\nrunc\\nAs previously mentioned, runc11 (pronounced “run see” and always written with a\\nlowercase “r”) is the reference implementation of the OCI runtime-spec. Docker, Inc.\\nwas heavily involved in defining the spec and contributed the initial code for runc.\\nrunc is a lightweight CLI wrapper for libcontainer that you can download and use\\nto manage OCI-compliant containers. However, it’s a very low-level tool and lacks'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 46}, page_content='runc is a lightweight CLI wrapper for libcontainer that you can download and use\\nto manage OCI-compliant containers. However, it’s a very low-level tool and lacks\\nalmost all of the features and add-ons you get with the Docker Engine. Fortunately, as\\npreviously shown in Figure 5.2, Docker uses runc as its low-level runtime. This means\\nyou get OCI-compliant containers and the feature-rich Docker user experience.\\nOn the jargon front, we sometimes say that runc operates at the OCI layer, and we often\\nrefer to it as a low-level runtime.\\nDocker and Kubernetes both use runc as their default low-level runtime, and both pair it\\nwith the containerd high-level runtime:\\n• containerd operates as the high-level runtime managing lifecycle events\\n• runc operates as the low-level runtime executing lifecycle events by interfacing\\nwith the kernel to do the work of actually building containers and deleting them\\nYou can see the latest releases here:\\n• https://github.com/opencontainers/runc/releases'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 46}, page_content='with the kernel to do the work of actually building containers and deleting them\\nYou can see the latest releases here:\\n• https://github.com/opencontainers/runc/releases\\ncontainerd\\ncontainerd (pronounced “container dee” and always written with a lowercase “c”) is\\nanother tool that Docker created while stripping functionality out of the daemon.\\n11https://github.com/opencontainers/runc'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 47}, page_content='5: The Docker Engine\\n41\\nWe refer to containerd as a high-level runtime as it manages lifecycle events such as\\nstarting, stopping, and deleting containers. However, it needs a low-level runtime to\\nperform the actual work. Most of the time, containerd is paired with runc as its low-\\nlevel runtime. However, as you saw in Figure 5.3, it uses shims that make it possible to\\nreplace runc with other low-level runtimes. We’ll go into more detail in the WebAssem-\\nbly chapter when you’ll see how to use Docker to run WebAssembly apps.\\nThe original plan was for containerd to be a small specialized tool for managing\\ncontainer lifecycle events. However, it has since grown to include the ability to manage\\nimages, networks, and volumes.\\nOne reason for adding more functionality is for projects such as Kubernetes that want\\ncontainerd to be able to push and pull images. Fortunately, this extra functionality is\\nmodular, meaning projects like Kubernetes can include containerd but only take the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 47}, page_content='containerd to be able to push and pull images. Fortunately, this extra functionality is\\nmodular, meaning projects like Kubernetes can include containerd but only take the\\npieces they need.\\ncontainerd was originally developed by Docker, Inc. and donated to the Cloud Native\\nComputing Foundation (CNCF). At the time of writing, containerd is a graduated\\nCNCF project, meaning it’s stable and production-ready. You can see the latest releases\\nhere:\\n• https://github.com/containerd/containerd/releases\\nStarting a new container (example)\\nNow that you’ve seen the big picture, let’s see how to use Docker to create a new\\ncontainer.\\nThe most common way of starting containers is using the Docker CLI. Feel free to run\\nthe following command to start a new container called ctr1 based on the nginx image.\\n$ docker run -d --name ctr1 nginx\\nRun a docker ps command to see if the container is running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\n9cfb0c9aacb2\\nnginx\\n\"/docker-entrypoint.…\"'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 47}, page_content='Run a docker ps command to see if the container is running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\n9cfb0c9aacb2\\nnginx\\n\"/docker-entrypoint.…\"\\n9 seconds ago\\nUp 9 seconds\\n80/tcp\\nctr1\\nWhen you run commands like this, the Docker client converts them into API requests\\nand sends them to the API exposed by the daemon.\\nThe daemon can expose the API on a local socket or over the network. On Linux, the\\nlocal socket is /var/run/docker.sock and on Windows it’s \\\\pipe\\\\docker_engine.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 48}, page_content='5: The Docker Engine\\n42\\nThe daemon receives the request, interprets it as a request to create a new container,\\nand passes it to containerd. Remember that the daemon no longer contains any code\\nto create containers.\\nThe daemon communicates with containerd via a CRUD-style API over gRPC12.\\nDespite its name, even containerd cannot create containers. It converts the required\\nDocker image into an OCI bundle and tells runc to use this to create a new container.\\nrunc interfaces with the OS kernel to pull together all the constructs necessary to create\\na container (namespaces, cgroups, etc.). The container starts as a child process of runc,\\nand as soon as the container starts, runc exits.\\nFigure 5.3 summarizes the process.\\nFigure 5.3\\nDecoupling the container creation and management from the Docker daemon and\\nimplementing it in containerd and runc makes it possible to stop, restart, and even\\nupdate the daemon without impacting running containers. We sometimes call this\\ndaemonless containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 48}, page_content='implementing it in containerd and runc makes it possible to stop, restart, and even\\nupdate the daemon without impacting running containers. We sometimes call this\\ndaemonless containers.\\n12https://grpc.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 49}, page_content='5: The Docker Engine\\n43\\nIf you started the NGINX container earlier, you should delete it using the following\\ncommand.\\n$ docker rm ctr1 -f\\nWhat’s the shim all about?\\nSome of the diagrams in the chapter have shown a shim component.\\nShims are a popular software engineering pattern, and the Docker Engine uses them in\\nbetween containerd and the OCI layer, bringing the following benefits:\\n• Daemonless containers\\n• Improved efficiency\\n• Pluggable OCI layer\\nWe’ve already said that daemonless containers is the ability to stop, restart, and even\\nupdate the Docker daemon without impacting running containers.\\nOn the efficiency front, containerd forks a shim and a runc process for every new\\ncontainer. However, each runc process exits as soon as the container starts running,\\nleaving the shim process as the container’s parent process. The shim is lightweight\\nand sits between containerd and the container. It reports on the container’s status and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 49}, page_content='leaving the shim process as the container’s parent process. The shim is lightweight\\nand sits between containerd and the container. It reports on the container’s status and\\nperforms low-level tasks such as keeping the container’s STDIN and STDOUT streams\\nopen.\\nShims also make it possible to replace runc with other low-level runtimes.\\nHow it’s implemented on Linux\\nOn a Linux system, Docker implements the components we’ve discussed as the follow-\\ning separate binaries:\\n• /usr/bin/dockerd (the Docker daemon)\\n• /usr/bin/containerd\\n• /usr/bin/containerd-shim-runc-v2\\n• /usr/bin/runc\\nYou can see all of these on a Linux-based Docker host by running a ps command. Some\\nof the processes will only be present when the system has running containers, and you\\ncan’t see them if you’re using Docker Desktop on a Mac because the Docker Engine is\\nrunning inside a VM.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 50}, page_content='5: The Docker Engine\\n44\\nDo we still need the daemon\\nAt the time of writing, Docker has stripped most of the functionality out of the daemon.\\nHowever, it still serves the Docker API.\\nChapter summary\\nThe Docker Engine comprises the server-side components of Docker and implements\\nmost of the code to build, share, and run containers. It implements the OCI standards\\nand is a modular app comprising many small, specialized components.\\nThe Docker daemon component implements the Docker API, but most other functionality\\nhas been stripped out and implemented as standalone composable tools such as\\ncontainerd and runc.\\ncontainerd performs image management tasks and oversees container lifecycle manage-\\nment, such as starting, stopping, and deleting containers. Docker, Inc. originally wrote it\\nand then contributed to the CNCF. It’s classed as a high-level runtime and used by many\\nother projects, including Kubernetes, Firecracker, and Fargate.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 50}, page_content='and then contributed to the CNCF. It’s classed as a high-level runtime and used by many\\nother projects, including Kubernetes, Firecracker, and Fargate.\\ncontainerd relies on a low-level runtime called runc to interface with the host kernel and\\nbuild containers. runc is the reference implementation of the OCI runtime-spec and\\nexpects to start containers from OCI-compliant bundles. containerd talks to runc and\\nensures Docker images are presented to runc as OCI-compliant bundles.\\nrunc is based on code from libcontainer, you can run it as a standalone CLI tool to\\ncreate containers, and it’s used almost everywhere that containerd is used.\\nShims make it possible to use containerd with other low-level runtimes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 51}, page_content='6: Working with Images\\nThis chapter is a dive deep into Docker images. You’ll learn what images are, how to\\nwork with them, and how they work under the hood. You’ll learn how to build your own\\nin Chapter 8: Containerizing an application.\\nI’ve arranged the chapter as follows:\\n• Docker images – The TLDR\\n• Intro to images\\n• Pulling images\\n• Image registries\\n• Image naming and tagging\\n• Images and layers\\n• Pulling images by digest\\n• Multi-architecture images\\n• Vulnerability scanning with Docker Scout\\n• Deleting images\\nDocker images – The TLDR\\nBefore getting started, all of the following terms mean the same thing, and we’ll use\\nthem interchangeably: Image, Docker image, container image, and OCI image.\\nAn image is a read-only package containing everything you need to run an application.\\nThis means they include application code, dependencies, a minimal set of OS constructs,\\nand metadata. You can start multiple containers from a single image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 51}, page_content='This means they include application code, dependencies, a minimal set of OS constructs,\\nand metadata. You can start multiple containers from a single image.\\nIf you’re familiar with VMware, images are a bit like VM templates — a VM template is\\nlike a stopped VM, whereas an image is like a stopped container. If you’re a developer,\\nimages are similar to classes — you can create one or more objects from a class, whereas\\nyou can create one or more containers from an image.\\nThe easiest way to get an image is to pull one from a registry. Docker Hub13 is the most\\ncommon registry, and pulling an image downloads it to your local machine where\\n13https://hub.docker.com'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 52}, page_content='6: Working with Images\\n46\\nDocker can use it to start one or more containers. Other registries exist, and Docker\\nworks with them all.\\nDocker creates images by stacking independent layers and representing them as a single\\nunified object. One layer might have the OS components, another layer might have\\napplication dependencies, and another layer might have the application. Docker stacks\\nthese layers and makes them look like a unified system.\\nImages are usually small. For example, the official NGINX image is around 80MB, and\\nthe official Redis image is around 40MB. However, Windows images can be huge.\\nThat’s the elevator pitch. Let’s dig a little deeper.\\nIntro to images\\nWe’ve already said that images are like stopped containers. You can even stop a con-\\ntainer and create a new image from it. With this in mind, images are build-time con-\\nstructs, whereas containers are run-time constructs. Figure 6.1 shows the build and run'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 52}, page_content='tainer and create a new image from it. With this in mind, images are build-time con-\\nstructs, whereas containers are run-time constructs. Figure 6.1 shows the build and run\\nnature of each and that you can start multiple containers from a single image.\\nFigure 6.1\\nThe docker run command is the most common way to start a container from an image.\\nOnce the container is running, the image and the container are bound, and you cannot\\ndelete the image until you stop and delete the container. If multiple containers use the\\nsame image, you can only delete the image after you’ve deleted all the containers using\\nit.\\nContainers are designed to run a single application or microservice. As such, they\\nshould only contain application code and dependencies. You should not include non-\\nessentials such as build tools or troubleshooting tools.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 53}, page_content='6: Working with Images\\n47\\nFor example, the official Alpine Linux image is currently about 3MB. This is because it\\ndoesn’t ship with six different shells, three different package managers, and a bunch of\\ntools you “might” need once every ten years. In fact, it’s increasingly common for images\\nto ship without a shell or a package manager — if the application doesn’t need it at run-\\ntime, the image doesn’t include it. We call these slim images.\\nAnother thing that keeps images small is the lack of an OS kernel. This is because con-\\ntainers use the kernel of the host they’re running on. The only OS-related components\\nin most images are filesystem objects, and you’ll sometimes hear people say images\\ncontain just enough OS.\\nUnfortunately, Windows images can be huge. For example, some Windows-based\\nimages can be gigabytes in size and take a long time to push and pull.\\nPulling images\\nA clean Docker installation has an empty local repository.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 53}, page_content='images can be gigabytes in size and take a long time to push and pull.\\nPulling images\\nA clean Docker installation has an empty local repository.\\nLocal repository is jargon for an area on your local machine where Docker stores images\\nfor more convenient access. We sometimes call it the image cache, and on Linux it’s\\nusually located in /var/lib/docker/<storage-driver>. However, if you’re using\\nDocker Desktop, it will be inside the Docker VM.\\nRun the following command to inspect the contents of your local repository. This\\nexample has three images relating to three Docker Desktop extensions I’m running.\\nYours will be different and may be empty.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\ndocker/disk-usage-extension\\n0.2.9\\nf4c95478a537\\n26 hours ago\\n3.64MB\\ndocker/logs-explorer-extension\\n0.2.6\\n417dd9a8f96d\\n26 hours ago\\n17.9MB\\nportainer/portainer-docker-extension\\n2.19.4\\n908d04d20e86\\n2 months ago\\n364MB\\nThe process of getting images is called pulling.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 53}, page_content='docker/logs-explorer-extension\\n0.2.6\\n417dd9a8f96d\\n26 hours ago\\n17.9MB\\nportainer/portainer-docker-extension\\n2.19.4\\n908d04d20e86\\n2 months ago\\n364MB\\nThe process of getting images is called pulling.\\nRun the following commands to pull the redis image and verify it exists in your local\\nrepository.\\nNote: If you are following along on Linux and haven’t added your user\\naccount to the local docker Unix group, you may need to add sudo to the\\nbeginning of all the following commands.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 54}, page_content=\"6: Working with Images\\n48\\n$ docker pull redis\\nUsing default tag: latest\\n<<---- Assume the 'latest' tag\\nlatest: Pulling from library/redis\\n<<---- Assume you want to pull from Docker Hub\\n08df40659127: Download complete\\n<<---- Pulling layer\\n4f4fb700ef54: Already exists\\n<<---- Pulling layer (local copy must exist)\\n4fe7fa4aab04: Download complete\\n<<---- Pulling layer\\n57dea0f129a5: Download complete\\n<<---- Pulling layer\\nf546e941f15b: Download complete\\n<<---- Pulling layer\\nf7f7da262cdb: Download complete\\n<<---- Pulling layer\\nf45ab649e450: Download complete\\n<<---- Pulling layer\\n983f900bbc88: Download complete\\n<<---- Pulling layer\\nDigest: sha256:76d5908f5e19fcdd73daf956a38826f790336ee4707d9028f32b24ad9ac72c08\\nStatus: Downloaded newer image for redis:latest\\ndocker.io/library/redis:latest\\n<<---- docker.io = Docker Hub\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nlatest\\n11c3e418c296\\n2 weeks ago\\n223MB\\n<Snip>\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 54}, page_content='docker.io/library/redis:latest\\n<<---- docker.io = Docker Hub\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nlatest\\n11c3e418c296\\n2 weeks ago\\n223MB\\n<Snip>\\nThe image now exists in your local repository. However, I’ve annotated a few interesting\\nlines from the docker pull output. We’ll cover them in more detail later in the chapter\\nbut they’re worth a quick mention now.\\nDocker is opinionated and made two assumptions when pulling the image:\\n1. It assumed you wanted to pull the image tagged as latest\\n2. It assumed you wanted to pull the image from Docker Hub\\nYou can override both, but Docker will use these as defaults if you don’t override them.\\nThe Redis image in the example has eight layers. However, Docker only pulled seven\\nlayers because it already had a local copy of one of them. This is because my system\\nruns the Portainer Docker Desktop extension, which is based on an image that shares a\\ncommon layer with the Redis image. You’ll learn about this very soon, but images can'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 54}, page_content='runs the Portainer Docker Desktop extension, which is based on an image that shares a\\ncommon layer with the Redis image. You’ll learn about this very soon, but images can\\nshare layers, and Docker is clever enough only to pull the layers it doesn’t already have.\\nImage registries\\nWe store images in centralized places called registries. The job of a registry is to securely\\nstore images and make them easy to access from different environments.\\nFigure 6.2 shows the central nature of registries in the build > share > run pipeline.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 55}, page_content='6: Working with Images\\n49\\nFigure 6.2\\nMost modern registries implement the OCI distribution-spec, and we sometimes call\\nthem OCI registries. Most registries also implement the Docker Registry v2 API, meaning\\nyou can use the Docker CLI and other API tools to query them and work with them in\\nstandard ways. Some offer advanced features such as image scanning and integration\\nwith build pipelines.\\nThe most common registry is Docker Hub, but others exist, including 3rd-party\\ninternet-based registries and secure on-premises registries. However, as previously\\nmentioned, Docker is opinionated and will default to Docker Hub unless you tell it\\nthe name of a different registry. We’ll use Docker Hub for the rest of the book, but the\\nprinciples apply to other registries.\\nImage registries contain one or more image repositories, and image repositories contain\\none or more images. Figure 6.3 shows an image registry with three repositories, each\\nwith one or more images.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 56}, page_content='6: Working with Images\\n50\\nFigure 6.3 - Registry architecture\\nOfficial repositories\\nDocker Hub has the concept of official repositories that are home to images vetted and\\ncurated by Docker and the application vendor. This means they should contain up-to-\\ndate high-quality code that is secure, well-documented, and follows good practices.\\nMost of the popular applications and operating systems have official repositories on\\nDocker Hub, and they’re easy to identify because they live at the top level of the Docker\\nHub namespace and have a green Docker Official Image badge. The following list shows\\na few official repositories and their URLs that exist at the top level of the Docker Hub\\nnamespace:\\n• nginx: https://hub.docker.com/_/nginx/\\n• busybox: https://hub.docker.com/_/busybox/\\n• redis: https://hub.docker.com/_/redis/\\n• mongo: https://hub.docker.com/_/mongo/\\nFigure 6.4 shows the official Alpine and NGINX repositories on Docker Hub. Both have'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 56}, page_content='• redis: https://hub.docker.com/_/redis/\\n• mongo: https://hub.docker.com/_/mongo/\\nFigure 6.4 shows the official Alpine and NGINX repositories on Docker Hub. Both have\\nthe green Docker Official Image badge and have over a billion pulls each. Also, notice how\\nboth are available for a wide range of CPU architectures.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 57}, page_content='6: Working with Images\\n51\\nFigure 6.4 - Official repos on Docker Hub\\nUnofficial repositories\\nThe next list shows two of my personal repositories in the “wild west” of unofficial\\nrepositories that you should be very careful when using.\\n• nigelpoulton/gsd — https://hub.docker.com/r/nigelpoulton/gsd-book/\\n• nigelpoulton/k8sbook — https://hub.docker.com/r/nigelpoulton/k8sbook/\\nNotice how they exist below the nigelpoulton second-level namespace. This is one of\\nseveral indications they are not official repositories.\\nWhile there are lots of great images in unofficial repositories, you should always start\\nwith the assumption that anything from an unofficial repository is unsafe. This is based\\non the good practice of never trusting software from the internet. In fact, you should\\nalso exercise caution when downloading and using Docker Official Images.\\nImage naming and tagging\\nMost of the time, you’ll work with images based on their names, and you can learn'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 57}, page_content='also exercise caution when downloading and using Docker Official Images.\\nImage naming and tagging\\nMost of the time, you’ll work with images based on their names, and you can learn\\na lot about an image from its name. Figure 6.5 shows a fully qualified image name,\\nincluding the registry name, user/organization name, repository name, and tag. Docker\\nautomatically populates the registry and tag values if you don’t specify them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 58}, page_content=\"6: Working with Images\\n52\\nFigure 6.5 - Fully qualified image name\\nAddressing images from official repositories is easy. All you need to supply is the\\nrepository name and image name separated by a colon. Sometimes we call the image\\nname the tag. The format for a docker pull command pulling an image from an official\\nrepository is:\\n$ docker pull <repository>:<tag>\\nThe example from earlier pulled the Redis image with the following command. It pulled\\nthe image tagged as latest from the top-level redis repository.\\n$ docker pull redis:latest\\nThe following examples show how to pull a few different official images.\\n$ docker pull redis:8.0-M02\\n//Pulls the image tagged as '8.0-M02' from the official 'redis' repository.\\n$ docker pull busybox:glibc\\n//Pulls the image tagged as 'glibc' from the official 'busybox' repository.\\n$ docker pull alpine\\n//Pulls the image tagged as 'latest' from the official 'alpine' repository.\\nA couple of things are worth noting.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 58}, page_content=\"$ docker pull alpine\\n//Pulls the image tagged as 'latest' from the official 'alpine' repository.\\nA couple of things are worth noting.\\n• As previously mentioned, if you don’t specify an image tag after the repository\\nname, Docker assumes you want the image tagged as latest. The command will\\nfail if the repository has no image tagged as latest.\\n• Images tagged as latest are not guaranteed to be the most up-to-date in the\\nrepository.\\nPulling images from unofficial repositories is almost the same as pulling from official\\nrepositories — you just need to add a Docker Hub username or organization name\\nbefore the repository name. The following example shows how to pull the v2 image\\nfrom the tu-demo repository owned by a not-to-be-trusted person whose Docker Hub\\nID is nigelpoulton.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 59}, page_content='6: Working with Images\\n53\\n$ docker pull nigelpoulton/tu-demo:v2\\nTo pull an image from a different registry, you just add the registry’s DNS name before\\nthe repository name. For example, the following command pulls the latest image from\\nBrandon Mitchell’s regclient/regsync repo on GitHub Container Registry (ghcr.io).\\n$ docker pull ghcr.io/regclient/regsync:latest\\nlatest: Pulling from regclient/regsync\\nf140ae7f526a: Download complete\\nc1cb552669af: Download complete\\nDigest: sha256:88b3d4dc3d7bf2d8ea6f641bea2be15142a9222db66d4b6f2043fc5cc19eead8\\nStatus: Downloaded newer image for ghcr.io/regclient/regsync:latest\\nghcr.io/regclient/regsync:latest\\nNotice how the pull looks the same as it did with Docker Hub. This is because GHCR\\nsupports the OCI registry-spec and implements the Docker Registry v2 API.\\nImages with multiple tags\\nYou can give a single image as many tags as you want.\\nAt first glance, the following output might look like it’s listing three images. However,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 59}, page_content='Images with multiple tags\\nYou can give a single image as many tags as you want.\\nAt first glance, the following output might look like it’s listing three images. However,\\non closer inspection it’s just two — the b4210d0aa52f image is tagged as latest and v1.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/tu-demo\\nlatest\\nb4210d0aa52f\\n2 days ago\\n115MB\\nnigelpoulton/tu-demo\\nv1\\nb4210d0aa52f\\n2 days ago\\n115MB\\nnigelpoulton/tu-demo\\nv2\\n6ba12825d092\\n12 minutes ago\\n115MB\\nThis is a great example of the latest tag not relating to the newest image in the repo.\\nIn this example, the latest tag refers to the same image as the v1 tag, which is actually\\nolder than the v2 image.\\nImages and layers\\nAs already mentioned, images are a collection of loosely connected read-only layers\\nwhere each layer comprises one or more files.\\nFigure 6.6 shows an image with four layers. Docker takes care of stacking them and\\nrepresenting them as a single unified image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 60}, page_content='6: Working with Images\\n54\\nFigure 6.6 - Image and stacked layers\\nYou’re about to look at all of the following ways to inspect layer information:\\n• Pull operations\\n• The docker inspect command\\n• The docker history command\\nRun the following command to pull the node:latest image and observe it pulling the\\nindividual layers. Some newer versions may have more or less layers, but the principle is\\nthe same.\\n$ docker pull node:latest\\nlatest: Pulling from library/ubuntu\\n952132ac251a: Pull complete\\n82659f8f1b76: Pull complete\\nc19118ca682d: Pull complete\\n8296858250fe: Pull complete\\n24e0251a0e2c: Pull complete\\nDigest: sha256:f4691c96e6bbaa99d...28ae95a60369c506dd6e6f6ab\\nStatus: Downloaded newer image for node:latest\\ndocker.io/node:latest\\nEach line ending with Pull complete represents a layer that Docker pulled. This image has\\nfive layers and is shown in Figure 6.7 with layer IDs.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 61}, page_content='6: Working with Images\\n55\\nFigure 6.7 - Image layers and IDs\\nAnother way to see image layers is to inspect the image with the docker inspect\\ncommand. The following example inspects the same node:latest image pulled in the\\nprevious step.\\n$ docker inspect node:latest\\n[\\n{\\n\"Id\": \"sha256:bd3d4369ae.......fa2645f5699037d7d8c6b415a10\",\\n\"RepoTags\": [\\n\"node:latest\"\\n<Snip>\\n\"RootFS\": {\\n\"Type\": \"layers\",\\n\"Layers\": [\\n\"sha256:c8a75145fc...894129005e461a43875a094b93412\",\\n\"sha256:c6f2b330b6...7214ed6aac305dd03f70b95cdc610\",\\n\"sha256:055757a193...3a9565d78962c7f368d5ac5984998\",\\n\"sha256:4837348061...12695f548406ea77feb5074e195e3\",\\n\"sha256:0cad5e07ba...4bae4cfc66b376265e16c32a0aae9\"\\n]\\n}\\n}\\n]\\nThe trimmed output shows the five layers. However, it shows their SHA256 hashes,\\nwhich are different from the short IDs shown in the docker pull output.\\nThe docker inspect command is great for getting detailed image information.\\nYou can also use the docker history command to inspect an image and see its layer'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 61}, page_content='The docker inspect command is great for getting detailed image information.\\nYou can also use the docker history command to inspect an image and see its layer\\ndata. However, this command shows the build history of an image and is not a strict list'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 62}, page_content='6: Working with Images\\n56\\nof layers in the final image. For example, some Dockerfile instructions (ENV, EXPOSE, CMD,\\nand ENTRYPOINT) only add metadata and don’t create layers.\\nBase layers\\nAll Docker images start with a base layer, and every time you add new content, Docker\\nadds a new layer.\\nConsider the following oversimplified example of building a simple Python application.\\nYour corporate policy mandates all applications be built on top of the official Ubuntu\\n24:04 image. This means the official Ubuntu 24:04 image will be the base layer for this\\napp. Installing your company’s approved version of Python will add a second layer, and\\nyour application source code will add a third. The final image will have three layers, as\\nshown in Figure 6.8. Remember, this is an oversimplified example for demonstration\\npurposes.\\nFigure 6.8\\nIt’s important to understand that an image is the combination of all layers stacked in the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 62}, page_content='shown in Figure 6.8. Remember, this is an oversimplified example for demonstration\\npurposes.\\nFigure 6.8\\nIt’s important to understand that an image is the combination of all layers stacked in the\\norder they were built. Figure 6.9 shows an image with two layers. Each layer has three\\nfiles, meaning the image has six files.\\nIt also shows that the layers are stored as independent objects, and the image is just\\nmetadata identifying the required layers and explaining how to stack them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 63}, page_content='6: Working with Images\\n57\\nFigure 6.9\\nIn the slightly more complex example of the three-layer image in Figure 6.10, the overall\\nimage only presents six files in the unified view. This is because File 7 in the top layer\\nis an updated version of File 5 directly below (inline). In this situation, the file in the\\nhigher layer obscures the file directly below it. This means you update files and make\\nother changes to images by adding new layers containing the changes.\\nFigure 6.10 - Stacking layers\\nUnder the hood, Docker uses storage drivers to stack layers and present them as a\\nunified filesystem and image. Almost all Docker setups use the overlay2 driver, but zfs,\\nbtrfs, and vfs are alternative options. However, whichever storage driver you use, the\\ndeveloper and user experience are always the same.\\nFigure 6.11 shows how the three-layer image from Figure 6.10 will appear on the system\\n— all three layers stacked and merged into a single unified view.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 64}, page_content='6: Working with Images\\n58\\nFigure 6.11 - Unified view of multi-layer image\\nSharing image layers\\nAs previously mentioned, images can share layers, leading to efficiencies in space and\\nperformance.\\nOne of the earlier docker pull commands generated an Already exists message for one\\nof the layers it pulled. This occurred because one of my Docker Desktop extensions had\\nalready pulled an image that used the exact same layer. As a result, Docker skipped that\\nlayer as it already had a local copy.\\nHere’s the code from earlier, and Figure 6.12 shows two images sharing the same layer.\\n$ docker pull redis:latest\\nlatest: Pulling from library/redis\\n25d3892798f8: Download complete\\ne5d458cf0bea: Download complete\\n4f4fb700ef54: Already exists\\n<<---- This line\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 65}, page_content='6: Working with Images\\n59\\nFigure 6.12 - Two images sharing a layer\\nLayers are also shared on the registry side. This means you can store lots of similar\\nimages in a registry, and the registry will save space by never storing more than a single\\ncopy of any layer.\\nPulling images by digest\\nSo far, you’ve seen how to pull and work with images using names (tags). While this\\nis the most common method, it has a problem — tags are arbitrary and mutable. This\\nmeans it’s possible to tag an image incorrectly or give a new image the same tag as an\\nolder one. An extremely common example is the latest tag. For example, pulling the\\nalpine:latest tag a year ago will not pull the same image as pulling the same tag today.\\nConsider a quick example outlining one potential implication of trusting mutable tags.\\nImagine you have an image called golftrack:1.5 and you get a warning that it has a\\ncritical vulnerability. You build a new image containing the fix and push the new image'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 65}, page_content='Imagine you have an image called golftrack:1.5 and you get a warning that it has a\\ncritical vulnerability. You build a new image containing the fix and push the new image\\nto the same repository with the same tag.\\nTake a moment to consider what just happened and the implications.\\nYou have an image called golftrack:1.5 that’s being used by lots of containers in your\\nproduction environment, and it has a critical bug. You create a new version containing\\nthe fix. So far, so good, but then you make the mistake. You push the new image to\\nthe same repository with the same tag as the vulnerable image. This overwrites the\\noriginal image and leaves you without a great way of knowing which of your production'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 66}, page_content='6: Working with Images\\n60\\ncontainers are using the vulnerable image and which are using the fixed image — both\\nimages have the same tag!\\nThis is where image digests come to the rescue.\\nDocker uses a content addressable storage model where every image gets a cryptographic\\ncontent hash that we usually call the digest. As these are hashes of an image’s contents,\\nit’s impossible for two different images to have the same digest. It’s also impossible to\\nchange an image without creating a new digest. Fortunately, Docker lets you work with\\nimage digests instead of just names.\\nIf you’ve already pulled an image by name, you can see its digest by running a docker\\nimages command with the --digests flag as shown.\\n$ docker images --digests alpine\\nREPOSITORY\\nTAG\\nDIGEST\\nIMAGE ID\\nCREATED\\nSIZE\\nalpine\\nlatest\\nsha256:c5b1261d...8e1ad6b\\nc5b1261d6d3e\\n2 weeks ago\\n11.8MB\\nIf you want to find an image’s digest before pulling it, you can use the docker buildx'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 66}, page_content='TAG\\nDIGEST\\nIMAGE ID\\nCREATED\\nSIZE\\nalpine\\nlatest\\nsha256:c5b1261d...8e1ad6b\\nc5b1261d6d3e\\n2 weeks ago\\n11.8MB\\nIf you want to find an image’s digest before pulling it, you can use the docker buildx\\nimagetools command. The following example retrieves the image digest for the\\nnigelpoulton/k8sbook/latest image on Docker Hub.\\n$ docker buildx imagetools inspect nigelpoulton/k8sbook:latest\\nName:\\ndocker.io/nigelpoulton/k8sbook:latest\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\\nDigest:\\nsha256:13dd59a0c74e9a147800039b1ff4d61201375c008b96a29c5bd17244bce2e14b\\n<Snip>\\nYou can now use the digest to pull the image. I’ve trimmed the command and the output\\nfor readability.\\n$ docker pull nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b\\ndocker.io/nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b: Pulling from nigelpoulton/k8sbook\\n59f1664fb787: Download complete\\na052f1888b3e: Download complete\\n94a9f4dfa0e5: Download complete\\nbb7e600677fa: Download complete\\nedfb0c26f1fb: Download complete'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 66}, page_content='59f1664fb787: Download complete\\na052f1888b3e: Download complete\\n94a9f4dfa0e5: Download complete\\nbb7e600677fa: Download complete\\nedfb0c26f1fb: Download complete\\n5b1423465504: Download complete\\n2f232a362cd9: Download complete\\nDigest: sha256:13dd59a0...bce2e14b\\nStatus: Downloaded newer image for nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b\\ndocker.io/nigelpoulton/k8sbook:latest@sha256:13dd59a0...bce2e14b\\nIt’s also possible to directly query the registry API for image data, including digest. The\\nfollowing curl command queries Docker Hub for the digest of the same image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 67}, page_content='6: Working with Images\\n61\\n$ curl \"https://hub.docker.com/v2/repositories/nigelpoulton/k8sbook/tags/?name=latest\" \\\\\\n|jq \\'.results[].digest\\'\\n\"sha256:13dd59a0c74e9a147800039b1ff4d61201375c008b96a29c5bd17244bce2e14b\"\\nImage hashes and layer hashes\\nYou already know that images are just a loose collection of independent layers. This\\nmeans an image is just a manifest file with some metadata and a list of layers. The actual\\napplication and all its dependencies live in the layers that are fully independent and have\\nno concept of being part of an image.\\nWith this in mind, images and layers have their own digests as follows:\\n• Images digests are a crypto hash of the image’s manifest file\\n• Layer digests are a crypto hash of the layer’s contents\\nThis means all changes to layers or image manifests result in new hashes, giving us an\\neasy and reliable way to know if changes have been made.\\nContent hashes vs distribution hashes'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 67}, page_content='This means all changes to layers or image manifests result in new hashes, giving us an\\neasy and reliable way to know if changes have been made.\\nContent hashes vs distribution hashes\\nDocker compares hashes before and after every push and pull to ensure no tampering\\noccurs while data is crossing the network. However, it also compresses images during\\npush and pull operations to save network bandwidth and storage space on the registry.\\nAs a result of this compression, the before and after hashes won’t match.\\nTo get around this, each layer gets two hashes:\\n• Content hash (uncompressed)\\n• Distribution hash (compressed)\\nEvery time Docker pushes or pulls a layer from a registry, it includes the layer’s distri-\\nbution hash and uses this to verify no tampering occurred. This is one reason why the\\nhashes in different CLI and registry outputs don’t always match — sometimes you’re\\nlooking at the content hash, and other times you’re looking at the distribution hash.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 68}, page_content='6: Working with Images\\n62\\nMulti-architecture images\\nOne of the best things about Docker is its simplicity. However, as technologies grow,\\nthey inevitably get more complex. This happened for Docker when it started supporting\\ndifferent platforms and architectures, such as Windows and Linux on variations of\\nARM, x64, PowerPC, s390x and more. Suddenly, there were multiple versions of\\nthe same image for all the different architectures, and developers and users had to\\nput in significant extra work to get the right version. This broke the smooth Docker\\nexperience.\\nMulti-architecture images to the rescue!\\nFortunately, Docker and the registry API adapted and became clever enough to hide\\nimages for multiple architectures behind a single tag. This means you can do a docker\\npull alpine on any architecture and get the correct version of the image. For example,\\nif you’re on an AMD64 machine, you’ll get the AMD64 image.\\nTo make this happen, the Registry API supports two important constructs:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 68}, page_content='if you’re on an AMD64 machine, you’ll get the AMD64 image.\\nTo make this happen, the Registry API supports two important constructs:\\n• Manifest lists\\n• Manifests\\nThe manifest list is exactly what it sounds like — a list of architectures supported by an\\nimage tag. Each supported architecture then has its own manifest that lists the layers\\nused to build it.\\nRun the following command to see the different architectures supported behind the\\nalpine:latest tag.\\n$ docker buildx imagetools inspect alpine\\nName:\\ndocker.io/library/alpine:latest\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\\nDigest:\\nsha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nManifests:\\nName:\\ndocker.io/library/alpine:latest@sha256:6457d53f...628977d0\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/amd64\\nName:\\ndocker.io/library/alpine:latest@sha256:b229a851...d144c1d8\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 68}, page_content='Platform:\\nlinux/amd64\\nName:\\ndocker.io/library/alpine:latest@sha256:b229a851...d144c1d8\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm/v6\\nName:\\ndocker.io/library/alpine:latest@sha256:ec299a7b...33b4c6fe\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm/v7'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 69}, page_content='6: Working with Images\\n63\\nName:\\ndocker.io/library/alpine:latest@sha256:a0264d60...93467a46\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm64/v8\\nName:\\ndocker.io/library/alpine:latest@sha256:15c46ced...ab073171\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/386\\nName:\\ndocker.io/library/alpine:latest@sha256:b12b826d...ba52a3a2\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/ppc64le\\nYour output may include additional annotations, but if you look closely, you’ll see a\\nsingle manifest list pointing to six manifests.\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json is the\\nmanifest list.\\nEach MediaType: application/vnd.docker.distribution.manifest.v2+json line\\nrefers to a manifest for each specific architecture.\\nFigure 6.13 shows how manifest lists and manifests are related. On the left, you can see'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 69}, page_content='refers to a manifest for each specific architecture.\\nFigure 6.13 shows how manifest lists and manifests are related. On the left, you can see\\na manifest list with entries for the different architectures supported by the image. The\\narrows show that each entry in the manifest list points to a manifest defining the image\\nconfig and the list of layers making up the image for that architecture.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 70}, page_content='6: Working with Images\\n64\\nFigure 6.13 - Manifest lists and manifests\\nLet’s step through a quick example.\\nAssume you’re using Docker Desktop on an M4 Mac where Docker runs inside a\\nlinux/arm VM. You ask Docker to pull an image, and Docker makes the relevant calls to\\nthe Registry API to request the appropriate manifest list. Assuming it exists, Docker then\\nparses it for a linux/arm entry. If linux/arm entry exists, Docker retrieves its manifest,\\nparses it for the crypto IDs of its layers, pulls each layer, and assembles them into the\\nimage.\\nLet’s see it in action.\\nThe following examples are from Docker Desktop on an ARM-based Mac and Docker\\nDesktop on an AMD-based Windows machine running in Windows containers mode.\\nBoth start a new container based the official golang image and execute the go version\\ncommand. The outputs show the version of Go and the host’s platform and CPU\\narchitecture. Notice how both commands are exactly the same, and Docker takes care\\nof pulling the correct image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 70}, page_content='command. The outputs show the version of Go and the host’s platform and CPU\\narchitecture. Notice how both commands are exactly the same, and Docker takes care\\nof pulling the correct image.\\nBoth images are large and may take a while to download. You do not need to complete\\nthese commands yourself.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 71}, page_content='6: Working with Images\\n65\\nLinux on arm64 example:\\n$ docker run --rm golang go version\\n<Snip>\\ngo version go1.23.4 linux/arm64\\nWindows on x64 example:\\n> docker run --rm golang go version\\n<Snip>\\ngo version go1.23.4 windows/amd64\\nYou’ve already seen how to use the docker buildx imagetools command to see the\\nmanifest list and manifests for an image. You can get similar information from the\\ndocker manifest command. The following example inspects the manifest list for\\nthe official golang image on Docker Hub. You can see it has images for Linux and\\nWindows on a variety of CPU architectures. You can run the same command without\\nthe grep filter to see the full JSON manifest list. Windows users should replace the grep\\ncommand with Select-String architecture,os\\n$ docker manifest inspect golang | grep \\'architecture\\\\|os\\'\\n\"architecture\": \"amd64\",\\n\"os\": \"linux\"\\n\"architecture\": \"arm\",\\n\"os\": \"linux\",\\n\"architecture\": \"arm64\",\\n\"os\": \"linux\",\\n\"architecture\": \"386\",\\n\"os\": \"linux\"\\n\"architecture\": \"mips64le\",'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 71}, page_content='\"architecture\": \"amd64\",\\n\"os\": \"linux\"\\n\"architecture\": \"arm\",\\n\"os\": \"linux\",\\n\"architecture\": \"arm64\",\\n\"os\": \"linux\",\\n\"architecture\": \"386\",\\n\"os\": \"linux\"\\n\"architecture\": \"mips64le\",\\n\"os\": \"linux\"\\n\"architecture\": \"ppc64le\",\\n\"os\": \"linux\"\\n\"architecture\": \"s390x\",\\n\"os\": \"linux\"\\n\"architecture\": \"amd64\",\\n\"os\": \"windows\",\\n\"os.version\": \"10.0.20348.2227\"\\n\"architecture\": \"amd64\",\\n\"os\": \"windows\",\\n\"os.version\": \"10.0.17763.5329\"\\nPulling the right image for your system is one thing, but what about building images for\\nall these different architectures?\\nThe docker buildx command makes it easy to create multi-architecture images. For\\nexample, you can use Docker Desktop on linux/arm to build images for linux/amd'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 72}, page_content='6: Working with Images\\n66\\nand possibly other architectures. We’ll perform builds like these in future chapters, but\\ndocker buildx offers two ways to create multi-architecture images:\\n• Emulation\\n• Build Cloud\\nEmulation mode performs builds for different architectures on your local machine by\\nrunning the build inside a QEMU virtual machine emulating the target architecture. It\\nworks most of the time but is slow and doesn’t have a shared cache.\\nBuild Cloud is a service from Docker, Inc. that performs builds in the cloud on native\\nhardware without requiring emulation. It’s very fast, lets you share a common build\\ncache with teammates, and is seamlessly integrated into Docker Desktop and any\\nversion of the Docker Engine using a version of buildx supporting the cloud driver.\\nIt also integrates with GitHub actions and other CI solutions. At the time of writing,\\nDocker Build Cloud is a subscription service you have to pay for.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 72}, page_content='It also integrates with GitHub actions and other CI solutions. At the time of writing,\\nDocker Build Cloud is a subscription service you have to pay for.\\nWe’ll use both in future chapters, but I ran the following command to build AMD and\\nARM versions of the nigelpoulton/tu-demo image using Docker Build Cloud.\\n$ docker buildx build \\\\\\n--builder=cloud-nigelpoulton-ddd-cloud \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/tu-demo:latest --push .\\nVulnerability scanning with Docker Scout\\nLots of tools and plugins exist that scan images for known vulnerabilities.\\nWe’ll look at Docker Scout, as it’s built into almost every level of Docker, including the\\nCLI, Docker Desktop, Docker Hub, and the scout.docker.com portal. It’s a very slick\\nservice, but it requires a paid subscription. Other similar products and services exist, but\\nmost require paid subscriptions.\\nRecent versions of Docker Desktop have the Scout CLI plugin pre-installed and ready'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 72}, page_content='most require paid subscriptions.\\nRecent versions of Docker Desktop have the Scout CLI plugin pre-installed and ready\\nto go. If you’re running a different version of Docker, you may be able to install the CLI\\nplugin from the GitHub repo14.\\nYou can use the docker scout quickview command to get a quick vulnerability\\noverview of an image. The following command analyses the nigelpoulton/tu-\\ndemo:latest image. If a local copy doesn’t exist, it pulls it from Docker Hub and\\nperforms the analysis locally.\\n14https://github.com/docker/scout-cli'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 73}, page_content='6: Working with Images\\n67\\n$ docker scout quickview nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\n│\\n0C\\n1H\\n1M\\n0L\\ndigest\\n│\\nb4210d0aa52f\\n│\\nBase image\\n│\\npython:3-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\nUpdated base image │\\npython:3.11-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\n│\\n│\\nThe output shows zero critical vulnerabilities (0C), one high (1H), one medium (1M),\\nand zero low (0L).\\nYou can use the docker scout cves command to get more detailed information,\\nincluding remediation advice.\\n$ docker scout cves nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\n\\uffffDetected 1 vulnerable package with 2 vulnerabilities\\n## Overview\\n│\\nAnalyzed Image\\n────────────────────┼────────────────────────────────\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64/v8\\nvulnerabilities │\\n0C\\n1H\\n1M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 73}, page_content='Target\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64/v8\\nvulnerabilities │\\n0C\\n1H\\n1M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2\\npkg:apk/alpine/expat@2.5.0-r2?os_name=alpine&os_version=3.19\\n\\uffffHIGH CVE-2023-52425\\nhttps://scout.docker.com/v/CVE-2023-52425\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n<Snip>\\nI’ve snipped the output so it only shows the critical and high vulnerabilities, but several\\nthings are clear:\\n• It has detected one vulnerable package containing two vulnerabilities\\n• The affected package is called expat and the vulnerable version we’re running is\\n2.5.0-r2\\n• It lists the vulnerability as CVE-2023-52425'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 74}, page_content='6: Working with Images\\n68\\n• It includes a link to a Scout report containing more info\\n• It suggests we update to version 2.6.0-r0 which contains the fix\\nFigure 6.14 shows how this looks in Docker Desktop, and you get similar integrations\\nand views in Docker Hub.\\nFigure 6.14 - Docker Scout integration with Docker Desktop\\nThe scout.docker.com portal provides an overview dashboard, allows you to configure\\npolicies, and lets you set up integrations with Docker Hub and other registries to\\nremotely scan and monitor multiple repositories.\\nDeleting Images\\nYou can delete images using the docker rmi command. rmi is short for remove image.\\nDeleting images removes them from your local repository and they’ll no longer show up\\nin your docker images commands. The operation also deletes all directories on your\\nlocal filesystem containing layer data. However, Docker won’t delete layers shared by\\nmultiple images until you delete all images that reference them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 74}, page_content='local filesystem containing layer data. However, Docker won’t delete layers shared by\\nmultiple images until you delete all images that reference them.\\nYou can delete images by name, short ID, or SHA. You can also delete multiple images\\nwith the same command.\\nThe following command deletes three images — one by name, one by short ID, and one\\nby SHA. I’ve trimmed the output for easier reading.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 75}, page_content='6: Working with Images\\n69\\n$ docker rmi redis:latest af111729d35a sha256:c5b1261d...f8e1ad6b\\nUntagged: redis:latest\\nDeleted: sha256:76d5908f5e19fcdd73daf956a38826f790336ee4707d9028f32b24ad9ac72c08\\nUntagged: nigelpoulton/tu-demo:v2\\nDeleted: sha256:af111729d35a09fd24c25607ec045184bb8d76e37714dfc2d9e55d13b3ebbc67\\nUntagged: alpine:latest\\nDeleted: sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nDocker will prevent the delete operation if the image is being used by a container or\\nreferenced by more than one tag. However, you can force the operation with the -f\\nflag, but you should do so with caution, as forcing Docker to delete an image in use by\\na container will untag the image and leave it on the system as a dangling image.\\nA handy way to delete all images is to pass a list of all local image IDs to the docker rmi\\ncommand. You should use this command with caution, and if you’re following along on\\nWindows, it will only work in a PowerShell terminal.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 75}, page_content='command. You should use this command with caution, and if you’re following along on\\nWindows, it will only work in a PowerShell terminal.\\n$ docker rmi $(docker images -q) -f\\nTo understand how this works, download a couple of images and then run docker\\nimages -q.\\n$ docker pull alpine\\n<Snip>\\n$ docker pull ubuntu\\n<Snip>\\n$ docker images -q\\n44dd6f223004\\n3f5ef9003cef\\nSee how the docker images -q returns a list of local image IDs. Passing this list to\\ndocker rmi will delete all images on the system as shown next.\\n$ docker rmi $(docker images -q) -f\\nUntagged: alpine:latest\\nUntagged: alpine@sha256:02bb6f428431fb...a33cb1af4444c9b11\\nDeleted: sha256:44dd6f2230041...09399391535c0c0183b\\nDeleted: sha256:94dd7d531fa56...97252ba88da87169c3f\\nUntagged: ubuntu:latest\\nUntagged: ubuntu@sha256:dfd64a3b4296d8...9ee20739e8eb54fbf\\nDeleted: sha256:3f5ef9003cefb...79cb530c29298550b92\\nDeleted: sha256:b49483f6a0e69...f3075564c10349774c3\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 75}, page_content='Deleted: sha256:3f5ef9003cefb...79cb530c29298550b92\\nDeleted: sha256:b49483f6a0e69...f3075564c10349774c3\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nLet’s remind ourselves of some of the commands we’ve used.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 76}, page_content='6: Working with Images\\n70\\nImages – The commands\\n• docker pull is the command to download images from remote registries. It\\ndefaults to Docker Hub but works with other registries. The following command\\nwill pull the image tagged as latest from the alpine repository on Docker Hub:\\ndocker pull alpine:latest.\\n• docker images lists all the images in your Docker host’s local repository (image\\ncache). You can add the --digests flag to see the SHA256 hashes.\\n• docker inspect gives you a wealth of image-related metadata in a nicely format-\\nted view.\\n• docker manifest inspect lets you inspect the manifest list of images stored\\nin registries. The following command will show the manifest list for the regctl\\nimage on GitHub Container Registry (GHCR): docker manifest inspect\\nghcr.io/regclient/regctl.\\n• docker buildx is a Docker CLI plugin that works with Docker’s latest build\\nengine features. You saw how to use the imagetools sub-command to query\\nmanifest-related data from images.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 76}, page_content='• docker buildx is a Docker CLI plugin that works with Docker’s latest build\\nengine features. You saw how to use the imagetools sub-command to query\\nmanifest-related data from images.\\n• docker scout is a Docker CLI plugin that integrates with the Docker Scout\\nbackend to perform image vulnerability scanning. It scans images, provides\\nreports on vulnerabilities, and even suggests remediation actions.\\n• docker rmi is the command to delete images. It deletes all layer data stored in the\\nlocal filesystem, and you cannot delete images that are in use by containers.\\nChapter summary\\nThis chapter taught you the important theory and fundamentals of images.\\nYou learned that images contain everything needed to run an application as a container.\\nThis includes just enough OS, source code, dependencies, and metadata.\\nYou can start one or more containers from a single image.\\nUnder the hood, Docker constructs images by stacking one or more read-only layers'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 76}, page_content='You can start one or more containers from a single image.\\nUnder the hood, Docker constructs images by stacking one or more read-only layers\\nand presenting them as a unified object. Every image has a manifest that lists the layers\\nthat make up the image and how to stack them.\\nYou learned that image names are also called tags, they’re mutable, and they don’t always\\npull the same image. For example, pulling the alpine:latest tag today will not pull\\nthe same image as it will a year from now. Fortunately, every image gets an immutable\\ndigest that you can use to guarantee you always pull the intended image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 77}, page_content='6: Working with Images\\n71\\nDocker Hub has the notion of curated official images that should be safer to use than\\nunofficial images. However, you should always exercise caution when downloading\\nsoftware from the internet, even official images from Docker Hub.\\nImages can share layers for efficiency, and Docker makes it easy to build and pull images\\nfor lots of different CPU architectures, such as ARM and AMD.\\nDocker Scout scans images for known vulnerabilities and provides remediation advice.\\nIt requires a Docker subscription and is integrated into the docker CLI, Docker Hub,\\nand Docker Desktop.\\nIn the next chapter, we’ll take a similar tour of containers — the run-time sibling of\\nimages.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 78}, page_content='7: Working with containers\\nDocker implements the Open Container Initiative (OCI) specifications. This means\\nsome of the things you’ll learn in this chapter will apply to other container runtimes and\\nplatforms that implement the OCI specifications.\\nI’ve divided the chapter into the following sections:\\n• Container – The TLDR\\n• Containers vs VMs\\n• Images and containers\\n• Check Docker is running\\n• Starting a container\\n• How containers start apps\\n• Connecting to a running container\\n• Inspecting container processes\\n• The docker inspect command\\n• Writing data to a container\\n• Stopping, restarting, and deleting a container\\n• Killing a container’s main process\\n• Debugging slim images and containers with Docker Debug\\n• Self-healing containers with restart policies\\n• The commands\\nContainers – The TLDR\\nContainers are run-time instances of images, and you can start one or more containers\\nfrom a single image.\\nFigure 7.1 shows multiple containers started from a single image. The shared image is'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 78}, page_content='Containers are run-time instances of images, and you can start one or more containers\\nfrom a single image.\\nFigure 7.1 shows multiple containers started from a single image. The shared image is\\nread-only, but you can write to the containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 79}, page_content='7: Working with containers\\n73\\nFigure 7.1\\nYou can start, stop, restart, and delete containers just like you can with VMs. However,\\ncontainers are smaller, faster, and more portable than VMs. They’re also designed to\\nbe stateless and ephemeral, whereas VMs are designed to be long-running and can be\\nmigrated with their state and data.\\nContainers are also designed to be immutable. This means you shouldn’t change them\\nafter you’ve deployed them — if a container fails, you replace it with a new one instead\\nof connecting to it and making a live fix.\\nContainers should only run a single process and we use them to build microservices\\napps. For example, an application with four features, such as a web server, auth, catalog,\\nand store, will have four containers — one running the web server, one running the auth\\nservice, one running the catalog, and another running the store.\\nContainers vs VMs\\nContainers and VMs are both virtualization technologies for running applications. They'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 79}, page_content='service, one running the catalog, and another running the store.\\nContainers vs VMs\\nContainers and VMs are both virtualization technologies for running applications. They\\nboth work on your laptop, bare metal servers, in the cloud, and more. However, the\\nways they virtualize are very different:\\n• VMs virtualize hardware\\n• Containers virtualize operating systems\\nIn the VM model, you power on a server and a hypervisor boots. When the hypervisor\\nboots, it claims all hardware resources such as CPU, RAM, storage, and network\\nadapters. To deploy an app, you ask the hypervisor to create a virtual machine. It does\\nthis by carving up the hardware resources into virtual versions, such as virtual CPUs\\nand Virtual RAM, and packaging them into a VM that looks exactly like a physical\\nserver. Once you have the VM, you install an OS and then an app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 80}, page_content='7: Working with containers\\n74\\nIn the container model, you power on the same server and an OS boots and claims all\\nhardware resources. You then install a container runtime such as Docker. To deploy\\nan app, you ask Docker to create a container. It does this by carving up OS resources\\nsuch as process trees and filesystems into virtual versions and then packaging them as a\\ncontainer that looks exactly like a regular OS. You then tell Docker to run the app inside\\nthe container.\\nFigure 7.2 shows the two models side by side and attempts to demonstrate the more\\nefficient nature of containers with the same server running 3x more containers than\\nVMs.\\nFigure 7.2\\nIn summary, hypervisors perform hardware virtualization where they divide hardware\\nresources into virtual versions and package them as VMs. Container runtimes perform\\nOS virtualization where they divide OS resources into virtual versions and package them'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 80}, page_content='resources into virtual versions and package them as VMs. Container runtimes perform\\nOS virtualization where they divide OS resources into virtual versions and package them\\nas containers. VMs look and feel exactly like physical servers. Containers look and feel\\nexactly like regular operating systems.\\nThe VM tax\\nOne of the biggest problems with the virtual machine model is that you need to\\ninstall an OS on every VM — every OS consumes CPU, RAM, and storage and takes a\\nrelatively long time to boot.\\nContainers get around all of this by sharing a single OS on the host they’re running on.\\nThis gives containers all of the following benefits over VMs:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 81}, page_content='7: Working with containers\\n75\\n• Containers are smaller and more portable\\n• You can run more containers on your infrastructure\\n• Containers start faster\\n• Containers reduce the number of operating systems you need to manage (patch,\\nupdate, etc.)\\n• Containers present a smaller attack surface\\nLet’s briefly expand on each point.\\nContainers are smaller than VMs because they only contain application code and a\\nminimal set of OS-related constructs such as essential filesystem objects. Because of this,\\nthey’re typically only a few megabytes in size. On the other hand, every VM needs a full\\nOS, meaning they’re usually hundreds or thousands of megabytes.\\nBecause containers don’t contain their own OS, you can run a lot more containers\\nthan VMs. For example, deploying 100 applications as VMs will require 100 operating\\nsystems, each consuming CPU, memory, and storage, and each needing to be patched\\nand managed. However, deploying the same 100 applications as containers requires no'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 81}, page_content='systems, each consuming CPU, memory, and storage, and each needing to be patched\\nand managed. However, deploying the same 100 applications as containers requires no\\nadditional operating systems. This drastically reduces your OS management overhead\\nand allows you to allocate more system resources to applications instead of operating\\nsystems.\\nContainers also start faster than VMs because they use the host’s OS which is already\\nbooted. On the other hand, VMs need to go through a full OS bootstrapping process\\nbefore starting the app.\\nOne of the early concerns about containers centered around the shared kernel model\\nwhere all containers on the same host share the host’s kernel. While this offers perfor-\\nmance and portability benefits, it’s less secure than the VM model where every VM has\\nits own dedicated kernel. For example, a rogue container that exploits a vulnerability\\nin the host’s kernel might be able to impact every other container on the same host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 81}, page_content='its own dedicated kernel. For example, a rogue container that exploits a vulnerability\\nin the host’s kernel might be able to impact every other container on the same host.\\nFortunately, this is much less of a concern now that container platforms have matured\\nand ship with class-leading tools that can make them more secure than non-container\\nplatforms. For example, most container engines and platforms implement sensible\\ndefaults for security-related technologies such as SELinux, AppArmor, seccomp, capabilities,\\nand more. You can even configure these to make containers more secure than VMs.\\nOther technologies, such as image vulnerability scanning, give you more control over\\nthe security of your software than you ever had before.\\nAt the time of writing, containers are the go-to solution for the vast majority of new\\napplications.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 82}, page_content='7: Working with containers\\n76\\nPre-reqs\\nYou’ll need a working Docker environment to follow along with the examples, and I\\nrecommend Docker Desktop. Other Docker setups should work, but you may have\\nto manually install the Docker Debug plugin if you want to follow along with those\\nexamples.\\nImages and Containers\\nAs previously mentioned, you can start multiple containers from a single image. The\\nimage is read-only in this relationship, but each container is read-write. As shown\\nin Figure 7.3, Docker accomplishes this by creating a thin read-write layer for each\\ncontainer and placing it on top of the shared image.\\nFigure 7.3 - Container R/W layers\\nIn this example, each container has its own thin R/W layer but shares the same image.\\nThe containers can see and access the files and apps in the image through their own R/W\\nlayer, and if they make any changes, these get written to their R/W layer. When you stop'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 82}, page_content='The containers can see and access the files and apps in the image through their own R/W\\nlayer, and if they make any changes, these get written to their R/W layer. When you stop\\na container, Docker keeps the R/W layer and restores it when you restart the container.\\nHowever, when you delete a container, Docker deletes its R/W layer. This way, each\\ncontainer can make and keep its own changes without requiring write access to the\\nshared image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 83}, page_content='7: Working with containers\\n77\\nCheck Docker is running\\nRun a docker version to check Docker is running. It’s a good command because it\\nchecks the CLI and engine components.\\n$ docker version\\nClient:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49\\nOS/Arch:\\ndarwin/arm64\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nOS/Arch:\\nlinux/arm64\\n<Snip>\\nAs long as you get a response from the Client and Server, you’re good to go and can\\nskip to the next section.\\nIf you get an error code in the Server section, this usually means your Docker daemon\\n(server) isn’t running or your user account doesn’t have permission to access it. If\\nyou’re running on Linux, you’ll need to ensure your user account is a member of the\\nlocal docker Unix group. If it isn’t, you can add it by running usermod -aG docker\\n<username> and restarting your shell. Alternatively, you can prefix all docker commands\\nwith sudo.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 83}, page_content='local docker Unix group. If it isn’t, you can add it by running usermod -aG docker\\n<username> and restarting your shell. Alternatively, you can prefix all docker commands\\nwith sudo.\\nYour account needs to be a member of the docker group so it can access the API, which\\nis exposed on a privileged local Unix socket at /var/run/docker.sock. It’s also possible\\nto expose the API over the network.\\nIf your user account is already a member of the local docker group and you still get an\\nerror from the daemon, there’s a good chance the Docker daemon isn’t running. Run\\none of the following commands to check the status of the daemon.\\nLinux systems not using Systemd.\\n$ service docker status\\ndocker start/running, process 29393\\nLinux systems using Systemd.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 84}, page_content=\"7: Working with containers\\n78\\n$ systemctl is-active docker\\nactive\\nIf the daemon isn’t running, start it with the appropriate command for your system.\\nStarting a container\\nThe docker run command is the simplest and most common way to start a new\\ncontainer.\\nRun the following command to start a new container called webserver.\\n$ docker run -d --name webserver -p 5005:8080 nigelpoulton/ddd-book:web0.1\\nUnable to find image 'nigelpoulton/ddd-book:web0.1' locally\\nweb0.1: Pulling from nigelpoulton/ddd-book\\n4f4fb700ef54: Already exists\\ncf2a607f33f7: Download complete\\n0a1f0c111e9a: Download complete\\nc1af4b5db242: Download complete\\nDigest: sha256:3f5b281b914b1e39df8a1fbc189270a5672ff9e98bfac03193b42d1c02c43ef0\\nStatus: Downloaded newer image for nigelpoulton/ddd-book:web0.1\\nb5594b3b8b3fdce544d2ca048e4340d176bce9f5dc430812a20f1852c395e96b\\nLet’s take a closer look at the command and the output.\\ndocker run tells Docker to run a new container\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 84}, page_content='b5594b3b8b3fdce544d2ca048e4340d176bce9f5dc430812a20f1852c395e96b\\nLet’s take a closer look at the command and the output.\\ndocker run tells Docker to run a new container\\nThe -d flag tells Docker to run it in the background as a daemon process and detached\\nfrom your local terminal\\nThe name flag tells Docker to name this container webserver.\\nThe -p 5005:8080 flag maps port 5005 on your local system to port 8080 inside the\\ncontainer. This works because the container’s web server is listening on port 8080.\\nThe nigelpoulton/ddd-book:web0.1 argument tells Docker which image to use to start\\nthe container.\\nWhen you hit Return, the Docker client converted the command into an API request\\nand posted it to the Docker API exposed by the Docker daemon. The Docker daemon\\naccepted the command and searched its local image repository for a copy of the\\nnigelpoulton/ddd-book:web0.1 image. It didn’t find one, so it searched Docker Hub.\\nIn the example, it found one on Docker Hub and pulled a local copy.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 84}, page_content='nigelpoulton/ddd-book:web0.1 image. It didn’t find one, so it searched Docker Hub.\\nIn the example, it found one on Docker Hub and pulled a local copy.\\nOnce it had a local copy of the image, the daemon made a request to containerd asking\\nfor a new container. containerd then instructed runc to create the container and start\\nthe app. It also performed the port mapping.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 85}, page_content='7: Working with containers\\n79\\nRun the following commands to verify Docker pulled the image and started the\\nwebserver container.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nweb0.1\\n3f5b281b914b\\n12 minutes ago\\n159MB\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\nb5594b3b8b3f\\nnigelpoulton...\\n\"node ./app.js\"\\nUp 2 mins\\n0.0.0.0:80->8080/tcp\\nwebserver\\nYou can also test the app by connecting a browser to port 5005 on your Docker host.\\nIf you’re using Docker Desktop, point your browser to localhost:5005. If you’re not\\nrunning Docker Desktop, you may need to substitute localhost with the name or IP of\\nthe host Docker is running on.\\nFigure 7.4 - Web app running in container\\nCongratulations. Docker pulled a local copy of the image and started a container\\nrunning the app shown in the image.\\nHow containers start apps\\nIn the previous section, you created a container running a web app. But how did the\\ncontainer know to start a web app?'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 85}, page_content='running the app shown in the image.\\nHow containers start apps\\nIn the previous section, you created a container running a web app. But how did the\\ncontainer know to start a web app?\\nThere are three ways you can tell Docker how to start an app in a container:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 86}, page_content='7: Working with containers\\n80\\n1. An Entrypoint instruction in the image\\n2. A Cmd instruction in the image\\n3. A CLI argument\\nYou’ll learn more about these in the next chapter, but the Entrypoint and Cmd instruc-\\ntions are optional image metadata where you can store the command you want Docker\\nto run to start the default app. Then, whenever you start a container from the image,\\nDocker checks the Entrypoint or Cmd instruction and executes the stored command.\\nEntrypoint instructions cannot be overridden on the CLI, and anything you pass in via\\nthe CLI will be appended to the Entrypoint instruction as an argument.\\nCmd instructions are overridden by CLI arguments.\\nRun the following command to see if the nigelpoulton/ddd-book:web0.1 image has\\nan Entrypoint instruction. The command searches the image metadata and returns any\\nlines containing the word “Entrypoint” as well as the three lines immediately following it.\\nWindows users will need to replace the grep command with Select-String -Pattern'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 86}, page_content='lines containing the word “Entrypoint” as well as the three lines immediately following it.\\nWindows users will need to replace the grep command with Select-String -Pattern\\n\\'Entrypoint\\' -Context 0,3.\\n$ docker inspect nigelpoulton/ddd-book:web0.1 | grep Entrypoint -A 3\\n<Snip>\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"\\n],\\nThis image has an Entrypoint instruction that translates into the following command\\n— node ./app.js. If you’re not familiar with Node.js, it’s a simple command telling the\\nNode.js runtime to execute the code in the app.js file.\\nIf an image doesn’t have an Entrypoint instruction, you can search for the presence of a\\nCmd instruction.\\nIf an image doesn’t have either, you’ll need to pass an argument on the CLI.\\nThe format of the docker run command is:\\ndocker run <arguments> <image> <command>\\nAs mentioned, the <command> is optional; you don’t need it if the image has a Cmd or\\nEntrypoint instruction. If you specify a <command>, it will override a Cmd instruction'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 86}, page_content='As mentioned, the <command> is optional; you don’t need it if the image has a Cmd or\\nEntrypoint instruction. If you specify a <command>, it will override a Cmd instruction\\nbut will be appended to an Entrypoint instruction.\\nThe following command starts a new background container based on the Alpine image\\nand tells it to run the sleep 60 command, causing it to run for 60 seconds and then exit.\\nThe --rm flag cleans up the exited container so you don’t have to delete it manually.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 87}, page_content='7: Working with containers\\n81\\n$ docker run --rm -d alpine sleep 60\\nIf you run a docker ps command before the 60-second sleep timer expires, you’ll see\\nthe container in the output. If you run it after 60 seconds, the container will be gone.\\nThe --rm argument automatically cleans up the exited container.\\nMost production images will specify an Entrypoint or Cmd instruction.\\nConnecting to a running container\\nYou can use the docker exec command to execute commands in running containers,\\nand it has two modes:\\n• Interactive\\n• Remote execution\\nInteractive exec sessions connect your terminal to a shell process in the container and\\nbehave like remote SSH sessions. Remote execution mode lets you send commands to a\\nrunning container and prints the output to your local terminal.\\nRun the following command to start an interactive exec session by creating a new\\nshell process (sh) inside the webserver container that is already running. The -it flag'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 87}, page_content='Run the following command to start an interactive exec session by creating a new\\nshell process (sh) inside the webserver container that is already running. The -it flag\\nmakes it an interactive exec session, and the sh argument starts a new sh process inside the\\ncontainer. sh is a minimal shell program installed in the container.\\n$ docker exec -it webserver sh\\n/src #\\nNotice how your shell prompt changed. This proves your terminal is connected to the\\nshell process inside the container.\\nTry executing a few common Linux commands. Some will work, and some won’t. This\\nis because container images are usually optimized to be lightweight and don’t have all of\\nthe normal commands and packages installed. The following example shows a couple of\\ncommands — one succeeds, and the other one fails.\\nThe examples list the contents of your current directory and try to edit the app.js file\\nwith the vim editor.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 88}, page_content='7: Working with containers\\n82\\n/src # ls -l\\ntotal 100\\n-rw-r--r--\\n1 root\\nroot\\n324 Feb 20 12:35 Dockerfile\\n-rw-r--r--\\n1 root\\nroot\\n377 Feb 20 12:35 README.md\\n-rw-r--r--\\n1 root\\nroot\\n341 Feb 20 12:35 app.js\\ndrwxr-xr-x\\n183 root\\nroot\\n4096 Feb 20 12:41 node_modules\\n-rw-r--r--\\n1 root\\nroot\\n74342 Feb 20 12:41 package-lock.json\\n-rw-r--r--\\n1 root\\nroot\\n404 Feb 20 12:38 package.json\\ndrwxr-xr-x\\n2 root\\nroot\\n4096 Feb 20 12:35 views\\n<Snip>\\n/src # vim app.js\\nsh: vim: not found\\nThe vim command fails because it isn’t installed in the container.\\nInspecting container processes\\nMost containers only run a single process. This is the container’s main app process and\\nis always PID 1.\\nRun a ps command to see the processes running in your container. You’ll need to be\\nconnected to the exec session from the previous section for these commands to work.\\n/src # ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n13 root\\n0:00 sh\\n22 root\\n0:00 ps\\nThe output shows three processes:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 88}, page_content='/src # ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n13 root\\n0:00 sh\\n22 root\\n0:00 ps\\nThe output shows three processes:\\n• PID 1 is the main application process running the Node.js web app\\n• PID 13 is the shell process your interactive exec session is connected to\\n• PID 22 is the ps command you just ran\\nThe ps process terminated as soon as it displayed the output, and the sh process will\\nterminate when you exit the exec session. This means the only long-running process is\\nPID 1 running the Node app.\\nIf you kill the container’s main process (PID 1), you’ll also kill the container. This is\\nbecause containers only run while their main process is executing — when that process\\nis no longer running, there’s no reason for the container to run. We’ll demonstrate this\\nlater.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 89}, page_content='7: Working with containers\\n83\\nType exit to quit the exec session and return to your local terminal.\\nRun another docker exec command without specifying the -it flags. This will\\nremotely execute the command without creating an interactive session. The format of\\nthe command is docker exec <container> <command>, and it will only work if the\\ncontainer has the command you’re trying to execute.\\n$ docker exec webserver ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n42 root\\n0:00 ps\\nThis time, only two processes are running because you terminated the sh process when\\nyou typed exit to quit the previous interactive exec session.\\nThe docker inspect command\\nYou’ll love the docker inspect command as it’s a treasure trove of detailed information\\nabout images and containers.\\nThe following command retrieves full details of the running webserver container, and\\nI’ve snipped the output to highlight a few interesting things. However, I recommend'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 89}, page_content='about images and containers.\\nThe following command retrieves full details of the running webserver container, and\\nI’ve snipped the output to highlight a few interesting things. However, I recommend\\nrunning the command on your system and studying the output.\\n$ docker inspect webserver\\n<Snip>\\n\"State\": {\\n\"Status\": \"running\"\\n},\\n\"Name\": \"/webserver\",\\n\"PortBindings\": {\\n\"8080/tcp\": [\\n{\\n\"HostIp\": \"\",\\n\"HostPort\": \"5005\"\\n}\\n]\\n},\\n\"RestartPolicy\": {\\n\"Name\": \"no\",\\n\"MaximumRetryCount\": 0\\n\"Image\": \"nigelpoulton/ddd-book:web0.1\",\\n\"WorkingDir\": \"/src\",\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 90}, page_content='7: Working with containers\\n84\\n],\\n}\\n<Snip>\\nThe snipped output shows the container is running, is called webserver, is binding port\\n8080 in the container to 5005 on the host, has no restart policy, and is based on the\\nnigelpoulton/ddd-book:web0.1 image. The Entrypoint block lists the command that\\nautomatically runs every time the container starts.\\nWe’ll cover this in more detail later, but this container inherited its Entrypoint instruc-\\ntion from the image you started it from. You can verify this by running the following\\ndocker inspect command against the image. I’ve snipped the output to highlight the\\nrelevant section.\\n$ docker inspect nigelpoulton/ddd-book:web0.1\\n<Snip>\\n\"Config\": {\\n\"WorkingDir\": \"/src\",\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"\\n],\\n<Snip>\\nI recommend you take time to investigate the output of docker inspect commands.\\nYou’ll learn a lot.\\nWriting data to a container\\nIn this section, you’ll exec onto the webserver container and edit the web server'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 90}, page_content='You’ll learn a lot.\\nWriting data to a container\\nIn this section, you’ll exec onto the webserver container and edit the web server\\nconfiguration to display a new message on the home page. In the next section, you’ll\\nstop and restart the container and verify your changes aren’t lost.\\nWARNING: This section is for demonstration purposes only. In the real\\nworld, you shouldn’t change live containers like this. Any time you need to\\nchange a live container, you should create and test a new container with the\\nrequired changes and then replace the existing container with the new one.\\nOpen a new interactive exec session to the webserver container with the following\\ncommand.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 91}, page_content='7: Working with containers\\n85\\n$ docker exec -it webserver sh\\n/src #\\nThe container runs a simple Node.js web app that uses the views/home.pug file to build\\nthe app’s home page.\\nRun the following command to open the home.pug file in the vi editor. Windows users\\ncan use Notepad or another editor.\\n/src # vi views/home.pug\\nIf you know how to use vi, you can go ahead and change the text on line 8 after the h1\\ntag to anything you like and save your changes.\\nCarefully follow these steps if you’re not familiar with vi:\\n1. Press the i key to put vi into insert mode\\n2. Use the arrow keys to navigate to line 8\\n3. Use your delete key to delete the text after the h1 tag on line 8\\n4. Type a new message of your choice\\n5. Press the escape key to exit insert mode and return to command mode\\n6. type :wq and press enter save your changes and exit (:wq is short for write and\\nquit)\\nOnce you’ve saved your changes, refresh your browser to see the updates.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 91}, page_content='6. type :wq and press enter save your changes and exit (:wq is short for write and\\nquit)\\nOnce you’ve saved your changes, refresh your browser to see the updates.\\nType exit to quit the exec session and return to your local terminal.\\nCongratulations, you’ve updated the web server config.\\nStopping, restarting, and deleting a container\\nIn this section, you’ll execute the typical container lifecycle events and see how they\\nimpact the changes you’ve made to the container.\\nThe following commands will only work if you’ve quit the interactive exec session.\\nCheck your container is still running.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 92}, page_content='7: Working with containers\\n86\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\nb5594b3b8b3f\\nnigelpoulton...\\n\"node ./app.js\"\\nUp 51 mins\\n0.0.0.0:80->8080\\nwebserver\\nStop it with the docker stop command. It will take up to 10 seconds to gracefully stop.\\n$ docker stop webserver\\nwebserver\\nRun another docker ps command.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nThe container no longer shows in the list of running containers. However, you can see it\\nif you run the same command with the -a flag to show all containers, including stopped\\nones.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nb5594b3b8b3f\\nnigelpou...\\n\"node ./app.js\"\\nExited (137) About a minute ago\\nwebserver\\nAs you can see in the output, it still exists but is in the Exited state. Restart it with the\\nfollowing command.\\n$ docker restart webserver\\nwebserver\\nIf you run another docker ps, you’ll see it in the Up state.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 92}, page_content='following command.\\n$ docker restart webserver\\nwebserver\\nIf you run another docker ps, you’ll see it in the Up state.\\nRefresh your browser to see if Docker has saved your changes to the home page or\\nreverted to the original.\\nDocker has saved your changes!\\nYou can also run the following command to return the contents of the file directly from\\nthe container’s filesystem.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 93}, page_content=\"7: Working with containers\\n87\\n$ docker exec webserver cat views/home.pug\\nhtml\\nhead\\ntitle='Docker FTW'\\nlink(rel='stylesheet', href='https://stackpath.bootstrapcdn.com/....\\nbody\\ndiv.container\\ndiv.jumbotron\\nh1 Everybody loves containers!\\n<<---- I changed this line\\n<Snip>\\nSo far, you’ve seen that starting and stopping containers doesn’t lose changes. You also\\nsaw that restarting them is very fast.\\nRun the following command to delete the container. The -f flag forces the operation\\nand doesn’t allow the app the usual 10-second grace period to flush buffers and grace-\\nfully quit. Be careful forcing operations like this, as Docker doesn’t ask you to confirm.\\n$ docker rm webserver -f\\nwebserver\\nRun a docker ps -a to see if there’s any sign of the container.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nAll signs of the container are gone and you cannot restart it. You can start a new\\ninstance by executing another docker run command and specifying the same image,\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 93}, page_content='COMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nAll signs of the container are gone and you cannot restart it. You can start a new\\ninstance by executing another docker run command and specifying the same image,\\nbut it won’t have the changes you made.\\nWARNING: As previously mentioned, changing live containers like this is an\\nanti-pattern and you shouldn’t do it. We only showed it here to demonstrate\\nhow containers work and how changes to the container’s filesystem (made\\nto the container’s own thin R/W layer) persist across restarts. An anti-pattern\\nis something that works but isn’t a good practice as it can have unintended\\nconsequences.\\nKilling a container’s main process\\nEarlier in the chapter, we learned that containers are designed to run a single process,\\nand we said that killing this process also kills the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 94}, page_content=\"7: Working with containers\\n88\\nLet’s test if that’s true.\\nRun the following command to start a new interactive container called ddd-ctr based on\\nthe Ubuntu image and tell it to run a Bash shell as its main process.\\n$ docker run --name ddd-ctr -it ubuntu:24.04 bash\\nUnable to find image 'ubuntu:24.04' locally\\n24.04: Pulling from library/ubuntu\\n51ae9e2de052: Download complete\\nDigest: sha256:ff0b5139e774bb0dee9ca8b572b4d69eaec2795deb8dc47c8c829becd67de41e\\nStatus: Downloaded newer image for ubuntu:24.04\\nroot@d3c892ad0eb3:/#\\nThe command pulls the Ubuntu image and attaches your terminal to the container’s\\nBash shell process.\\nRun a ps command to list all running processes.\\nroot@d3c892ad0eb3:/# ps\\nPID TTY\\nTIME CMD\\n1 pts/0\\n00:00:00 bash\\n9 pts/0\\n00:00:00 ps\\nPID 1 is the container’s main process and is the Bash shell you told the container to run.\\nThe other one is the ps command and has already exited. This means the Bash process is\\nthe only process running in the container.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 94}, page_content='The other one is the ps command and has already exited. This means the Bash process is\\nthe only process running in the container.\\nIf you type exit, you’ll terminate the Bash process and kill the container. This is because\\ncontainers only run while their main process executes.\\nTest this by typing exit to return to your local terminal and then running a docker ps\\n-a command to see if the container terminated.\\nroot@d3c892ad0eb3:/# exit\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nd3c892ad0eb3\\nubuntu:24.04\\n\"bash\"\\nExited (0) 3 secs ago\\nddd-ctr\\nAs expected, the container is in the exited state and not running. However, you can run\\nthe following two commands to restart it and attach your shell to its main process.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 95}, page_content='7: Working with containers\\n89\\n$ docker restart ddd-ctr\\nddd-ctr\\n$ docker attach ddd-ctr\\nroot@d3c892ad0eb3:/#\\nYour terminal is once again attached to the Bash shell in the container.\\nYou can type Ctrl PQ to exit a container without killing the process you’re attached to.\\nType Ctrl PQ to exit the container and run another docker ps command to verify the\\ncontainer is still running this time.\\nroot@d3c892ad0eb3:/# <Ctrl PQ>\\nread escape sequence\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nd3c892ad0eb3\\nubuntu:24.04\\n\"bash\"\\nUp 27 seconds\\nddd-ctr\\nThe container is still up.\\nNow that you know how to exit containers without killing them, let’s switch focus and\\nsee how to use Docker Debug to debug slim containers and images.\\nDebugging slim images and containers with Docker\\nDebug\\nAt the time of writing, Docker Debug is only included as part of Docker Desktop and\\nrequires a Pro, Team, or Business subscription.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 95}, page_content='Debugging slim images and containers with Docker\\nDebug\\nAt the time of writing, Docker Debug is only included as part of Docker Desktop and\\nrequires a Pro, Team, or Business subscription.\\nIt’s a widely accepted good practice to deploy slim images that only contain app code and\\ndependencies. This means no shell or debugging tools and is a big part of making images\\nand containers small and secure. However, it also makes it difficult to debug them when\\nthings go wrong.\\nThis is where Docker Debug comes to the rescue by allowing you to get shell access\\nto images and containers that don’t include a shell and seamlessly inject powerful\\ndebugging tools into them.\\nAt a high level, Docker Debug works by attaching a shell to a container and mounting a\\ntoolbox loaded with debugging tools. This toolbox is mounted as a directory called /nix\\nand is available during your debugging session but is never visible to the container. As'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 95}, page_content='toolbox loaded with debugging tools. This toolbox is mounted as a directory called /nix\\nand is available during your debugging session but is never visible to the container. As\\nsoon as you exit the Docker Debug session, the /nix directory is removed. If you’re\\ndebugging a running container, any changes you make are immediately visible to the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 96}, page_content='7: Working with containers\\n90\\ncontainer and persist across container restarts. For example, updating an index.html\\nduring a Docker Debug session will immediately update the running web app, and the\\nchanges will persist if the container is stopped and restarted. If you’re debugging an\\nimage or stopped container, the Docker Debug session creates a debug sandbox and\\nadds it to the image as a R/W layer to make it feel like a running container. However,\\nchanges you make while debugging an image or stopped container are not persisted and\\nare lost as soon as you quit the debug session.\\nIf you’ve been following along, you’ll have a running container called ddd-ctr. If you\\ndon’t, you can start one by running docker run --name ddd-ctr -it ubuntu:24.04\\nbash.\\nRun the following commands to attach to the container and see if it has any debugging\\ntools. The following docker attach command is similar to the docker exec commands'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 96}, page_content='bash.\\nRun the following commands to attach to the container and see if it has any debugging\\ntools. The following docker attach command is similar to the docker exec commands\\nyou learned earlier but automatically connects to a container’s main process. You don’t\\nneed to run the docker attach command if you’re already connected to the container.\\n$ docker attach ddd-ctr\\nroot@d3c892ad0eb3:/#\\nroot@d3c892ad0eb3:/# ping nigelpoulton.com\\nbash: ping: command not found\\nroot@d3c892ad0eb3:/# nslookup nigelpoulton.com\\nbash: nslookup: command not found\\nroot@d3c892ad0eb3:/# vim\\nbash: vim: command not found\\nThe commands all failed because none of the tools are installed in this container. This\\nwould make debugging this container difficult without Docker Debug.\\nType Ctrl PQ to gracefully disconnect from the container without killing the Bash\\nprocess.\\nIn the following steps, you’ll use Docker Debug to get a shell session to the container'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 96}, page_content='Type Ctrl PQ to gracefully disconnect from the container without killing the Bash\\nprocess.\\nIn the following steps, you’ll use Docker Debug to get a shell session to the container\\nand run commands that aren’t installed in the container. You can even use Docker\\nDebug to get shell access to containers and images that don’t include a shell.\\nYou need to log in to Docker to use Docker Debug, and it only works if you have a Pro,\\nTeam, or Business license.\\n$ docker login\\nAuthenticating with existing credentials...\\nLogin Succeeded\\nRun the following command to check if you have the Docker Debug CLI plugin. All\\nmodern versions of Docker Desktop include this by default. Other Docker installations\\nmay not have it, but you may be able to install it manually.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 97}, page_content='7: Working with containers\\n91\\n$ docker info\\nClient:\\nVersion:\\n26.1.1\\nContext:\\ndesktop-linux\\nDebug Mode: false\\nPlugins:\\ndebug: Get a shell into any image or container. (Docker Inc.)\\nVersion:\\n0.0.29\\nPath:\\n/Users/nigelpoulton/.docker/cli-plugins/docker-debug\\n<Snip>\\nOnce you’re logged in and have the plugin installed, you’re ready to continue.\\nThe format of the command is docker debug <image>|<container>. We’ll open a\\nDocker Debug session to the running container called ddd-ctr.\\n$ docker debug ddd-ctr\\nThis is an attach shell, i.e.:\\n- Any changes to the container filesystem are visible to the container directly.\\n- The /nix directory is invisible to the actual container.\\nVersion: 0.0.37 (BETA)\\nroot@d3c892ad0eb3 / [ddd-ctr]\\ndocker >\\nYou’ve successfully connected to the running container and got a new shell prompt\\n(docker >). You also got some helpful info displaying the short ID and name of the\\ncontainer you’re debugging, as well as a reminder that any changes you make will be'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 97}, page_content='(docker >). You also got some helpful info displaying the short ID and name of the\\ncontainer you’re debugging, as well as a reminder that any changes you make will be\\nvisible to the container.\\nTry running the ping, nslookup, and vim commands that failed in the previous section.\\nIf you get stuck in the vim session, just type :q and press Enter.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 98}, page_content='7: Working with containers\\n92\\ndocker > ping nigelpoulton.com\\nPING nigelpoulton.com (192.124.249.126) 56(84) bytes of data.\\n64 bytes from cloudproxy10126.sucuri.net (192.124.249.126): icmp_seq=1 ttl=63 time=211 ms\\n64 bytes from cloudproxy10126.sucuri.net (192.124.249.126): icmp_seq=2 ttl=63 time=58.3 ms\\n^C\\ndocker > nslookup nigelpoulton.com\\nzsh: command not found: nslookup\\ndocker > vim\\n~\\nVIM\\n- Vi IMproved\\n~\\nversion 9.0.1441\\n~\\nby Bram Moolenaar et al.\\n~\\nVim is open source and freely distributable\\n<Snip>\\n:q\\nThe ping and vim commands worked, but the nslookup still failed. This is because the\\ndefault Docker Debug toolbox includes ping and vim but doesn’t include nslookup. Don’t\\nworry, though. You can use Docker Debug’s built-in install command to add any\\npackage listed on search.nixos.org.\\nRun the following command to install the bind package (which includes the nslookup\\ntool), and then run the nslookup command again.\\ndocker > install bind'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 98}, page_content=\"package listed on search.nixos.org.\\nRun the following command to install the bind package (which includes the nslookup\\ntool), and then run the nslookup command again.\\ndocker > install bind\\nTip: You can install any package available at: https://search.nixos.org/packages.\\ninstalling 'bind-9.18.19'\\n<Snip>\\ndocker > nslookup nigelpoulton.com\\nServer:\\n192.168.65.7\\nAddress:\\n192.168.65.7#53\\nNon-authoritative answer:\\nName:\\nnigelpoulton.com\\nAddress:\\n192.124.249.126\\nThe command worked, and nslookup is now installed in your toolbox and will be\\navailable in future Docker Debug sessions.\\nCongratulations, you’ve used Docker Debug to attach to a running container and run\\ntroubleshooting commands that aren’t part of the container. You’ve also seen how to\\ninstall additional tools to your Docker Debug toolbox. Remember, any changes you\\nmake to running containers are immediately visible to the container and persist after\\nyou close the session.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 98}, page_content='install additional tools to your Docker Debug toolbox. Remember, any changes you\\nmake to running containers are immediately visible to the container and persist after\\nyou close the session.\\nType exit to terminate the debug session and return to your local shell.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 99}, page_content='7: Working with containers\\n93\\nRun the following command to create a new Docker Debug session that debugs the\\nnigelpoulton/ddd-book:web0.1 image. Docker will automatically pull the image from\\nDocker Hub if you don’t have a local copy.\\n$ docker debug nigelpoulton/ddd-book:web0.1\\nNote: This is a sandbox shell. All changes will not affect the actual image.\\nVersion: 0.0.37 (BETA)\\nroot@3f5b281b914b /src [nigelpoulton/ddd-book:web0.1]\\ndocker >\\nNotice the different message this time. Debugging images creates a sandbox shell and\\nchanges won’t affect the actual image. This reminds you that debugging images and\\nstopped containers behaves differently from debugging running containers:\\n• Changes made while debugging a live container are persisted\\n• Changes made while debugging images or stopped containers are deleted when\\nyou quit the debug session\\nRun an nslookup command to prove the tool is saved to your toolbox and available for\\nuse without re-installing.\\ndocker > nslookup craigalanson.com'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 99}, page_content='you quit the debug session\\nRun an nslookup command to prove the tool is saved to your toolbox and available for\\nuse without re-installing.\\ndocker > nslookup craigalanson.com\\nServer:\\n192.168.65.7\\nAddress:\\n192.168.65.7#53\\nNon-authoritative answer:\\nName:\\ncraigalanson.com\\nAddress:\\n198.185.159.144\\n<Snip>\\nDocker Debug has a built-in entrypoint command that lets you print, lint, and test an\\nimage or container’s Entrypoint or Cmd command. These are the commands Docker\\nexecutes to start the container’s app.\\nRun the following entrypoint command to reveal the default command this container\\nwill run when it starts.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 100}, page_content='7: Working with containers\\n94\\ndocker > entrypoint --print\\nnode ./app.js\\nThe entrypoint command is clever enough to look for Entrypoint and Cmd instruc-\\ntions.\\nType exit to quit the debug session.\\nIn summary, Docker Debug is a fantastic tool for debugging slim images and containers.\\nIt gets you shell access to containers and images that don’t include a shell, and you can\\nrun troubleshooting tools that aren’t available in the container or image. Any changes\\nyou make to running containers take immediate effect and persist across stop and restart\\noperations. However, changes made while debugging images and stopped containers are\\nlost when you close the session. In all cases, the tools you install and use are never part\\nof the container or image.\\nSelf-healing containers with restart policies\\nContainer restart policies are a simple form of self-healing that allows the local Docker\\nEngine to automatically restart failed containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 100}, page_content='Self-healing containers with restart policies\\nContainer restart policies are a simple form of self-healing that allows the local Docker\\nEngine to automatically restart failed containers.\\nYou apply restart policies per container, and Docker supports the following four policies:\\n• no (default)\\n• on-failure\\n• always\\n• unless-stopped\\nThe following table shows how each policy reacts to different scenarios. A Y indicates\\nthe policy will attempt a container restart, whereas an N indicates it won’t.\\nRestart\\nRestart\\nNon-zero\\nZero\\ndocker stop\\nwhen Daemon\\npolicy\\nexit code\\nexit code\\ncommand\\nrestarts\\nno\\nN\\nN\\nN\\nN\\non-failure\\nY\\nN\\nN\\nY\\nalways\\nY\\nY\\nN\\nY\\nunless-stopped\\nY\\nY\\nN\\nN\\nNon-zero exit codes indicate a failure occurred. Zero exit codes indicate the container\\nexited normally without an error.\\nWe’ll demo some examples, but you should also do your own testing.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 101}, page_content='7: Working with containers\\n95\\nLet’s demonstrate the always policy by starting a new interactive container with the --\\nrestart always flag and telling it to run a shell process. We’ll then type exit to kill the\\nshell process and the container to see what happens.\\nRun the following command to start an interactive container called neversaydie with\\nthe always restart policy.\\n$ docker run --name neversaydie -it --restart always alpine sh\\n/#\\nYour terminal will automatically connect to the shell process inside the container.\\nType exit to kill the shell process and return to your local terminal. This will cause the\\ncontainer to exit with a zero exit code, indicating a normal exit without any failures.\\nAccording to the previous table, the always restart policy should automatically restart\\nthe container.\\nRun a docker ps command to see if this happened.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\n1933623830bb\\nalpine\\n\"sh\"\\n35 seconds ago\\nUp 2 seconds\\nneversaydie'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 101}, page_content='the container.\\nRun a docker ps command to see if this happened.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\n1933623830bb\\nalpine\\n\"sh\"\\n35 seconds ago\\nUp 2 seconds\\nneversaydie\\nThe container is running as expected. However, you can see it was created 35 seconds\\nago but has only been running for 2 seconds. This is because you forced it to exit\\nwhen you killed the shell process, and then Docker automatically restarted it. It’s also\\nimportant to know that Docker restarted the same container and didn’t create a new\\none. In fact, if you run a docker inspect against it, you’ll see the RestartCount has\\nbeen incremented to 1. Remember to replace grep with Select-String -Pattern\\n\\'RestartCount\\' if you’re on Windows using PowerShell.\\n$ docker inspect neversaydie | grep RestartCount\\n\"RestartCount\": 1,\\nAn interesting feature of the --restart always policy is that if you stop a container\\nwith docker stop and then restart the Docker daemon, Docker will restart the con-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 101}, page_content='\"RestartCount\": 1,\\nAn interesting feature of the --restart always policy is that if you stop a container\\nwith docker stop and then restart the Docker daemon, Docker will restart the con-\\ntainer when the daemon comes up. To be clear:\\n1. You start a new container with the --restart always policy\\n2. You manually stop it with the docker stop command\\n3. You restart Docker (or an event causes Docker to restart)\\n4. When Docker comes back up, it starts the stopped container\\nIf you don’t want this behavior, you should try the unless-stopped policy.\\nIf you are working with Docker Compose or Docker Stacks, you can apply restart\\npolicies to services as follows. We’ll cover these in more detail in later chapters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 102}, page_content='7: Working with containers\\n96\\nservices:\\nmyservice:\\n<Snip>\\nrestart_policy:\\ncondition: always | unless-stopped | on-failure\\nClean up\\nYou can run docker images and docker ps -a commands to see the images you pulled\\nand the containers you created as part of this chapter. Your output will be similar to this.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nweb0.1\\n3f5b281b914b\\n4 days ago\\n159MB\\nubuntu\\n24.04\\nff0b5139e774\\n13 days ago\\n138MB\\nalpine\\nlatest\\nc5b1261d6d3e\\n4 weeks ago\\n11.8MB\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\nac165419214f\\nalpine\\n\"sh\"\\n33 secs ago\\nUp 24 seconds\\nneversaydie\\n5bd3741185fa\\nubuntu:24.04\\n\"bash\"\\n3 mins ago\\nExited (0) ~1min ago\\nddd-ctr\\nYou can delete individual containers with the docker rm <container> -f command\\nand images with the docker rmi command, and you should always delete containers\\nbefore images.\\nYou can also delete all containers and all images with the following two commands. Be'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 102}, page_content='and images with the docker rmi command, and you should always delete containers\\nbefore images.\\nYou can also delete all containers and all images with the following two commands. Be\\nwarned though, Docker will not prompt you for confirmation.\\n$ docker rm $(docker ps -aq) -f\\nac165419214f\\n5bd3741185fa\\n$ docker rmi $(docker images -q)\\nUntagged: nigelpoulton/ddd-book:web0.1\\nDeleted: sha256:3f5b281b914b1e39df8a1fbc189270a5672ff9e98bfac03193b42d1c02c43ef0\\nUntagged: ubuntu:24.04\\nDeleted: sha256:ff0b5139e774bb0dee9ca8b572b4d69eaec2795deb8dc47c8c829becd67de41e\\nUntagged: alpine:latest\\nDeleted: sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nBoth commands work by passing a list of all container/image IDs to the delete com-\\nmand.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 103}, page_content='7: Working with containers\\n97\\nContainers – The commands\\n• docker run is the command to start new containers. You give it the name of an\\nimage and it starts a container from it. This example starts an interactive container\\nfrom the Ubuntu image and tells it to run the Bash shell: docker run -it ubuntu\\nbash.\\n• Ctrl-PQ is how you detach from a container without killing the process you’re\\nattached to. You’ll use it frequently to detach from running containers without\\nkilling them.\\n• docker ps lists all running containers, and you can add the -a flag to also see\\ncontainers in the stopped (Exited) state.\\n• docker exec allows you to run commands inside containers. The following\\ncommand will start a new Bash shell inside a running container and connect\\nyour terminal to it: docker exec -it <container-name> bash. This next\\ncommand runs a ps command inside a running container without opening an\\ninteractive shell session: docker exec <container-name> ps. For these to work,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 103}, page_content='command runs a ps command inside a running container without opening an\\ninteractive shell session: docker exec <container-name> ps. For these to work,\\nthe container must include the Bash shell.\\n• docker stop stops a running container and puts it in the Exited (137) state. It\\nissues a SIGTERM to the container’s PID 1 process and allows the container 10\\nseconds to gracefully quit. If the process hasn’t cleaned up and stopped within 10\\nseconds, it sends a SIGKILL to force the container to terminate immediately.\\n• docker restart restarts a stopped container.\\n• docker rm deletes a stopped container. You can add the -f flag to delete the\\ncontainer without having to stop it first.\\n• docker inspect shows you detailed configuration and run-time information\\nabout a container.\\n• docker debug attaches a debug shell to a container or image and lets you run\\ncommands that aren’t available inside the container or image. It requires a Pro,\\nTeam, or Business Docker subscription.\\nChapter summary'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 103}, page_content='commands that aren’t available inside the container or image. It requires a Pro,\\nTeam, or Business Docker subscription.\\nChapter summary\\nIn this chapter, you learned some of the major differences between VMs and containers,\\nincluding that containers are smaller, faster, and more portable.\\nYou learned how to start, stop, and restart containers with the docker CLI, and you saw\\nthat changes to a container’s filesystem persist across restarts.\\nYou learned that containers run a single process and terminate if this process is killed.\\nYou also saw the three ways of telling a container which app to run and how to start it —\\nvia Entrypoint or Cmd instructions in the image metadata or via the docker run CLI.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 104}, page_content='7: Working with containers\\n98\\nYou learned about Docker Debug and how it allows you to get a shell to slim containers\\nand run troubleshooting commands that don’t exist in the container.\\nFinally, you learned how to attach restart policies to containers and how the different\\nrestart policies work.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 105}, page_content='8: Containerizing an app\\nDocker makes it easy to package applications as images and run them as containers.\\nWe call this process containerization, and this chapter will walk you through the entire\\nprocess.\\nI’ve divided the chapter as follows:\\n• Containerizing an app – The TLDR\\n• Containerize a single-container app\\n• Moving to production with multi-stage-builds\\n• Buildx, BuildKit, drivers, and Build Cloud\\n• Multi-architecture builds\\n• A few good practices\\nContainerizing an app – The TLDR\\nDocker aims to make it easy to build, share, and run applications. We call this containeriza-\\ntion and the process looks like this:\\n1. Write your applications and create the list of dependencies\\n2. Create a Dockerfile that tells Docker how to build and run the app\\n3. Build the app into an image\\n4. Push the image to a registry (optional)\\n5. Run a container from the image\\nYou can see these five steps in Figure 8.1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 106}, page_content='8: Containerizing an app\\n100\\nFigure 8.1 - Basic flow of containerizing an app\\nContainerize a single-container app\\nIn this section, you’ll complete the following steps to containerize a simple Node.js app:\\n• Get the application code from GitHub\\n• Create the Dockerfile\\n• Containerize the app\\n• Run the app\\n• Test the app\\n• Look a bit closer\\nI recommend you follow along with Docker Desktop. This is because we’ll be using\\nthe new docker init command, which might not be installed on other versions of\\nDocker. Don’t worry if your Docker installation doesn’t have docker init, we include\\ninstructions for you as well.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 107}, page_content=\"8: Containerizing an app\\n101\\nGet the application code\\nThe application we’ll use is a Node.js web app that serves a web page on port 8080.\\nYou’ll need a copy of the book’s GitHub repo containing the application code. If you\\ndon’t already have it, run the following command to get it. You’ll need git installed, and\\nthe command will create a new directory called ddd-book.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nCloning into 'ddd-book'...\\nremote: Enumerating objects: 47, done.\\nremote: Counting objects: 100% (47/47), done.\\nremote: Compressing objects: 100% (32/32), done.\\nremote: Total 47 (delta 11), reused 44 (delta 11), pack-reused 0\\nReceiving objects: 100% (47/47), 167.30 KiB | 1.66 MiB/s, done.\\nResolving deltas: 100% (11/11), done.\\nChange into the ddd-book/node-app directory and list its contents.\\n$ cd ddd-book/node-app\\n$ ls -l\\ntotal 98\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n341 20 Feb 12:35 app.js\\ndrwxr-xr-x\\n103 nigelpoulton\\nstaff\\n3296 12 Mar 16:18 node_modules\\n-rw-r--r--\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 107}, page_content='$ cd ddd-book/node-app\\n$ ls -l\\ntotal 98\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n341 20 Feb 12:35 app.js\\ndrwxr-xr-x\\n103 nigelpoulton\\nstaff\\n3296 12 Mar 16:18 node_modules\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n39975 12 Mar 16:18 package-lock.json\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n355\\n8 Mar 10:10 package.json\\ndrwxr-xr-x\\n3 nigelpoulton\\nstaff\\n96 20 Feb 12:35 views\\nThis directory is your build context because it contains the application source code and\\nthe files listing dependencies.\\nFor Docker to containerize it, it needs a Dockerfile with build instructions. Let’s create it.\\nCreate the Dockerfile\\nIn the past, you had to create Dockerfiles manually. Fortunately, newer versions of\\nDocker support the docker init command that reads your build context, analyzes your\\napplication, and automatically creates a Dockerfile implementing good practices.\\nRun the following command to create a Dockerfile for the app. If your Docker installa-\\ntion doesn’t have the docker init plugin, you’ll have to skip this step.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 107}, page_content='Run the following command to create a Dockerfile for the app. If your Docker installa-\\ntion doesn’t have the docker init plugin, you’ll have to skip this step.\\nFeel free to accept a newer version of Node.js, but complete all other prompts as shown.\\nYou’ll need to run it from the node-app directory.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 108}, page_content='8: Containerizing an app\\n102\\n$ docker init\\nWelcome to the Docker Init CLI!\\n<Snip>\\n? What application platform does your project use? Node\\n? What version of Node do you want to use? 23.3.0\\n<<---- Newer versions are OK\\n? Which package manager do you want to use? npm\\n? What command do you want to use to start the app? node app.js\\n? What port does your server listen on? 8080\\nCREATED: .dockerignore\\nCREATED: Dockerfile\\nCREATED: compose.yaml\\nCREATED: README.Docker.md\\n\\uffffYour Docker files are ready!\\nThe process created a new Dockerfile and placed it in your current directory. It looks\\nlike this.\\n1. ARG NODE_VERSION=20.8.0\\n2. FROM node:${NODE_VERSION}-alpine\\n3. ENV NODE_ENV production\\n4. WORKDIR /usr/src/app\\n5. RUN --mount=type=bind,source=package.json,target=package.json \\\\\\n--mount=type=bind,source=package-lock.json,target=package-lock.json \\\\\\n--mount=type=cache,target=/root/.npm \\\\\\nnpm ci --omit=dev\\n6. USER node\\n7. COPY . .\\n8. EXPOSE 8080\\n9. CMD node app.js'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 108}, page_content='--mount=type=bind,source=package-lock.json,target=package-lock.json \\\\\\n--mount=type=cache,target=/root/.npm \\\\\\nnpm ci --omit=dev\\n6. USER node\\n7. COPY . .\\n8. EXPOSE 8080\\n9. CMD node app.js\\nLines 1 and 2 tell Docker to pull the node:23.3.0-alpine image and use it as the base\\nfor the new image.\\nLine 3 tells Node to run in production mode. This is a Node.js optimization that increases\\nperformance while minimizing logging and other common development features.\\nLine 4 sets the working directory for the remaining steps. For example, the RUN and COPY\\ninstructions on lines 5 and 7 will run against the WORKDIR directory, as will the node\\napp.js command on line 9.\\nLine 5 bind mounts the dependency files and installs them with the npm ci --omit-dev\\ncommand.\\nLine 6 ensures Node.js runs the app as a non-root user.\\nLine 7 copies the application’s source code from your build context (the first period)\\ninto the WORKDIR directory (the second period) inside the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 109}, page_content='8: Containerizing an app\\n103\\nLine 8 documents the application’s network port.\\nLine 9 is the command Docker will execute whenever it starts a container from the\\nimage.\\nYou now have everything Docker needs to build the application into a container image\\n— source code, dependencies, and a Dockerfile.\\nContainerize the app\\nIn this section, you’ll build the application into a container image.\\nIf your Docker installation doesn’t have the docker init plugin and you didn’t follow\\nthe previous step, you’ll need to rename the sample-Dockerfile to Dockerfile before\\ncontinuing.\\nRun the following command to build a new image called ddd-book:ch8.node. Be sure to\\ninclude the trailing period (.) as this tells Docker to use your current working directory\\nas the build context. Remember, the build context is the directory where your app files live.\\n$ docker build -t ddd-book:ch8.node .\\n[+] Building 16.2s (12/12) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 109}, page_content='$ docker build -t ddd-book:ch8.node .\\n[+] Building 16.2s (12/12) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n=> => transferring dockerfile: 1.21kB\\n0.0s\\n=> => transferring context: 659B\\n0.0s\\n=> [stage-0 1/4] FROM docker.io/library/node:20.8.0-alpine\\n3s\\n<<---- Base layer\\n=> [stage-0 2/4] WORKDIR /usr/src/app\\n0.2s\\n<<---- New layer\\n=> [stage-0 3/4] RUN --mount=type=bind,source=package...\\n1.1s\\n<<---- New layer\\n=> [stage-0 4/4] COPY . .\\n0.1s\\n<<---- New layer\\n=> exporting to image\\n0.2s\\n=> => exporting layers\\n0.2s\\n=> => writing image sha256:f282569b8bd0f0...016cc1adafc91\\n0.0s\\n=> => naming to docker.io/library/ddd-book:ch8.node\\nI’ve snipped the output, but you can see four numbered steps creating four image layers.\\nThese map to the instructions in the Dockerfile.\\nCheck the image exists in your Docker host’s local repository.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nddd-book\\nch8.node\\n24dd040fa06b\\n18 minutes ago\\n242MB'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 109}, page_content='Check the image exists in your Docker host’s local repository.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nddd-book\\nch8.node\\n24dd040fa06b\\n18 minutes ago\\n242MB\\nCongratulations, you’ve containerized the app as an OCI image!\\nRun a docker inspect ddd-book:ch8.node command to verify the image and see the\\nsettings from the Dockerfile. You should be able to see the image layers and metadata\\nsuch as the Exposed Ports, WorkingDir, and Entrypoint values.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 110}, page_content='8: Containerizing an app\\n104\\n$ docker inspect ddd-book:ch8.node\\n[\\n{\\n\"Id\": \"sha256:24dd040fa06baf6e40144c5a59f99a749159a932ecebb737751f7f862963527a\",\\n\"RepoTags\": [\\n\"ddd-book:ch8.node\"\\n<Snip>\\n\"ExposedPorts\": {\\n\"8080/tcp\": {}\\n\"WorkingDir\": \"/usr/src/app\",\\n\"Cmd\": [\\n\"/bin/sh\",\\n\"-c\",\\n\"node app.js\"\\n],\\n<Snip>\\n\"Layers\": [\\n\"sha256:5f4d9fc4d98de91820d2a9c81e501c8cc6429bc8758b43fcb2cd50f4cab9a324\",\\n\"sha256:6b20c4e93dbab9786f96268bbe32c208d385f2c4490a278ad3b1e55cc79480e4\",\\n\"sha256:012c308a78ec993a47fdb7c4c6d17b53d8ce2649a463be28ae5c48ab1af2e039\",\\n\"sha256:35a839ac7cc922afd896a0297e692141c77ed6e03eff6a70db13bb23f6cd4f8f\",\\n\"sha256:918caa8070410ccfb2c5b3b4d62ca66742c46bf21fe0bd433738b7796c530e68\",\\n\"sha256:a48b3b3d0c5a693840e7e4abd7971f130b4447573483628bcb996091e1e8e8b8\",\\n\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n<Snip>\\nYou might wonder why the image has seven layers when only four Dockerfile instruc-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 110}, page_content='\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n<Snip>\\nYou might wonder why the image has seven layers when only four Dockerfile instruc-\\ntions created layers. This is because the node:20.8.0-alpine base image already had\\nfour layers. Therefore, the FROM instruction pulled a base image with four layers, and\\nthen the WORKDIR, RUN and COPY instructions added three more layers. You can see this\\nin Figure 8.2.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 111}, page_content='8: Containerizing an app\\n105\\nFigure 8.2 - Dockerfile and image layers\\nPush the image to Docker Hub\\nThis is an optional section, and you’ll need a Docker Hub account to follow along. Go to\\nhub.docker.com and sign up for a free one now.\\nYou’ll complete the following steps:\\n1. Login to Docker Hub\\n2. Re-tag the image\\n3. Push the image\\nAfter creating images, you’ll normally push them to a registry where you can keep them\\nsafe and make them accessible to teammates and clients. Lots of registries exist, but\\nDocker Hub is the most common public registry and is where Docker pushes images\\nby default.\\nLog in to Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 112}, page_content=\"8: Containerizing an app\\n106\\n$ docker login\\nUSING WEB-BASED LOGIN\\nTo sign in with credentials on the command line, use 'docker login -u <username>'\\nYour one-time device confirmation code is: PNXK-SGJG\\nPress ENTER to open your browser or submit your device code here: https://login.docker.com/activate\\nLogin Succeeded\\nOnce logged in, you need to re-tag the image. This is because Docker uses the image tag\\nto determine which registry and repository to push it to.\\nIf you run a docker images command, you’ll see an image tagged as ddd-book:ch8.node.\\nIf you push this image, Docker will try to push it to a repository called ddd-book on\\nDocker Hub. However, no such repository exists, and the command will fail.\\nRun the following command to re-tag the image to include your Docker ID. The format\\nof the command is docker tag <current-tag> <new-tag>, and it creates an additional\\ntag for the same image.\\n$ docker tag ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 112}, page_content='of the command is docker tag <current-tag> <new-tag>, and it creates an additional\\ntag for the same image.\\n$ docker tag ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\\nRun another docker images command to see the image with both tags. Notice how\\neverything is identical except the REPO column. This is because it’s the same image with\\ndifferent names.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nch8.node\\n24dd040fa06b\\n38 minutes ago\\n268MB\\nddd-book\\nch8.node\\n24dd040fa06b\\n38 minutes ago\\n268MB\\nPush it to Docker Hub. You’ll need to be logged in with your Docker ID for this to work,\\nand you’ll need to use your Docker ID instead of mine.\\n$ docker push nigelpoulton/ddd-book:ch8.node\\nThe push refers to repository [docker.io/nigelpoulton/ddd-book]\\ne4ef261755c8: Pushed\\nd25f74b85615: Pushed\\n7e1aebde141d: Pushed\\n7b3f8039e3c4: Pushed\\n2a2799ae89a2: Mounted from library/node\\n4927cb899c33: Mounted from library/node\\n579b34f0a95b: Pushed\\nced319b3ffb5: Pushed'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 112}, page_content='d25f74b85615: Pushed\\n7e1aebde141d: Pushed\\n7b3f8039e3c4: Pushed\\n2a2799ae89a2: Mounted from library/node\\n4927cb899c33: Mounted from library/node\\n579b34f0a95b: Pushed\\nced319b3ffb5: Pushed\\nch8.node: digest: sha256:24dd040fa06baf...1f7f862963527a size: 856'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 113}, page_content='8: Containerizing an app\\n107\\nFigure 8.3 shows how Docker figured out where to push the image.\\nFigure 8.3\\nNow that you’ve pushed the image to a registry, you can access it from anywhere with\\nan internet connection. You can also grant other people access to pull it and push\\nchanges.\\nRun the app\\nAs previously mentioned, the application is a web server listening on port 8080.\\nRun the following command to start it as a container. You’ll have to delete the\\nnigelpoulton image prefix or replace it with your ID.\\n$ docker run -d --name c1 \\\\\\n-p 5005:8080 \\\\\\nnigelpoulton/ddd-book:ch8.node\\nThe -d flag runs the container in the background, and the --name flag calls it c1. The\\n-p 5005:8080 maps port 5005 on your Docker host to port 8080 inside the container,\\nwhich means you’ll be able to point a browser to port 5005 and reach the app. The last\\nline tells Docker to base the container on the nigelpoulton/ddd-book:ch8.node image\\nyou just built.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 113}, page_content='which means you’ll be able to point a browser to port 5005 and reach the app. The last\\nline tells Docker to base the container on the nigelpoulton/ddd-book:ch8.node image\\nyou just built.\\nDocker will use the local copy of the image from the previous steps. It only pulls a copy\\nfrom Docker Hub if it doesn’t have a local copy.\\nCheck the container is running and verify the port mapping.\\n$ docker ps\\nID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\n49..\\nddd-book:ch8.node\\n\"node ./app.js\"\\nUP 6 secs\\n0.0.0.0:5005->8080/tcp\\nc1\\nI’ve snipped the output for readability, but the container is running, and port 5005 on\\nthe Docker host maps to port 8080 in the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 114}, page_content='8: Containerizing an app\\n108\\nTest the app\\nOpen a web browser and point it to the DNS name or IP address of your Docker host\\non port 5005. If you’re using Docker Desktop or a similar local environment, you can\\nconnect to localhost:5005. Otherwise, use the IP or DNS of the Docker host on port\\n5005.\\nYou should see the app as shown in Figure 8.4.\\nFigure 8.4\\nYou can try the following if it doesn’t work:\\n1. Run a docker ps command to ensure the c1 container is running\\n2. Check port mapping is correct — 0.0.0.0:5005->8080/tcp\\n3. Check that firewall and other network security settings aren’t blocking traffic to\\nyour Docker host on port 5005\\nCongratulations, the application is containerized and running as a container!\\nLooking a bit closer\\nNow that you’ve containerized the application let’s take a closer look at how some of the\\nmachinery works.\\nThe docker build command parses the Dockerfile one line at a time, starting from the\\ntop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 114}, page_content='Now that you’ve containerized the application let’s take a closer look at how some of the\\nmachinery works.\\nThe docker build command parses the Dockerfile one line at a time, starting from the\\ntop.\\nYou can insert comments by starting a line with the # character, and the builder will\\nignore them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 115}, page_content='8: Containerizing an app\\n109\\nAll non-comment lines are called instructions or steps and take the format <INSTRUCTION>\\n<arguments>. Instruction names are not case-sensitive, but it’s common to write them in\\nUPPERCASE to make the file easier to read.\\nSome instructions create new layers, whereas others add metadata.\\nExamples of instructions that create new layers are FROM, RUN, COPY and WORKDIR.\\nExamples that create metadata include EXPOSE, ENV, CMD, and ENTRYPOINT. The premise\\nis this:\\n• Instructions that add content, such as files and programs, create new layers\\n• Instructions that don’t add content don’t add layers and only create metadata\\nYou can run a docker history command against any image to see the instructions that\\ncreated it.\\n$ docker history ddd-book:ch8.node\\nIMAGE\\nCREATED BY\\nSIZE\\nCOMMENT\\n24dd...a06b\\nCMD [\"/bin/sh\" \"-c\" \"node app.js\"]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nEXPOSE map[8080/tcp:{}]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nCOPY . . # buildkit\\n98kB\\nbuildkit.dockerfile.v0'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 115}, page_content='COMMENT\\n24dd...a06b\\nCMD [\"/bin/sh\" \"-c\" \"node app.js\"]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nEXPOSE map[8080/tcp:{}]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nCOPY . . # buildkit\\n98kB\\nbuildkit.dockerfile.v0\\n<missing>\\nUSER node\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nRUN /bin/sh -c npm ci --omit=dev # buildkit\\n13.6MB\\nbuildkit.dockerfile.v0\\n<missing>\\nWORKDIR /usr/src/app\\n16.4kB\\nbuildkit.dockerfile.v0\\n<missing>\\nENV NODE_ENV=production\\n0B\\nbuildkit.dockerfile.v0\\n<Snip>\\n<missing>\\nADD alpine-minirootfs-3.21.0-aarch64.tar.gz\\n8.84MB\\n8.35MB\\nA few things are worth noting from the output.\\nThe bottom few lines that I’ve snipped from the book related to the history of the\\nnode:23.3.0-alpine base image that was pulled by the FROM instruction.\\nAll lines ending with buildkit.dockerfile.v0 relate to instructions from the Docker-\\nfile used to build the image.\\nThe CREATED BY column lists the exact Dockerfile instruction that created the layer or\\nmetadata.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 115}, page_content='file used to build the image.\\nThe CREATED BY column lists the exact Dockerfile instruction that created the layer or\\nmetadata.\\nLines with a non-zero value in the SIZE column created new layers, whereas the lines\\nwith 0B only added metadata. In this example, three lines/instructions created layers.\\nRun a docker inspect to see the list of image layers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 116}, page_content='8: Containerizing an app\\n110\\n$ docker inspect ddd-book:ch8.node\\n<Snip>\\n},\\n\"RootFS\": {\\n\"Type\": \"layers\",\\n\"Layers\": [\\n\"sha256:5f4d9fc4d98de91820d2a9c81e501c8cc6429bc8758b43fcb2cd50f4cab9a324\",\\n\"sha256:6b20c4e93dbab9786f96268bbe32c208d385f2c4490a278ad3b1e55cc79480e4\",\\n\"sha256:012c308a78ec993a47fdb7c4c6d17b53d8ce2649a463be28ae5c48ab1af2e039\",\\n\"sha256:35a839ac7cc922afd896a0297e692141c77ed6e03eff6a70db13bb23f6cd4f8f\",\\n\"sha256:918caa8070410ccfb2c5b3b4d62ca66742c46bf21fe0bd433738b7796c530e68\",\\n\"sha256:a48b3b3d0c5a693840e7e4abd7971f130b4447573483628bcb996091e1e8e8b8\",\\n\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n},\\nAs previously mentioned, the output shows seven layers because the base image had four\\nlayers, and the Dockerfile added three more.\\nFigure 8.5 maps the Dockerfile instructions to image layers. The bold instructions with\\narrows create layers; the others create metadata. The layer IDs will be different in your\\nenvironment.\\nFigure 8.5'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 116}, page_content='arrows create layers; the others create metadata. The layer IDs will be different in your\\nenvironment.\\nFigure 8.5\\nNote: Older builders didn’t create a layer for WORKDIR instructions. However,\\nthe instruction modifies filesystem permissions and the current builder\\ncreates a very small layer. This behavior may change in the future.\\nIt’s generally considered a good practice to use Docker Official Images and Verified Pub-\\nlisher images as the base layer for new images you create. This is because they maintain a'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 117}, page_content='8: Containerizing an app\\n111\\nhigh standard and quickly implement fixes for known vulnerabilities.\\nMoving to production with multi-stage builds\\nWhen it comes to container images… big is bad! For example:\\n• Big means slow\\n• Big means more potential vulnerabilities\\n• Big means a larger attack surface\\nFor these reasons, your container images should only contain the stuff needed to run\\nyour applications in production.\\nThis is where multi-stage builds come into play.\\nAt a high level, multi-stage builds use a single Dockerfile with multiple FROM instructions\\n— each FROM instruction represents a new build stage. This allows you to have a stage\\nwhere you do the heavy lifting of building the app inside a large image with compilers\\nand other build tools, but then you have another stage where you copy the compiled app\\ninto a slim image for production. The builder can even run different stages in parallel for\\nfaster builds.\\nNote: A slim image is a very small image intended for production use that'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 117}, page_content='into a slim image for production. The builder can even run different stages in parallel for\\nfaster builds.\\nNote: A slim image is a very small image intended for production use that\\nonly contains files and apps that are absolutely necessary to run the applica-\\ntion. They do not include shells, package managers, or troubleshooting tools.\\nFigure 8.6 shows a high-level workflow. Stage 1 builds an image with all the required\\nbuild and compilation tools. Stage 2 copies the app code into the image and builds it.\\nStage 3 creates a small production-ready image containing only the compiled app and\\nanything needed to run it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 118}, page_content='8: Containerizing an app\\n112\\nFigure 8.6\\nLet’s look at an example!\\nWe’ll work with the code in the multi-stage folder of the book’s GitHub repo. It’s a\\nsimple Go app with a client and server borrowed from the Docker samples buildme repo\\non GitHub. Don’t worry if you’re not a Go programmer; you don’t need to be. You only\\nneed to know that it compiles the client and server apps into executable files that do not\\nneed the Go language or any other tools or runtimes to execute.\\nHere’s the Dockerfile:\\nFROM golang:1.23.4-alpine AS base\\n<<---- Stage 0\\nWORKDIR /src\\nCOPY go.mod go.sum .\\nRUN go mod download\\nCOPY . .\\nFROM base AS build-client\\n<<---- Stage 1\\nRUN go build -o /bin/client ./cmd/client\\nFROM base AS build-server\\n<<---- Stage 2\\nRUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod\\n<<---- Stage 3\\nCOPY --from=build-client /bin/client /bin/\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 118}, page_content='RUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod\\n<<---- Stage 3\\nCOPY --from=build-client /bin/client /bin/\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]\\nThe first thing to note is that there are four FROM instructions. Each of these is a distinct\\nbuild stage, and Docker numbers them starting from 0. However, we’ve given each stage a\\nfriendly name:\\n• Stage 0 is called base and builds an image with compilation tools, etc'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='8: Containerizing an app\\n113\\n• Stage 1 is called build-client and compiles the client executable\\n• Stage 2 is called build-server and compiles the server executable\\n• Stage 3 is called prod and copies the client and server executables into a slim image\\nEach stage outputs an intermediate image that later stages can use. However, Docker\\ndeletes them when the final stage completes.\\nThe goal of the base stage is to create a reusable build image with all the tools stages\\n1 and 2 need to build the client and server applications. The image created by this\\nstage is only used to compile the executables and not for production. It pulls the\\ngolang:1.23.4-alpine image, which is over 350MB when uncompressed. It sets the\\nworking directory to /src and copies in the go.mod and go.sum files from your working\\ndirectory. These files list the application dependencies and hashes. After that, it uses the\\nRUN instruction to install the dependencies and then the COPY instruction to copy the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='directory. These files list the application dependencies and hashes. After that, it uses the\\nRUN instruction to install the dependencies and then the COPY instruction to copy the\\napplication source code into the image. All of this creates a large image with three layers\\ncontaining a lot of build stuff but not much app stuff. When this build stage completes, it\\noutputs a large image that later stages can use.\\nThe build-client stage doesn’t pull a new image. Instead, it uses the FROM base AS\\nbuild-client instruction to use the intermediate image created by the base stage. It\\nthen issues a RUN instruction to compile the client app into a binary executable. The goal\\nof this stage is to create an image with the compiled client binary that later stages can\\nreference.\\nThe build-server stage does the same for the server component and outputs a similar\\nimage for use by later stages.\\nThe prod stage pulls the minimal scratch image. It then runs two COPY --from instruc-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='image for use by later stages.\\nThe prod stage pulls the minimal scratch image. It then runs two COPY --from instruc-\\ntions to copy the compiled client app from the build-client stage and the compiled\\nserver app from the build-server stage. It then tells Docker to run the server app when\\nit’s started as a container. This stage outputs the final production image containing just\\nthe client and server binaries inside a tiny scratch image and the metadata telling Docker\\nhow to start the app.\\nThe builder will run the base stage first, then run the build-client and build-server\\nstages in parallel, and finally run the prod stage.\\nIt will always attempt to run stages in parallel, but it can only do this when no depen-\\ndencies exist. For example, the build-client and build-server stages both start with\\nFROM base..., meaning they depend on the base stage and cannot run until that stage\\nis built. However, the build-client and build-server can run in parallel because they'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='FROM base..., meaning they depend on the base stage and cannot run until that stage\\nis built. However, the build-client and build-server can run in parallel because they\\ndon’t depend on each other. To work out if build stages can run in parallel, start reading\\nthe Dockerfile from the top and check if the FROM instructions reference other FROM\\ninstructions immediately before or after — if they do, they can’t run in parallel.\\nLet’s see it in action.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 120}, page_content='8: Containerizing an app\\n114\\nChange into the multi-stage directory and verify the Dockerfile and associated app\\nfiles exist.\\n$ ls -l\\ntotal 28\\n-rw-rw-r-- 1 ubuntu ubuntu\\n368 Mar 25 10:09 Dockerfile\\n-rw-rw-r-- 1 ubuntu ubuntu\\n433 Mar 25 10:09 Dockerfile-final\\n-rw-rw-r-- 1 ubuntu ubuntu\\n305 Mar 25 10:09 README.md\\ndrwxrwxr-x 4 ubuntu ubuntu 4096 Mar 25 10:09 cmd\\n-rw-rw-r-- 1 ubuntu ubuntu 1013 Mar 25 10:09 go.mod\\n-rw-rw-r-- 1 ubuntu ubuntu 5631 Mar 25 10:09 go.sum\\nBuild the image and watch the build-client and build-server stages execute in\\nparallel. This can significantly improve the performance of large builds.\\n$ docker build -t multi:full .\\n[+] Building 14.6s (15/15) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n=> => transferring dockerfile: 736B\\n0.0s\\n<Snip>\\n=> [build-client 1/1] RUN go build -o /bin/client ./cmd/client\\n5.1s\\n<<---- parallel\\n=> [build-server 1/1] RUN go build -o /bin/server ./cmd/server\\n5.1s\\n<<---- parallel\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 120}, page_content='0.0s\\n<Snip>\\n=> [build-client 1/1] RUN go build -o /bin/client ./cmd/client\\n5.1s\\n<<---- parallel\\n=> [build-server 1/1] RUN go build -o /bin/server ./cmd/server\\n5.1s\\n<<---- parallel\\n<Snip>\\nRun a docker images to see the new image.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nmulti\\nfull\\na7a01440f2b5\\n5 seconds ago\\n26.7MB\\nThe final production image is only 26MB, much smaller than the 350MB+ base image\\npulled by the base stage to build and compile the app. This is because the final prod\\nstage extracted the compiled client and server binaries and placed them in a tiny new\\nscratch image.\\nRun a docker history to see the final production image. It only has two layers — one\\ncreated by copying in the client binary and the other by copying in the server binary.\\nNone of the previous build stages are included in the final production image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 121}, page_content='8: Containerizing an app\\n115\\n$ docker history multi:full\\nIMAGE\\nCREATED\\nCREATED BY\\nSIZE\\na7a01440f2b5\\n2 minutes ago\\nENTRYPOINT [\"/bin/server\"]\\n0B\\n<missing>\\n2 minutes ago\\nCOPY /bin/server /bin/ # buildkit\\n8.64MB\\n<missing>\\n2 minutes ago\\nCOPY /bin/client /bin/ # buildkit\\n8.53MB\\nMulti-stage builds and build targets\\nYou can also build multiple images from a single Dockerfile.\\nThe previous example compiled client and server apps and copied both into the same\\nimage. However, Docker makes it easy to create a separate image for each by splitting\\nthe final prod stage into two stages as follows:\\nFROM golang:1.20-alpine AS base\\nWORKDIR /src\\nCOPY go.mod go.sum .\\nRUN go mod download\\nCOPY . .\\nFROM base AS build-client\\nRUN go build -o /bin/client ./cmd/client\\nFROM base AS build-server\\nRUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod-client\\n<<---- New stage\\nCOPY --from=build-client /bin/client /bin/\\nENTRYPOINT [ \"/bin/client\" ]\\nFROM scratch AS prod-server\\n<<---- New stage'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 121}, page_content='FROM scratch AS prod-client\\n<<---- New stage\\nCOPY --from=build-client /bin/client /bin/\\nENTRYPOINT [ \"/bin/client\" ]\\nFROM scratch AS prod-server\\n<<---- New stage\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]\\nI’ve pre-created the Dockerfile and called it Dockerfile-final in the multi-stage\\nfolder, but you can see the only change is splitting the final prod stage into two stages\\n— one for the client build and the other for the server build. With a Dockerfile like this,\\nyou tell a docker build command which of the two final stages to target for the build.\\nLet’s do it.\\nRun the following two commands to create two different images from the same\\nDockerfile-final file. Both commands use the -f flag to tell Docker to use the\\nDockerfile-final file. They also use the --target flag to tell the builder which stage\\nto build from.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 122}, page_content='8: Containerizing an app\\n116\\n$ docker build -t multi:client --target prod-client -f Dockerfile-final .\\n<Snip>\\n$ docker build -t multi:server --target prod-server -f Dockerfile-final .\\n<Snip>\\nCheck the builds and image sizes.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nmulti\\nfull\\na7a01440f2b5\\n4 minutes ago\\n26.7MB\\nmulti\\nserver\\na75778df1b9c\\n4 seconds ago\\n11.7MB\\nmulti\\nclient\\n02b621e9415f\\n12 seconds ago\\n11.9MB\\nYou now have three images, and the client and server images are each about half the\\nsize of the full image. This makes sense because the full image contains the client and\\nserver binaries, whereas the others only include one.\\nBuildx, BuildKit, drivers, and Build Cloud\\nThis section takes a quick look at the major build components.\\nBehind the scenes, Docker’s build system has a client and server:\\n• Client: Buildx\\n• Server: BuildKit\\nBuildx is Docker’s latest and greatest build client. It’s implemented as a CLI plugin and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 122}, page_content='Behind the scenes, Docker’s build system has a client and server:\\n• Client: Buildx\\n• Server: BuildKit\\nBuildx is Docker’s latest and greatest build client. It’s implemented as a CLI plugin and\\nsupports all the latest features of BuildKit, such as multi-stage builds, multi-architecture\\nimages, advanced caching, and more. It’s been the default build client since Docker v23.0\\nand Docker Desktop v4.19. This means every time you run a docker build command,\\nyou’re automatically using the Buildx builder.\\nYou can configure Buildx to talk to multiple BuildKit instances, and we call each\\ninstance of BuildKit a builder. Builders can run on your local machine, in your cloud or\\ndatacenter, or Docker’s Build Cloud.\\nIf you point buildx at a local builder, image builds will be done on your local machine.\\nIf you point it at a remote builder, such as Docker Build Cloud, builds will be done on\\nremote infrastructure.\\nFigure 8.7 shows a Docker environment configured to talk to a local and a remote\\nbuilder.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 123}, page_content='8: Containerizing an app\\n117\\nFigure 8.7 - Docker build architecture\\nIn the diagram, the local builder uses the docker-container driver to create a local\\nBuildKit instance inside a dedicated container. All builds using this driver will run in the\\ndedicated container. The other option uses the cloud driver to send builds to Docker’s\\nBuild Cloud service. Build Cloud offers fast builds and a shared cache but requires a\\npaid subscription.\\nWhen you run a docker build command, buildx interprets the command and sends\\nthe build request to the selected builder. This includes the Dockerfile, command line\\narguments, caching options, export options, and the build context (app and dependency\\nlist). The builder performs the build and exports the image. The Buildx client monitors\\nthe build and reports on progress.\\nRun the following command to see the builders you have configured on your system.\\nI’ve trimmed the output in the book, but you can see a local and a remote builder.\\n$ docker buildx ls'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 123}, page_content='Run the following command to see the builders you have configured on your system.\\nI’ve trimmed the output in the book, but you can see a local and a remote builder.\\n$ docker buildx ls\\nNAME/NODE\\nDRIVER/ENDPOINT\\nPLATFORMS\\nbuilder *\\ndocker-container\\nbuilder0\\ndesktop-linux\\nlinux/arm64, linux/amd64, linux/amd64/v2,\\nlinux/riscv64, linux/ppc64le, linux/s390x,\\nlinux/386, linux/mips64le, linux/mips64,\\nlinux/arm/v7, linux/arm/v6\\ncloud-nigelpoulton-ddd\\ncloud\\nlinux-arm64\\ncloud://nigel...arm64\\nlinux/arm64*\\nlinux-amd64\\ncloud://nigel...amd64\\nlinux/amd64*, linux/amd64/v2,\\nlinux/amd64/v3,linux/amd64/v4\\n<Snip>\\nNotice how the first builder supports more platforms than the cloud builder. This is\\nbecause the docker-container driver utilizes QEMU to emulate target hardware. It\\nusually works but can be slow.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 124}, page_content='8: Containerizing an app\\n118\\nThe second builder is Docker’s Build Cloud, which only supports AMD and ARM builds.\\nBuilds running in Build Cloud run on native hardware and offer a shared cache so that\\nteammates can share a common cache for even faster builds. Complex builds can be\\nmuch quicker when executed on native hardware such as Build Cloud.\\nRun a docker buildx inspect command against one of your builders.\\n$ docker buildx inspect cloud-nigelpoulton-ddd\\nName:\\ncloud-nigelpoulton-ddd\\nDriver:\\ncloud\\nNodes:\\nName:\\nlinux-arm64\\nEndpoint:\\ncloud://nigelpoulton/ddd_linux-arm64\\nStatus:\\nrunning\\nBuildkit:\\nv0.16.0\\nPlatforms: linux/arm64*, linux/arm/v6, linux/arm/v7\\nLabels:\\norg.mobyproject.buildkit.worker.executor:\\noci\\norg.mobyproject.buildkit.worker.hostname:\\nnigelpoulton_ddd-cloud_linux-arm64\\norg.mobyproject.buildkit.worker.network:\\nhost\\norg.mobyproject.buildkit.worker.oci.process-mode: sandbox\\norg.mobyproject.buildkit.worker.selinux.enabled:\\nfalse\\norg.mobyproject.buildkit.worker.snapshotter:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 124}, page_content='host\\norg.mobyproject.buildkit.worker.oci.process-mode: sandbox\\norg.mobyproject.buildkit.worker.selinux.enabled:\\nfalse\\norg.mobyproject.buildkit.worker.snapshotter:\\noverlayfs\\nGC Policy rule#0:\\nAll:\\ntrue\\nKeep Bytes: 25GiB\\n<Snip>\\nLet’s see how to perform multi-architecture builds.\\nMulti-architecture builds\\nYou can use the docker build command to build images for multiple platforms and\\nCPU architectures, including ones different from your local machine. For example:\\n• Docker on an AMD machine can build ARM images\\n• Docker on an ARM machine can build AMD images\\nYou also have the option to perform builds locally or in the cloud. Both work with the\\nstandard docker build command and only require minimal backend configuration.\\nRun the following command to list your current builders. Remember, a builder is an\\ninstance of BuildKit that will perform builds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 125}, page_content='8: Containerizing an app\\n119\\n$ docker buildx ls\\nNAME/NODE\\nDRIVER/ENDPOINT\\nPLATFORMS\\nbuilder *\\ndocker-container\\nbuilder0\\ndesktop-linux\\nlinux/arm64, linux/amd64, linux/amd64/v2,\\nlinux/riscv64, linux/ppc64le, linux/s390x,\\nlinux/386, linux/mips64le, linux/mips64,\\nlinux/arm/v7, linux/arm/v6\\ncloud-nigelpoulton-ddd\\ncloud\\nlinux-arm64\\ncloud://nigel...arm64\\nlinux/arm64*\\nlinux-amd64\\ncloud://nigel...amd64\\nlinux/amd64*, linux/amd64/v2, linux/amd64/v3,\\nlinux/amd64/v4\\n<Snip>\\nThe book’s output shows two builders; the one with the asterisk (*) is the default builder.\\nIn this example, the default builder is called builder and uses the docker-container\\ndriver to perform builds inside a local build container. Unless you specify a different\\nbuilder, all builds will run inside this build container. It supports multiple architectures,\\nincluding AMD, ARM, RISC-V, s390x, and more.\\nIf you don’t already have one, create a new builder called container that uses the docker-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 125}, page_content='including AMD, ARM, RISC-V, s390x, and more.\\nIf you don’t already have one, create a new builder called container that uses the docker-\\ncontainer driver with the following command.\\n$ docker buildx create --driver=docker-container --name=container\\nRun another docker buildx ls to show the new builder. Don’t worry if it shows as\\npresent but inactive.\\nMake it the default builder.\\n$ docker buildx use container\\nChange into the web-app directory and run the following command to build the app\\ninto AMD and ARM images and export them directly to Docker Hub.\\nBe sure to substitute your Docker ID as the command pushes directly to Docker Hub\\nand will fail if you try to push it to my repositories. If you don’t have a Docker Hub\\naccount or don’t want to push the images, you can replace the --push with --load.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 126}, page_content='8: Containerizing an app\\n120\\n$ docker buildx build --builder=container \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n[+] Building 79.3s (26/26) FINISHED\\n<Snip>\\n=> [linux/arm64 2/5] RUN apk add --update nodejs npm curl\\n19.0s\\n=> [linux/amd64 2/5] RUN apk add --update nodejs npm curl\\n17.4s\\n=> [linux/amd64 3/5] COPY . /src\\n0.0s\\n=> [linux/amd64 4/5] WORKDIR /src\\n0.0s\\n=> [linux/amd64 5/5] RUN\\nnpm install\\n7.3s\\n=> [linux/arm64 3/5] COPY . /src\\n0.0s\\n=> [linux/arm64 4/5] WORKDIR /src\\n0.0s\\n=> [linux/arm64 5/5] RUN\\nnpm install\\n5.6s\\n=> exporting to image\\n<Snip>\\n=> => pushing layers\\n31.5s\\n=> => pushing manifest for docker.io/nigelpoulton/ddd-book:web0.2@sha256:8fc61...\\n3.6s\\n=> [auth] nigelpoulton/ddd-book:pull,push token for registry-1.docker.io\\n0.0s\\nI’ve snipped the output, but you can still see two important things:\\n• Each Dockerfile instruction executed twice — once for AMD and once for ARM'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 126}, page_content='0.0s\\nI’ve snipped the output, but you can still see two important things:\\n• Each Dockerfile instruction executed twice — once for AMD and once for ARM\\n• The last few lines show the image layers being pushed directly to Docker Hub\\nNow that you’ve performed a build, the builder will show as active and list the architec-\\ntures it supports.\\nFigure 8.8 shows how the images for both architectures appear on Docker Hub under\\nthe same repository and tag.\\nFigure 8.8 - Multi-platform image\\nYou can also perform the builds using Docker Build Cloud. This is a cloud-based service\\nthat offers fast builds and lets you share your build cache with teammates. It requires a\\npaid subscription.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 127}, page_content='8: Containerizing an app\\n121\\nIf you have a Docker subscription that grants you access to Build Cloud, you can go to\\nbuild.docker.com and configure your first cloud builder. You can also create cloud\\nbuilders from the CLI as follows. If you’re following along, you’ll need to give yours a\\ndifferent name.\\n$ docker buildx create --driver cloud nigelpoulton/ddd\\nOnce you have a cloud builder, you can either make it your default builder with a\\ndocker buildx use <builder> command, or you can specify it when performing\\nindividual builds.\\nThe following command uses the --builder flag to use the cloud-nigelpoulton-ddd\\ncloud builder to build the same images as in the previous steps. Remember to use your\\nown cloud builder if you’re following along.\\n$ docker buildx build \\\\\\n--builder=cloud-nigelpoulton-ddd \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n=> [internal] connected to docker build cloud service\\n0.0s\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 127}, page_content='--builder=cloud-nigelpoulton-ddd \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n=> [internal] connected to docker build cloud service\\n0.0s\\n<Snip>\\nAt the time of writing, Build Cloud supports various AMD and ARM architectures,\\nwhereas the docker-container driver supports more but is slower and less reliable.\\nA few good practices\\nLet’s finish the chapter with a few best practices. This isn’t a full list, and the advice\\napplies to local builds and cloud builds.\\nLeverage the build cache\\nBuildKit uses a cache to speed up builds. The best way to see the impact is to build a\\nnew image on a clean Docker host and then repeat the same build immediately after.\\nThe first build will pull images and take time to build layers. The second build will\\ninstantly complete because the layers and other artifacts from the first build are cached\\nand leveraged by later builds.\\nIf you use a local builder, the cache is only available to other builds you execute on the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 127}, page_content='and leveraged by later builds.\\nIf you use a local builder, the cache is only available to other builds you execute on the\\nsame system. However, your entire team can share the cache on Docker Build Cloud.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 128}, page_content='8: Containerizing an app\\n122\\nFor each build, the builder iterates through the Dockerfile one line at a time, starting\\nfrom the top. For each line, it checks if it already has the layer in its cache. If it does,\\na cache hit occurs, and it uses the cached layer. If it doesn’t, a cache miss occurs, and it\\nbuilds a new layer from the instruction. Cache hits are one of the best ways to make\\nbuilds faster.\\nLet’s take a closer look.\\nAssume the following Dockerfile:\\nFROM alpine\\nRUN apk add --update nodejs npm\\nCOPY . /src\\nWORKDIR /src\\nRUN npm install\\nEXPOSE 8080\\nENTRYPOINT [\"node\", \"./app.js\"]\\nThe first instruction tells Docker to use the alpine:latest image as its base image. If\\nyou already have a copy of this image, the builder moves on to the next instruction. If\\nyou don’t have a copy, it pulls it from Docker Hub.\\nThe next instruction (RUN apk...) runs a command to update package lists and install\\nnodejs and npm. Before executing the instruction, Docker checks the build cache for a'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 128}, page_content='The next instruction (RUN apk...) runs a command to update package lists and install\\nnodejs and npm. Before executing the instruction, Docker checks the build cache for a\\nlayer built from the same base image using the same instruction. In this case, it’s looking\\nfor a layer built by executing the RUN apk add --update nodejs npm instruction\\ndirectly on top of the alpine:latest image.\\nIf it finds a matching layer, it links to that layer and continues the build with the cache\\nintact. If it does not find a matching layer, it invalidates the cache and builds the\\nlayer. Invalidating the cache means the builder must execute all remaining Dockerfile\\ninstructions in full and cannot use the cache.\\nLet’s assume Docker had a cached layer for the RUN instruction and that the layer’s ID is\\nAAA.\\nThe next instruction runs a COPY . /src command to copy the app code into the image.\\nThe previous instruction scored a cache hit, meaning Docker can check if it has a cached'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 128}, page_content='AAA.\\nThe next instruction runs a COPY . /src command to copy the app code into the image.\\nThe previous instruction scored a cache hit, meaning Docker can check if it has a cached\\nlayer built by running a COPY . /src against the AAA layer. If it has a cached layer for\\nthis, it links to the layer and proceeds to the next instruction. If it doesn’t have a cached\\nlayer, it builds it and invalidates the cache for the rest of the build.\\nThis process continues for the rest of the Dockerfile.\\nIt’s important to understand a few things.\\nAny time an instruction results in a cache miss, the cache is invalidated and no longer\\nchecked for the rest of the build. This means you should write your Dockerfiles so that'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 129}, page_content='8: Containerizing an app\\n123\\ninstructions most likely to invalidate the cache go near the end of the Dockerfile. This\\nallows builds to benefit from the cache for as long as possible.\\nYou can force a build to ignore the cache by running docker build with the --no-cache\\noption.\\nIt’s also important to understand that COPY and ADD instructions include logic to ensure\\nthe content you’re copying into the image hasn’t changed since the last build. For exam-\\nple, you might have a cached layer that Docker built by running a COPY . /src against\\nthe AAA image. However, if the files that the COPY . /src instruction copies into the\\nlayer have changed since the cached layer was built, you cannot use the cached layer as\\nyou’d get old versions of the files. To protect against this, Docker performs checksums\\nagainst each file it copies. If the checksums don’t match, the cache is invalidated, and\\nDocker builds a new layer.\\nOnly install essential packages'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 129}, page_content='against each file it copies. If the checksums don’t match, the cache is invalidated, and\\nDocker builds a new layer.\\nOnly install essential packages\\nWe often joke that we install the entire internet when we build apps. As a quick example,\\nthe simple Node.js app used earlier in the chapter depends on two packages:\\n• Express\\n• Pug\\nHowever, these packages depend on other packages, which in turn depend on others.\\nAt the time of writing, building this simple application with two dependencies actually\\ndownloads over 110 packages!\\nFortunately, some package managers provide a way for you to only download and install\\nessential packages instead of the entire internet. One example is the apt package manager\\nthat lets you specify the no-install-recommends flag so that it only installs packages\\nin the depends field and not every recommended and suggested package. Each package\\nmanager does this differently, but it’s worth investigating as it can massively impact the\\nsize of your images.\\nClean up'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 129}, page_content='manager does this differently, but it’s worth investigating as it can massively impact the\\nsize of your images.\\nClean up\\nIf you’ve followed along, you’ll have one running container and several images in your\\nlocal image repository. You should delete the running container and, optionally, the\\nlocal images.\\nRun the following command to delete the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 130}, page_content='8: Containerizing an app\\n124\\n$ docker rm c1 -f\\nOptionally delete the local images with the following command. Be sure to use the\\nnames of the images in your environment.\\n$ docker rmi \\\\\\nmulti:full multi:client multi:server ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\\nContainerizing an app – The commands\\n• docker build containerizes applications. It reads a Dockerfile and follows the\\ninstructions to create an OCI image. The -t flag tags the image, and the -f flag\\nlets you specify the name and location of the Dockerfile. The build context is where\\nyour application files exist and can be a directory on your local Docker host or a\\nremote Git repo.\\n• The Dockerfile FROM instruction specifies the base image. It’s usually the first\\ninstruction in a Dockerfile, and it’s considered a good practice to build from\\nDocker Official Images or images from Verified Publishers. FROM is also used to\\nidentify new build stages in multi-stage builds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 130}, page_content='Docker Official Images or images from Verified Publishers. FROM is also used to\\nidentify new build stages in multi-stage builds.\\n• The Dockerfile RUN instruction lets you run commands during a build. It’s com-\\nmonly used to update packages and install dependencies. Every RUN instruction\\ncreates a new image layer.\\n• The Dockerfile COPY instruction adds files to images, and you’ll regularly use it to\\ncopy your application code into a new image. Every COPY instruction creates an\\nimage layer.\\n• The Dockerfile EXPOSE instruction documents an application’s network port.\\n• The Dockerfile ENTRYPOINT and CMD instructions tell Docker how to run the app\\nwhen starting a new container.\\n• Some other Dockerfile instructions include LABEL, ENV, ONBUILD, HEALTHCHECK and\\nmore.\\nChapter summary\\nThis chapter taught you how to containerize an application. This is the process of\\nbuilding an app into a container image and running it as a container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 130}, page_content='more.\\nChapter summary\\nThis chapter taught you how to containerize an application. This is the process of\\nbuilding an app into a container image and running it as a container.\\nYou pulled some application source code from GitHub and used the docker init\\ncommand to auto-generate a Dockerfile with instructions telling Docker how to build'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 131}, page_content='8: Containerizing an app\\n125\\nthe app into a container image. You then used docker build to create the image, docker\\npush to push it to Docker Hub, and docker run to run it as a container.\\nAlong the way, you learned that some Dockerfile instructions add content to an\\nimage and therefore create new layers. Instructions that don’t add content only create\\nmetadata.\\nAfter that, you learned how multi-stage builds allow you to create small and efficient\\nproduction images without the bloat carried over from compiling the app.\\nAfter that, you learned that buildx is the default build client that integrates with the\\nlatest features of the BuildKit build engine. You learned how to create local and remote\\nbuilders (BuildKit instances) and how to use them to perform multi-architecture builds.\\nYou also learned the importance of the build cache for speeding up builds and how to\\noptimize Dockerfiles to leverage the build cache.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 132}, page_content='9: Multi-container apps with Compose\\nIn this chapter, you’ll deploy and manage a multi-container application using Docker\\nCompose. When talking about Docker Compose, we usually shorten it to Compose and\\nalways write it with a capital “C”.\\nI’ve organized the chapter as follows:\\n• Docker Compose – The TLDR\\n• Compose background\\n• Installing Compose\\n• The sample app\\n• Compose files\\n• Deploying apps with Compose\\n• Managing apps with Compose\\nDocker Compose – The TLDR\\nWe create modern cloud-native applications by combining lots of small services that\\nwork together to form a useful app. We call them microservices applications, and they\\nbring a lot of benefits, such as self-healing, autoscaling, and rolling updates. However,\\nthey can be complex.\\nFor example, you might have a microservices app with the following services:\\n• Web front-end\\n• Ordering\\n• Catalog\\n• Back-end datastore\\n• Logging\\n• Authentication\\n• Authorization'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 133}, page_content='9: Multi-container apps with Compose\\n127\\nInstead of hacking together complex scripts and long docker commands, Compose lets\\nyou describe the application in a simple YAML file called a Compose file. You then use the\\nCompose file with the docker compose command to deploy and manage the entire app.\\nThis makes Compose files important parts of your applications that you should host in a\\nversion control system such as Git.\\nThat’s the basics. Let’s dig deeper.\\nCompose background\\nWhen Docker was new, a company called Orchard Labs built a tool called Fig that made\\ndeploying and managing multi-container apps easy. It was a Python tool that ran on\\ntop of Docker and let you define complex multi-container microservices apps in a\\nsimple YAML file. You could even use the fig command-line tool to manage the entire\\napplication lifecycle.\\nBehind the scenes, Fig would read the YAML file and call the appropriate Docker\\ncommands to deploy and manage the app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 133}, page_content='application lifecycle.\\nBehind the scenes, Fig would read the YAML file and call the appropriate Docker\\ncommands to deploy and manage the app.\\nFig was so good that Docker, Inc. acquired Orchard Labs and rebranded Fig as Docker\\nCompose. They renamed the command-line tool from fig to docker-compose, and\\nthen, more recently, they folded it into the main docker CLI with its own compose sub-\\ncommand. You can now run simple docker compose commands to easily manage multi-\\ncontainer microservices apps.\\nThere is also a Compose Specification15 driving Compose as an open standard for multi-\\ncontainer microservices apps. The specification is community-led and kept separate\\nfrom the Docker implementation to maintain better governance and demarcation.\\nHowever, Docker Compose is the reference implementation, and you should expect Docker\\nto implement the full spec.\\nReading the spec is a great way to learn the details.\\nInstalling Compose'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 133}, page_content='However, Docker Compose is the reference implementation, and you should expect Docker\\nto implement the full spec.\\nReading the spec is a great way to learn the details.\\nInstalling Compose\\nAll modern versions of Docker come with Docker Compose pre-installed, and you no\\nlonger need to install it as a separate application.\\nTest it with the following command.\\n15https://www.compose-spec.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 134}, page_content=\"9: Multi-container apps with Compose\\n128\\n$ docker compose version\\nDocker Compose version v2.35.1\\nThe sample app\\nWe’ll use the sample app shown in Figure 9.1 with two services, a network, and a\\nvolume.\\nFigure9.1 - Sample app\\nThe web-fe service runs a web server that increments a counter in the redis service\\nevery time it receives a request for the web page. Both services are connected to the\\ncounter-net network and use it to communicate. The redis service mounts the\\ncounter-vol volume.\\nThis is all defined in the compose.yaml file in the multi-container folder of the book’s\\nGitHub repo.\\nIf you haven’t already done so, clone the repo so you have a local copy of everything\\nyou’ll need. You’ll need git installed, and the command will create a new directory\\ncalled ddd-book.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nCloning into 'ddd-book'...\\nremote: Enumerating objects: 67, done.\\nremote: Counting objects: 100% (67/67), done.\\nremote: Compressing objects: 100% (47/47), done.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 134}, page_content=\"Cloning into 'ddd-book'...\\nremote: Enumerating objects: 67, done.\\nremote: Counting objects: 100% (67/67), done.\\nremote: Compressing objects: 100% (47/47), done.\\nremote: Total 67 (delta 17), reused 63 (delta 16), pack-reused 0\\nReceiving objects: 100% (67/67), 173.61 KiB | 1.83 MiB/s, done.\\nResolving deltas: 100% (17/17), done.\\nChange into the ddd-book/multi-container directory and list its contents.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 135}, page_content='9: Multi-container apps with Compose\\n129\\n$ cd ddd-book/multi-container/\\n$ ls -l\\ntotal 20\\ndrwxrwxr-x 4 ubuntu ubuntu 4096 May 21 15:53 app\\n-rw-rw-r-- 1 ubuntu ubuntu\\n288 May 21 15:53 Dockerfile\\n-rw-rw-r-- 1 ubuntu ubuntu\\n18 May 21 15:53 requirements.txt\\n-rw-rw-r-- 1 ubuntu ubuntu\\n355 May 21 15:53 compose.yaml\\n-rw-rw-r-- 1 ubuntu ubuntu\\n332 May 21 15:53 README.md\\nThis directory is your build context and contains all the app code and configuration files\\nDocker needs to deploy and manage the app.\\n• The app folder contains the application code, views, and templates\\n• The Dockerfile describes how to build the image for the web-fe service\\n• The requirements.txt file lists the application dependencies for the web-fe\\nservice\\n• The compose.yaml file tells Docker how to deploy the app\\nFigure 9.2 shows the app in more detail.\\nFigure 9.2 - Detailed view of sample app\\nWhen you deploy the app, you’ll use the docker compose command to send the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 135}, page_content='Figure 9.2 shows the app in more detail.\\nFigure 9.2 - Detailed view of sample app\\nWhen you deploy the app, you’ll use the docker compose command to send the\\ncompose.yaml file to Docker, where Docker parses the file and completes the necessary\\nsteps to deploy the app. These steps include creating the network, volume, image, and\\nservices, and connecting the services to the appropriate network and volume.\\nAs you’ll see later, Docker assigns the app a project name based on the name of your build\\ncontext’s directory. In our example, the build context is the multi-container directory,\\nso Docker will use “multi-container” as the project name. You’ll see why this matters later.\\nNow that you know what the app looks like, let’s take a closer look at the Compose file.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 136}, page_content='9: Multi-container apps with Compose\\n130\\nCompose files\\nCompose uses YAML files to define microservices applications. We call them Compose\\nfiles, and Compose expects you to name them compose.yaml or compose.yml. However,\\nyou can specify a different filename with the -f flag.\\nHere is the Compose file we’ll be using. It’s called compose.yaml from the multi-\\ncontainer folder.\\nservices:\\n<<--- Microservices are defined in the \"services\" block\\nweb-fe:\\n----┐\\ndeploy:\\n|\\nreplicas: 1\\n|\\nbuild: .\\n| This block\\ncommand: python app.py\\n| defines the\\nports:\\n| *web-fe*\\n- target: 8080\\n| microservice\\npublished: 5001\\n|\\nnetworks:\\n|\\n- counter-net\\n----┘\\nredis:\\n----┐\\ndeploy:\\n|\\nreplicas: 1\\n|\\nimage: \"redis:alpine\"\\n|\\nnetworks:\\n| The *redis*\\ncounter-net\\n| service\\nvolumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\ntarget: /app\\n----┘\\nnetworks:\\n<<--- Networks are defined in this block\\ncounter-net:\\nvolumes:\\n<<--- Volumes are defined in this block\\ncounter-vol:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 136}, page_content='volumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\ntarget: /app\\n----┘\\nnetworks:\\n<<--- Networks are defined in this block\\ncounter-net:\\nvolumes:\\n<<--- Volumes are defined in this block\\ncounter-vol:\\nThe first thing to note is that the file has three top-level keys with a block of code\\nbeneath each:\\n• services\\n• networks\\n• volumes\\nMore top-level keys exist, but this app only uses the three in the list.\\nThe top-level services key is mandatory and is where you define application microser-\\nvices. This app has two microservices called web-fe and redis. The web-fe service runs\\nthe application’s web server and the redis service runs a database backend.\\nLet’s look at both, starting with the web-fe service.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 137}, page_content='9: Multi-container apps with Compose\\n131\\nservices:\\nweb-fe:\\n<<--- Service name. Containers will inherit this name\\ndeploy:\\nreplicas: 1\\n<<--- Deploy a single container for this service\\nbuild: .\\n<<--- Build from the Dockerfile in the current directory\\ncommand: python app/app.py <<-- Execute this command when starting containers\\nports:\\n- target: 8080\\n----┐Map port 8080 in the container\\npublished: 5001\\n----┘to port 5001 on the Docker host\\nnetworks:\\n- counter-net\\n<<--- Attach the service\\'s containers to the \"counter-net\" network\\nLet’s step through it.\\n• web-fe: is the service’s name, and all containers Docker creates for this service\\nwill inherit “web-fe” as part of their names.\\n• deploy.replicas: 1 tells Docker to deploy a single container for this service. You\\ncan specify a different number of replicas to deploy multiple identical containers\\nfor the service. However, you’ll only be able to deploy a single replica on Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 137}, page_content='can specify a different number of replicas to deploy multiple identical containers\\nfor the service. However, you’ll only be able to deploy a single replica on Docker\\nDesktop as only one container can bind to the port in the ports field.\\n• build: . tells Docker to build the image for this service from the Dockerfile in the\\ncurrent directory.\\n• command: python app/app.py is the command Docker executes inside every\\ncontainer it creates for this service. The app.py file must exist in the image, and\\nthe image must have Python installed. The Dockerfile takes care of both of these\\nrequirements.\\n• ports: is where you map network ports from the service’s containers to the\\nDocker host. This example maps port 5001 on the Docker host to port 8080 inside\\nthe container and is why Docker Desktop readers can only deploy a single replica\\nfor this service.\\n• networks: tells Docker to attach this service’s containers to the counter-net'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 137}, page_content='the container and is why Docker Desktop readers can only deploy a single replica\\nfor this service.\\n• networks: tells Docker to attach this service’s containers to the counter-net\\nnetwork. The network should already exist or be defined in the networks top-level\\nkey.\\nIn summary, Compose will build a new image from the Dockerfile in the same directory\\nand start a single container from it. When it starts, the container will have web-fe in\\nits name and run the python app/app.py command. It will attach to the counter-net\\nnetwork, expose the web service on the host’s port 5001.\\nNow, let’s look at the redis service.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 138}, page_content='9: Multi-container apps with Compose\\n132\\nservices:\\n..\\nredis:\\n<<--- Service name. Containers will inherit this name\\nimage: \"redis:alpine\"\\n<<--- Pull the \"redis:alpine\" image for this service\\ndeploy:\\nreplicas: 1\\n<<--- Deploy a single container for this service\\nnetworks:\\ncounter-net:\\n<<--- Attach containers to the \"counter-net\" network\\nvolumes:\\n- type: volume\\nsource: counter-vol\\n----┐Mount the \"counter-vol\" volume\\ntarget: /app\\n----┘to \"/app\" in the containers for this service\\nLet’s step through this one.\\n• redis: is the service’s name, and all containers created as part of this service will\\ninherit “redis” as part of their names.\\n• image: redis:alpine tells Docker to pull the redis:alpine image from Docker\\nHub and use it to start the service’s containers.\\n• deploy.replicas: 1 tells Docker to deploy a single container for this service.\\n• networks: tells Docker to attach the service’s containers to the counter-net\\nnetwork.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 138}, page_content='• deploy.replicas: 1 tells Docker to deploy a single container for this service.\\n• networks: tells Docker to attach the service’s containers to the counter-net\\nnetwork.\\n• volumes: tells Docker to mount the counter-vol volume to the /data directory\\ninside all of the service’s containers. This is where Redis stores data and will mean\\nyou can stop and delete most of the app without losing data.\\nConnecting both services to the counter-net network means they can resolve each\\nother by name and communicate. This is important, as the following extract from the\\napp.py file shows the web app communicating with the redis service by name.\\nimport time\\nimport redis\\nfrom flask import Flask, render_template\\napp = Flask(__name__)\\ncache = redis.Redis(host=\\'redis\\', port=6379)\\n<<---- \"redis\" is the name of the service\\n<Snip>\\nThe network and volumes blocks are extremely simple and define a network called\\ncounter-net and a volume called counter-vol.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 139}, page_content='9: Multi-container apps with Compose\\n133\\nnetworks:\\n<<---- This block defines a new network called \"counter-net\"\\ncounter-net:\\nvolumes:\\n<<---- This block defines a new volume called \"counter-vol\"\\ncounter-vol:\\nNow that we understand the Compose file, let’s deploy the app.\\nDeploying apps with Compose\\nIn this section, you’ll use the app from the Compose file. You’ll need a local copy of the\\nbook’s GitHub repo, and you’ll need to run all commands from the multi-container\\nfolder.\\nRun the following command to deploy the app. By default, it deploys the app defined in\\nthe compose.yaml file in the working directory.\\n$ docker compose up --detach\\n- redis 7 layers [||||||]\\n0B/0B\\nPulled\\n5.2s\\n- b0dd12c8e070: Pull complete\\n<Snip>\\n- 4f4fb700ef54: Pull complete\\n- redis Pulled\\n<Snip>\\n=> [web-fe internal] load build definition from Dockerfile\\n[+] Building 613s (11/11) FINISHED\\n<Snip>\\n[+] Running 5/5\\n- web-fe\\nBuilt\\n0.0s\\n- Network multi-container_counter-net\\nCreated\\n0.0s'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 139}, page_content='<Snip>\\n=> [web-fe internal] load build definition from Dockerfile\\n[+] Building 613s (11/11) FINISHED\\n<Snip>\\n[+] Running 5/5\\n- web-fe\\nBuilt\\n0.0s\\n- Network multi-container_counter-net\\nCreated\\n0.0s\\n- Volume \"multi-container_counter-vol\"\\nCreated\\n0.0s\\n- Container multi-container-redis-1\\nCreated\\n0.0s\\n- Container multi-container-web-fe-1\\nCreated\\n0.0s\\nIt’ll take a few seconds to build the web-fe image, pull the redis image, and then\\nstart the app. We’ll review what happened in a second, but let’s talk about the docker\\ncompose command first.\\nRunning a docker compose up command is the most common way to deploy a\\nCompose app. It reads through the Compose file in the local directory and runs the\\nDocker commands required to deploy the app. This includes building and pulling\\nimages, creating required networks and volumes, and starting all containers.\\nThe command you executed didn’t specify the name or location of the Compose file, so'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 139}, page_content='images, creating required networks and volumes, and starting all containers.\\nThe command you executed didn’t specify the name or location of the Compose file, so\\nDocker assumed it was called compose.yaml in the local directory. However, you can use\\nthe -f flag to point to a Compose file with a different name in a different directory. For'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 140}, page_content='9: Multi-container apps with Compose\\n134\\nexample, the following command will deploy the application defined in a Compose file\\ncalled sample-app.yml in the apps/ddd-book directory.\\n$ docker compose -f apps/ddd-book/sample-app.yml up --detach\\nNow that you’ve deployed the app, you can run regular docker commands to see the\\nimages, containers, networks, and volumes that Compose created.\\nRun the following command to see the image created for the web-fe service and the\\nimage pulled for the redis service.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nalpine\\nf773b35a95e1\\n8 days ago\\n61.4MB\\nmulti-container-web-fe\\nlatest\\n811f22c9edb7\\n2 minutes ago\\n99.7MB\\nDocker pulled the redis:alpine image from Docker Hub, but it used the Dockerfile to\\nbuild the multi-container-web-fe:latest image.\\nIf you look at the Dockerfile, you’ll see it pulls the python:alpine image, copies in the\\napp code, installs requirements, and sets the command to start the app.\\nFROM python:alpine\\n<<---- Base image'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 140}, page_content='If you look at the Dockerfile, you’ll see it pulls the python:alpine image, copies in the\\napp code, installs requirements, and sets the command to start the app.\\nFROM python:alpine\\n<<---- Base image\\nCOPY . /app\\n<<---- Copy app code into image\\nWORKDIR /app\\n<<---- Set working directory\\nRUN pip install -r requirements.txt\\n<<---- Install requirements\\nENTRYPOINT [\"python\", \"app/app.py\"]\\n<<---- Set the default app\\nNotice how the newly built image’s name is a combination of the project name and the\\nservice name. The project name is the name of the build context directory, which in our\\nexample is multi-container, and the service name is web-fe. Compose uses this format\\nto name all resources, and the following table shows the names it will give the resources\\nfor our sample app.\\nResource type\\nResource\\nName\\nService\\nweb-fe\\nmulti-container-web-fe-1\\nService\\nredis\\nmulti-container-redis-1\\nNetwork\\ncounter-net\\nmulti-container_counter-net\\nVolume\\ncounter-vol\\nmulti-container_counter-vol'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 140}, page_content='Resource\\nName\\nService\\nweb-fe\\nmulti-container-web-fe-1\\nService\\nredis\\nmulti-container-redis-1\\nNetwork\\ncounter-net\\nmulti-container_counter-net\\nVolume\\ncounter-vol\\nmulti-container_counter-vol\\nList running containers to see the containers Compose created for the app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 141}, page_content='9: Multi-container apps with Compose\\n135\\n$ docker ps\\nID\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\n61..\\n\"python app/app.py\"\\nUp 35 mins\\n0.0.0.0:5001->8080/tcp..\\nmulti-container-web-fe-1\\n80..\\n\"docker-entrypoint..\"\\nUp 35 mins\\n6379/tcp\\nmulti-container-redis-1\\nAs you can see, the multi-container-web-fe-1 container is running the Python web\\napp and is mapped to port 5001 on all interfaces on the Docker host. We’ll connect to\\nthis later.\\nThe number at the end of the container names allows each service to have multiple\\nreplicas. For example, if the web-fe service had three replicas they would be called\\nmulti-container-web-fe-1, multi-container-web-fe-2, and multi-container-web-\\nfe-3.\\nRun the following commands to see the counter-net network and counter-vol\\nvolume.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n46100cae7441\\nmulti-container_counter-net\\nbridge\\nlocal\\n<Snip>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmulti-container_counter-vol\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 141}, page_content='volume.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n46100cae7441\\nmulti-container_counter-net\\nbridge\\nlocal\\n<Snip>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmulti-container_counter-vol\\n<Snip>\\nWith the application deployed, you can point a web browser at your Docker host on port\\n5001 to view it. You can connect to localhost:5001 if you’re running Docker Desktop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 142}, page_content='9: Multi-container apps with Compose\\n136\\nRefresh the page a few times and watch the counter increment. This is the app counting\\npage refreshes and storing the value on the volume in the Redis service.\\nCongratulations. You’ve successfully deployed a multi-container application using\\nDocker Compose!\\nManaging apps with Compose\\nIn this section, you’ll see how to stop, restart, delete, and get the status of Compose apps.\\nMake a note of how many times you’ve refreshed the page, and then run the following\\ncommand to shut the app down.\\n$ docker compose down\\n[+] Running 3/3\\n- Container multi-container-redis-1\\nRemoved\\n0.2s\\n- Container multi-container-web-fe-1\\nRemoved\\n0.2s\\n- Network multi-container_counter-net\\nRemoved\\n0.2s\\nThe output shows Docker deleting both containers and the network. However, it\\ndoesn’t mention the volume.\\nRun a docker volumes ls command to see if the volume still exists.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 143}, page_content='9: Multi-container apps with Compose\\n137\\n$ docker volume ls\\n<Snip>\\nlocal\\nmulti-container_counter-vol\\nThe volume still exists because Docker knows we store important information in\\nvolumes that we might want to keep when stopping and restarting apps. In our example,\\nthe redis service stored the refresh count in the volume, meaning we’ll see the same\\ncount when we redeploy the app in a later step.\\nDocker also keeps the images it built and pulled when it started the app. Feel free to run\\na docker images command to prove the images still exist.\\nLet’s explore a few other docker compose commands.\\nRun the following command to redeploy the app.\\n$ docker compose up --detach\\n<Snip>\\n[+] Running 3/3\\n- Network multi-container_counter-net\\nCreated\\n0.2s\\n- Container multi-container-redis-1\\nStarted\\n0.2s\\n- Container multi-container-web-fe-1\\nStarted\\n0.2s\\nNotice how it started much faster this time. This is because the images and volume\\nalready exist.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 143}, page_content='- Container multi-container-redis-1\\nStarted\\n0.2s\\n- Container multi-container-web-fe-1\\nStarted\\n0.2s\\nNotice how it started much faster this time. This is because the images and volume\\nalready exist.\\nGo back to your browser and refresh the app. The refresh count should continue from\\nwhere you left it. This is because Redis stores the count in the /data directory, which\\nuses the volume Docker didn’t delete.\\nSwitch back to the CLI and check the current state of the app with a docker compose\\nps command.\\n$ docker compose ps\\nNAME\\nCOMMAND\\nSERVICE\\nSTATUS\\nPORTS\\nmulti-container-redis-1\\n\"docker-entrypoint..\"\\nredis\\nUp 33 sec\\n6379/tcp\\nmulti-container-web-fe-1\\n\"python app/app.py\"\\nweb-fe\\nUp 33 sec\\n0.0.0.0:5001->8080\\nThe output shows both containers, the commands they’re executing, their current state,\\nand the network ports they’re listening on.\\nRun a docker compose top to list the processes inside each container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 144}, page_content='9: Multi-container apps with Compose\\n138\\n$ docker compose top\\nmulti-container-redis-1\\nUID\\nPID\\nPPID\\n... CMD\\nlxd\\n12023\\n11980\\nredis-server *:6379\\nmulti-container-web-fe-1\\nUID\\nPID\\nPPID\\n... CMD\\nroot\\n12024\\n12002\\n0\\npython app/app.py python app/app.py\\nroot\\n12085\\n12024\\n0\\n/usr/local/bin/python app/app.py python app/app.py\\nThe PID numbers returned are the PID numbers as seen from the Docker host (not from\\nwithin the containers).\\nRun the following commands to stop the app and recheck its status.\\n$ docker compose stop\\n[+] Running 2/2\\n- Container multi-container-redis-1\\nStopped\\n0.4s\\n- Container multi-container-web-fe-1\\nStopped\\n0.5\\n$ docker compose ps -a\\nNAME\\nCOMMAND\\nSERVICE\\nSTATUS\\nPORTS\\nNAME\\nIMAGE\\n...\\nSERVICE\\nSTATUS\\nmulti-container-redis-1\\nredis:alpine\\n...\\nredis\\nExited (0) 25 seconds ago\\nmulti-container-web-fe-1\\nmulti-container-web-fe\\n...\\nweb-fe\\nExited (0) 25 seconds ago\\nThe app is down, but Docker hasn’t deleted the containers — it’s only stopped them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 144}, page_content='Exited (0) 25 seconds ago\\nmulti-container-web-fe-1\\nmulti-container-web-fe\\n...\\nweb-fe\\nExited (0) 25 seconds ago\\nThe app is down, but Docker hasn’t deleted the containers — it’s only stopped them.\\nRestart the app with the docker compose restart command.\\n$ docker compose restart\\n[+] Running 2/2\\n- Container multi-container-redis-1\\nStarted\\n0.1s\\n- Container multi-container-web-fe-1\\nStarted\\n0.1s\\nCheck the status of the app.\\n$ docker compose ls\\nNAME\\nSTATUS\\nCONFIG FILES\\nmulti-container\\nrunning(2)\\n/Users/nigelpoulton/temp/ddd-book/multi-container/compose.yaml\\nGo back to your browser and refresh the page again. The counter will continue from\\nwhere you left it because Docker didn’t delete the containers or the volumes. Even if\\nyour app doesn’t use volumes, it won’t lose data across container restarts.\\nCongratulations. You’ve deployed and managed a multi-container microservices app\\nusing Docker Compose.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 145}, page_content='9: Multi-container apps with Compose\\n139\\nBefore cleaning up and reviewing the commands, it’s important to understand that\\nthis was a simple example and that Docker Compose can deploy and manage far more\\ncomplex applications.\\nClean up\\nRun the following command to stop and delete the app. The --volumes flag will delete\\nall of the app’s volumes, and the --rmi all will delete all of its images.\\n$ docker-compose down --volumes --rmi all\\n[+] Running 6/6\\n- Container multi-container-web-fe-1\\nRemoved\\n0.2s\\n- Container multi-container-redis-1\\nRemoved\\n0.1s\\n- Volume multi-container_counter-vol\\nRemoved\\n0.0s\\n- Image multi-container-web-fe:latest\\nRemoved\\n0.1s\\n- Image redis:alpine\\nRemoved\\n0.1s\\n- Network multi-container_counter-net\\nRemoved\\n0.1s\\nDeploying apps with Compose – The commands\\n• docker compose up is the command to deploy a Compose app. It creates all\\nimages, containers, networks, and volumes the app needs. It expects you to call'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 145}, page_content='Deploying apps with Compose – The commands\\n• docker compose up is the command to deploy a Compose app. It creates all\\nimages, containers, networks, and volumes the app needs. It expects you to call\\nthe Compose file compose.yaml, but you can specify a custom filename with the -f\\nflag. You’ll normally start the app in the background with the --detach flag.\\n• docker compose stop will stop all containers in a Compose app without deleting\\nthem. You can easily restart them with docker compose restart, and you\\nshouldn’t lose any data.\\n• docker compose restart will restart a stopped Compose app. If you make\\nchanges to the Compose file while it’s stopped, these changes will not appear in\\nthe restarted app. You need to redeploy the app to see any changes you made in the\\nCompose file.\\n• docker compose ps lists each container in the Compose app. It shows the current\\nstate, the command each container is running, and network ports.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 145}, page_content='Compose file.\\n• docker compose ps lists each container in the Compose app. It shows the current\\nstate, the command each container is running, and network ports.\\n• docker compose down will stop and delete a running Compose app. By default, it\\ndeletes containers and networks but not volumes and images.\\nChapter Summary\\nIn this chapter, you learned how to deploy and manage multi-container applications\\nusing Docker Compose.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 146}, page_content='9: Multi-container apps with Compose\\n140\\nCompose is fully integrated into the Docker toolset with its own docker compose sub-\\ncommand. It lets you define multi-container applications in declarative configuration\\nfiles and deploy them with a single command.\\nCompose files define all the containers, networks, volumes, secrets, and other configu-\\nrations an application needs. You then use the docker compose command to post the\\nCompose file to Docker, and Docker deploys it.\\nOnce you’ve deployed the app, you can manage its entire lifecycle using docker\\ncompose sub-commands.\\nDocker Compose is popular with developers, and the Compose file is an excellent\\nsource of application documentation as it defines all the services that make up the app,\\nthe images they use, the ports they expose, the networks and volumes they use, and\\nmuch more. As such, it can help bridge the gap between development and operations\\nteams. You should also treat Compose files as code and store them in version control'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 146}, page_content='much more. As such, it can help bridge the gap between development and operations\\nteams. You should also treat Compose files as code and store them in version control\\nsystems.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 147}, page_content='10: Docker and AI\\nDocker offers two ways of deploying and running AI apps:\\n1. Docker Model Runner (preferred)\\n2. Containers\\nBoth methods run AI apps locally, making them suitable for companies with privacy\\nconcerns, that do not want unpredictable cloud costs, have latency-sensitive require-\\nments, and require full control over things like prompt customization and fine-tuning.\\nHowever, Docker Model Runner is the preferred method and will be the focus of this\\nchapter.\\nI’ve organized the chapter as follows:\\n• Docker Model Runner background\\n• Docker Model Runner architecture\\n• Install Docker Model Runner\\n• Explore Docker Model Runner\\n• Use Docker Model Runner with Compose\\n• Use Docker Model Runner with 3rd-party apps\\n• Running models in containers\\nThroughout the chapter, we’ll use the terms “LLMs”, “models, “AI models”, and “AI apps” to\\nmean the same thing.\\nDocker Model Runner background\\nDocker Model Runner (DMR) is a new technology, fully integrated with the Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 147}, page_content='mean the same thing.\\nDocker Model Runner background\\nDocker Model Runner (DMR) is a new technology, fully integrated with the Docker\\ntoolchain, that executes AI models directly on host machines rather than inside\\ncontainers. Yes… Docker Model Runner executes AI models outside of containers! This\\nis because containers cannot access the majority of AI acceleration hardware like GPUs,\\nNPUs, and TPUs that make AI models fast. This is because most AI acceleration devices\\nare proprietary, with their own drivers and SDKs, and it’s extremely hard for Docker\\nand the wider ecosystem to develop and maintain support for them all.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 148}, page_content='10: Docker and AI\\n142\\nYes, it’s possible for containers to access modern NVIDIA GPUs if you install the\\nNVIDIA Container Toolkit. However, this is complex to install and only works for CUDA-\\ncapable NVIDIA GPUs. By executing models outside of containers, Docker Model\\nRunner gives you the best of both worlds:\\n• Integration with Docker tools and the wider cloud native ecosystem\\n• Easier access to AI acceleration hardware\\nThe early releases of DMR work with NVIDIA GPUs on Windows hosts and the built-\\nin GPUs on Macs with Apple silicon. Future releases will support a broader range of AI\\nacceleration hardware.\\nNow that you know the background, let’s look at Docker Model Runner’s architecture.\\nDocker Model Runner Architecture\\nDMR executes models directly on host hardware, exposes them via OpenAI-compatible\\nendpoints, and integrates with the wider Docker toolchain and cloud native ecosystem.\\nFigure 10.1 shows the high-level architecture and major components.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 148}, page_content='endpoints, and integrates with the wider Docker toolchain and cloud native ecosystem.\\nFigure 10.1 shows the high-level architecture and major components.\\nFigure 10.1 - Docker Model Runner Architecture\\nYou can see Docker Model Runner at the bottom of the diagram in the center. It’s a host\\nprocess that wraps one or more runtimes, provides models with direct access to host'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 149}, page_content='10: Docker and AI\\n143\\nhardware, dynamically loads and unloads models based on demand, and serves them\\nvia OpenAI-compatible endpoints that applications can access from inside containers or\\nvia the network. The Docker CLI can pull and push models from Docker Hub and DMR\\nstores them in a local store for fast access.\\nLet’s dig a little deeper.\\nDMR is a host process separate from the Docker Engine. For Mac users, this means it runs\\noutside the Docker Desktop VM with direct access to hardware. It wraps a pluggable\\nruntime layer that allows you to choose the best runtime for your requirements. Runtime\\nis another word for the core inference engine that loads and executes models and provides\\ninference. Early releases use llama.cpp as the runtime, but future releases will support\\nadditional runtimes.\\nDMR exposes several API endpoints for model management and inference. The\\nmodel management endpoints allow you to query and manage models, whereas the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 149}, page_content='additional runtimes.\\nDMR exposes several API endpoints for model management and inference. The\\nmodel management endpoints allow you to query and manage models, whereas the\\ninference endpoints are OpenAI-compatible. Containers on the same host can access\\nthe endpoints via the special http://model-runner.docker.internal/ hostname, non-\\ncontainerized apps on the same host can reach them via the local Docker socket or the\\nhost’s loopback address on port 12434, and apps running on different hosts can access\\nthem via the DMR host’s IP or DNS name on port 12434.\\nThe initial versions of DMR use a Docker CLI plugin that provides the docker model\\ncommand. Docker Desktop automatically installs the plugin when you enable DMR,\\nbut future versions may integrate DMR functionality into core Docker commands\\nlike docker pull and docker run. If this happens, commands like docker pull and\\ndocker run will read the object manifest to know they’re working with models instead\\nof images or containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 149}, page_content='like docker pull and docker run. If this happens, commands like docker pull and\\ndocker run will read the object manifest to know they’re working with models instead\\nof images or containers.\\nDocker Hub maintains a catalog of verified models below the ai namespace16. You can pull\\nthese in the same way you pull images, and DMR will store them in a local model store in\\nyour filesystem below ∼/.docker/models. As is normal for AI models, they are usually\\nseveral gigabytes in size. You can even push your own models to Docker Hub where they\\nare stored as a new (proposed) OCI artifact type called a model.\\nWe’ll get into more details and see all of this in action as you progress through the\\nchapter. However, a quick word on how DMR compares with other popular model\\nservers.\\nDocker Model Runner vs Ollama vs LM Studio\\nIf you’re already running local models, you’ll recognize similarities with tools like LM\\nStudio and Ollama.\\n16https://hub.docker.com/u/ai'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 150}, page_content='10: Docker and AI\\n144\\nFor example, they can all use llama.cpp as their core inference engine and can expose\\nmodels via OpenAI-style endpoints. This means they all offer similar core functionality\\nand performance. However, Docker Model Runner offers seamless integration with\\nDocker tools and the wider cloud native ecosystem.\\nWith these points in mind, you should seriously consider DMR if you’re:\\n• An existing Docker user who already runs local models\\n• An existing Docker user with plans to start running local models\\n• Already running local models and about to start using Docker for containers\\nIn all of these cases, switching to Docker Model Runner allows you to consolidate tools\\nand ecosystems.\\nHowever, early versions of Docker Model Runner may offer fewer features than some\\nof the alternatives, and you should always test new products against your current and\\nfuture requirements.\\nInstalling Docker Model Runner\\nYou’ll need all of the following to complete the examples:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 150}, page_content='of the alternatives, and you should always test new products against your current and\\nfuture requirements.\\nInstalling Docker Model Runner\\nYou’ll need all of the following to complete the examples:\\n• A Mac or Windows machine, preferably with Apple or NVIDIA GPUs\\n• Docker Desktop v4.41 or newer (includes Docker Compose v2.35)\\n• A clone of the book’s GitHub repo\\nDocker Model Runner also works on CPUs, meaning you can still use it if you don’t\\nhave a machine with supported GPUs. Models will just run slower.\\nYou can run the following command to clone the book’s GitHub repo:\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nChange into the dmr directory.\\n$ cd ddd-book/dmr\\nOpen Docker Desktop’s Settings page, click the Features in development tab, and\\ncheck the Enable Docker Model Runner and Enable host-side TCP support check-\\nboxes. Accept the default port of 12434 and then click the blue Apply & restart button\\nto activate your changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 151}, page_content='10: Docker and AI\\n145\\nChecking the Enable host-side TCP support option maps DMR to port 12434 on the\\nhost’s network interface so that local apps can access it on localhost:12434 and remote\\napps can access it from the network on the same port.\\nOnce you’ve enabled DMR, switch to the command line and verify it’s working.\\n$ docker model status\\nDocker Model Runner is running\\nStatus:\\nllama.cpp: running llama.cpp latest-metal (sha256:ad58230f548...) version: a0f7016\\nDMR is running and you can see it’s using llama.cpp as its core inference engine (run-\\ntime) which, in turn, is using Apple’s Metal API to give models access to my MacBook’s\\nGPUs. Future versions of DMR may support Apple’s MLX framework so that models\\ncan leverage Apple’s Neural Engine for even better performance. As the runtime layer is\\npluggable, things like MLX and support for other hardware can come through the use of\\ndifferent runtimes.\\nCongratulations. You’ve enabled Docker Model Runner and are ready to start using it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 151}, page_content='pluggable, things like MLX and support for other hardware can come through the use of\\ndifferent runtimes.\\nCongratulations. You’ve enabled Docker Model Runner and are ready to start using it.\\nExplore Docker Model Runner\\nIn this section, you’ll learn how to:\\n• Pull models from Docker Hub\\n• List and inspect models\\n• Test models\\n• Inspect the DMR APIs\\nPull models from Docker Hub\\nDocker maintains a catalog of models below the ai namespace17 on Docker Hub. These\\nare part of the Docker Verified Publisher Program, meaning they should be high quality and\\nup to date.\\nPoint your browser at https://hub.docker.com/catalogs/models and click through\\nthe available models. Clicking a particular model shows its model card with detailed\\nmodel info. Figure 10.2 shows the model card for the Mistral model. We’ll look more\\nclosely later in the chapter, but you can see it’s a verified model, you can see the model\\n17https://hub.docker.com/u/ai'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 152}, page_content='10: Docker and AI\\n146\\narchitecture, training cut-off date, model variants, and even benchmark info. However,\\nbenchmark info is from the original model publisher, and you should always perform\\nyour own testing to see how well a model performs for your specific requirements.\\nFigure 10.2 - Model info card\\nRun the following command to download a quantized version of a Gemma3 4B model.\\nQuantization is a way to reduce model size without losing too much model accuracy or\\nperformance. However, even quantized can be several gigabytes and can take a while to\\ndownload. Feel free to download a newer quantized version if available.\\n$ docker model pull ai/gemma3:4B-Q4_K_M\\nDownloaded: 18.10 MB...\\n<Snip>\\nModel pulled successfully\\nOnce the pull operation is complete, list your local models to see the one you down-\\nloaded.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 153}, page_content='10: Docker and AI\\n147\\n$ docker model ls\\nMODEL NAME\\nPARAMS\\nQUANTIZATION\\nARCHITECTURE\\nMODEL ID\\nSIZE\\nai/gemma3:4B-Q4_K_M\\n3.88 B\\nIQ2_XXS/Q4_K_M\\ngemma3\\n0b329b335467\\n2.31G\\nInspecting models\\nDMR automatically pulls images from Docker Hub where it stores and distributes them\\nas a new type of OCI artifact called a model. This model-spec18 is currently in draft and\\nmay change slightly.\\nRun the following command to inspect the manifest of the Gemma3 model you just\\npulled. The command connects to Docker Hub and inspects the manifest from Docker\\nHub and not the local copy you pulled.\\n$ docker manifest inspect ai/gemma3:4B-Q4_K_M | jq\\n{\\n\"schemaVersion\": 2,\\n\"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\\n<<--- Image manifest\\n\"config\": {\\n----┐\\n\"mediaType\": \"application/vnd.docker.ai.model.config.v0.1+json\", | Model config\\n\"size\": 372,\\n| descriptor\\n\"digest\": \"sha256:22273fdf4e6dbaf...af0e6569be41539\"\\n----┘\\n},\\n\"layers\": [\\n{\\n\"mediaType\": \"application/vnd.docker.ai.gguf.v3\",\\n----┐'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 153}, page_content='\"size\": 372,\\n| descriptor\\n\"digest\": \"sha256:22273fdf4e6dbaf...af0e6569be41539\"\\n----┘\\n},\\n\"layers\": [\\n{\\n\"mediaType\": \"application/vnd.docker.ai.gguf.v3\",\\n----┐\\n\"size\": 2489757856,\\n| GGUF descriptor\\n\"digest\": \"sha256:09b370de51ad3...fc96ab2dc1adaa7\"\\n----┘\\n},\\n{\\n\"mediaType\": \"application/vnd.docker.ai.license\",\\n----┐\\n\"size\": 8346,\\n| License descriptor\\n\"digest\": \"sha256:a4b03d96571f0...dc90e3f960823e5\"\\n----┘\\n}\\n]\\n}\\nThe output shows three descriptors relating to the model config and its two layers, and\\nyou’ll recognize it if you’re familiar with the structure of OCI images.\\nWhen you pulled the model, DMR queried Docker Hub (OCI registry) for the requested\\nmodel, read its manifest, pulled the config and two layers, and stored them in the local\\nmodel store with filenames matching the SHAs. This means the config file and layer\\nfiles are in your local filesystem below ∼/.docker/models/blobs/sha256 and you can\\ninspect them with your favorite tools.\\n18https://github.com/docker/model-spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 154}, page_content='10: Docker and AI\\n148\\n$ ls -lh ~/.docker/models/blobs/sha256\\ntotal 13609568\\n-rw-r--r--@ 1\\n2.3G\\n09b370de51ad3bde8c3aea...667ddbafc96ab2dc1adaa7\\n<<---- model file (GGUF)\\n-rw-r--r--@ 1\\n372B\\n22273fd2f4e6dbaf5b5dae...308eb0faf0e6569be41539\\n<<---- model config JSON\\n-rw-r--r--@ 1\\n8.2K\\na4b03d96571f0ad98b1253...328909bdc90e3f960823e5\\n<<---- License\\nThe following command prints the model’s configuration from the local copy of the\\nconfig file. It shows the model format, quantization, parameters, architecture, size, and\\nmore. Yours may have a different SHA and filename.\\n$ cat ~/.docker/models/blobs/sha256/22273fdf4e6dbaf...af0e6569be41539 | jq\\n{\\n\"config\": {\\n\"format\": \"gguf\",\\n\"quantization\": \"IQ2_XXS/Q4_K_M\",\\n\"parameters\": \"3.88 B\",\\n\"architecture\": \"gemma3\",\\n\"size\": \"2.31 GiB\"\\n},\\n\"descriptor\": {\\n\"created\": \"2025-03-26T09:57:32.086694+01:00\"\\n},\\n\"rootfs\": {\\n\"type\": \"rootfs\",\\n\"diff_ids\": [\\n\"sha256:09b370de51ad3bde8c3aea3559a769a59e7772e813667ddbafc96ab2dc1adaa7\",'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 154}, page_content='},\\n\"descriptor\": {\\n\"created\": \"2025-03-26T09:57:32.086694+01:00\"\\n},\\n\"rootfs\": {\\n\"type\": \"rootfs\",\\n\"diff_ids\": [\\n\"sha256:09b370de51ad3bde8c3aea3559a769a59e7772e813667ddbafc96ab2dc1adaa7\",\\n\"sha256:a4b03d96571f0ad98b1253bb134944e508a4e9b9de328909bdc90e3f960823e5\"\\n]\\n}\\n}\\nYou can see the same information with the docker model inspect command.\\nYou can also inspect the model’s GGUF file and license file. However, model files can be\\nlarge, and although they have a header with readable metadata, they also have a large\\nbody with the tensors that represent model parameters, including the weights and\\nbiases, which are not human-readable.\\nPackaging and storing models as OCI artifacts allows you to leverage the huge number\\nof existing public and private OCI registries that most companies already use to store all\\nof the following:\\n• Container images\\n• Signatures\\n• SBOMs\\n• OPA Policies'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 155}, page_content='10: Docker and AI\\n149\\n• Helm charts\\n• Wasm modules\\n• MCP tools\\nAdding AI models to this growing list reduces registry sprawl and makes AI models more\\naccessible to existing cloud-native tools and workflow pipelines.\\nTest your model\\nDMR offers two easy ways to test your models:\\n• The CLI\\n• Docker Desktop UI\\nThe CLI offers very basic testing capabilities with zero conversational history.\\nThe following example opens an interactive REPL (Read, Evaluate, Print, Loop) envi-\\nronment and asks the model two related questions. However, there’s no conversational\\nhistory, and it treats each question independently. I’ve clipped the responses as they can\\nbe quite long.\\n$ docker model run ai/gemma3:4B-Q4_K_M\\nInteractive chat mode started. Type \\'/bye\\' to exit.\\n> How long is a day on Mars?\\nA day on Mars, also known as a \"sol,\" is about **24 hours, 39 minutes, and 35 seconds** long...\\n> What about Venus?\\nOkay, let\\'s talk about Venus! It\\'s a truly fascinating and incredibly hostile planet, often'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 155}, page_content='> What about Venus?\\nOkay, let\\'s talk about Venus! It\\'s a truly fascinating and incredibly hostile planet, often\\ncalled Earth\\'s \"sister planet\" due to its similar size and composition. However, that\\'s\\nwhere the similarities largely end. Here\\'s a breakdown of key information about Venus:...\\nType /bye to return to your shell.\\nDocker Desktop offers a slightly better way to test.\\nOpen the Docker Desktop UI and click the Models tab in the left navigation bar. Click\\nthe model you want to test to open a chat session and then ask it the same questions.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 156}, page_content='10: Docker and AI\\n150\\nFigure 10.3 - Docker Desktop’s Model Chat Window\\nThis time, the environment has realized the two questions are related.\\nInspect the DMR API\\nDocker Model Runner exposes a set of native endpoints for model management and a\\nset of OpenAI-compatible endpoints for model interaction.\\nDMR endpoints\\n/models\\n<<---- GET\\n/models/create\\n<<---- POST\\n/models/{namespace}/{name}\\n<<---- GET and DELETE\\nOpenAI-compatible endpoints'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 157}, page_content='10: Docker and AI\\n151\\n/engines/llama.cpp/v1/models\\n<<---- GET\\n/engines/llama.cpp/v1/chat/completions\\n<<---- POST\\n/engines/llama.cpp/v1/completions\\n<<---- POST\\n/engines/llama.cpp/v1/embeddings\\n<<---- POST\\nLet’s craft an API request to DMR’s OpenAI-compatible chat/completions endpoint so\\nthat it asks the Gemma3 model we pulled earlier how long a Martian day is.\\nThe first thing we need to do is get the list of available models. We already pulled the\\nai/gemma3:4B-Q4_K_M, but it’s always worth querying DMR to ensure the OpenAI\\nendpoints refer to it by the same name.\\nRun the following curl command to get the list of local models and see their names.\\n$ curl -s localhost:12434/engines/v1/models | jq\\n{\\n\"object\": \"list\",\\n\"data\": [\\n{\\n\"id\": \"ai/gemma3:4B-Q4_K_M\",\\n\"object\": \"model\",\\n\"created\": 1742979452,\\n\"owned_by\": \"docker\"\\n}\\n]\\n}\\nGreat, DMR refers to it as ai/gemma3:4B-Q4_K_M.\\nNow, POST your question to DMR’s chat/completions endpoint.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 157}, page_content='\"object\": \"model\",\\n\"created\": 1742979452,\\n\"owned_by\": \"docker\"\\n}\\n]\\n}\\nGreat, DMR refers to it as ai/gemma3:4B-Q4_K_M.\\nNow, POST your question to DMR’s chat/completions endpoint.\\n$ curl -s http://localhost:12434/engines/v1/chat/completions \\\\\\n-H \"Content-Type: application/json\" \\\\\\n-d \\'{\\n\"model\": \"ai/gemma3:4B-Q4_K_M\",\\n\"messages\": [\\n{\\n\"role\": \"system\",\\n\"content\": \"Keep your responses to one sentence only.\"\\n},\\n{\\n\"role\": \"user\",\\n\"content\": \"How long is a day on Mars?\"\\n}\\n],\\n\"temperature\": 0.7,\\n\"max_tokens\": 500\\n}\\' | jq -r \\'.choices[0].message.content\\'\\nA day on Mars, also known as a sol, is approximately 24.6 hours long.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 158}, page_content='10: Docker and AI\\n152\\nIt worked. Let’s quickly step through the command.\\nThe curl command targets DMR’s /engines/v1/chat/completions endpoint. If your\\nDMR has multiple runtimes, you can target a specific one by including it between the\\nbase path and API version. For example, you’d use the following path to explicitly call\\nthe llama.cpp runtime:\\n/engines/llama.cpp/v1/chat/completions\\nThe -d flag indicates the data to send in the request body and includes all of the\\nfollowing:\\n• model: This is the name of the desired model\\n• messages: Includes the system prompt telling the model to give short answers, as\\nwell as the user prompt with the question\\n• temperature: Tells the model how creative to be (usually between 0-1, with 0\\nbeing predictable and 1 being very creative)\\n• max_tokens: Restricts the length of responses\\nNow that you understand how DMR works, let’s see how to integrate it with a Com-\\npose-based chatbot app.\\nUse Docker Model Runner with Compose'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 158}, page_content='• max_tokens: Restricts the length of responses\\nNow that you understand how DMR works, let’s see how to integrate it with a Com-\\npose-based chatbot app.\\nUse Docker Model Runner with Compose\\nIn this section, you’ll use Compose to deploy a chatbot app that uses DMR as its\\ninference server.\\nYou’ll need Docker Desktop v4.41 or newer with Docker Model Runner enabled.\\nThe app is a multi-tier application with three services:\\n• frontend: Chat interface\\n• backend: Backend API\\n• dmr: Model server (DMR)\\nFigure 10.4 shows the chatbot architecture. The fronted service implements a Remix-\\nbased chatbot interface that you access on port 3000. This communicates with a FastAPI\\nbackend server over the project’s default network on port 8000. The backend API\\nserver calls DMR’s OpenAI-compatible chat/completions API with streaming enabled\\nand streams responses to the frontend.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 159}, page_content='10: Docker and AI\\n153\\nFigure 10.4 - Chatbot architecture\\nThe app’s Compose file is in the dmr folder and defines the three services from Figure\\n10.4.\\nservices:\\nfrontend:\\n----┐\\nbuild: ./frontend\\n|\\nports:\\n|\\n- \"3000:3000\"\\n| Frontend\\nenv_file:\\n| service\\n- .env\\n|\\ndepends_on:\\n|\\n- backend\\n----┘\\nbackend:\\n----┐\\nbuild: ./backend\\n|\\nports:\\n|\\n- \"8000:8000\"\\n| Backend\\nenv_file:\\n| service\\n- .env\\n|\\ndepends_on:\\n|\\n- dmr\\n----┘\\ndmr:\\n----┐\\nprovider:\\n|\\ntype: model\\n| DMR\\noptions:\\n|\\nmodel: ${LLM_MODEL_NAME} ----┘\\nLet’s step through the file.\\nThe frontend service builds an image from the Dockerfile and application code in the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 160}, page_content='10: Docker and AI\\n154\\n./frontend folder, exposes port 3000, loads environment variables from the local .env\\nfile, and will only start when the backend service is running.\\nThe backend service builds an image from the Dockerfile and code in the ./backend\\nfolder, listens on port 8000, loads the same environment variables from the same .env\\nfile, and will only start when the dmr service is running.\\nThe dmr service declares Docker Model Runner as part of the Compose app and uses\\nthe provider extension to tell DMR to download and use the model defined in the LLM_-\\nMODEL_NAME variable from the local .env file. You need Docker Compose v2.35 or newer\\nto leverage DMR like this.\\nThe local .env file defines the following two variables that tell the app how to connect to\\nDMR and which model to use:\\nMODEL_HOST=http://model-runner.docker.internal/engines/v1\\nLLM_MODEL_NAME=ai/gemma3:4B-Q4_K_M\\nYou can integrate with remote DMR instances by changing the MODEL_HOST variable'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 160}, page_content='MODEL_HOST=http://model-runner.docker.internal/engines/v1\\nLLM_MODEL_NAME=ai/gemma3:4B-Q4_K_M\\nYou can integrate with remote DMR instances by changing the MODEL_HOST variable\\nto point to your remote DMR instance like this: http://<host>:12434/engines/v1.\\nHowever, the provider extension doesn’t support remote instances yet, so you won’t be\\nable to declare dependencies on DMR. This may change in the future.\\nWhen you deploy the app, Docker will automatically create a network for the project\\ncalled default, build the images for the frontend and backend, and start all three ser-\\nvices. The dependencies ensure the dmr service will start first, then the backend service,\\nand finally the frontend. Docker will connect the frontend and backend services to\\nthe project’s default network so the frontend can send requests to the backend on port\\n8000. The backend will connect to the dmr service (the local instance of Docker Model'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 160}, page_content='the project’s default network so the frontend can send requests to the backend on port\\n8000. The backend will connect to the dmr service (the local instance of Docker Model\\nRunner) via HTTP requests to http://model-runner.docker.internal/engines/v1.\\nThis is a special hostname that all containers can use to access DMR.\\nChange into the dmr folder and run the following commands.\\nDeploy the app.\\n$ docker compose up --build --detach\\n[+] Building 3.3s (25/25) FINISHED\\n[+] Running 6/6\\n- backend\\nBuilt\\n0.0s\\n- frontend\\nBuilt\\n0.0s\\n- Network dmr_default\\nCreated\\n0.0s\\n- dmr\\nCreated\\n1.5s\\n- Container dmr-backend-1\\nStarted\\n0.4s\\n- Container dmr-frontend-1\\nStarted\\n0.2s\\nYou can see it’s built the frontend and backend images, created the project’s network,\\nand started the services in the expected order.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 161}, page_content='10: Docker and AI\\n155\\nOpen your browser to http://localhost:3000 and ask your chatbot some questions.\\nFigure 10.5 - Working chatbot\\nThe example proves the chatbot maintains a conversation history and infers context\\nfrom previous questions.\\nThe small text below the message box displays the name of the model DMR is using and\\nwill match the value of the LLM_MODEL_NAME environment variable in the .env file.\\nCongratulations. You used Compose to deploy a chatbot app that leverages an LLM via\\nDocker Model Runner!\\nUse Docker Model Runner with Open WebUI\\nIn theory, any OpenAI-compatible third-party app can leverage Docker Model Runner\\nvia its OpenAI-compatible endpoints.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 162}, page_content='10: Docker and AI\\n156\\nIn this section, you’ll combine Open WebUI19 with Docker Model Runner to create a\\npowerful and customizable local chatbot experience that looks and feels like commer-\\ncial-grade chatbots such as ChatGPT and Claude.\\nYou’ll need Docker Desktop v4.41 or newer with Docker Model Runner enabled. The\\nexample uses the gemma3:4B-Q4_K_M that you pulled earlier. If you haven’t pulled\\nthe model, DMR will pull it when you deploy the app. You can also experiment with\\ndifferent models.\\nYou’ll complete all of the following steps:\\n1. Check DMR status and local models\\n2. Install Open WebUI as a container\\n3. Connect to Open WebUI and use it\\nCheck DMR status and pull models\\nRun the following command to check the status of DMR.\\n$ docker model status\\nDocker Model Runner is running\\nStatus:\\nllama.cpp: running llama.cpp latest-metal (sha256:af30fb4847b...)\\nDownload a small quantized Qwen model.\\n$ docker model pull ai/qwen3:0.6B-Q4_K_M\\nDownloaded: 0.00 MB\\nModel pulled successfully'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 162}, page_content='Status:\\nllama.cpp: running llama.cpp latest-metal (sha256:af30fb4847b...)\\nDownload a small quantized Qwen model.\\n$ docker model pull ai/qwen3:0.6B-Q4_K_M\\nDownloaded: 0.00 MB\\nModel pulled successfully\\nList models to make sure you have at least two models so you can switch between them\\nin the app.\\n$ docker model ls\\nMODEL NAME\\nPARAMS\\nQUANTIZATION\\nARCH\\nMODEL ID\\nSIZE\\nai/gemma3:4B-Q4_K_M\\n3.88 B\\nIQ2_XXS/Q4_K_M\\ngemma3\\n0b329b335467\\n2.3G\\nai/qwen3:0.6B-Q4_K_M\\n751.63 M\\nIQ2_XXS/Q4_K_M\\nqwen3\\n18e5114fc13b\\n456.11 MiB\\nFeel free to pull additional models.\\n19https://www.openwebui.com/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 163}, page_content='10: Docker and AI\\n157\\nInstall Open WebUI as a container\\nOpen WebUI is a popular AI platform that integrates with Ollama and OpenAI-\\ncompatible model servers to create powerful chatbot experiences. You can install it via\\npip or as a Docker container. We’ll use the following Compose file from the openwebui\\nfolder to install it as a container.\\nvolumes:\\nopen-webui:\\nservices:\\nopen-webui:\\nimage: ghcr.io/open-webui/open-webui:main\\nenvironment:\\n- DEFAULT_MODELS=${MODEL_NAME}\\n- WEBUI_AUTH=False\\n- OPENAI_API_KEY=${OPENAI_KEY}\\n- OPENAI_API_BASE_URL=${MODEL_HOST}\\nvolumes:\\n- open-webui:/app/backend/data\\nports:\\n- \"3001:8080\"\\nrestart: always\\ndepends_on:\\n- dmr\\ndmr:\\nprovider:\\ntype: model\\noptions:\\nmodel: ${MODEL_NAME}\\nThe open-webui service pulls the official Open WebUI image from GitHub Container\\nRegistry, configures it with four environment variables, mounts a volume so you don’t\\nlose your configuration every time you restart it, exposes the web interface on port 3001,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 163}, page_content='Registry, configures it with four environment variables, mounts a volume so you don’t\\nlose your configuration every time you restart it, exposes the web interface on port 3001,\\nand declares a dependency on the dmr service.\\nThe dmr service tells Docker Model Runner to use the model defined in the MODEL_NAME\\nvariable. In our example, this will be the Qwen model you pulled earlier and DMR will\\nautomatically pull it if needed.\\nThere’s a local .env file defining the following variables:\\n• MODEL_HOST: Docker Model Runner base URL\\n• MODEL_NAME: Default model to use\\n• OPENAI_KEY: OpenAI API key (set to “na” as DMR doesn’t require it)\\nChange into the openwebui directory and deploy the app with the following command.\\nThe Open WebUI image is nearly 6GB in size and may take a while to download on a\\nslow internet connection.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 164}, page_content='10: Docker and AI\\n158\\n$ docker compose up\\n[+] Running 16/16\\n- open-webui Pulled\\n227.8s\\n<Snip>\\n[+] Running 4/4\\n- Network open-webui_default\\nCreated\\n0.0s\\n- Volume \"open-webui_open-webui\"\\nCreated\\n0.0s\\n- dmr\\nCreated\\n1.3s\\n- Container open-webui-open-webui-1\\nStarted\\n1.7s\\nAttaching to open-webui-1\\nopen-webui-1\\n| Loading...\\n<Snip>\\nFetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 278481.02it/s]\\n<Snip>\\nThe first time you start Open WebUI it downloads important files before serving the\\napp. You need to wait for these to download before connecting to the app.\\nCongratulations. You’ve installed Open WebUI as a Docker container and can connect\\nto it on http://localhost:3001. A 500: Internal Error message usually means\\nOpen WebUI is still downloading files in the background.\\nConnect to Open WebUI and use it\\nOpen a new browser tab to http://localhost:3001.\\nYou’ll need to create an admin account the first time you access it. Don’t worry though,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 164}, page_content='Connect to Open WebUI and use it\\nOpen a new browser tab to http://localhost:3001.\\nYou’ll need to create an admin account the first time you access it. Don’t worry though,\\neverything is stored locally and nothing leaves your computer.\\nOnce you’ve created your account, you’ll be automatically logged in and will see the\\nOpen WebUI interface as shown in Figure 10.6'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 165}, page_content='10: Docker and AI\\n159\\nFigure 10.6 - Open WebUI interface\\nOpen WebUI is a powerful tool, and I encourage you to investigate its features after\\nyou’ve completed the chapter. For now, Figure 10.6 highlights three important elements.\\nClicking the model selector dropdown lets you select from the models you’ve already\\ndownloaded to Docker Model Runner. If you download new models, they’ll appear in\\nthe list. Changing the model will update the active model shown in the middle of the\\nscreen. Finally, you talk with the chatbot via the prompt box.\\nHowever, before asking your chatbot any questions, I recommend you give it a cus-\\ntomized system prompt so that it responds in a way that’s useful to you. A system prompt\\nis a set of instructions you give the AI model to help it respond in ways that are helpful\\nto you.\\nTo do this, click your user in the bottom left corner, choose Settings > General, and\\nenter a new system prompt. I used the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 165}, page_content='to you.\\nTo do this, click your user in the bottom left corner, choose Settings > General, and\\nenter a new system prompt. I used the following:\\nGive simple answers. Limit responses to two sentences. Never ask if you can help with anything\\nelse.\\nBe sure to click Save to apply your changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 166}, page_content='10: Docker and AI\\n160\\nNow, ask your chatbot some questions to see if it’s useful and maintains a conversational\\nhistory.\\nFigure 10.7 shows a very brief conversation asking how far away the moon is and then\\nthe sun. I phrased the second question to test if the chatbot is intelligent enough to rec-\\nognize it as a follow-up to the previous question. You can see the chatbot remembered\\nthe first question and gave a contextually appropriate answer for the second question.\\nFigure 10.7 - Conversational history\\nYou can also see that Open WebUI saved the conversation in the left navigation pane\\nand that the prompt box has options for executing code, voice recording, and much\\nmore. As previously mentioned, I recommend you play around with Open WebUI’s\\nadvanced features, as you can easily create a powerful local chatbot with many of the\\nfeatures of ChatGPT, Claude, and other advanced chatbot apps.\\nRunning models in containers'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 166}, page_content='advanced features, as you can easily create a powerful local chatbot with many of the\\nfeatures of ChatGPT, Claude, and other advanced chatbot apps.\\nRunning models in containers\\nRunning models in containers is no longer recommended, and I’ve only included this\\nshort section for reference. I do not recommend you complete the example.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 167}, page_content='10: Docker and AI\\n161\\nAs previously stated, AI models run fastest on AI acceleration hardware like GPUs and\\nNPUs. However, exposing them inside containers is very difficult. So much so that\\nDocker containers can only access modern CUDA-capable NVIDIA GPUs, and even\\nthese require the complex installation of the NVIDIA Container Toolkit.\\nIn summary, if you run Docker on a host with CUDA-capable NVIDIA GPUs and install\\nthe NVIDIA Container Toolkit, you can run models inside containers and leverage\\nthe GPUs. If your host has NPUs, TPUs, or GPUs from another manufacturer, models\\ninside containers will run slowly on the host’s CPUs.\\nThe ai-compose folder has two Compose files to deploy a three-tier chatbot like the\\none you deployed in the Use Docker Model Runner with Compose section. The biggest\\ndifference is that this version talks to a containerized Ollama server instead of Docker\\nModel Runner. The two Compose files are:\\n• compose.yaml: Runs the model on CPUs'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 167}, page_content='difference is that this version talks to a containerized Ollama server instead of Docker\\nModel Runner. The two Compose files are:\\n• compose.yaml: Runs the model on CPUs\\n• gpu-compose.yaml: Runs the model on NVIDIA GPUs if you have NVIDIA GPUs\\nand have installed the NVIDIA Container Toolkit (outside of the scope of this\\nbook)\\nThe ollama service, shown below, replaces Docker Model Runner. It pulls a pre-created\\nimage that runs an Ollama server, executes a script to pull a Mistral model into the\\ncontainer, and provides inference. It stores the pulled model in the volume, defines a\\nhealthcheck, and sets some resource limits.\\nollama:\\nimage: nigelpoulton/gsd-book:chat-model\\nvolumes:\\n- ollama_data:/root/.ollama\\nenvironment:\\n- MODEL=${MODEL:-mistral:latest}\\nhealthcheck:\\n<Snip>\\ndeploy:\\nresources:\\nlimits:\\nmemory: 8G\\nYou can start and manage the app with the usual docker compose commands. However,\\nthe app maps to port 3000 on your host and will conflict with the chatbot from earlier in'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 167}, page_content='limits:\\nmemory: 8G\\nYou can start and manage the app with the usual docker compose commands. However,\\nthe app maps to port 3000 on your host and will conflict with the chatbot from earlier in\\nthe chapter. If you want to run this app (not recommended), manually edit the Compose\\nfile to map it to a different port.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 168}, page_content='10: Docker and AI\\n162\\nClean up\\nCongratulations on completing the examples and running local models with Docker\\nModel Runner.\\nIf you followed the examples, you’ll have all of the following running and downloaded.\\n• Docker Model Runner and at least one downloaded model\\n• Two Compose apps (Open WebUI chatbot, and Remix chatbot)\\nRunning the following command from within the openwebui directory will delete the\\nOpen WebUI chatbot app along with its images, networks, and volumes. It will not stop\\nDMR or delete any local models.\\n$ docker compose down --rmi all --volumes\\n[+] Running 2/2\\n- Container openwebui-open-webui-1\\nRemoved\\n1.4s\\n- dmr\\nRemoved\\n0.0s\\n- Image ghcr.io/open-webui/open-webui:main\\nRemoved\\n1.0s\\n- Volume openwebui_open-webui\\nRemoved\\n0.1s\\n- Network openwebui_default\\nRemoved\\n0.2s\\nDon’t worry about the line saying dmr is removed. It’s removing the dmr Compose\\nservice and not disabling Docker Model Runner on the host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 168}, page_content='Removed\\n0.1s\\n- Network openwebui_default\\nRemoved\\n0.2s\\nDon’t worry about the line saying dmr is removed. It’s removing the dmr Compose\\nservice and not disabling Docker Model Runner on the host.\\nChange into the dmr directory and run the same command if you want to delete the\\nRemix chatbot app from the Use Docker Model Runner with Compose section.\\nYou can list your downloaded models with docker model ls and delete them with\\ndocker model rm.\\nFinally, you can disable DMR in Docker Desktop by going to the Settings page, clicking\\nFeatures in development, and then unchecking the Enable Docker Model Runner\\ncheckbox.\\nDocker Model Runner – The commands\\n• docker model status shows if DMR is running and prints basic runtime\\ninformation\\n• docker model pull downloads models from Docker Hub or other OCI-compliant\\nregistries that support models as a mediaType\\n• docker model push pushes models to Docker Hub and other OCI-compliant\\nregistries that support models as a mediaType'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 169}, page_content='10: Docker and AI\\n163\\n• docker model ls lists the models pulled to your local model store\\n• docker model inspect shows detailed model information, including tag, format,\\narchitecture, quantization, and more\\n• docker model rm deletes models from your local store\\nChapter Summary\\nIn this chapter, you learned that Docker Model Runner (DMR) is the best way to run\\nlocal AI models with Docker. It runs as a host process outside of the Docker Engine and\\nexecutes models directly on host hardware rather than inside containers. This gives\\nit access to a wider range of AI acceleration hardware than containers. It dynamically\\nloads and unloads models based on demand and serves them via OpenAI-compatible\\nendpoints. It has a pluggable runtime layer that defaults to llama.cpp.\\nRight now, DMR is a feature of Docker Desktop and works on Mac and Windows.\\nHowever, it will soon be integrated with Docker CE so that we can use it on Linux and\\nas part of CI/CD pipelines.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 169}, page_content='Right now, DMR is a feature of Docker Desktop and works on Mac and Windows.\\nHowever, it will soon be integrated with Docker CE so that we can use it on Linux and\\nas part of CI/CD pipelines.\\nDMR is tightly integrated with the Docker CLI, the Docker API, Docker Hub, Docker\\nCompose, the Docker MCP Toolkit, and more. You learned how to pull models from\\nDocker Hub, list and inspect models, run models, and integrate DMR with Compose\\nand 3rd-party off-the-shelf apps.\\nYou can still run model servers like Ollama inside of containers, but these will usually\\nbe slower than DMR as they have access to a smaller pool of supported AI acceleration\\nhardware.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 170}, page_content='11: Docker and Wasm\\nWasm (WebAssembly) is driving the third wave of cloud computing, and Docker is\\nevolving to take advantage.\\nWe built the first wave on virtual machines (VMs), the second on containers, and\\nwe’re building the third on Wasm. Each wave drives smaller, faster, and more secure\\nworkloads, and all three are working together to drive the future of cloud computing.\\nIn this chapter, you’ll write a simple Wasm application and use Docker to containerize\\nand run it in a container. The goal is to introduce you to Wasm and show you how easy\\nit is to work with Docker and Wasm together.\\nThe terms Wasm and WebAssembly mean the same thing, and we’ll use the term Wasm.\\nI’ve divided the chapter as follows:\\n• Pre-reqs\\n• Intro to Wasm\\n• Write a Wasm app\\n• Containerize a Wasm app\\n• Deploy a Wasm app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 171}, page_content='11: Docker and Wasm\\n165\\nPre-reqs\\nYou’ll need all of the following if you plan on following along:\\n• Docker Desktop 4.37+ with Wasm enabled\\n• Rust 1.82+ with the Wasm target installed\\n• Spin 3.1+\\nAt the time of writing, support for Wasm is a beta feature in Docker Desktop and doesn’t\\nwork with Multipass Docker VMs. This may change in the future. It also means there’s a\\nhigher risk of bugs. I’ve tested the examples in this chapter on Docker Desktop 4.37.0.\\nConfigure Docker Desktop for Wasm\\nOpen the Docker Desktop UI, click the Settings icon at the top right, and make sure Use\\ncontainerd for pulling and storing images is selected on the General tab. Next, click\\nthe Features in development tab, select the Enable Wasm option and click the blue\\nApply & restart button.\\nfigure 11.2 shows some of the settings.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 172}, page_content=\"11: Docker and Wasm\\n166\\nFigure 11.2 - Docker Desktop Wasm settings\\nInstall Rust and configure for Wasm\\nSearch the web for how to install Rust and follow the instructions for your platform.\\nOnce you’ve installed Rust, run the following command to install the wasm32-wasip1\\ntarget so that Rust can compile to Wasm.\\n$ rustup target add wasm32-wasip1\\ninfo: downloading component 'rust-std' for 'wasm32-wasip1'\\ninfo: installing component 'rust-std' for 'wasm32-wasip1'\\nInstall Spin\\nSpin is a Wasm framework and runtime that makes building and running Wasm apps\\neasy.\\nSearch the web for how to install Fermyon spin and follow the instructions for your\\nsystem.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 173}, page_content='11: Docker and Wasm\\n167\\nRun the following command to verify the installation.\\n$ spin --version\\nspin 3.1.0 (1aa89da 2024-12-18)\\nYou’re ready to build and run Wasm apps on your local machine.\\nIntro to Wasm and Wasm containers\\nWasm is a new type of application that is smaller, faster, and more portable than tradi-\\ntional Linux containers. However, traditional Linux containers can do a lot more than\\nWasm apps. For example, Wasm apps are currently great for AI workloads, serverless\\nfunctions, plugins, and edge devices, but not so good for complex networking or heavy\\nI/O.\\nHowever, Wasm is evolving fast and may become better at other workloads in the\\nfuture.\\nDigging a little deeper…\\nAs we’re about to see, Wasm is a new virtual machine architecture that programming\\nlanguages compile to. So, instead of compiling apps to Linux on ARM or Linux on\\nAMD, you compile them to Wasm and they’ll run on any system with a Wasm runtime.\\nFortunately, Docker Desktop ships with several Wasm runtimes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 173}, page_content='AMD, you compile them to Wasm and they’ll run on any system with a Wasm runtime.\\nFortunately, Docker Desktop ships with several Wasm runtimes.\\nRun the following command to see the list of Wasm runtimes installed as part of your\\nDocker Desktop environment. The first time you run the command, it will download\\nthe image.\\n$ docker run --rm -i --privileged --pid=host jorgeprendes420/docker-desktop-shim-manager:latest\\nio.containerd.wasmtime.v1\\nio.containerd.wws.v1\\nio.containerd.slight.v1\\nio.containerd.wasmer.v1\\nio.containerd.spin.v2\\nio.containerd.lunatic.v1\\nio.containerd.wasmedge.v1\\nMy installation has seven Wasm runtimes, including the io.containerd.spin.v2\\nruntime we’ll use in the examples.\\nThese Wasm runtimes allow containerd to deploy and manage Wasm containers. A Wasm\\ncontainer is a Wasm binary running inside a minimal scratch container so that you can\\nbuild, ship, and run them with familiar Docker tools such as the docker run command\\nand Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 173}, page_content='container is a Wasm binary running inside a minimal scratch container so that you can\\nbuild, ship, and run them with familiar Docker tools such as the docker run command\\nand Docker Hub.\\nTalk is cheap, though. Let’s see it in action.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 174}, page_content='11: Docker and Wasm\\n168\\nWrite a Wasm app\\nIn this step, you’ll use spin to create a simple web server and compile it as a Wasm app.\\nIn a later step, you’ll build, share, and run the app as a Wasm container.\\nChange into a new directory and then run the following command to create a new\\nWasm app called hello-world. Respond to the prompts as shown in the example.\\n$ spin new hello-world -t http-rust\\nDescription: Wasm app\\nHTTP path: /hello\\nThe command creates a new hello-world directory and scaffolds a simple Rust-based\\nweb app. Change into this directory and inspect the app files. If you don’t have the tree\\ncommand, you can run an ls -l for similar results.\\n$ cd hello-world\\n$ tree\\n.\\n├──Cargo.toml\\n├──spin.toml\\n└──src\\n└──lib.rs\\nWe’re only interested in the spin.toml and src/lib.rs files.\\nEdit the src/lib.rs file and change the text inside the double quotes as shown in the\\nfollowing snippet. This configures the app to display Docker loves Wasm.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 174}, page_content='Edit the src/lib.rs file and change the text inside the double quotes as shown in the\\nfollowing snippet. This configures the app to display Docker loves Wasm.\\nuse spin_sdk::http::{IntoResponse, Request, Response};\\n<Snip>\\nOk(http::Response::builder()\\n.status(200)\\n.header(\"content-type\", \"text/plain\")\\n.body(\"Docker loves Wasm\")?)\\n<<---- Change text inside quotes\\n.build())\\n}\\nOnce you’ve saved your changes, run a spin build command to compile the app as a\\nWasm binary.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 175}, page_content='11: Docker and Wasm\\n169\\n$ spin build\\nBuilding component hello-world with `cargo build --target wasm32-wasip1 --release`\\n<Snip>\\nFinished building all Spin components\\nIf you look at the first line of the output, you’ll see it’s running a more complex cargo\\nbuild command that compiles the app as a Wasm binary.\\nRun another tree command to see the Wasm binary.\\n$ tree\\n<Snip>\\n└──target\\n└──wasm32-wasip1\\n└──release\\n└──hello_world.wasm\\nThe output is much longer this time, and I’ve trimmed the example in the book so you\\nonly see the hello_world.wasm binary. This is the Wasm app, and it will run on any\\nsystem with the spin Wasm runtime.\\nYou’ll containerize the app in the next section, but you should test it works before\\nproceeding.\\nRun a spin up command to start the app using the local spin runtime you installed\\nearlier.\\n$ spin up\\nLogging component stdio to \".spin/logs/\"\\nServing http://127.0.0.1:3000\\nAvailable Routes:\\nhello-world: http://127.0.0.1:3000/hello'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 175}, page_content='earlier.\\n$ spin up\\nLogging component stdio to \".spin/logs/\"\\nServing http://127.0.0.1:3000\\nAvailable Routes:\\nhello-world: http://127.0.0.1:3000/hello\\nPoint your browser to http://127.0.0.1:3000/hello and make sure the app works.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 176}, page_content='11: Docker and Wasm\\n170\\nFigure 11.3 - Wasm app running locally\\nCongratulations. You just built a simple web server, compiled it to Wasm, and executed\\nit locally using spin! In the next section, you’ll containerize it and run it in Docker.\\nPress Ctrl-C to kill the app.\\nContainerize a Wasm app\\nDocker Desktop lets you containerize Wasm apps so you can use familiar Docker tools\\nto push and pull them to OCI registries and run them inside containers.\\nAs always, you need a Dockerfile that tells Docker how to package the app as an image.\\nCreate a new file called Dockerfile in your current directory and populate it with the\\nfollowing three lines.\\nFROM scratch\\nCOPY /target/wasm32-wasip1/release/hello_world.wasm .\\nCOPY spin.toml .\\nThe file references the scratch empty base image because Wasm containers don’t need a\\nLinux OS.\\nThe two COPY instructions copy the hello_world.wasm Wasm app and the spin.toml\\nfile into the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 176}, page_content='The file references the scratch empty base image because Wasm containers don’t need a\\nLinux OS.\\nThe two COPY instructions copy the hello_world.wasm Wasm app and the spin.toml\\nfile into the image.\\nIf you look closely, you’ll see that the spin.toml file expects the Wasm app to be in the\\ntarget/wasm32-wasip1/release/ directory. However, the second COPY instruction'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 177}, page_content='11: Docker and Wasm\\n171\\nplaces it in the root folder. This means we’ll need to update the spin.toml file so\\nit knows where to find the app after the Dockerfile copies it into the image’s root\\ndirectory.\\nEdit the spin.toml file and remove the leading path for the source line as shown.\\n<Snip>\\n[component.hello-world]\\nsource = \"hello_world.wasm\"\\n<<---- Remove any leading directories so it looks like this\\n<Snip>\\nSave your changes.\\nRun the following command to containerize the Wasm app. Be sure to tag the image\\nwith your own Docker Hub username instead of mine.\\n$ docker build \\\\\\n--platform wasi/wasm \\\\\\n--provenance=false \\\\\\n-t nigelpoulton/ddd-book:wasm .\\nThe --platform wasi/wasm flag sets the image as a Wasm image.\\nSome older versions of Docker have an older builder and will fail. If this happens, try\\nrunning the same command, but change the first line to docker buildx build \\\\.\\nList the images on your system.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nwasm'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 177}, page_content='running the same command, but change the first line to docker buildx build \\\\.\\nList the images on your system.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nwasm\\n7b55889f1006\\n28 seconds ago\\n104kB\\nSee how the Wasm image looks like a regular image, just smaller.\\nYou can push and pull the image to Docker Hub and other OCI registries as normal.\\nThe following command pushes the image to one of my repos in Docker Hub. Be sure to\\ntag the image with your own Docker username.\\n$ docker push nigelpoulton/ddd-book:wasm\\nThe push refers to repository [docker.io/nigelpoulton/ddd-book]\\n301823195c36: Pushed\\n8966226af76a: Pushed\\nwasm: digest: sha256:7b55889f1006285ed6c394dcc7a56aca8955c107587b2216340e592299b8ae4c size: 695'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 178}, page_content='11: Docker and Wasm\\n172\\nIf you look at Docker Hub, you can see it’s recognized it as a wasi/wasm image. You’ll\\nalso see there’s no vulnerability analysis data. This is because image scanning tools can’t\\nanalyze Wasm images yet.\\nFigure 11.4 - Wasm image on Docker Hub\\nRun a Wasm container\\nNow that you’ve packaged the Wasm app as an OCI image and pushed it to a registry,\\nyou can run it as a container.\\nThe following command runs it in a new container called wasm-ctr and maps it to\\nport 5556 on your Docker host. The --runtime flag makes sure Docker executes the\\ncontainer with the spin Wasm runtime. Older versions of Docker Desktop may not have\\nthe spin runtime and will fail.\\n$ docker run -d --name wasm-ctr \\\\\\n--runtime=io.containerd.spin.v2 \\\\\\n--platform=wasi/wasm \\\\\\n-p 5556:80 \\\\\\nnigelpoulton/ddd-book:wasm /\\nYou can check it’s running with a regular docker ps command.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 179}, page_content='11: Docker and Wasm\\n173\\nConnect your browser to http://localhost:5556/hello to see the app.\\nFigure 11.5 - Wasm app running in container\\nCongratulations, your Wasm app is running inside a Wasm container.\\nClean up\\nRun the following commands to delete the container and the local image. Use your own\\nimage name when deleting the image.\\n$ docker rm wasm-ctr -f\\nwasm-ctr\\n$ docker rmi nigelpoulton/ddd-book:wasm\\nUntagged: nigelpoulton/ddd-book:wasm\\nDeleted: sha256:7b55889f1006285ed6c394dcc7a56aca8955c107587b2216340e592299b8ae4c\\nYou’ll still have a copy of the image on Docker Hub and the spin app in your local\\nfilesystem. Feel free to delete these as well.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 180}, page_content='11: Docker and Wasm\\n174\\nChapter summary\\nIn this chapter, you containerized a Wasm app and ran it in a Wasm container.\\nWasm is a new technology driving a new wave of cloud computing. Wasm apps are\\nsmaller, faster, more secure, and more portable than traditional Linux containers.\\nHowever, they’re not as flexible. For example, at the time of writing, Wasm apps aren’t\\ngreat for apps with heavy I/O requirements or complex networking. This will change\\nquickly as the Wasm ecosystem is evolving fast.\\nFortunately, Docker already works with Wasm, and Docker Desktop ships with a\\nfew popular Wasm runtimes. This means you can use industry-standard tools such as\\ndocker build and docker run to containerize and run Wasm apps. You can even push\\nthem to OCI registries such as Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 181}, page_content='12: Docker Swarm\\nThis chapter that shows you how to deploy a multi-node Swarm cluster and how to run\\napps on it.\\nIt’s a smaller chapter than in previous editions because Swarm is declining in popularity\\nand is no longer core to modern Docker workflows. If you need more of a deep dive,\\nyou can access the longer version in the swarm-chapters folder of the book’s GitHub\\nrepo. I’ve rewritten this shorter chapter to make way for adding the Docker and AI\\nchapter without increasing the cost of the book.\\nI’ve divided this chapter as follows:\\n• Swarm primer\\n• Build a swarm\\n• Deploy a Swarm app\\nThroughout the chapter, we’ll use Swarm with a capital “S” to refer to the Docker Swarm\\norchestration technology, and we’ll use swarm with a lower case “s” to refer to a cluster\\nof Docker nodes.\\nSwarm primer\\nThe orchestration wars were back in the mid-2010s when technologies like Docker\\nSwarm, HashiCorp Nomad, Mesosphere DC/OS, and Kubernetes battled it out to see'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 181}, page_content='of Docker nodes.\\nSwarm primer\\nThe orchestration wars were back in the mid-2010s when technologies like Docker\\nSwarm, HashiCorp Nomad, Mesosphere DC/OS, and Kubernetes battled it out to see\\nwhich would be crowned the de facto container orchestration platform. Fast forward to\\nnow, and it’s clear that Kubernetes came out on top and has the largest and most vibrant\\necosystem. However, Docker Swarm continues to have small followings and can be\\nbetter than Kubernetes for certain use cases. For example, Docker Swarm can be a great\\nsolution for small businesses with small requirements that don’t need the steep learning\\ncurve and overheads of a full Kubernetes environment.\\nWith this in mind, Docker Swarm is two things:\\n1. A secure cluster of Docker nodes (swarm with a little “s”)\\n2. An intelligent application orchestrator (Swarm with a big “S”)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 182}, page_content='12: Docker Swarm\\n176\\nAs you’re about to see, a swarm is a cluster of Docker nodes with one or more manager\\nnodes and optional worker nodes. Managers run the control plane services that secure\\nthe cluster and provide the orchestration intelligence. Workers run user apps. Both\\ntypes of nodes can be physical machines, VMs, cloud instances, and more. The only\\nrequirements are that they run Docker and can communicate over reliable networks.\\nBy default, swarm managers run user apps and control plane services. This is fine for lab\\nenvironments, but you should probably dedicate them to control plane services in busy\\nproduction environments.\\nBuild a swarm\\nIn this section, you’ll build two or more Docker nodes into a highly available swarm.\\nI recommend you go to http://https://labs.play-with-docker.com/ and spin up a\\nfew Docker nodes to follow along. You can also use tools like Multipass and VirtualBox\\nto create local VMs and install Docker on them. However, I do not recommend Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 182}, page_content='few Docker nodes to follow along. You can also use tools like Multipass and VirtualBox\\nto create local VMs and install Docker on them. However, I do not recommend Docker\\nDesktop for this chapter as it only gives you a single Docker node.\\nI’ll build the swarm shown in Figure 12.1 with three managers and two workers.\\nYour swarm can be different, but you should consider the following for production\\nenvironments:\\n• Three managers spread across availability zones for high availability\\n• Enough workers to handle application requirements\\nFigure 12.1 - Five-node swarm'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 183}, page_content='12: Docker Swarm\\n177\\nI’ve configured DNS name resolution so that nodes can communicate via name, and I’ve\\nensured port 2377 isn’t blocked on my network.\\nYou’ll complete the following steps to build your swarm:\\n• Initialize the first swarm manager\\n• Add workers (optional)\\n• Add additional managers\\nIf you only have a small lab, you can build a swarm with just two managers.\\nInitialize your swarm\\nLog on to the node you want to make your first manager and run the following com-\\nmand. If the node has multiple IPs, you’ll be prompted to use the --advertise-addr flag.\\nIf this happens, use the node’s primary IP address.\\n$ docker swarm init\\nSwarm initialized: current node (b8slc7l29tgdetxgy8acy1k1q) is now a manager.\\nTo add a worker to this swarm, run the following command:\\ndocker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nCongratulations. You have a single-node swarm.\\nAdd workers\\nAdding worker nodes is optional, as your managers will also run user apps. Only add'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 183}, page_content='Congratulations. You have a single-node swarm.\\nAdd workers\\nAdding worker nodes is optional, as your managers will also run user apps. Only add\\nworkers if your lab has enough nodes and resources.\\nIf you want to add workers, copy the docker swarm join command from the previous\\noutput and paste it into the nodes you want as workers. Be sure to copy the entire\\ncommand, including the join token.\\nwrkr-1\\n$ docker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nThis node joined a swarm as a worker.\\nwrkr-2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 184}, page_content='12: Docker Swarm\\n178\\n$ docker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nThis node joined a swarm as a worker.\\nSwitch back to your manager node and run the following command to see your swarm.\\n$ docker node ls\\nMANAGER\\nENGINE\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nSTATUS\\nVERSION\\nb8slc7l29tgdetxgy8acy1k1q *\\nnode1\\nReady\\nActive\\nLeader\\n27.3.1\\nw3e321uxty2quuqnsk1w19kfc\\nnode4\\nReady\\nActive\\n27.3.1\\nkbodotf68tz8dne2ktk1g5mt4\\nnode5\\nReady\\nActive\\n27.3.1\\nGreat. You’ve got one manager and two workers. Managers have either Leader or\\nReachable in the MANAGER STATUS column, whereas workers leave this column empty.\\nAdd managers for high availability\\nMost production swarms run three managers for high availability. This means one\\nmanager can fail and Swarm operations will continue via the surviving managers.\\nHowever, this is cluster availability and not application availability. For example, if the\\nfailed manager was running the only instance of a database, that database will be\\nunavailable.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 184}, page_content='However, this is cluster availability and not application availability. For example, if the\\nfailed manager was running the only instance of a database, that database will be\\nunavailable.\\nRun the following command from your manager node to extract the command for\\nadding more managers.\\n$ docker swarm join-token manager\\nTo add a manager to this swarm, run the following command:\\ndocker swarm join --token SWMTKN-1-2f4s47lja0z1ddkgv...6ytm3qnq9bu8uei9stiu 172.31.40.192:2377\\nCopy the long docker swarm join command and run it on the nodes you want to add\\nas additional managers.\\nOnce you’ve added all your managers and workers, run another docker node ls to see\\nyour swarm. You can run it from any manager node.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 185}, page_content='12: Docker Swarm\\n179\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\nENGINE VER\\nb8slc7l29tgdetxgy8acy1k1q *\\nnode1\\nReady\\nActive\\nLeader\\n27.3.1\\ny43jr1d754pbjv3arlhpn9pqw\\nnode2\\nReady\\nActive\\nReachable\\n27.3.1\\nk1npnfxr7ykueac4jovmyiv0b\\nnode3\\nReady\\nActive\\nReachable\\n27.3.1\\nw3e321uxty2quuqnsk1w19kfc\\nnode4\\nReady\\nActive\\n27.3.1\\nkbodotf68tz8dne2ktk1g5mt4\\nnode5\\nReady\\nActive\\n27.3.1\\nNotice how one of the managers is showing as the Leader and the other two as Reach-\\nable. This is because Swarm operates an active/passive multi-manager high-availability\\nmodel where one manager controls the cluster and the others provide backup. The\\nasterisk (*) indicates the manager you executed the command from.\\nYour swarm is ready to run apps.\\nDeploy Swarm app\\nIn this section, you’ll deploy an app to your swarm and see Swarm’s orchestration\\ncapabilities. These include scheduling apps across cluster nodes, scaling apps up and\\ndown, self-healing from app failures, and performing rolling updates.\\nThe app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 185}, page_content='capabilities. These include scheduling apps across cluster nodes, scaling apps up and\\ndown, self-healing from app failures, and performing rolling updates.\\nThe app\\nFigure 12.2 shows the application you’ll deploy. It’s a multi-container microservices\\napplication with:\\n• Two services (web-fe and redis)\\n• An encrypted overlay network (counter-net)\\n• A volume (counter-vol)\\n• A published port (5001)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 186}, page_content='12: Docker Swarm\\n180\\nFigure 12.2 - The sample app\\nTerminology: Throughout the remainder of the chapter, we’ll use the\\nterm service to refer to the Docker service object that manages one or more\\nidentical containers in a Swarm app. We’ll use the terms container and replica\\ninterchangeably.\\nLog on to a swarm manager and clone the book’s GitHub repo.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nChange into the ddd-book/swarm-new directory.\\n$ cd ddd-book/swarm-new\\nThe application’s Compose file defines a network called counter-net, a volume called\\ncounter-vol, and two services called web-fe and redis.\\nI’ve annotated the listing to draw your attention to the major parts.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 187}, page_content='12: Docker Swarm\\n181\\nnetworks:\\n----┐\\ncounter-net:\\n|\\ndriver: overlay\\n| Deploy an encrypted overlay network called *counter-net*\\ndriver_opts:\\n|\\nencrypted: \\'yes\\'\\n----┘\\nvolumes:\\ncounter-vol:\\n<<--- Create a volume called *counter-vol*\\nservices:\\nweb-fe:\\n----┐\\nimage: nigelpoulton/ddd-book:swarm-app\\n|\\ncommand: python app.py\\nw\\ndeploy:\\ne\\nreplicas: 4\\nb\\n<<---- Deploy four replicas\\nupdate_config:\\n-\\n<<---- Next 3 lines define how to update the app\\nparallelism: 2\\nf\\n<<---- Update two replicas at a time\\ndelay: 10s\\ne\\n<<---- Wait 10 seconds after each pair\\nfailure_action: rollback\\n<<---- Rollback if there\\'s a failure\\nrestart_policy:\\ns\\ncondition: on-failure\\ne\\n<<---- Restart replicas if they fail\\ndelay: 5s\\nr\\n<<---- Wait five seconds between restart attempts\\nmax_attempts: 3\\nv\\n<<---- Only try three restarts\\nwindow: 120s\\ni\\n<<---- Give up after trying for two minutes\\nnetworks:\\nc\\n- counter-net\\ne\\n<<---- Attach to the *counter-net* network\\nports:\\n|\\n- \"5001:8080\"\\n----┘\\n<<---- Map the app to 5001 on the host\\nredis:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 187}, page_content='i\\n<<---- Give up after trying for two minutes\\nnetworks:\\nc\\n- counter-net\\ne\\n<<---- Attach to the *counter-net* network\\nports:\\n|\\n- \"5001:8080\"\\n----┘\\n<<---- Map the app to 5001 on the host\\nredis:\\n----┐\\n<<---- Redis service\\nimage: \"redis:alpine\"\\n|\\nnetworks:\\n|\\ncounter-net:\\n|\\n<<---- Join the *counter-net* network\\nvolumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\n<<---- Mount the *counter-vol* volume to\\ntarget: /app\\n----┘\\n<<---- /data in the container\\nLet’s step through it.\\nThe networks key defines an encrypted overlay network called counter-net, the\\nvolumes key defines a volume called counter-vol, and the services block defines two\\nservices.\\nThe web-fe service pulls an image from Docker Hub, sets the start command for\\neach replica, and tells Swarm to deploy four identical containers for this service. The\\ndeploy.update_config block tells Swarm how to perform updates whenever a new\\nimage or config change occurs. This file tells Swarm to update two replicas in parallel,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 187}, page_content='deploy.update_config block tells Swarm how to perform updates whenever a new\\nimage or config change occurs. This file tells Swarm to update two replicas in parallel,\\nwait 10 seconds before updating the next two, and perform a rollback if it encounters\\nfailures. The deploy.restart_policy block tells Swarm to restart replicas if they fail,\\nto wait five seconds after each restart attempt, to attempt a maximum of three restarts,\\nand to stop trying after two minutes. It joins all replicas to the counter-net network and\\nmaps port 8080 on each replica to 5001 on the host the replica is running on.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 188}, page_content='12: Docker Swarm\\n182\\nThe redis service pulls an image from Docker Hub, joins the counter-net network,\\nand mounts the counter-vol volume to /data in its container.\\nEncrypting the network keeps application traffic private but incurs a performance\\npenalty that varies based on factors such as traffic type and traffic flow. However, it’s\\nusually around 10%, but you should perform your own testing.\\nDeploy the app\\nA vital part of Swarm is the concept of desired state. This is jargon for what your app\\nshould look like and is defined in the Compose file. In our example, desired state can be\\nsummarised as four replicas of the web-fe service, a single replica of the redis service,\\nand all the networks, volumes, and port mappings.\\nYou’ll need to run the commands in this section from the ddd-book/swarm-new folder of\\nthe manager you downloaded the book’s GitHub repo to.\\nRun the following command to deploy the app and call it ddd.\\n$ docker stack deploy -c compose.yaml ddd'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 188}, page_content='the manager you downloaded the book’s GitHub repo to.\\nRun the following command to deploy the app and call it ddd.\\n$ docker stack deploy -c compose.yaml ddd\\nCreating network ddd_counter-net\\nCreating volume ddd_counter-vol\\nCreating service ddd_web-fe\\nCreating service ddd_redis\\nSwarm has deployed the app and observed state matches desired state — you asked for four\\nreplicas of the web-fe service and a single replica of the redis service, and that’s what\\nyou’ve got.\\nRun the following commands to confirm this.\\n$ docker stack ps ddd\\nDESIRED\\nCURRENT\\nID\\nNAME\\nIMAGE\\nNODE\\nDESIRED\\nSTATE\\npgeupeqyqg5t\\nddd_redis.1\\nredis:alpine\\nwrk2\\nRunning\\nRunning 8 min\\nqbtkiz1p9v1n\\nddd_web-fe.1\\nnigelpoulton/ddd-book:swarm-app\\nwrk1\\nRunning\\nRunning 8 min\\nwbs2ndy22xhh\\nddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nRunning\\nRunning 8 min\\nskqz1mbreluo\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 min\\nsg5u9b6t8m44\\nddd_web-fe.4\\nnigelpoulton/ddd-book:swarm-app\\nmgr3\\nRunning\\nRunning 8 min'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 188}, page_content='mgr1\\nRunning\\nRunning 8 min\\nskqz1mbreluo\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 min\\nsg5u9b6t8m44\\nddd_web-fe.4\\nnigelpoulton/ddd-book:swarm-app\\nmgr3\\nRunning\\nRunning 8 min\\n$ docker stack services ddd\\nID\\nNAME\\nMODE\\nREPLICAS\\nIMAGE\\nPORTS\\notr7927s9m1s\\nddd_redis\\nrepl\\n1/1\\nredis:alpine\\nrsm3x02o9fwc\\nddd_web-fe\\nrepl\\n4/4\\nnigelpoulton/ddd-book:swarm-app\\n*:5001->8080\\nIf you look closely, you’ll see that Swarm has evenly balanced the four web-fe replicas\\nacross your nodes. You can also see the web-fe service is publishing port 5001.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 189}, page_content='12: Docker Swarm\\n183\\nPoint your browser to the IP address of one of your Swarm nodes on port 5001.\\nFigure 12.3\\nManage the app\\nYou can manage Swarm apps in two ways:\\n• Imperatively\\n• Declaratively\\nThe imperative method is where you run Docker CLI commands to make changes. For\\nexample, you can use the docker service scale command to increase and decrease the\\nnumber of service replicas.\\nThe declarative method is the preferred method, where you make all changes via the\\nCompose file. For example, if you want to change the number of replicas for a service,\\nyou edit the Compose file and run another docker stack deploy command.\\nThe following example demonstrates why you should manage Swarm apps declaratively.\\nImagine you’ve deployed an app from a Compose file that defines reporting and catalog services.\\nIt’s currently running one replica of the reporting service, but it’s year-end and demand on the\\nreporting service has gone through the roof. A colleague decides to run an imperative docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 189}, page_content='It’s currently running one replica of the reporting service, but it’s year-end and demand on the\\nreporting service has gone through the roof. A colleague decides to run an imperative docker\\nservice scale command to increase the number of reporting replicas to 10. This fixes the\\nissue, but the observed state of the app no longer matches the desired state defined in its Compose\\nfile — the Compose file only defines one replica, but there are 10 on the cluster. Later in the\\nday, you roll out a new version of the catalog service by specifying a new image version in\\nthe Compose file and running a docker stack deploy command. This pushes the updated\\nCompose file to Swarm as your new desired state, and Swarm compares it to the observed state of'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 190}, page_content='12: Docker Swarm\\n184\\nthe cluster. When it does this, it sees you’ve requested a new version of the app and schedules the\\nupdates. However, it will also reduce the number of replicas from 10 down to 1, as the Compose\\nfile wasn’t used to increase the count to 10. This will cause the reporting service to start running\\nslowly again.\\nThis is why you should make all changes declaratively via your Compose files, and you\\nshould manage your Compose files in a version control system.\\nWith this in mind, let’s complete the following as a single task:\\n• Increase the number of web-fe replicas from 4 to 10\\n• Update the web-fe service to the newer swarm-appv2 image\\nYou know you should do this declaratively, so let’s edit the following lines in the Com-\\npose file.\\n<Snip>\\nservices:\\nweb-fe:\\nimage: nigelpoulton/ddd-book:swarm-appv2\\n<<---- changed to swarm-appv2\\ncommand: python app.py\\ndeploy:\\nreplicas: 10\\n<<---- Changed from 4 to 10\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 190}, page_content='pose file.\\n<Snip>\\nservices:\\nweb-fe:\\nimage: nigelpoulton/ddd-book:swarm-appv2\\n<<---- changed to swarm-appv2\\ncommand: python app.py\\ndeploy:\\nreplicas: 10\\n<<---- Changed from 4 to 10\\n<Snip>\\nSave your changes and redeploy the app. This will send the updated Compose file to the\\nswarm manager, and Swarm will roll out a new version of the web-fe service with all 10\\nreplicas running the new image.\\n$ docker stack deploy -c compose.yaml ddd\\nUpdating service ddd_web-fe (id: rsm3x02o9fwcftt3a87fqcabq)\\nUpdating service ddd_redis (id: otr7927s9m1s5mkz326243kv3)\\nRun a docker stack ps to see the rollout’s progress.\\n$ docker stack ps ddd\\nNAME\\nIMAGE\\nNODE\\nDESIRED\\nCURRENT STATE\\nddd_web-fe.1\\nnigelpoulton/ddd-book:swarm-app\\nwrk1\\nRunning\\nRunning 8 mins ago\\nddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-appv2\\nmgr1\\nRunning\\nRunning 13 secs ago\\n\\\\_ddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nShutdown\\nShutdown 26 secs ago\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 mins ago\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 190}, page_content='mgr1\\nRunning\\nRunning 13 secs ago\\n\\\\_ddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nShutdown\\nShutdown 26 secs ago\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 mins ago\\n<Snip>\\nI’ve trimmed the output, and I’ve only listed some of the replicas. However, you can see a\\nfew things.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 191}, page_content='12: Docker Swarm\\n185\\nSwarm has evenly balanced the six new replicas across both worker nodes (not shown in\\nthe book).\\nThe top line shows the ddd_web-fe.1 replica running the old image for the last 8\\nminutes. The next two lines show the ddd_web-fe.2 replica. You can see that the\\nold replica was running the old image and that it was shut down 26 seconds ago and\\nreplaced with a new replica running the new image. The new replica has been running\\nfor 13 seconds.\\nThe last line shows the ddd_web-fe.3 replica is still running the old version.\\nSwarm immediately adds the six new replicas, but honors the update settings in the\\ndeploy.update_config section of your Compose file for existing replicas. This means\\nit updates the four original replicas two at a time and waits 10 seconds before updating\\nanother two.\\nBefore moving on, it’s important to clarify the reconciliation process that just happened.\\nThe application was running four web-fe replicas, all based on the swarm-app image,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 191}, page_content='another two.\\nBefore moving on, it’s important to clarify the reconciliation process that just happened.\\nThe application was running four web-fe replicas, all based on the swarm-app image,\\nand this was recorded on the Swarm as desired state. We edited the Compose file and\\nchanged all web-fe replicas to use the newer swarm-appv2 image and increased the\\nreplica count from four to ten. We saved our changes and ran a docker stack deploy\\ncommand to push this new desired state to Swarm. Shortly after, Swarm compared\\nthe observed state of the cluster with the new desired state and noticed it had four\\nweb-fe replicas running the swarm-app image but should actually have ten web-fe\\nreplicas running the swarm-appv2 image. As such, it deleted the existing four replicas\\nand replaced them with ten new replicas. It even followed rules you defined in the\\ndeploy.update_config section of the Compose file.\\nRefresh your browser to see the updated version of the app.\\nFigure 12.4 - The updated app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 192}, page_content='12: Docker Swarm\\n186\\nCongratulations, you’ve deployed and managed a Swarm app.\\nClean up\\nIf you’ve been following along, you’ve deployed a Swarm app with two services, a\\nnetwork, and a volume.\\nRun the following command to delete the app. Be warned though, it deletes it without\\nrequesting confirmation.\\n$ docker stack rm ddd\\nRemoving service ddd_redis\\nRemoving service ddd_web-fe\\nRemoving network ddd_counter-net\\nThe command deleted the network and services, but not the volume. This is because\\nSwarm decouples volume lifecycles from containers and services.\\nRun the following command on the node that hosted the redis replica. It will delete the\\nvolume.\\n$ docker volume rm ddd_counter-vol\\nddd_counter-vol\\nYou can delete your Swarm by running a docker swarm leave command on all swarm\\nnodes. You should remove the leader node last, and you may have to use the --force\\nflag.\\nDocker Swarm – The Commands\\n• docker swarm init initializes a new Swarm and makes the node the first manager\\nof the Swarm.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 192}, page_content='flag.\\nDocker Swarm – The Commands\\n• docker swarm init initializes a new Swarm and makes the node the first manager\\nof the Swarm.\\n• docker stack deploy is the command you’ll run to deploy and update Swarm\\napps. You need to specify the Compose file and the name of the app.\\n• docker stack ls lists all Swarm apps and shows the number of services in each.\\n• docker stack ps gives you detailed information about a Swarm app. It tells you\\nwhich node each replica is running on, which images they’re based on, and shows\\nthe desired state and current state of each replica.\\n• docker stack services gives you a line of information for each application\\nservice and includes useful information such as replication mode, how many\\nreplicas, and port mappings.\\n• docker stack rm deletes a Swarm app and doesn’t ask for confirmation.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 193}, page_content='12: Docker Swarm\\n187\\nChapter Summary\\nDocker Swarm lets you group multiple Docker nodes into a secure, highly available\\ncluster and provides advanced application orchestration services similar to Kubernetes.\\nWorking with Swarm is a good way to kick-start your Kubernetes learning.\\nYou built a multi-node swarm, deployed an app to it, scaled the app, and performed a\\nlive rollout. And you did it all declaratively via a Compose file.\\nIf you want to learn Kubernetes, check out my Kubernetes books:\\n• Quick Start Kubernetes: The fastest way to master Kubernetes fundamentals.\\n• The Kubernetes Book: The best-selling Kubernetes book that goes into all the\\ndetail.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 194}, page_content='13: Docker Networking\\nIt’s always the network!\\nAny time we experience infrastructure issues, we always blame the network. One of the\\nreasons we do this is that networks are at the center of everything. With this in mind, it’s\\nimportant you have a strong understanding of Docker networking.\\nIn the early days of Docker, networking was hard. Fortunately, these days it’s almost a\\npleasure ;-)\\nThis chapter will get you up to speed with the fundamentals of Docker networking.\\nYou’ll learn all the theory behind the Container Network Model (CNM) and libnetwork, and\\nyou’ll get your hands dirty with lots of examples. You’ll learn about overlay networks in\\nthe next chapter.\\nI’ve divided the chapter into the following sections:\\n• Docker networking – the TLDR\\n• Docker networking theory\\n• Single-host bridge networks\\n• External access via port mappings\\n• Connecting to existing networks and VLANs\\n• Service Discovery\\n• Ingress load balancing\\nA few quick things before we start.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 194}, page_content='• Single-host bridge networks\\n• External access via port mappings\\n• Connecting to existing networks and VLANs\\n• Service Discovery\\n• Ingress load balancing\\nA few quick things before we start.\\nEverything we’ll cover relates to Linux containers, and I recommend you follow along\\nusing something like Multipass or Play with Docker, as they give you easy access to\\nsome of the Linux commands we’ll use. I don’t recommend following along on Docker\\nDesktop as it runs everything inside a Linux VM and you won’t have access to the Linux\\ncommands.\\nSome of the examples explain how networking works on a swarm. You’ll only be able to\\nfollow these if you’re following along with a Swarm cluster.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 195}, page_content='13: Docker Networking\\n189\\nDocker Networking – The TLDR\\nDocker runs microservices applications comprised of many containers that work\\ntogether to form the overall app. These containers need to be able to communicate,\\nand some will have to connect with external services, such as physical servers, virtual\\nmachines, or something else.\\nFortunately, Docker has solutions for both of these requirements.\\nDocker networking is based on libnetwork, which is the reference implementation of an\\nopen-source architecture called the Container Network Model (CNM).\\nFor a smooth out-of-the-box experience, Docker ships with everything you need\\nfor the most common networking requirements, including multi-host container-to-\\ncontainer networks and options for plugging into existing VLANs. However, the model\\nis pluggable, and the ecosystem can extend Docker’s networking capabilities via drivers\\nthat plug into libnetwork.\\nLast but not least, libnetwork also provides native service discovery and basic load'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 195}, page_content='is pluggable, and the ecosystem can extend Docker’s networking capabilities via drivers\\nthat plug into libnetwork.\\nLast but not least, libnetwork also provides native service discovery and basic load\\nbalancing.\\nThat’s the big picture. Let’s get into the detail.\\nDocker networking theory\\nAt the highest level, Docker networking is based on the following three components:\\n• The Container Network Model (CNM)\\n• Libnetwork\\n• Drivers\\nThe CNM is the design specification and outlines the fundamental building blocks of a\\nDocker network.\\nLibnetwork is a real-world implementation of the CNM. It’s open-sourced as part of\\nthe Moby project20 and used by Docker and other platforms.\\nDrivers extend the model by implementing specific network topologies such as VXLAN\\noverlay networks.\\nFigure 13.1 shows all three.\\n20https://mobyproject.org/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 196}, page_content='13: Docker Networking\\n190\\nFigure 13.1\\nLet’s take a closer look at each.\\nThe Container Network Model (CNM)\\nEverything starts with a design.\\nThe design guide for Docker networking is the CNM that outlines the fundamental\\nbuilding blocks of a Docker network.\\nI recommend you read the specification document21, but at a high level, it defines three\\nbuilding blocks:\\n• Sandboxes\\n• Endpoints\\n• Networks\\nA sandbox is an isolated network stack inside a container. It includes Ethernet interfaces,\\nports, routing tables, DNS configuration, and everything else you’d expect from a\\nnetwork stack.\\nEndpoints are virtual network interfaces that look, smell, and feel like regular network\\ninterfaces. They connect sandboxes to networks.\\nNetworks are virtual switches (usually software implementations of an 802.1d bridge). As\\nsuch, they group together and isolate one or more endpoints that need to communicate.\\nFigure 13.2 shows how all three connect and relate to familiar infrastructure compo-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 196}, page_content='such, they group together and isolate one or more endpoints that need to communicate.\\nFigure 13.2 shows how all three connect and relate to familiar infrastructure compo-\\nnents. Using CNM terminology, endpoints connect sandboxes to networks. Every container\\nyou create will have a sandbox with at least one endpoint connecting it to a network.\\n21https://github.com/moby/moby/blob/master/libnetwork/docs/design.md'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 197}, page_content='13: Docker Networking\\n191\\nFigure 13.2 - The Container Network Model (CNM)\\nAs the name suggests, the Container Network Model is all about providing networking\\nfor containers. Figure 13.3 shows how CNM components relate to containers —\\neach container gets its own sandbox which hosts the container’s entire network stack,\\nincluding one or more endpoints that act as Ethernet interfaces and can be connected to\\nnetworks.\\nFigure 13.3\\nContainer A has a single interface (endpoint) and is only connected to Network A.\\nHowever, Container B has two interfaces connected to Network A and Network B.\\nThe containers can communicate with each other because they are both connected to\\nNetwork A. However, the two endpoints inside of Container B cannot communicate\\nwith each other as they’re on different networks.\\nIt’s also important to understand that endpoints behave exactly like regular network\\nadapters, meaning you can only connect them to a single network. This is why Con-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 197}, page_content='It’s also important to understand that endpoints behave exactly like regular network\\nadapters, meaning you can only connect them to a single network. This is why Con-\\ntainer B needs two endpoints if it wants to connect to both networks.\\nFigure 13.4 extends the diagram further by adding the Docker host. Even though both\\ncontainers are running on the same host this time, their network stacks are completely\\nisolated and can only communicate via a network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 198}, page_content='13: Docker Networking\\n192\\nFigure 13.4\\nLibnetwork\\nLibnetwork is the reference implementation of the CNM. It’s open-source, cross-\\nplatform (Linux and Windows), maintained by the Moby project, and used by Docker.\\nBefore Docker created libnetwork, it implemented all of its networking code inside\\nthe daemon. However, over time, the daemon became bloated and difficult for other\\nprojects to use. As a result, Docker removed the networking code from the daemon and\\nrefactored it as an external library called libnetwork based on the CNM design. Today,\\nDocker implements all of its core networking in libnetwork.\\nAs well as implementing the core components of the CNM, libnetwork also implements\\nthe network control plane, including management APIs, service discovery, and ingress-\\nbased container load balancing.\\nDrivers\\nLibnetwork implements the control plane, but it relies on drivers to implement the data\\nplane. For example, drivers are responsible for creating networks and ensuring isolation'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 198}, page_content='Drivers\\nLibnetwork implements the control plane, but it relies on drivers to implement the data\\nplane. For example, drivers are responsible for creating networks and ensuring isolation\\nand connectivity.\\nDocker ships with several built-in drivers that we sometimes call native drivers or local\\ndrivers. These include bridge, overlay, and macvlan, and they build the most common\\nnetwork topologies. Third parties can also write network drivers to implement other\\nnetwork topologies and more advanced configurations.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 199}, page_content='13: Docker Networking\\n193\\nFigure 13.5 shows the roles of libnetwork and drivers and how they relate to control\\nplane and data plane responsibilities.\\nFigure 13.5\\nEvery network you create is owned by a driver, and the driver creates and manages\\neverything about the network. For example, if you create an overlay network called\\nprod-fe-cuda, Docker will invoke the overlay driver to create the network and its\\nresources.\\nTo meet the demands of complex, highly fluid environments, a single Docker host or\\nSwarm cluster can have multiple heterogeneous networks managed by different drivers.\\nLet’s look at single-host bridge networks and connecting to existing networks. You’ll\\nlearn about overlay networks in the next chapter.\\nSingle-host bridge networks\\nThe simplest type of Docker network is the single-host bridge network.\\nThe name tells us two things:\\n• Single-host tells us the network only spans a single Docker host'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 199}, page_content='Single-host bridge networks\\nThe simplest type of Docker network is the single-host bridge network.\\nThe name tells us two things:\\n• Single-host tells us the network only spans a single Docker host\\n• Bridge tells us that it’s an implementation of an 802.1d bridge (layer 2 switch)\\nDocker creates single-host bridge networks with the built-in bridge driver. If you run\\nWindows containers you’ll need to use the nat driver, but for all intents and purposes they\\nwork the same.\\nFigure 13.6 shows two Docker hosts with identical local bridge networks, both called\\nmynet. Even though the networks are identical, they are independent and isolated,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 200}, page_content='13: Docker Networking\\n194\\nmeaning the containers in the picture cannot communicate, even if the nodes are part\\nof the same swarm.\\nFigure 13.6\\nEvery new Docker host gets a default single-host bridge network called bridge that\\nDocker connects new containers to unless you override it with the --network flag.\\nThe following commands show the output of a docker network ls command on\\nDocker installation.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\nc7464dce29ce\\nbridge\\nbridge\\nlocal\\n<<---- Default on all Docker hosts\\nc65ab18d0580\\nhost\\nhost\\nlocal\\n42a783df0fbe\\nnone\\nnull\\nlocal\\nAs always, you can run docker inspect commands to get more information. I highly\\nrecommend running the command on your own system and studying the output.\\n$ docker network inspect bridge\\n[\\n{\\n\"Name\": \"bridge\",\\n\"Id\": \"c7464dce2...ba2e3b8\",\\n\"Scope\": \"local\",\\n\"Driver\": \"bridge\",\\n\"EnableIPv6\": false,\\n\"IPAM\": {\\n\"Driver\": \"default\",\\n\"Options\": null,\\n\"Config\": [\\n{\\n\"Subnet\": \"172.17.0.0/16\",\\n\"Gateway\": \"172.17.0.1\"\\n}'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 201}, page_content='13: Docker Networking\\n195\\n]\\n},\\n\"Internal\": false,\\n\"Attachable\": false,\\n\"Ingress\": false,\\n\"ConfigFrom\": {\\n\"Network\": \"\"\\n},\\n<Snip>\\n}\\n]\\nAll bridge networks are based on the battle-hardened Linux bridge technology that has\\nexisted in the Linux kernel for over 20 years. This means they’re high-performance and\\nhighly stable. It also means you can inspect them using standard Linux utilities.\\nThe default bridge network on all Linux-based Docker hosts is called bridge and maps to\\nan underlying Linux bridge in the host’s kernel called docker0. This is shown in Figure\\n13.7.\\nFigure 13.7 - Mapping the default Docker “bridge” network to the “docker0” bridge in the host’s kernel\\nYou can run a docker network inspect command to confirm that the bridge network\\nis based on the docker0 bridge in the host’s kernel. If you’re on Windows using Power-\\nShell, you’ll need to replace grep with SelectString.\\n$ docker network inspect bridge | grep bridge.name\\n\"com.docker.network.bridge.name\": \"docker0\",'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 201}, page_content='Shell, you’ll need to replace grep with SelectString.\\n$ docker network inspect bridge | grep bridge.name\\n\"com.docker.network.bridge.name\": \"docker0\",\\nNow run these Linux commands to inspect the docker 0 bridge from the Linux host.\\nYou might need to manually install the brctl utility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 202}, page_content='13: Docker Networking\\n196\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\ndocker0\\n8000.0242aff9eb4f\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\n$ ip link show docker0\\n3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc...\\nlink/ether 02:42:af:f9:eb:4f brd ff:ff:ff:ff:ff:ff\\nThe first command lists all the bridges on your Docker host and shows if they have any\\ndevices connected to them. The example in the book shows the docker0 bridge with no\\ndevices connected in the interfaces column. You’ll only see the docker_gwbridge if\\nyour host is a member of a swarm cluster.\\nThe second command shows the configuration and state of the docker0 bridge.\\nFigure 13.8 shows the complete stack with containers connecting to the bridge\\nnetwork, which, in turn, maps to the docker0 Linux bridge in the host’s kernel. It also\\nshows how you can use port mappings to publish connected devices on the Docker\\nhost’s interface. More on port mappings later.\\nFigure 13.8'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 202}, page_content='shows how you can use port mappings to publish connected devices on the Docker\\nhost’s interface. More on port mappings later.\\nFigure 13.8\\nIn the next few steps, you’ll complete all of the following:\\n1. Create a new Docker bridge network\\n2. Connect a container to the new network'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 203}, page_content='13: Docker Networking\\n197\\n3. Inspect the new network\\n4. Test name-based discovery\\nRun the following command to create a new single-host bridge network called local-\\nnet.\\n$ docker network create -d bridge localnet\\nf918f1bb0602373bf949615d99cb2bbbef14ede935fbb2ff8e83c74f10e4b986\\nThe long number returned by the command is the network’s ID and you’ll need it in the\\nnext step.\\nAs expected, the command creates a new Docker bridge network called localnet that\\nyou can list and inspect with the usual docker commands. However, behind the scenes,\\nit also creates a new Linux bridge in the host’s kernel.\\nRun another brctl show command to see it.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\ndocker0\\n8000.024258ee84bc\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\nThe example in the book shows a new bridge called br-f918f1bb0602 with no devices\\nconnected. If you look closely at the name, you’ll recognize f918f1bb0602 as the first 12'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 203}, page_content='8000.02427abba76b\\nno\\nThe example in the book shows a new bridge called br-f918f1bb0602 with no devices\\nconnected. If you look closely at the name, you’ll recognize f918f1bb0602 as the first 12\\ncharacters from the ID of the new localnet network you just created.\\nAt this point, the bridge configuration on the host looks like Figure 13.9, with three\\nDocker networks and three associated bridges in the host’s kernel.\\nFigure 13.9\\nLet’s create a new container called c1 and attach it to the new localnet bridge network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 204}, page_content='13: Docker Networking\\n198\\n$ docker run -d --name c1 \\\\\\n--network localnet \\\\\\nalpine sleep 1d\\nOnce you’ve created the container, inspect the localnet network and verify the\\ncontainer is connected to it. You’ll need the jq utility installed for the command to work.\\nLeave off the \"| jq\" if it doesn’t work.\\n$ docker network inspect localnet --format \\'{{json .Containers}}\\' | jq\\n{\\n\"09c5f4926c87da12039b3b510a5950b3fe9db80e13431dc17d870450a45fd84a\": {\\n\"Name\": \"c1\",\\n\"EndpointID\": \"27770ac305773b352d716690fb9f8e05c1b71e10dc66f67b88e93cb923ab9749\",\\n\"MacAddress\": \"02:42:ac:15:00:02\",\\n\"IPv4Address\": \"172.21.0.2/16\",\\n\"IPv6Address\": \"\"\\n}\\n}\\nThe output shows the c1 container and its IP address. This proves Docker connected it\\nto the network.\\nIf you run another brctl show command, you’ll see the c1 container’s interface\\nconnected to the br-1597657726bc bridge.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\nveth833aaf9\\ndocker0\\n8000.024258ee84bc\\nno'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 204}, page_content='connected to the br-1597657726bc bridge.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\nveth833aaf9\\ndocker0\\n8000.024258ee84bc\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\nFigure 13.10 shows the updated configuration. Your veth IDs will be different, but the\\nimportant thing to understand is that every veth is like a cable with an interface on\\neither end. One end is connected to the Docker network, and the other end is connected\\nto the associated bridge in the kernel.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 205}, page_content='13: Docker Networking\\n199\\nFigure 13.10\\nIf you add more containers to the localnet network, they’ll all be able to communicate\\nusing names. This is because Docker automatically registers container names with an\\ninternal DNS service and allows containers on the same network to find each other by\\nname. The exception to this rule is the built-in bridge network that does not support\\nDNS resolution.\\nLet’s test name resolution by creating a new container called c2 on the same localnet\\nnetwork and seeing if it can ping the c1 container.\\nRun the following command to create the c2 container on the localnet network. You’ll\\nneed to type exit if you’re still logged in to the c1 container.\\n$ docker run -it --name c2 \\\\\\n--network localnet \\\\\\nalpine sh\\nYour terminal will switch into the c2 container.\\nTry to ping the c1 container by name.\\n# ping c1\\nPING c1 (172.21.0.2): 56 data bytes\\n64 bytes from 172.21.0.2: seq=0 ttl=64 time=1.564 ms\\n64 bytes from 172.21.0.2: seq=1 ttl=64 time=0.338 ms'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 205}, page_content='Try to ping the c1 container by name.\\n# ping c1\\nPING c1 (172.21.0.2): 56 data bytes\\n64 bytes from 172.21.0.2: seq=0 ttl=64 time=1.564 ms\\n64 bytes from 172.21.0.2: seq=1 ttl=64 time=0.338 ms\\n64 bytes from 172.21.0.2: seq=2 ttl=64 time=0.248 ms\\n<Control-c>\\nIt works! This is because all containers run a DNS resolver that forwards name lookups\\nto Docker’s internal DNS server that holds name-to-IP mappings for all containers\\nstarted with the --name or --net-alias flag.\\nType exit to log out of the container and return to your local shell.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 206}, page_content='13: Docker Networking\\n200\\nExternal access via port mappings\\nSo far, we’ve said that containers on bridge networks can only communicate with\\nother containers on the same network. However, you can get around this by mapping\\ncontainers to ports on the Docker host. It’s a bit clunky and has a lot of limitations, but it\\nmight be useful for occasional testing and development work.\\nFigure 13.11 shows a single Docker host running two containers. The web container on\\nthe right is running a web server on port 80 that is mapped to port 5005 on the Docker\\nhost. The client container on the left is sending requests to the Docker host on port\\n5005 and the external client at the bottom is doing the same. Both requests will hit the\\nhost’s IP on port 5005 and be redirected to the web server running in the web container.\\nFigure 13.11\\nLet’s test the setup to see if it works.\\nCreate a new container called web running NGINX on port 80 and map it to port 5005'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 206}, page_content='Figure 13.11\\nLet’s test the setup to see if it works.\\nCreate a new container called web running NGINX on port 80 and map it to port 5005\\non the Docker host. If you’re still logged on to the container from the previous example,\\nyou’ll need to type exit first.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 207}, page_content='13: Docker Networking\\n201\\n$ docker run -d --name web \\\\\\n--network localnet \\\\\\n--publish 5005:80 \\\\\\nnginx\\nVerify the port mapping.\\n$ docker port web\\n80/tcp -> 0.0.0.0:5005\\n80/tcp -> [::]:5005\\nThe output shows the port mapping exists on all interfaces on the Docker host.\\nYou can test external access by pointing a web browser to the Docker host on port 5005.\\nYou’ll need to know the IP or DNS name of your Docker host (if you’re following along\\non Multipass it will probably be your Multipass VM’s 192.168.x.x address). You’ll see\\nthe Welcome to nginx! page.\\nLet’s create another container and see if it can reach the web container via the port\\nmapping.\\nRun the following command to create a new container called client on the bridge\\nnetwork.\\n$ docker run -it --name client --network bridge alpine sh\\n#\\nThe command will log you into the container and your prompt will change.\\nInstall the curl utility.\\n# apk add curl\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/aarch64/APKINDEX.tar.gz'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 207}, page_content='#\\nThe command will log you into the container and your prompt will change.\\nInstall the curl utility.\\n# apk add curl\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/aarch64/APKINDEX.tar.gz\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/community/aarch64/APKINDEX.tar.gz\\n(1/8) Installing ca-certificates (20240226-r0)\\n<Snip>\\nNow connect to the IP of your Docker host on port 5005 to see if you can reach the\\ncontainer.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 208}, page_content='13: Docker Networking\\n202\\n# curl 192.168.64.69:5005\\n<!DOCTYPE html>\\n<html>\\n<head>\\n<title>Welcome to nginx!</title>\\n...\\n</html>\\nYou’ve reached the NGINX web server running on the c1 container via a port mapping\\nto the Docker host’s IP.\\nEven though this works, it’s clunky and doesn’t scale. For example, no other containers\\nor host processes will be able to use port 5005 on the host. This is one of the reasons\\nthat single-host bridge networks are only useful for local development or very small\\napplications.\\nConnecting to existing networks and VLANs\\nThe ability to connect containerized apps to external systems and physical networks is\\nimportant. A common example is partially containerized apps where the parts running\\nin containers need to be able to communicate with the parts not running in containers.\\nThe built-in MACVLAN driver (transparent if you’re using Windows containers) was\\ncreated with this in mind. It gives every container its own IP and MAC address on the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 208}, page_content='The built-in MACVLAN driver (transparent if you’re using Windows containers) was\\ncreated with this in mind. It gives every container its own IP and MAC address on the\\nexternal physical network, making each one look, smell, and feel like a physical server or\\nVM. This is shown in Figure 13.12.\\nFigure 13.12 - MACVLAN driver making containers visible on external networks\\nOn the positive side, MACVLAN performance is good as it doesn’t require port\\nmappings or additional bridges. However, you need to run your host NICs in promis-\\ncuous mode, which isn’t allowed on many corporate networks and public clouds. So,\\nMACVLAN will work on your data center networks if your network team allows\\npromiscuous mode, but it probably won’t work on your public cloud.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 209}, page_content='13: Docker Networking\\n203\\nLet’s dig a bit deeper with the help of some pictures and a hypothetical example. This\\nexample will only work if your host NIC is in promiscuous mode on a network that\\nallows it. It also requires an existing VLAN 100. You can adapt it if the VLAN config on\\nyour physical network is different. You can follow along without the VLANs, but you\\nwon’t get the full experience.\\nAssume you have the network shown in Figure 13.13 with two VLANs:\\nFigure 13.13\\nNext, you add a Docker host and connect it to the network.\\nFigure 13.14\\nNow comes the requirement to attach a container to VLAN 100. To do this, you create a\\nnew Docker network with the macvlan driver and configure it with all of the following:\\n• Subnet info\\n• Gateway\\n• Range of IPs it can assign to containers\\n• Which of the host’s interfaces or sub-interfaces to use\\nRun the following command to create a new MACVLAN network called macvlan100'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 209}, page_content='• Gateway\\n• Range of IPs it can assign to containers\\n• Which of the host’s interfaces or sub-interfaces to use\\nRun the following command to create a new MACVLAN network called macvlan100\\nthat will connect containers to VLAN 100. You may need to change the name of the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 210}, page_content='13: Docker Networking\\n204\\nparent interface to match the parent interface name on your system. For example,\\nchanging -o parent=eth0.100 to -o parent=enp0s1.100. The parent interface must\\nbe connected to the VLAN, and you’ll need to type exit if you’re still logged on to the\\ncontainer from the previous example.\\n$ docker network create -d macvlan \\\\\\n--subnet=10.0.0.0/24 \\\\\\n--ip-range=10.0.0.0/25 \\\\\\n--gateway=10.0.0.1 \\\\\\n-o parent=eth0.100 \\\\\\n<<---- Make sure this matches your system\\nmacvlan100\\nDocker will create the macvlan100 network and a new sub-interface on the host called\\neth0.100@eth0. The config now looks like this.\\nFigure 13.15\\nThe MACVLAN driver creates standard Linux sub-interfaces and tags them with the ID\\nof the VLAN they will connect to. In this example, we’re connecting to VLAN 100, so we\\ntag the sub-interface with .100 (-o parent=eth0.100).\\nWe also used the --ip-range flag to tell the new network which sub-set of IP addresses'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 210}, page_content='tag the sub-interface with .100 (-o parent=eth0.100).\\nWe also used the --ip-range flag to tell the new network which sub-set of IP addresses\\nit can assign to containers. It’s vital that you reserve this range of addresses for Docker,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 211}, page_content='13: Docker Networking\\n205\\nas the MACVLAN driver has no management plane feature to check if IPs are already in\\nuse.\\nIf you inspect the network, you’ll be able to see the important configuration information.\\nI’ve snipped the output to show the most relevant parts.\\n$ docker network inspect macvlan100\\n[\\n{\\n\"Name\": \"macvlan100\",\\n\"Driver\": \"macvlan\",\\n\"IPAM\": {\\n\"Config\": [\\n{\\n\"Subnet\": \"10.0.0.0/24\",\\n\"IPRange\": \"10.0.0.0/25\",\\n\"Gateway\": \"10.0.0.1\"\\n}\\n]\\n},\\n\"Options\": {\\n\"parent\": \"enp0s1.100\"\\n},\\n}\\n]\\nOnce you’ve created the macvlan100 network, you can connect containers to it and\\nDocker will assign the IP and MAC addresses on the underlying VLAN so they’ll be\\nvisible to other systems.\\nThe following command creates a new container called mactainer1 and connects it to\\nthe macvlan100 network.\\n$ docker run -d --name mactainer1 \\\\\\n--network macvlan100 \\\\\\nalpine sleep 1d\\nThe config now looks like Figure 13.16.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 212}, page_content='13: Docker Networking\\n206\\nFigure 13.16\\nHowever, remember that the underlying network (VLAN 100) does not see any of\\nthe MACVLAN magic, it only sees the container with its MAC and IP addresses,\\nmeaning the mactainer1 container will be able to communicate with every other system\\nconnected to VLAN 100!\\nNote: If you can’t get this to work, it might be because your host NIC isn’t\\nin promiscuous mode. Also, remember that public cloud platforms normally\\nblock promiscuous mode.\\nAt this point, you’ve got a MACVLAN network and used it to connect a new container\\nto an existing VLAN. If you have the complete setup, with the existing VLAN, you can\\ntest that the container is reachable form other system on the VLAN.\\nHowever, it doesn’t stop there. The Docker MACVLAN driver supports VLAN trunking.\\nThis means you can create multiple MACVLAN networks that connect to different\\nVLANs. Figure 13.17 shows a single Docker host running two MACVLAN networks\\nconnecting containers to two different VLANs.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 213}, page_content='13: Docker Networking\\n207\\nFigure 13.17\\nTroubleshooting connectivity problems\\nA quick note on troubleshooting connectivity issues before moving on to service\\ndiscovery.\\nDaemon logs and container logs can be useful when troubleshooting connectivity issues.\\nIf you’re running Windows containers, you can view them in the Windows Event\\nViewer or directly in ∼\\\\AppData\\\\Local\\\\Docker. For Linux containers, it depends on\\nwhich init system you’re using. If you’re running a systemd, Docker will post logs to\\njournald and you can view them with the journalctl -u docker.service command.\\nIf you’re using a different init system, you might want to check the following locations:\\n• Ubuntu systems running upstart: /var/log/upstart/docker.log\\n• RHEL-based systems: /var/log/messages\\n• Debian: /var/log/daemon.log\\nYou can also tell Docker how verbose you want daemon logging to be. To do this, edit\\nthe daemon config file at /etc/docker/daemon.json and set \"debug\" to \"true\" and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 213}, page_content='• Debian: /var/log/daemon.log\\nYou can also tell Docker how verbose you want daemon logging to be. To do this, edit\\nthe daemon config file at /etc/docker/daemon.json and set \"debug\" to \"true\" and\\n\"log-level\" to one of the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 214}, page_content='13: Docker Networking\\n208\\n• debug – the most verbose option\\n• info – the default value and second-most verbose option\\n• warn – third most verbose option\\n• error – fourth most verbose option\\n• fatal – least verbose option\\nThe following snippet from a daemon.json enables debugging and sets the level to\\ndebug. It will work on all Docker platforms.\\n{\\n<Snip>\\n\"debug\":true,\\n\"log-level\":\"debug\",\\n<Snip>\\n}\\nIf your daemon.json file doesn’t exist, create it. Also, be sure to restart Docker after\\nmaking any changes to the file.\\nThat was the daemon logs. What about container logs?\\nYou can normally view container logs with the docker logs command. If you’re\\nrunning Swarm, you should use the docker service logs command. However,\\nDocker supports a few different log drivers, and they don’t all work with native Docker\\ncommands. For some of them, you might have to view logs using the platform’s native\\ntools.\\njson-file and journald are probably the easiest to configure and they both work with'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 214}, page_content='commands. For some of them, you might have to view logs using the platform’s native\\ntools.\\njson-file and journald are probably the easiest to configure and they both work with\\nthe docker logs and docker service logs commands.\\nThe following snippet from a daemon.json shows a Docker host configured to use\\njournald.\\n{\\n\"log-driver\": \"journald\"\\n}\\nYou can also start a container or a service with the --log-driver and --log-opts flags\\nto override the settings in daemon.json.\\nContainer logs work on the premise that your application runs as PID 1 and sends logs\\nto STDOUT and errors to STDERR. The logging driver then forwards everything to the\\nlocations configured via the logging driver.\\nThe following is an example of running the docker logs command against a container\\ncalled vantage-db that is configured with the json-file logging driver.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 215}, page_content='13: Docker Networking\\n209\\n$ docker logs vantage-db\\n1:C 2 Feb 09:53:22.903 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\\n1:C 2 Feb 09:53:22.904 # Redis version=4.0.6, bits=64, commit=00000000, modified=0, pid=1\\n1:C 2 Feb 09:53:22.904 # Warning: no config file specified, using the default config.\\n1:M 2 Feb 09:53:22.906 * Running mode=standalone, port=6379.\\n1:M 2 Feb 09:53:22.906 # WARNING: The TCP backlog setting of 511 cannot be enforced...\\n1:M 2 Feb 09:53:22.906 # Server initialized\\n1:M 2 Feb 09:53:22.906 # WARNING overcommit_memory is set to 0!\\nThere’s a good chance you’ll find network connectivity errors in the daemon logs or\\ncontainer logs.\\nService discovery\\nAs well as core networking, libnetwork also provides service discovery that allows all\\ncontainers and Swarm services to locate each other by name. The only requirement is\\nthat the containers be on the same network.\\nUnder the hood, Docker implements a native DNS server and configures every con-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 215}, page_content='that the containers be on the same network.\\nUnder the hood, Docker implements a native DNS server and configures every con-\\ntainer to use it for name resolution.\\nFigure 13.18 shows a container called c1 pinging another container called c2 by name.\\nThe same principle applies to Swarm service replicas.\\nFigure 13.18\\nLet’s step through the process.\\n• Step 1: The c1 container issues a ping c2 command. The container’s local DNS\\nresolver checks its cache to see if it has an IP address for c2. All Docker containers\\nhave a local DNS resolver.\\n• Step 2: The local resolver doesn’t have an IP address for c2, so it initiates a\\nrecursive query to the embedded Docker DNS server. All Docker containers are\\npre-configured to know how to send queries to the embedded DNS server.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 216}, page_content='13: Docker Networking\\n210\\n• Step 3: The Docker DNS server maintains name-to-IP mappings for every\\ncontainer you create with the --name or --net-alias flags. This means it knows\\nthe IP address of the c2 container.\\n• Step 4: The DNS server returns the IP address of the c2 container to the local\\nresolver in the c1 container. If c1 and c2 are on different Docker networks it won’t\\nreturn the IP address — name resolution only works for containers on the same\\nnetwork.\\n• Step 5: The c1 container sends the ping request (ICMP echo request) to the IP\\naddress of c2.\\nJust to confirm a few points.\\nDocker will automatically register the name and IP of every container you create\\nwith the --name or net-alias flag with the embedded Docker DNS service. It also\\nautomatically configures every container to use the embedded DNS service to convert\\nnames to IPs. And name resolution (service discovery) is network scoped, meaning it only\\nworks for containers and services on the same network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 216}, page_content='names to IPs. And name resolution (service discovery) is network scoped, meaning it only\\nworks for containers and services on the same network.\\nOne last point on service discovery and name resolution…\\nYou can use the --dns flag to start containers and services with a customized list of\\nDNS servers, and you can use the --dns-search flag to add custom search domains\\nfor queries against unqualified names (i.e., when the application doesn’t specify fully\\nqualified DNS names for services they consume). You’ll find both of these useful if your\\napplications query names outside of your Docker environment such as internet services.\\nBoth of these options work by adding entries to the container’s /etc/resolv.conf file.\\nRun the following command to start a new container with the infamous 8.8.8.8\\nGoogle DNS server and nigelpoulton.com as a search domain for unqualified queries.\\n$ docker run -it --name custom-dns \\\\\\n--dns=8.8.8.8 \\\\\\n--dns-search=nigelpoulton.com \\\\\\nalpine sh'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 216}, page_content='Google DNS server and nigelpoulton.com as a search domain for unqualified queries.\\n$ docker run -it --name custom-dns \\\\\\n--dns=8.8.8.8 \\\\\\n--dns-search=nigelpoulton.com \\\\\\nalpine sh\\nYour shell prompt will change to indicate you’re connected to the container.\\nInspect its /etc/resolv.conf file.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 217}, page_content='13: Docker Networking\\n211\\n# cat /etc/resolv.conf\\nGenerated by Docker Engine.\\nThis file can be edited; Docker Engine will not make further changes once it\\nhas been modified.\\nnameserver 8.8.8.8\\nsearch nigelpoulton.com\\nThe file’s contents might be slightly different if you connect the container to a custom\\nnetwork, but the options work the same.\\nType exit to return to your local terminal.\\nIngress load balancing\\nThis section only applies to Docker Swarm.\\nSwarm supports two ways of publishing services to external clients:\\n• Ingress mode (default)\\n• Host mode\\nExternal clients can access ingress mode services via any swarm node — even nodes not\\nhosting a service replica. However, they can only access host mode services via nodes\\nrunning replicas. Figure 13.19 shows both modes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 218}, page_content='13: Docker Networking\\n212\\nFigure 13.19\\nIngress mode is the default, meaning any time you create a service with -p or --publish,\\nDocker will publish it in ingress mode. If you want to publish a service in host mode, you’ll\\nneed to use the --publish flag with the mode=host option. The following example\\npublishes a service in host mode and will only work on a swarm.\\n$ docker service create -d --name svc1 \\\\\\n--publish published=5005,target=80,mode=host \\\\\\nnginx\\nA few notes about the command. docker service create lets you publish services\\nusing either long form syntax or short form syntax.\\nThe short form looks like -p 5005:80 and you’ve seen it a few times already. However,\\nyou cannot publish a service in host mode using the short form.\\nLong form looks like this: --publish published=5005,target=80,mode=host. It’s a\\ncomma-separated list with no whitespace after the commands, and the options work as\\nfollows:\\n• published=5005 makes the service available to external clients via port 5005'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 218}, page_content='comma-separated list with no whitespace after the commands, and the options work as\\nfollows:\\n• published=5005 makes the service available to external clients via port 5005\\n• target=80 makes sure requests hitting the published port get mapped back to port\\n80 on service replicas'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 219}, page_content='13: Docker Networking\\n213\\n• mode=host makes sure requests will only reach the service if they arrive on nodes\\nrunning a service replica\\nYou’ll almost always use ingress mode.\\nBehind the scenes, ingress mode uses a layer 4 routing mesh that Docker calls the\\nservice mesh or the swarm-mode service mesh. Figure 13.20 shows the basic traffic\\nflow when an external request hits the cluster for a service exposed in ingress mode.\\nFigure 13.20\\nLet’s quickly walk through the diagram.\\nThe command at the top deploys a new Swarm service called svc1 with one replica,\\nattaches it to the overnet network and publishes it on port 5005 on the ingress network.\\nDocker automatically creates the ingress network when you create the swarm, and\\nit attaches every node to it. The act of publishing the service on port 5005 makes it\\naccessible via port 5005 on every swarm node because every node is connected to the\\ningress network. Docker also creates a swarm-wide rule to route all traffic hitting nodes'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 219}, page_content='accessible via port 5005 on every swarm node because every node is connected to the\\ningress network. Docker also creates a swarm-wide rule to route all traffic hitting nodes\\non port 5005 to port 80 in the svc1 replicas via the ingress network.\\nNow let’s track that external request.\\n1. The external client sends a request to Node 1 on port 5005\\n2. Node 1 receives the request and knows to forward traffic arriving on port 5005 to\\nthe ingress network\\n3. The ingress network forwards the request to Node 2 which is running a replica\\n4. Node 2 receives the request and passes it to the replica on port 80'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 220}, page_content='13: Docker Networking\\n214\\nIf the service has multiple replicas, swarm is clever enough to balance requests across\\nthem all.\\nClean up\\nIf you’ve been following along, you’ll have a lot of containers, networks, and services\\nthat you probably want to clean up.\\nRun the following command to delete the services you created.\\n$ docker service rm svc1\\nNow, delete the standalone containers you created.\\n$ docker rm c1 c2 client web mactainer1 -f\\nFinally, delete the networks you created.\\n$ docker network rm localnet macvlan100\\nDocker Networking – The Commands\\nDocker networking has its own docker network sub-command, and the main com-\\nmands include:\\n• docker network ls lists all the Docker networks available to the host.\\n• docker network create is how you create a new Docker network. You have\\nto give the network a name and you can use the -d flag to specify which driver\\ncreates it.\\n• docker network inspect provides detailed configuration information about\\nDocker networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 220}, page_content='to give the network a name and you can use the -d flag to specify which driver\\ncreates it.\\n• docker network inspect provides detailed configuration information about\\nDocker networks.\\n• docker network prune deletes all unused networks on a Docker host.\\n• docker network rm Deletes specific networks on a Docker host or swarm.\\nYou also ran some native Linux commands.\\n• brctl show prints a list of all kernel bridges on the Docker host and shows if any\\ncontainers are connected.\\n• ip link show prints bridge configuration data. You ran an ip link show\\ndocker0 to see the configuration of the docker0 bridge on your Docker host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 221}, page_content='13: Docker Networking\\n215\\nChapter Summary\\nThe Container Network Model (CNM) is the design document for Docker networks\\nand defines the three major constructs — sandboxes, endpoints, and networks.\\nLibnetwork is the reference implementation of the CMN and is an open-source project\\nmaintained by the Moby project. Docker uses it to implement its core networking,\\nincluding control plane services such as service discovery.\\nDrivers extend the capabilities of libnetwork by implementing specific network topolo-\\ngies, such as bridge and overlay networks. Docker ships with built-in drivers, but you\\ncan also use third-party drivers.\\nSingle-host bridge networks are the most basic type of Docker network but are only\\nsuitable for local development and very small applications. They do not scale, and you\\nneed to map containers to host ports if you want to publish services outside of the\\nnetwork.\\nOverlay networks are all the rage and are excellent container-only multi-host networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 221}, page_content='need to map containers to host ports if you want to publish services outside of the\\nnetwork.\\nOverlay networks are all the rage and are excellent container-only multi-host networks.\\nWe’ll talk about them in-depth in the next chapter.\\nThe macvlan driver lets you create Docker networks that connect containers to existing\\nphysical networks and VLANs. They make containers first-class citizens on external\\nnetworks by giving them their own MAC and IP addresses. Unfortunately, you have to\\nrun your host NICs in promiscuous mode, meaning they won’t work in public clouds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 222}, page_content='14: Docker overlay networking\\nOverlay networks are at the center of most cloud-native microservices apps, and this\\nchapter will get you up to speed on how they work in Docker.\\nI’ve divided the chapter into the following sections:\\n• Docker overlay networking – The TLDR\\n• Docker overlay networking history\\n• Building and testing overlay networks\\n• Overlay networks explained\\nLet’s do some networking magic!\\nDocker overlay networking – The TLDR\\nReal-world containers need a reliable and secure way to communicate without caring\\nwhich host they’re running on or which networks those hosts are connected to. This\\nis where overlay networks come into play — they create flat, secure, layer 2 networks\\nthat span multiple hosts. Containers on different hosts can connect to the same overlay\\nnetwork and communicate directly.\\nDocker offers native overlay networking that is simple to configure and secure by\\ndefault.\\nBehind the scenes, Docker builds overlay networking on top of libnetwork and the native'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 222}, page_content='Docker offers native overlay networking that is simple to configure and secure by\\ndefault.\\nBehind the scenes, Docker builds overlay networking on top of libnetwork and the native\\noverlay driver. Libnetwork is the canonical implementation of the Container Network\\nModel (CNM), and the overlay driver implements all of the machinery to build overlay\\nnetworks.\\nDocker overlay networking history\\nIn March 2015, Docker, Inc. acquired a container networking startup called Socket Plane\\nwith two goals in mind:\\n1. Bring overlay networking to Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 223}, page_content='14: Docker overlay networking\\n217\\n2. Make container networking simple for developers\\nThey accomplished both goals, and overlay networking continues to be at the heart of\\ncontainer networking in 2024 and the foreseeable future.\\nHowever, there’s a lot of complexity hiding behind the simple Docker commands.\\nKnowing the commands is probably enough if you’re a casual Docker user. However,\\nif you plan to use Docker in production, especially if you plan to use Swarm and Docker\\nnetworking, then the things we’ll cover will be vital.\\nBuilding and testing Docker overlay networks\\nYou’ll need at least two Docker nodes configured in a swarm to follow along. The\\nexamples in the book show the two nodes on different networks connected by a router,\\nbut yours can be on the same network. You can follow along with two Multipass VMs\\non the same laptop or computer, but any Docker configuration will work as long as the\\nnodes can communicate. I don’t recommend using Docker Desktop as you only get a'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 223}, page_content='on the same laptop or computer, but any Docker configuration will work as long as the\\nnodes can communicate. I don’t recommend using Docker Desktop as you only get a\\nsingle node and won’t get the full experience.\\nFigure 14.1 shows the initial lab configuration. Remember, your nodes can be on\\nthe same network, this will just mean your underlay network is simpler. We’ll explain\\nunderlay networks later.\\nFigure 14.1'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 224}, page_content='14: Docker overlay networking\\n218\\nBuild a Swarm\\nIf you’re following along, you’ll need a swarm because overlay networks leverage the\\nswarm’s key-value store and other security features.\\nThis section builds a two-node swarm with two Docker nodes called node1 and node2.\\nIf you already have a swarm, you can skip this section.\\nYou’ll need to substitute the IP addresses and names with the values from your environ-\\nment. You’ll also need to ensure the following network ports are open between the two\\nnodes:\\n• 2377/tcp for management plane comms\\n• 7946/tcp and 7946/udp for control plane comms (SWIM-based gossip)\\n• 4789/udp for the VXLAN data plane\\nRun the following command on node1.\\n$ docker swarm init\\nSwarm initialized: current node (1ex3...o3px) is now a manager.\\nThe command output includes a docker swarm join command. Copy this command\\nand run it node2.\\n$ docker swarm join \\\\\\n--token SWMTKN-1-0hz2ec...2vye \\\\\\n172.31.1.5:2377\\nThis node joined a swarm as a worker.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 224}, page_content='and run it node2.\\n$ docker swarm join \\\\\\n--token SWMTKN-1-0hz2ec...2vye \\\\\\n172.31.1.5:2377\\nThis node joined a swarm as a worker.\\nYou now have a two-node Swarm with node1 as a manager and node2 as a worker.\\nCreate a new overlay network\\nLet’s create a new encrypted overlay network called uber-net.\\nRun the following command from your manager node (node1).\\n$ docker network create -d overlay -o encrypted uber-net\\nvdu1yly429jvt04hgdm0mjqc6'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 225}, page_content='14: Docker overlay networking\\n219\\nThat’s it. You’ve created a brand-new encrypted overlay network. The network spans\\nboth nodes in the swarm and Docker uses TLS to encrypt it (AES in GCM mode). It also\\nrotates the encryption keys every 12 hours.\\nIf you don’t specify the -o encrypted flag, Docker will still encrypt the control plane\\n(management traffic) but won’t encrypt the data plane (application traffic). This can\\nbe important, as encrypting the data plane can decrease network performance by\\napproximately 10%.\\nList the networks on node1.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n65585dda7500\\nbridge\\nbridge\\nlocal\\n7e368a1105c7\\ndocker_gwbridge\\nbridge\\nlocal\\na38083cdab1c\\nhost\\nhost\\nlocal\\n4dsqo7jc36ip\\ningress\\noverlay\\nswarm\\nd97e92a23945\\nnone\\nnull\\nlocal\\nvdu1yly429jv\\nuber-net\\noverlay\\nswarm\\n<<---- New overlay network\\nThe new network is at the bottom of the list called uber-net and is scoped to the entire\\nswarm (SCOPE = swarm). This means it spans every node in the swarm. However, if you'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 225}, page_content='<<---- New overlay network\\nThe new network is at the bottom of the list called uber-net and is scoped to the entire\\nswarm (SCOPE = swarm). This means it spans every node in the swarm. However, if you\\nlist networks on node2 you won’t see the uber-net network. This is because Docker\\nonly extends overlay networks to worker nodes when they need them. In our example,\\nDocker will extend the uber-net network to node2 when it runs a container that needs\\nit. This lazy approach to network deployment improves scalability by reducing the\\namount of network gossip on the swarm.\\nAttach a container to the overlay network\\nNow that you have an overlay network let’s connect a container to it.\\nBy default, you can only attach containers that are part of swarm services to overlay\\nnetworks. If you want to add standalone containers, you need to create the overlay with\\nthe --attachable flag.\\nThe example will create a swarm service called test with two replicas on the uber-net'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 225}, page_content='networks. If you want to add standalone containers, you need to create the overlay with\\nthe --attachable flag.\\nThe example will create a swarm service called test with two replicas on the uber-net\\nnetwork. One replica will be deployed to node1 and the other to node2, causing Docker\\nto extend the overlay network to node2.\\nRun the following commands from node1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 226}, page_content='14: Docker overlay networking\\n220\\n$ docker service create --name test \\\\\\n--network uber-net \\\\\\n--replicas 2 \\\\\\nubuntu sleep infinity\\nCheck the status of the service.\\n$ docker service ps test\\nID\\nNAME\\nIMAGE\\nNODE\\nDESIRED STATE\\nCURRENT STATE\\nsm1...1nw\\ntest.1\\nubuntu:latest\\nnode1\\nRunning\\nRunning\\ntro...kgk\\ntest.2\\nubuntu:latest\\nnode2\\nRunning\\nRunning\\nThe NODE column shows one replica running on each node.\\nSwitch over to node2 and run a docker network ls to verify it can now see the uber-\\nnet network.\\nCongratulations. You’ve created a new overlay network spanning two nodes on separate\\nunderlay networks and attached two containers to it. You’ll appreciate the simplicity\\nof what you’ve done when we reach the theory section and learn about the outrageous\\ncomplexity going on behind the scenes!\\nTest the overlay network\\nFigure 14.2 shows the current setup with two containers running on different Docker\\nhosts but connected to the same overlay.\\nFigure 14.2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 227}, page_content='14: Docker overlay networking\\n221\\nThe following steps will walk you through obtaining the container names and IP\\naddresses and then seeing if they can ping each other.\\nSwitch back to node1 and run a docker network inspect to see the overlay network’s\\nsubnet information and any IP addresses it’s assigned to service replicas.\\n$ docker network inspect uber-net\\n[\\n{\\n\"Name\": \"uber-net\",\\n\"Id\": \"vdu1yly429jvt04hgdm0mjqc6\",\\n\"Scope\": \"swarm\",\\n\"Driver\": \"overlay\",\\n\"EnableIPv6\": false,\\n\"IPAM\": {\\n\"Driver\": \"default\",\\n\"Options\": null,\\n\"Config\": [\\n{\\n\"Subnet\": \"10.0.0.0/24\",\\n<<---- Subnet info\\n\"Gateway\": \"10.0.0.1\"\\n<<---- Subnet info\\n}\\n\"Containers\": {\\n\"Name\": \"test.1.tro80xqwm7k1bsyn3mt1fjkgk\",\\n<<---- Replica ID\\n\"IPv4Address\": \"10.0.0.3/24\",\\n<<---- Container IP\\n<Snip>\\n},\\n<Snip>\\nI’ve snipped the output and highlighted the subnet info and the IPs of connected con-\\ntainers. One thing to note is that Docker only shows you the IP addresses of containers'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 227}, page_content='<Snip>\\n},\\n<Snip>\\nI’ve snipped the output and highlighted the subnet info and the IPs of connected con-\\ntainers. One thing to note is that Docker only shows you the IP addresses of containers\\nrunning on the local node. For example, the output in the book only shows the IP of the\\nfirst replica called test.1.tro...kgk. If you run the same command on node2, you’ll\\nsee the name and IP of the other replica.\\nRun the following commands on both nodes to get the local container names, IDs, and\\nIP addresses of both replicas and make a note of them.\\nThe ID at the end of the second command (d7766923a5a7) is the container ID as\\nreturned by the docker ps command. You’ll need to substitute the value from your\\nenvironment.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 228}, page_content='14: Docker overlay networking\\n222\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAME\\nd7766923a5a7\\nubuntu:latest\\n\"sleep infinity\"\\n2 hrs ago\\nUp 2 hrs\\ntest.1.tro...kgk\\n$ docker inspect \\\\\\n--format=\\'{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\\' d7766923a5a7\\n10.0.0.3\\nI have the following in my environment :\\n• replica 1: ID=d7766923a5a7, Name=test.1.tr0...kgk, IP=10.0.0.3\\n• replica 2: ID=b6c897d1186d, Name=test.2.sm1...1nw, IP=10.0.0.4\\nFigure 14.3 shows the configuration so far. Subnet and IP addresses may be different in\\nyour lab.\\nFigure 14.3\\nAs you can see, a layer 2 overlay network spans both nodes, and each container is\\nconnected to it with its own IP. This means the container on node1 can ping the\\ncontainer on node2 even though both nodes are on different underlay networks.\\nLet’s test it. You’ll need the names and IPs of your containers.\\nLog on to either of the containers and install the ping utility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 229}, page_content='14: Docker overlay networking\\n223\\n$ docker exec -it d7766923a5a7 bash\\n# apt update && apt-get install iputils-ping -y\\n<Snip>\\nReading package lists... Done\\nBuilding dependency tree\\nReading state information... Done\\n<Snip>\\nSetting up iputils-ping (3:20190709-3) ...\\nProcessing triggers for libc-bin (2.31-0ubuntu9) ...\\nNow ping the remote container by IP and then by replica ID.\\n# ping 10.0.0.4\\nPING 10.0.0.4 (10.0.0.4) 56(84) bytes of data.\\n64 bytes from 10.0.0.4: icmp_seq=1 ttl=64 time=1.06 ms\\n64 bytes from 10.0.0.4: icmp_seq=2 ttl=64 time=1.07 ms\\n64 bytes from 10.0.0.4: icmp_seq=3 ttl=64 time=1.03 ms\\n64 bytes from 10.0.0.4: icmp_seq=4 ttl=64 time=1.26 ms\\n^C\\n# ping test.2.sm180xqwm7k1bsyn3mt1fj1nw\\nPING test.2.sm180xqwm7k1bsyn3mt1fj1nw (10.0.0.4) 56(84) bytes of data.\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=1 ttl=64 time=2.83 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=2 ttl=64 time=8.39 ms'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 229}, page_content='64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=1 ttl=64 time=2.83 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=2 ttl=64 time=8.39 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=3 ttl=64 time=5.88 ms\\n^C\\nCongratulations. The containers can ping each other via the overlay network, and all the\\ntraffic is encrypted.\\nYou can also trace the route of the ping command. This will report a single hop, proving\\nthat the containers are communicating directly via the overlay network — blissfully\\nunaware of any underlay networks being traversed.\\nYou’ll need to install traceroute in the container for this to work.\\n# apt install traceroute\\n<Snip>\\n# traceroute 10.0.0.4\\ntraceroute to 10.0.0.4 (10.0.0.4), 30 hops max, 60 byte packets\\n1\\ntest-svc.2.sm180xqwm7k1bsyn3mt1fj1nw.uber-net (10.0.0.4)\\n1.110ms\\n1.034ms\\n1.073ms\\nSo far, you’ve created an overlay network and a swarm service that connected two'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 229}, page_content='1\\ntest-svc.2.sm180xqwm7k1bsyn3mt1fj1nw.uber-net (10.0.0.4)\\n1.110ms\\n1.034ms\\n1.073ms\\nSo far, you’ve created an overlay network and a swarm service that connected two\\ncontainers to it. Swarm scheduled the containers to two different nodes and you proved\\nthey could ping each other via the overlay network.\\nNow that you’ve seen how easy it is to build and use secure overlay networks, let’s find\\nout how Docker builds them behind the scenes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 230}, page_content='14: Docker overlay networking\\n224\\nOverlay networks explained\\nFirst and foremost, Docker uses VXLAN tunnels to create virtual layer 2 overlay net-\\nworks. So, let’s do a quick VXLAN primer.\\nVXLAN primer\\nAt the highest level, Docker uses VXLANs to create layer 2 networks on top of existing\\nlayer 3 infrastructure. That’s a lot of jargon that means you can create simple networks\\non top of complex networks. The hands-on example in the previous sections created\\na new 10.0.0.0/24 layer 2 network that abstracted a more complex network topology\\nbelow. See Figure 14.4 and remember that your underlay network configuration was\\nprobably different.\\nFigure 14.4\\nFortunately, VXLAN is an encapsulation technology and, therefore, transparent to exist-\\ning routers and network infrastructure. This means the routers and other infrastructure\\nin the underlay network see the VXLAN/overlay traffic as regular IP/UDP packets and\\nhandle it without requiring changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 230}, page_content='in the underlay network see the VXLAN/overlay traffic as regular IP/UDP packets and\\nhandle it without requiring changes.\\nTo create the overlay, Docker creates a VXLAN tunnel through the underlay networks,\\nand this tunnel is what allows the overlay traffic to flow freely without having to\\ninteract with the complexity of the underlay networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 231}, page_content='14: Docker overlay networking\\n225\\nTerminology: We use the terms underlay networks or underlay infrastructure to\\nrefer to the networks the overlay tunnels through.\\nEach end of the VXLAN tunnel is terminated by a VXLAN Tunnel Endpoint (VTEP), and\\nit’s this VTEP that encapsulates and de-encapsulates the traffic entering and exiting the\\ntunnel. See Figure 14.5.\\nFigure 14.5\\nThe image shows the layer 3 infrastructure as a cloud for two reasons:\\n• It can be a lot more complex than the two networks and a single router from the\\nprevious diagrams\\n• The VXLAN tunnel abstracts the complexity and makes it opaque\\nIn reality, the VXLAN tunnel traverses the underlay network. However, I don’t show\\nthis in the diagram to keep the diagram simple.\\nTraffic flow example\\nThe hands-on examples from earlier had two hosts connected via an IP network. You\\ndeployed an overlay network across both hosts, connected two containers to it, and did'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 231}, page_content='Traffic flow example\\nThe hands-on examples from earlier had two hosts connected via an IP network. You\\ndeployed an overlay network across both hosts, connected two containers to it, and did\\na ping test. Let’s explain some of the things that happened behind the scenes.\\nDocker created a new sandbox (network namespace) on each host with a new switch\\ncalled Br0. It also created a VTEP with one end connected to the Br0 virtual switch and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 232}, page_content='14: Docker overlay networking\\n226\\nthe other end connected to the host’s network stack. The end in the host’s network stack\\ngot an IP address on the underlay network that the host is connected to and was bound\\nto UDP port 4789. Finally, the two VTEPs on each host created a VXLAN tunnel as the\\nbackbone for the overlay network.\\nFigure 14.6 shows the configuration. Remember, the VXLAN tunnel goes through the\\nnetworks at the bottom of the diagram; I’ve just drawn it higher up for readability.\\nFigure 14.6\\nAt this point, you’ve created the VXLAN overlay, and you’re ready to connect contain-\\ners.\\nDocker now creates a virtual Ethernet adapter (veth) in each container and connects it\\nto the local Br0 virtual switch. The final topology looks like Figure 14.7, and although\\nit’s complex, you should now see how the containers communicate over the VXLAN\\noverlay despite their hosts being on two separate networks — the overlay is a virtual\\nnetwork tunneled through the underlay networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 233}, page_content='14: Docker overlay networking\\n227\\nFigure 14.7\\nNow that you know how Docker creates overlay networks, let’s see how the two\\ncontainers communicate.\\nWarning! This section is very technical, and you don’t need to understand it\\nall for day-to-day operations.\\nFor this example, we’ll call the container on node1 “C1” and the container on node2\\n“C2”. We’ll also assume C1 wants to ping C2 like we did in the practical example earlier.\\nFigure 14.8 shows the full configuration with container names and IPs added.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 234}, page_content='14: Docker overlay networking\\n228\\nFigure 14.8\\nC1 initiates a ping request to 10.0.0.4 — the IP address of C2.\\nC1 doesn’t have an entry for 10.0.0.4 in its local MAC address table (ARP cache), so\\nit floods the packet on all interfaces, including the veth interface connected to the Br0\\nbridge. The Br0 bridge knows it can forward traffic for 10.0.0.4 to the connected\\nVTEP interface and sends a proxy ARP reply to the container. This results in the veth\\nlearning how to forward the packet by updating its own MAC table to send all future\\npackets for 10.0.0.4 directly to the local VTEP. The Br0 switch knew about the C2\\ncontainer because Docker propagates details of all new containers to every swarm node\\nvia the network’s built-in gossip protocol.\\nNext, the veth in the C1 container sends the ping to the VTEP interface which encapsu-\\nlates it for transmission through the VXLAN tunnel. The encapsulation adds a VXLAN\\nheader containing a VXLAN network ID (VNID) that maps traffic from VLANs to'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 234}, page_content='lates it for transmission through the VXLAN tunnel. The encapsulation adds a VXLAN\\nheader containing a VXLAN network ID (VNID) that maps traffic from VLANs to\\nVXLANs and vice versa — each VLAN gets mapped to its own VNID so that packets\\ncan be de-encapsulated on the receiving end and forwarded to the correct VLAN. This\\nmaintains network isolation.\\nThe encapsulation also wraps the frame in a UDP packet and adds the IP of the remote\\nVTEP on node2 in the destination IP field. It also adds the UDP/4789 socket information.\\nThis encapsulation allows the packets to be routed across the underlay networks\\nwithout the underlays knowing anything about VXLAN.\\nWhen the packet arrives at node2, the host’s kernel sees it’s addressed to UDP port\\n4789 and knows it has a VTEP bound to this socket. This means it sends the packet to\\nthe VTEP, which reads the VNID, de-encapsulates it, and sends it to its own local Br0\\nswitch on the VLAN corresponding to the VNID. From there, it delivers it to the C2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 235}, page_content='14: Docker overlay networking\\n229\\ncontainer.\\nAnd that, my friends, is how Docker uses VXLAN to build and operate overlay networks\\n— a whole load of mind-blowing complexity beautifully hidden behind a single Docker\\ncommand.\\nI’m hoping that’s enough to get you started and help you when talking to your network-\\ning team about the networking aspects of your Docker infrastructure. On the topic of\\ntalking to your networking team… don’t approach them thinking that you now know\\neverything about VXLAN. If you do, you’ll probably embarrass yourself. I’m speaking\\nfrom experience ;-)\\nOne final thing. Docker also supports layer 3 routing within an overlay network. For\\nexample, you can create a single overlay network with two subnets, and Docker will\\nhandle the routing. The following command will create a new overlay called prod-net\\nwith two subnets. Docker will automatically create two virtual switches called Br0 and\\nBr1 inside the sandbox and handle all the routing.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 235}, page_content='with two subnets. Docker will automatically create two virtual switches called Br0 and\\nBr1 inside the sandbox and handle all the routing.\\n$ docker network create --subnet=10.1.1.0/24 --subnet=11.1.1.0/24 -d overlay prod-net\\nClean up\\nIf you followed along, you’ll have created an overlay network called uber-net and\\ndeployed a service called test. You may also have created a swarm.\\nRun the following command to delete the test service.\\n$ docker service rm test\\nDelete the uber-net network with the following command. You may have to wait a few\\nseconds while Docker deletes the service using it.\\n$ docker network rm uber-net\\nIf you no longer need the swarm, you can run a docker swarm leave -f command on\\nboth nodes. You should run it on node2 first.\\nDocker overlay networking – The commands\\n• docker network create tells Docker to create a new network. You use the -d\\noverlay flag to use the overlay driver to create an overlay network. You can also'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 235}, page_content='Docker overlay networking – The commands\\n• docker network create tells Docker to create a new network. You use the -d\\noverlay flag to use the overlay driver to create an overlay network. You can also\\npass the -o encrypted flag to tell Docker to encrypt network traffic. However,\\nperformance may drop in the region of 10%.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 236}, page_content='14: Docker overlay networking\\n230\\n• docker network ls lists all the container networks visible to a Docker host.\\nDocker hosts running in swarm mode only see overlay networks if they run\\ncontainers attached to the network. This keeps network-related management\\ntraffic to a minimum.\\n• docker network inspect shows detailed information about a particular container\\nnetwork. You can find out the scope, driver, IPv4 and IPv6 info, subnet configura-\\ntion, IP addresses of connected containers, VXLAN network ID, encryption state,\\nand more.\\n• docker network rm deletes a network.\\nChapter Summary\\nIn this chapter, you created a new Docker overlay network and learned about the\\ntechnologies Docker uses to build them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 237}, page_content='15: Volumes and persistent data\\nStateful applications that create and manage data are a big part of modern cloud-native\\napps. This chapter explains how Docker volumes help stateful applications manage their\\ndata.\\nI’ve split the chapter into the following parts:\\n• Volumes and persistent data – The TLDR\\n• Containers without volumes\\n• Containers with volumes\\n• The commands\\nVolumes and persistent data – The TLDR\\nThere are two main types of data — persistent and non-persistent.\\nPersistent data is the stuff you care about and need to keep. It includes things like cus-\\ntomer records, financial data, research results, audit data, and even some types of logs.\\nNon-persistent data is the stuff you don’t care about and don’t need to keep. We call\\napplications that create and manage persistent data stateful apps, and applications that\\ndon’t create or manage persistent data stateless apps.\\nBoth are important, and Docker has solutions for both.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 237}, page_content='applications that create and manage persistent data stateful apps, and applications that\\ndon’t create or manage persistent data stateless apps.\\nBoth are important, and Docker has solutions for both.\\nFor stateless apps, Docker creates every container with an area of non-persistent local\\nstorage that’s tied to the container lifecycle. This storage is suitable for scratch data\\nand temporary files, but you’ll lose it when you delete the container or the container\\nterminates.\\nDocker has volumes for stateful apps that create and manage important data. Volumes are\\nseparate objects that you mount into containers, and they have their own lifecycles. This\\nmeans you don’t lose the volumes or the data on them when you delete containers. You\\ncan even mount volumes into different containers.\\nThat’s the TLDR. Let’s take a closer look.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 238}, page_content='15: Volumes and persistent data\\n232\\nContainers without volumes\\nIn the early days of Docker, containers were only good for stateless applications that\\ndidn’t generate important data. However, despite being stateless, many of these apps still\\nneeded a place to write temporary scratch data. So, as shown in Figure 15.1, Docker\\ncreates containers by stacking read-only image layers and placing a thin layer of local\\nstorage on top. The same technology allows multiple containers to share the same read-\\nonly image layers.\\nFigure 15.1 - Ephemeral container storage\\nThis thin layer of local storage is integral to the read-write nature of containers. For\\nexample, if an application needs to update existing files or add new files, it makes\\nthe changes in the local storage layer, and Docker merges them into the view of the\\ncontainer. However, the local storage is coupled to the container’s lifecycle, meaning it\\ngets created when you create the container, and deleted when you delete it. This means'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 238}, page_content='container. However, the local storage is coupled to the container’s lifecycle, meaning it\\ngets created when you create the container, and deleted when you delete it. This means\\nit’s not a good place for data that you need to keep (persist).\\nDocker keeps the local storage layer on the Docker host’s filesystem, and you’ll hear it\\ncalled various names such as the thin writeable layer, ephemeral storage, read-write storage,\\nand graphdriver storage. It’s usually located in the following locations on your Docker\\nhosts:\\n• Linux containers: /var/lib/docker/<storage-driver>/...\\n• Windows containers: C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\...\\nEven though the local storage layer allows you to update live containers, you should\\nnever do this. Instead, you should treat containers as immutable objects and never change\\nthem once deployed. For example, if you need to fix or change the configuration of a live\\ncontainer, you should create and test a new container with the changes and then replace'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 238}, page_content='them once deployed. For example, if you need to fix or change the configuration of a live\\ncontainer, you should create and test a new container with the changes and then replace\\nthe live container with the new one.\\nTo be clear, applications like databases can change the data they manage. But users\\nand configuration tools should never change the container’s configuration, such as its\\nnetwork or application configuration. You should always make changes like these in a\\nnew container and then replace the old container with the new one.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 239}, page_content='15: Volumes and persistent data\\n233\\nIf your containers don’t create persistent data, this thin writable layer of local storage\\nwill be fine, and you’ll be good to go. However, if your containers create persistent data,\\nyou need to read the next section.\\nContainers with volumes\\nThere are three main reasons you should use volumes to handle persistent data in\\ncontainers:\\n• Volumes are independent objects that are not tied to the lifecycle of a container\\n• You can map volumes to specialized external storage systems\\n• Multiple containers on different Docker hosts can use volumes to access and share\\nthe same data\\nAt a high level, you create a volume, then create a container, and finally mount the\\nvolume into the container. When you mount it into the volume, you mount it into a\\ndirectory in the container’s filesystem, and anything you write to that directory gets\\nstored in the volume. If you delete the container, the volume and data will still exist.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 239}, page_content='directory in the container’s filesystem, and anything you write to that directory gets\\nstored in the volume. If you delete the container, the volume and data will still exist.\\nYou’ll even be able to mount the surviving volume into another container.\\nFigure 15.2 shows a Docker volume outside the container as a separate object. The\\nvolume is mounted into the container’s filesystem at /data, and anything you write to\\nthat directory will be stored on the volume and exist after you delete the container.\\nFigure 15.2 - High-level view of volumes and containers\\nThe image also shows that you can map the volume to an external storage system\\nor a directory on the Docker host. External storage systems can be cloud services or\\ndedicated storage appliances, but either way, the volume’s lifecycle is decoupled from\\nthe container. All of the container’s other directories use the thin writable layer in the\\nlocal storage area on the Docker host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 240}, page_content='15: Volumes and persistent data\\n234\\nCreating and managing Docker volumes\\nVolumes are first-class objects in Docker. This means there’s a docker volume sub-\\ncommand, and a volume resource in the API.\\nRun the following command to create a new volume called myvol.\\n$ docker volume create myvol\\nmyvol\\nBy default, Docker creates new volumes with the built-in local driver. And, as the name\\nof the driver suggests, these volumes are only available to containers on the same node\\nas the volume. You can use the -d flag to specify a different driver, but you’ll need to\\ninstall the driver first.\\nThird-party drivers22 provide advanced features and access to external storage systems\\nsuch as cloud storage services and on-premises storage systems such as SAN and NAS.\\nFigure 15.3 shows a Docker host connected to an external storage system via a plugin\\n(driver).\\nFigure 15.3 - Plugging external storage into Docker\\nOnce you’ve created the volume, you can see it with the docker volume ls command'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 240}, page_content='(driver).\\nFigure 15.3 - Plugging external storage into Docker\\nOnce you’ve created the volume, you can see it with the docker volume ls command\\nand inspect it with the docker volume inspect command.\\n22https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 241}, page_content='15: Volumes and persistent data\\n235\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmyvol\\n$ docker volume inspect myvol\\n[\\n{\\n\"CreatedAt\": \"2024-05-15T12:23:14Z\",\\n\"Driver\": \"local\",\\n\"Labels\": null,\\n\"Mountpoint\": \"/var/lib/docker/volumes/myvol/_data\",\\n\"Name\": \"myvol\",\\n\"Options\": null,\\n\"Scope\": \"local\"\\n}\\n]\\nNotice that the Driver and Scope fields are both set to local. This means you created\\nthe volume with the local driver, and it’s only available to containers on this Docker\\nhost. Mountpoint tells you where the volume exists in the Docker host’s filesystem.\\nBy default, Docker gives every volume created with the local driver its own directory\\non the host under /var/lib/docker/volumes. This means anyone with access to the\\nDocker host can bypass the container and access the volume’s contents directly in the\\nhost’s filesystem. You saw this in the Docker Compose chapter when we copied a file\\ndirectly into a volume’s directory on the Docker host, and the file immediately appeared'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 241}, page_content='host’s filesystem. You saw this in the Docker Compose chapter when we copied a file\\ndirectly into a volume’s directory on the Docker host, and the file immediately appeared\\nin the volume inside the container. However, that’s not a recommended practice.\\nNow that you’ve created a volume, you can create containers to use it. However, before\\nyou do that, there are two ways to delete Docker volumes:\\n• docker volume prune\\n• docker volume rm\\nThe docker volume prune --all command deletes all volumes not mounted into a\\ncontainer or service replica, so use it with caution!\\nThe docker volume rm command is more precise and lets you specify which volumes to\\ndelete.\\nNeither command will delete a volume in use by a container or service replica.\\nThe myvol volume you created isn’t used by a container, so you can delete it with either\\ncommand. Be careful if you use the prune command, as it may also delete other volumes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 242}, page_content='15: Volumes and persistent data\\n236\\n$ docker volume prune --all\\nWARNING! This will remove all local volumes not used by at least one container.\\nAre you sure you want to continue? [y/N] y\\nDeleted Volumes:\\nmyvol\\nTotal reclaimed space: 0B\\nCongratulations. You’ve created, inspected, and deleted a Docker volume, and none\\nof the actions involved a container. This proves that volumes are decoupled from\\ncontainers.\\nAt this point, you know all the commands to create, list, inspect, and delete Docker\\nvolumes. You’ve even seen how to deploy them via Compose files in the Compose and\\nSwarm stacks chapters. However, you can also deploy volumes via Dockerfiles by using\\nthe VOLUME instruction. The format is VOLUME <container-mount-point>. Interestingly,\\nyou cannot specify a host directory when you define volumes in a Dockerfile. This is\\nbecause host directories can differ depending on your host OS, and you could easily'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 242}, page_content='you cannot specify a host directory when you define volumes in a Dockerfile. This is\\nbecause host directories can differ depending on your host OS, and you could easily\\nbreak your builds if you specified a directory that doesn’t exist on a host. As a result,\\ndefining a volume in a Dockerfile requires you to specify host directories at deployment\\ntime.\\nUsing volumes with containers\\nLet’s see how to use volumes with containers.\\nRun the following command to create a new standalone container called voltainer that\\nmounts a volume called bizvol.\\n$ docker run -it --name voltainer \\\\\\n--mount source=bizvol,target=/vol \\\\\\nalpine\\nThe command specified the --mount flag, telling Docker to mount a volume called\\nbizvol into the container at /vol. The command completed successfully even though\\nyou didn’t have a volume called bizvol. This raises an important point:\\n• If you specify a volume that already exists, Docker will use it\\n• If you specify a volume that does not exist, Docker will create it'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 242}, page_content='• If you specify a volume that already exists, Docker will use it\\n• If you specify a volume that does not exist, Docker will create it\\nIn our case, bizvol didn’t exist, so Docker created it and mounted it into the container.\\nType Ctrl PQ to return to your local shell, and then list volumes to make sure Docker\\ncreated it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 243}, page_content='15: Volumes and persistent data\\n237\\n# <Ctrl-PQ>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nbizvol\\nEven though volumes are decoupled from containers, Docker won’t let you delete this\\none because it’s in use by the voltainer container.\\nTry to delete it.\\n$ docker volume rm bizvol\\nError response from daemon: remove bizvol: volume is in use - [b44d3f82...dd2029ca]\\nAs expected, you can’t delete it.\\nThe volume is brand new, so it doesn’t have any data. Let’s exec onto the container and\\nwrite some data to it.\\n$ docker exec -it voltainer sh\\n# echo \"I promise to write a book review on Amazon\" > /vol/file1\\nThe command writes some text to a file called file1 in the /vol directory where the\\nvolume is mounted.\\nRun a few commands to make sure the file and data exist.\\n# ls -l /vol\\ntotal 4\\n-rw-r--r-- 1 root\\nroot\\n50 May 23 08:49 file1\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nType exit to return to your Docker host’s shell, and then delete the container with the\\nfollowing commands.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 243}, page_content='root\\n50 May 23 08:49 file1\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nType exit to return to your Docker host’s shell, and then delete the container with the\\nfollowing commands.\\n# exit\\n$ docker rm voltainer -f\\nvoltainer\\nCheck that Docker deleted the container but kept the volume.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 244}, page_content='15: Volumes and persistent data\\n238\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nbizvol\\nAs the volume still exists, you can view its contents in the Docker host’s local filesystem.\\nRemember, though, that it’s not recommended to access volumes directly via the host’s\\nfilesystem. We’re just showing you how to do it for demonstration and educational\\nreasons.\\nRun the following commands from your Docker host terminal. They’ll show the\\ncontents of the volume’s directory on your Docker host. The first command will show\\nthat the file still exists, and the second will show its contents.\\nThis step won’t work on Docker Desktop, as Docker Desktop runs inside a VM. You\\nmay have to prefix the commands with sudo.\\n$ ls -l /var/lib/docker/volumes/bizvol/_data/\\ntotal 4\\n-rw-r--r-- 1 root root 50 Jan 12 14:25 file1\\n$ cat /var/lib/docker/volumes/bizvol/_data/file1\\nI promise to write a book review on Amazon\\nGreat, the volume and the data still exist.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 244}, page_content='total 4\\n-rw-r--r-- 1 root root 50 Jan 12 14:25 file1\\n$ cat /var/lib/docker/volumes/bizvol/_data/file1\\nI promise to write a book review on Amazon\\nGreat, the volume and the data still exist.\\nLet’s see if you can mount the existing bizvol volume into a new service or container.\\nRun the following command to create a new container called newctr that mounts bizvol\\nat /vol.\\n$ docker run -it \\\\\\n--name newctr \\\\\\n--mount source=bizvol,target=/vol \\\\\\nalpine sh\\nYour terminal is now attached to the newctr container. Check to see if the volume and\\ndata are mounted as expected.\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nCongratulations. You’ve created a volume, written some data to it, deleted the original\\ncontainer, mounted it in a second container, and verified the data still exists.\\nType exit to leave the container and jump over to Amazon to leave the book review you\\npromised to write.\\nIf you left a review, thanks! If you didn’t, I’ll cry, but I’ll live ;-)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 245}, page_content='15: Volumes and persistent data\\n239\\nSharing storage across cluster nodes\\nIntegrating Docker with external storage systems lets you present shared storage to\\nmultiple nodes so that the containers running on different nodes can share the same\\nvolumes. These external systems can be cloud storage services or enterprise storage\\nsystems in your on-premises data centers. For example, you can present a single storage\\nLUN or NFS share (shared volume) to multiple Docker hosts so that any container on\\nthose hosts can access and share the volume. Figure 15.4 shows an external storage\\nsystem presenting a shared volume to two Docker nodes. The Docker nodes use the\\nappropriate driver for the external system to make the shared volume available to either\\nor both containers.\\nFigure 15.4\\nBuilding a shared setup like this requires a lot of things. You need access to specialized\\nstorage systems and knowledge of how they work. You also need a volume driver/plugin'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 245}, page_content='Figure 15.4\\nBuilding a shared setup like this requires a lot of things. You need access to specialized\\nstorage systems and knowledge of how they work. You also need a volume driver/plugin\\nthat works with the external storage system. Finally, you need to know how your\\napplications read and write to the shared storage to avoid potential data corruption.\\nPotential data corruption\\nData corruption is a major concern for any shared storage configuration.\\nAssume the following example based on Figure 15.4.\\nThe application running in ctr1 writes an update to the shared volume. However,\\ninstead of directly committing the update, it keeps it in a local cache for faster recall. At\\nthis point, the application in ctr1 thinks it’s written data to the volume. However, before\\nctr1 flushes its cache and commits the data to the volume, the app in ctr2 updates the\\nsame data with a different value and commits it directly to the volume. At this point,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 245}, page_content='ctr1 flushes its cache and commits the data to the volume, the app in ctr2 updates the\\nsame data with a different value and commits it directly to the volume. At this point,\\nboth applications think they’ve updated the data in the volume, but in reality, only'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 246}, page_content='15: Volumes and persistent data\\n240\\nthe application in ctr2 has. A few seconds later, ctr1 flushes the data to the volume\\nand overwrites the changes made by the application in ctr2. However, neither of the\\napplications is aware of the changes the other has made.\\nThis is why you need to design applications that share data to coordinate updates to\\nshared volumes.\\nClean up\\nIf you’ve been following along, you’ll have a container and a volume.\\nRun the following command to delete the container.\\n$ docker rm\\nNow, run this command to delete the volume.\\n$ docker volume rm bizvol\\nVolumes and persistent data – The Commands\\n• docker volume create creates new volumes. By default, it creates them with the\\nlocal driver, but you can use the -d flag to specify a different driver.\\n• docker volume ls lists all volumes on your Docker host.\\n• docker volume inspect shows you detailed volume information. You can use this\\ncommand to see where a volume exists in the Docker host’s filesystem.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 246}, page_content='• docker volume inspect shows you detailed volume information. You can use this\\ncommand to see where a volume exists in the Docker host’s filesystem.\\n• docker volume prune deletes all volumes not in use by a container or service\\nreplica. Use with caution!\\n• docker volume rm deletes specific volumes that are not in use.\\nChapter Summary\\nThere are two main types of data: persistent and non-persistent.\\nPersistent data is data you need to keep, and non-persistent data is data you don’t need\\nto keep.\\nBy default, all containers get a layer of writable non-persistent storage that lives and dies\\nwith the container. We sometimes call this local storage, and it’s ideal for non-persistent'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 247}, page_content='15: Volumes and persistent data\\n241\\ndata. However, if your apps create data you need to keep, you should store the data in a\\nDocker volume.\\nDocker volumes are first-class objects in the Docker API, and you manage them\\nindependently of containers using their own docker volume sub-command. This means\\ndeleting containers doesn’t delete the data in their volumes.\\nA few third-party plugins exist that provide Docker with access to specialized external\\nstorage systems.\\nVolumes are the recommended way to work with persistent data in Docker environ-\\nments.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 248}, page_content='16: Docker security\\nIf security is hard, we’re less likely to implement it. Fortunately, most of the security\\nin Docker is easy and pre-configured with sensible defaults. This means you get a\\nmoderately secure experience with zero effort. The defaults are not perfect, but they’re a\\ngood starting point.\\nDocker supports all major Linux security technologies and adds some of its own. As\\nsuch, I’ve divided the chapter so we cover the Linux security technologies first and\\nfinish the chapter covering the Docker technologies:\\n• Docker security – The TLDR\\n• Linux security technologies\\n– Kernel namespaces\\n– Control Groups\\n– Capabilities\\n– Mandatory Access Control\\n– seccomp\\n• Docker security technologies\\n– Swarm security\\n– Docker Scout and vulnerability scanning\\n– Docker Content Trust\\n– Docker secrets\\nThe chapter focuses heavily on Linux, but the sections relating to Docker security\\ntechnologies apply to Linux and Windows containers.\\nDocker security – The TLDR'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 248}, page_content='– Docker secrets\\nThe chapter focuses heavily on Linux, but the sections relating to Docker security\\ntechnologies apply to Linux and Windows containers.\\nDocker security – The TLDR\\nGood security is about layers and defence in depth, and more layers is always better.\\nFortunately, Docker offers a lot of security layers, including the ones shown in Figure\\n16.1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 249}, page_content='16: Docker security\\n243\\nFigure 16.1\\nAs you can see, Docker leverages the common Linux security and workload isolation\\ntechnologies, including namespaces, control groups, capabilities, mandatory access control\\n(MAC), and seccomp. It ships with sensible defaults for each one, but you can customize\\nthem to your specific requirements.\\nDocker also has its own security technologies, including Docker Scout and Docker\\nContent Trust.\\nDocker Scout offers class-leading vulnerability scanning that scans your images, provides\\ndetailed reports on known vulnerabilities, and recommends solutions. Docker Content\\nTrust (DCT) lets you cryptographically sign and verify images.\\nIf you use Docker Swarm, you’ll also get all of the following that Docker automatically\\nconfigures: cryptographic node IDs, mutual authentication (TLS), automatic CA\\nconfiguration and certificate rotation, secure cluster join tokens, an encrypted cluster\\nstore, encrypted networks, and more.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 249}, page_content='configuration and certificate rotation, secure cluster join tokens, an encrypted cluster\\nstore, encrypted networks, and more.\\nOther security-related technologies also exist, but the important thing to know is that\\nDocker works with the major Linux security technologies and adds a few of its own.\\nSometimes, the Linux security technologies can be complex and challenging to work\\nwith, but the native Docker ones are always easy.\\nKernel Namespaces\\nKernel namespaces, usually shortened to namespaces, are the main technology for building\\ncontainers.\\nLet’s quickly compare namespaces and containers with hypervisors and virtual ma-\\nchines (VM).'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 250}, page_content='16: Docker security\\n244\\nNamespaces virtualize operating system constructs such as process trees and filesystems,\\nwhereas hypervisors virtualize physical resources such as CPUs and disks. In the VM model,\\nhypervisors create virtual machines by grouping virtual CPUs, virtual disks, and virtual\\nnetwork cards so that every VM looks, smells, and feels like a physical machine. In the\\ncontainer model, namespaces create virtual operating systems (containers) by grouping\\nvirtual process trees, virtual filesystems, and virtual network interfaces so that every\\ncontainer looks, smells, and feels exactly like a regular OS.\\nAt a very high level, namespaces provide lightweight isolation but do not provide a\\nstrong security boundary. Compared with VMs, containers are more efficient, but\\nvirtual machines are more secure.\\nDon’t worry, though. Platforms like Docker implement additional security technologies,\\nsuch as cgroups, capabilities, and seccomp, to improve container security.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 250}, page_content='virtual machines are more secure.\\nDon’t worry, though. Platforms like Docker implement additional security technologies,\\nsuch as cgroups, capabilities, and seccomp, to improve container security.\\nNamespaces are a tried and tested technology that’s existed in the Linux kernel for\\na very long time. However, they were complex and hard to work with until Docker\\ncame along and hid all the complexity behind the simple docker run command and a\\ndeveloper-friendly API.\\nAt the time of writing, every Docker container gets its own instance of the following\\nnamespaces:\\n• Process ID (pid)\\n• Network (net)\\n• Filesystem/mount (mnt)\\n• Inter-process Communication (ipc)\\n• User (user)\\n• UTS (uts)\\nFigure 16.2 shows a single Docker host running two containers. The host OS has its\\nown collection of namespaces we call the root namespaces, and each container has its own\\ncollection of equivalent isolated namespaces. Applications in containers think they’re'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 250}, page_content='own collection of namespaces we call the root namespaces, and each container has its own\\ncollection of equivalent isolated namespaces. Applications in containers think they’re\\nrunning on their own host and are unaware of the root namespaces or namespaces in\\nother containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 251}, page_content='16: Docker security\\n245\\nFigure 16.2\\nLet’s briefly look at how Docker uses each namespace:\\n• Process ID namespace: Docker uses the pid namespace to give each container\\nits own isolated process tree. This means every container gets its own PID 1 and\\ncannot see or access processes running in other containers. Nor can any container\\nsee or access processes running on the host.\\n• Network namespace: Docker uses the net namespace to provide each container\\nwith an isolated network stack. This stack includes interfaces, IP addresses,\\nport ranges, and routing tables. For example, every container gets its own eth0\\ninterface with its own unique IP and range of ports.\\n• Mount namespace: Every container has its own mnt namespace with its own\\nunique isolated root (/) filesystem. This means every container can have its own\\n/etc, /var, /dev, and other important filesystem constructs. Processes inside a\\ncontainer cannot access the host’s filesystem or filesystems in other containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 251}, page_content='/etc, /var, /dev, and other important filesystem constructs. Processes inside a\\ncontainer cannot access the host’s filesystem or filesystems in other containers.\\n• Inter-process Communication namespace: Docker uses the ipc namespace\\nfor shared memory access within a container. It also isolates the container from\\nshared memory on the host and other containers.\\n• User namespace: Docker gives each container its own users that are only valid\\ninside the container. It also lets you map those users to different users on the\\nDocker host. For example, you can map a container’s root user to a non-root user\\non the host.\\n• UTS namespace: Docker uses the uts namespace to provide each container with\\nits own hostname.\\nRemember, a container is a collection of namespaces that Docker organizes to look like\\na regular OS. These namespaces provide isolation, but they are not a strong enough'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 252}, page_content='16: Docker security\\n246\\nsecurity boundary on their own. This is why Docker augments container security with\\nthe technologies we’re about to discuss.\\nControl Groups\\nIf namespaces are about isolation, control groups (cgroups) are about limits.\\nThink of containers as similar to rooms in a hotel. While each room might appear to be\\nisolated, they actually share a lot of things such as water supply, electricity supply, air\\nconditioning, swimming pool, gym, elevators, breakfast bar, and more. Containers are\\nsimilar — even though they’re isolated, they share a lot of common resources such as the\\nhost’s CPU, RAM, network I/O, and disk I/O.\\nDocker uses cgroups to limit a container’s use of these shared resources and prevent any\\ncontainer from consuming them all and causing a denial of service (DoS) attack.\\nCapabilities\\nThe Linux root user is extremely powerful, and you shouldn’t use it to run apps and\\ncontainers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 252}, page_content='container from consuming them all and causing a denial of service (DoS) attack.\\nCapabilities\\nThe Linux root user is extremely powerful, and you shouldn’t use it to run apps and\\ncontainers.\\nHowever, it’s not as simple as running them as non-root users, as most non-root users\\nare so powerless that they are practically useless. What’s needed is a way to run apps and\\ncontainers with the exact set of permissions they need — nothing more, nothing less.\\nThis is where capabilities come to the rescue.\\nUnder the hood, the Linux root user is a combination of a long list of capabilities. Some\\nof these capabilities include:\\n• CAP_CHOWN: lets you change file ownership\\n• CAP_NET_BIND_SERVICE: lets you bind a socket to low-numbered network\\nports\\n• CAP_SETUID: lets you elevate the privilege level of a process\\n• CAP_SYS_BOOT: lets you reboot the system.\\nThe list goes on and is long.\\nDocker leverages capabilities so that you can run containers as root but strip out'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 252}, page_content='• CAP_SYS_BOOT: lets you reboot the system.\\nThe list goes on and is long.\\nDocker leverages capabilities so that you can run containers as root but strip out\\nall the capabilities you don’t need. For example, suppose the only capability your\\ncontainer needs is the ability to bind to low-numbered network ports. In that case,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 253}, page_content='16: Docker security\\n247\\nDocker can start the container as root, drop all root capabilities, and then add back the\\nCAP_NET_BIND_SERVICE capability.\\nThis is a good example of implementing the principle of least privilege as you end up\\nwith a container that only has the capabilities it needs. Docker also sets restrictions to\\nprevent containers from re-adding dropped capabilities.\\nDocker ships with sensible out-of-the-box capabilities, but you should configure your\\nown for your production apps and containers. However, configuring your own requires\\nextensive effort and testing.\\nMandatory Access Control systems\\nDocker works with major Linux MAC technologies such as AppArmor and SELinux.\\nDepending on your Linux distribution, Docker applies default AppArmor or SELinux\\nprofiles to all new containers, and according to the Docker documentation, the default\\nprofiles are moderately protective while providing wide application compatibility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 253}, page_content='profiles to all new containers, and according to the Docker documentation, the default\\nprofiles are moderately protective while providing wide application compatibility.\\nYou can tell Docker to start containers without these policies, and you can configure\\nyour own. However, as with capabilities, configuring your own policies is very powerful\\nbut requires a lot of effort and testing.\\nseccomp\\nDocker uses seccomp to limit which syscalls a container can make to the host’s kernel.\\nSyscalls are how applications ask the Linux kernel to perform tasks. At the time of writ-\\ning, Linux has over 300 syscalls and the default Docker profile disables approximately\\n40-50.\\nAs per the Docker security philosophy, all new containers get a default seccomp profile\\nconfigured with sensible defaults designed to provide moderate security without impacting\\napplication compatibility.\\nAs always, you can customize your own seccomp profiles or tell Docker to start'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 253}, page_content='configured with sensible defaults designed to provide moderate security without impacting\\napplication compatibility.\\nAs always, you can customize your own seccomp profiles or tell Docker to start\\ncontainers without one. Unfortunately, the Linux syscall table is long, and configuring\\ncustom seccomp policies may be prohibitively complex for some users.\\nFinal thoughts on the Linux security technologies\\nDocker supports most of the important Linux security technologies and ships with\\nsensible defaults that add security without being too restrictive. Figure 16.3 shows how\\nDocker uses them to build a defence in depth security posture with multiple layers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 254}, page_content='16: Docker security\\n248\\nFigure 16.3 - Linux security defense in depth\\nSome of these technologies require knowledge of the Linux kernel and can be complex\\nto customize. Fortunately, many platforms, including Docker, ship with defaults that are\\na good place to start.\\nDocker security technologies\\nLet’s switch our focus to some of the security technologies Docker offers.\\nSwarm security\\nDocker Swarm lets you cluster multiple Docker hosts and manage applications declar-\\natively. Every Swarm comprises manager nodes and worker nodes that can be Linux or\\nWindows. Managers host the control plane and are responsible for configuring the\\ncluster and dispatching work tasks. Workers run application containers.\\nFortunately, swarm mode includes many security features that Docker automatically\\nconfigures with sensible defaults. These include:\\n• Cryptographic node IDs\\n• TLS for mutual authentication'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 255}, page_content='16: Docker security\\n249\\n• Secure join tokens\\n• CA configuration with automatic certificate rotation\\n• Encrypted cluster store\\n• Encrypted networks\\nLet’s walk through building a secure swarm and configuring some of the security\\naspects.\\nIf you’re following along, you’ll need three Docker hosts that can ping each other by\\nname. The examples use three hosts called mgr1, mgr2, and wrk1.\\nConfigure a secure Swarm\\nRun the following command from the node you want to be the first manager. We’ll run\\nthe example from mgr1.\\n$ docker swarm init\\nSwarm initialized: current node (7xam...662z) is now a manager.\\nThat’s it! You’ve configured a secure swarm with a cryptographic cluster ID, an en-\\ncrypted cluster store, a certificate authority (CA) with a 90-day certificate rotation\\npolicy, a set of secure join tokens to use when adding new managers and workers, and\\nconfigured the current manager with a client certificate for mutual TLS — all with a\\nsingle command!'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 255}, page_content='policy, a set of secure join tokens to use when adding new managers and workers, and\\nconfigured the current manager with a client certificate for mutual TLS — all with a\\nsingle command!\\nThe CA is for internal Swarm security, and you should be careful using it for anything\\nelse.\\nFigure 16.4 shows the current swarm configuration. Some of the details may be\\ndifferent in your lab.\\nFigure 16.4'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 256}, page_content='16: Docker security\\n250\\nLet’s join mgr2 as an additional manager.\\nJoining new managers is a two-step process:\\n• Extract the secure join token\\n• Execute a docker swarm join command with the join token on the node you’re\\nadding\\nRun the following command from mgr1 to extract the manager join token.\\n$ docker swarm join-token manager\\nTo add a manager to this swarm, run the following command:\\ndocker swarm join --token \\\\\\nSWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz \\\\\\n172.31.5.251:2377\\nThe output gives you the full command and join token to run on mgr2. The join token\\nand IP address will be different in your lab.\\nThe format of the join command is:\\n• docker swarm join --token <manager-join-token> <ip-of-existing-\\nmanager>:<swarm-port>\\nThe format of the token is:\\n• SWMTKN-1-<hash-of-cluster-certificate>-<manager-join-token>\\nCopy the command and run it on mgr2:\\n$ docker swarm join --token SWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz 172.31.5.251:2377\\nThis node joined a swarm as a manager.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 256}, page_content='Copy the command and run it on mgr2:\\n$ docker swarm join --token SWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz 172.31.5.251:2377\\nThis node joined a swarm as a manager.\\nList the nodes in your swarm.\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\n7xamk...ge662z\\nmgr1\\nReady\\nActive\\nLeader\\ni0ue4...zcjm7f *\\nmgr2\\nReady\\nActive\\nReachable'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 257}, page_content='16: Docker security\\n251\\nYou now have a two-node swarm with mgr1 and mgr2 as managers. Both have access to\\nthe cluster store and are configured with client certificates for mutual TLS.\\nIn the real world, you’ll always run three or five managers for high availability.\\nFigure 16.5 shows the updated swarm with both managers.\\nFigure 16.5\\nAdding worker nodes is a similar two-step process — extract the join token and run the\\ncommand on the node.\\nRun the following command on either of the managers to expose the worker join\\ncommand and token.\\n$ docker swarm join-token worker\\nTo add a worker to this swarm, run the following command:\\ndocker swarm join --token \\\\\\nSWMTKN-1-1dmtw...17stb-ehp8g...w738q \\\\\\n172.31.5.251:2377\\nCopy the command and run it on wrk1:\\n$ docker swarm join --token SWMTKN-1-1dmtw...17stb-ehp8g...w738q 172.31.5.251:2377\\nThis node joined a swarm as a worker.\\nRun another docker node ls from either of your managers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 258}, page_content='16: Docker security\\n252\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\n7xamk...ge662z *\\nmgr1\\nReady\\nActive\\nLeader\\nailrd...ofzv1u\\nwrk1\\nReady\\nActive\\ni0ue4...zcjm7f\\nmgr2\\nReady\\nActive\\nReachable\\nYour swarm has two managers and a worker. The managers are configured for high\\navailability (HA) and the cluster store is replicated to both. The worker node is part of\\nthe swarm but cannot access the cluster store. Figure 16.6 shows the final configuration.\\nFigure 16.6\\nNow that you’ve built a secure Swarm, let’s examine some of the security aspects.\\nSwarm join tokens\\nThe only requirement for joining managers and workers is possession of the secure join\\ntoken. This means you should keep them safe and never post them on public repos or\\neven internal repos that are not restricted.\\nEvery swarm maintains two distinct join tokens:\\n• Manager token\\n• Worker token\\nEvery join token has four distinct fields separated by dashes (-):\\n• PREFIX - VERSION - SWARM ID - TOKEN'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 258}, page_content='Every swarm maintains two distinct join tokens:\\n• Manager token\\n• Worker token\\nEvery join token has four distinct fields separated by dashes (-):\\n• PREFIX - VERSION - SWARM ID - TOKEN\\nThe prefix is always SWMTKN and allows you to pattern-match against it to prevent people\\nfrom accidentally posting it publicly. The VERSION field indicates the version of the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 259}, page_content='16: Docker security\\n253\\nswarm. The Swarm ID field is a hash of the swarm’s certificate. The TOKEN field is the\\nworker or manager token.\\nAs you can see in the following table, the manager and worker tokens for any given\\nswarm are identical except for the final TOKEN field.\\nRole\\nPrefix\\nVersion\\nSwarm ID\\nToken\\nManager\\nSWMTKN\\n1\\n1dmtwusdc…r17stb\\n2axi53zjbs45lqxykaw8p7glz\\nWorker\\nSWMTKN\\n1\\n1dmtwusdc…r17stb\\nehp8gltji64jbl45zl6hw738q\\nIf you suspect either of your join tokens are compromised, you can revoke them and\\nissue new ones with a single command. The following example revokes the existing\\nmanager token and issues a new one.\\n$ docker swarm join-token --rotate manager\\nSuccessfully rotated manager join token.\\nExisting managers are unaffected, but you can only add new ones with the new token.\\nAs expected, the last field is the only difference between the old and new tokens.\\nDocker keeps a copy of join tokens in the encrypted cluster store.\\nTLS and mutual authentication'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 259}, page_content='As expected, the last field is the only difference between the old and new tokens.\\nDocker keeps a copy of join tokens in the encrypted cluster store.\\nTLS and mutual authentication\\nDocker issues every manager and worker with a client certificate that they use for\\nmutual authentication. It identifies the node, the swarm it’s a member of, and whether\\nit’s a manager or worker.\\nYou can inspect a node’s client certificate on Linux with the following command.\\n$ sudo openssl x509 \\\\\\n-in /var/lib/docker/swarm/certificates/swarm-node.crt \\\\\\n-text\\nCertificate:\\nData:\\nVersion: 3 (0x2)\\nSerial Number:\\n7c:ec:1c:8f:f0:97:86:a9:1e:2f:4b:a9:0e:7f:ae:6b:7b:b7:e3:d3\\nSignature Algorithm: ecdsa-with-SHA256\\nIssuer: CN = swarm-ca\\nValidity\\nNot Before: May 23 08:23:00 2024 GMT\\nNot After : Aug 21 09:23:00 2024 GMT\\nSubject: O = tcz3w1t7yu0s4wacovn1rtgp4, OU = swarm-manager,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 260}, page_content='16: Docker security\\n254\\nCN = 2gxz2h1f0rnmc3atm35qcd1zw\\nSubject Public Key Info:\\n<SNIP>\\nAs shown in Figure 16.7, the Subject field uses the standard O, OU, and CN fields to\\nspecify the Swarm ID, the node’s role, and the node ID:\\n• The Organization (O) field stores the Swarm ID\\n• The Organizational Unit (OU) field stores the node’s role in the swarm\\n• The Canonical Name (CN) field stores the node’s crypto ID.\\nYou can also see the certificate rotation period in the Validity section.\\nFigure 16.7\\nYou can match these values to the corresponding values from a docker info command.\\n$ docker info\\n<SNIP>\\nSwarm: active\\nNodeID: 2gxz2h1f0rnmc3atm35qcd1zw\\n<<---- Relates to the CN field\\nIs Manager: true\\n<<---- Relates to the OU field\\nClusterID: tcz3w1t7yu0s4wacovn1rtgp4\\n<<---- Relates to the O field\\n<SNIP>\\nCA Configuration:\\nExpiry Duration: 3 months\\n<<---- Relates to the validity block\\nForce Rotate: 0\\nRoot Rotation In Progress: false\\n<SNIP>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 261}, page_content='16: Docker security\\n255\\nSwarm CA configuration\\nYou can use the docker swarm update command to configure the certificate rotation\\nperiod. The following example changes it to 30 days.\\n$ docker swarm update --cert-expiry 720h\\nSwarm allows nodes to renew certificates early so that all nodes don’t update at exactly\\nthe same time.\\nYou can configure a new swarm to use an external CA by passing the --external-ca\\nflag to docker swarm init command, and you can use the docker swarm ca command\\nto manage other CA-related settings.\\n$ docker swarm ca --help\\nUsage:\\ndocker swarm ca [OPTIONS]\\nDisplay and rotate the root CA\\nOptions:\\n--ca-cert pem-file\\nPath to the PEM-formatted root CA certificate to use\\nfor the new cluster\\n--ca-key pem-file\\nPath to the PEM-formatted root CA key to use for the\\nnew cluster\\n--cert-expiry duration\\nValidity period for node certificates (ns|us|ms|s|m|h)\\n(default 2160h0m0s)\\n-d, --detach\\nExit immediately instead of waiting for the root rotation\\nto converge'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 261}, page_content='new cluster\\n--cert-expiry duration\\nValidity period for node certificates (ns|us|ms|s|m|h)\\n(default 2160h0m0s)\\n-d, --detach\\nExit immediately instead of waiting for the root rotation\\nto converge\\n--external-ca external-ca\\nSpecifications of one or more certificate signing endpoints\\n-q, --quiet\\nSuppress progress output\\n--rotate\\nRotate the swarm CA - if no certificate or key are\\nprovided, new ones will be generated\\nThe cluster store\\nThe cluster store is where Docker keeps the configuration and state of a swarm. It’s also\\ncritical to other Docker technologies, such as overlay networks and secrets. This is why\\noverlay networks and many other advanced security features only work in swarm mode.\\nThe cluster store is based on the popular etcd distributed database and is automatically\\nencrypted and replicated to all managers.\\nDocker handles day-to-day maintenance, but you should implement strong backup and\\nrecovery procedures for production clusters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 261}, page_content='encrypted and replicated to all managers.\\nDocker handles day-to-day maintenance, but you should implement strong backup and\\nrecovery procedures for production clusters.\\nThat’s enough about swarm mode security for now. Let’s look at some Docker security\\ntechnologies that don’t require swarm mode.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 262}, page_content='16: Docker security\\n256\\nDocker Scout and vulnerability scanning\\nEvery container runs multiple software packages that are susceptible to bugs and\\nvulnerabilities that malicious actors can exploit.\\nImage scanning analyzes your images and produces a detailed list of all the software\\npackages it uses. We call this list a software bill of materials (SBOM), and the image\\nscanning system compares the SBOM against databases of known vulnerabilities and\\nprovides a report of vulnerabilities in your software. Most vulnerability scanners will\\nrank the vulnerabilities and provide advice on fixes.\\nVulnerability scanning is now an integral part of most software supply chains.\\nDocker Scout is Docker’s native scanning platform and works with Docker Hub,\\nDocker Desktop, the Docker CLI, and even has its own Docker Scout Dashboard.\\nHowever, it’s a subscription-based service.\\nOther scanning platforms are available, but most of these also require some form of\\nsubscription.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 262}, page_content='However, it’s a subscription-based service.\\nOther scanning platforms are available, but most of these also require some form of\\nsubscription.\\nIf you’re using Docker Desktop, you can run the following command to see an example\\nof Docker Scout.\\n$ docker scout quickview nigelpoulton/tu-demo:latest\\n✓Provenance obtained from attestation\\n✓Pulled\\n✓Image stored for indexing\\n✓Indexed 66 packages\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\n│\\n0C\\n4H\\n2M\\n0L\\ndigest\\n│\\nb4210d0aa52f\\n│\\nBase image\\n│\\npython:3-alpine\\n│\\n0C\\n2H\\n1M\\n0L\\nUpdated base image │\\npython:3.11-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\n│\\n│\\nThe output shows zero critical vulnerabilities (0C), four high (4H), two medium (2M),\\nand zero low (0L).\\nYou can also run a docker scout cves command to get more detailed information,\\nincluding remediation advice.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 263}, page_content='16: Docker security\\n257\\n$ docker scout cves nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\n\\uffffDetected 6 vulnerable packages with a total of 8 vulnerabilities\\n## Overview\\n│\\nAnalyzed Image\\n────────────────────┼────────────────────────────────\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64\\nvulnerabilities │\\n0C\\n4H\\n2M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2\\npkg:apk/alpine/expat@2.5.0-r2?os_name=alpine&os_version=3.19\\n\\uffffHIGH CVE-2023-52425\\nhttps://scout.docker.com/v/CVE-2023-52425\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n\\uffffMEDIUM CVE-2023-52426\\nhttps://scout.docker.com/v/CVE-2023-52426\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n<Snip>\\nI’ve snipped the output, so it only shows some of the vulnerabilities. However, even\\nfrom the snipped output in the book, you can see:\\n• Scout has scanned 66 packages and detected several vulnerabilities'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 263}, page_content='from the snipped output in the book, you can see:\\n• Scout has scanned 66 packages and detected several vulnerabilities\\n• We’re using version 2.5.0-r2 of the expat package which has one high (1H) and\\none medium (1M) vulnerability\\n• The high vulnerability is listed as CVE-2023-52425 and the medium as CVE-2023-\\n52426\\n• The report includes links to Scout reports containing more info on each vulnera-\\nbility\\n• Scout recommends updating to expat version 2.6.0-r0 which contains fixes for\\nboth\\nFigure 16.8 shows what it looks like in in Docker Desktop, and you get similar integra-\\ntions and views in Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 264}, page_content='16: Docker security\\n258\\nFigure 16.8 - Docker Scout integration with Docker Desktop\\nIf you subscribe to Docker Scout, you can use the scout.docker.com portal to configure\\npolicies and integrations with Docker Hub and other registries.\\nAs good as vulnerability scanning is, it only scans images and doesn’t detect security\\nproblems with networks, nodes, or orchestrators. Also, not all image scanners are equal.\\nFor example, the best ones perform deep binary-level scans, whereas others may just\\nlook at package names and do not inspect content closely.\\nIn summary, scanning tools are great for inspecting your images and detecting known\\nvulnerabilities. Beware though, with great knowledge comes great responsibility — once\\nyou’re aware of vulnerabilities, you’re responsible for mitigating or fixing them.\\nSigning and verifying images with Docker Content\\nTrust\\nDocker Content Trust (DCT) makes it simple for you to verify the integrity and pub-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 264}, page_content='Signing and verifying images with Docker Content\\nTrust\\nDocker Content Trust (DCT) makes it simple for you to verify the integrity and pub-\\nlisher of images and is especially important when you’re pulling images over untrusted\\nnetworks such as the internet.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 265}, page_content='16: Docker security\\n259\\nAt a high level, DCT lets you sign your images when you push them to registries like\\nDocker Hub. It also lets you verify the images you pull and run as containers.\\nFigure 16.9 shows the high-level process.\\nFigure 16.9 - Docker Content Trust image signing and verification\\nYou can also use DCT to provide context, such as whether or not a developer has signed\\nan image for use in a particular environment such as prod or dev, or whether an image\\nhas been superseded by a newer version and is therefore stale.\\nThe following steps walk you through configuring Docker Content Trust, signing and\\npushing an image, and then pulling the signed image.\\nIf you plan on following along, you’ll need a cryptographic key pair. If you don’t already\\nhave one, you can run the following docker trust command to generate one. The\\ncommand generates a new key pair called nigel and loads it to the local trust store ready\\nfor use. It will prompt you to enter a passphrase; don’t forget it :-)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 265}, page_content='command generates a new key pair called nigel and loads it to the local trust store ready\\nfor use. It will prompt you to enter a passphrase; don’t forget it :-)\\n$ docker trust key generate nigel\\nGenerating key for nigel...\\nEnter passphrase for new nigel key with ID 1f78609:\\nRepeat passphrase for new nigel key with ID 1f78609:\\nSuccessfully generated and loaded private key.... key available: /Users/nigelpoulton/nigel.pub\\nIf you already have a key pair, you can import and load it with docker trust key load\\nkey.pem --name nigel.\\nThe next step is associating your key pair with the image repository to which you’ll push\\nsigned images. This example associates the nigel.pub key with the nigelpoulton/ddd-\\ntrust repo on Docker Hub. Your key file and repo will be different, and the repository\\ndoesn’t have to exist before you run the command.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 266}, page_content='16: Docker security\\n260\\n$ docker trust signer add --key nigel.pub nigel nigelpoulton/ddd-trust\\nAdding signer \"nigel\" to nigelpoulton/dct...\\nInitializing signed repository for nigelpoulton/dct...\\nEnter passphrase for root key with ID aee3314:\\nEnter passphrase for new repository key with ID 1a18dd1:\\nRepeat passphrase for new repository key with ID 1a18dd1:\\nSuccessfully initialized \"nigelpoulton/dct\"\\nSuccessfully added signer: nigel to nigelpoulton/dct\\nNow that you’ve loaded the key pair and associated it with a repository, the final step is\\nto sign an image and push it to the repo.\\nThe following command signs a local image called nigelpoulton/ddd-trust:signed\\nand pushes it to Docker Hub. Your image will have a different name and you’ll push it to\\na different repo.\\n$ docker trust sign nigelpoulton/ddd-trust:signed\\nSigning and pushing trust data for local image nigelpoulton/ddd-trust:signed may...\\nThe push refers to repository [docker.io/nigelpoulton/ddd-trust]'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 266}, page_content='$ docker trust sign nigelpoulton/ddd-trust:signed\\nSigning and pushing trust data for local image nigelpoulton/ddd-trust:signed may...\\nThe push refers to repository [docker.io/nigelpoulton/ddd-trust]\\n6495b414566f: Mounted from nigelpoulton/ddd-book\\n798676f7ef8b: Mounted from nigelpoulton/ddd-book\\nbca4290a9639: Mounted from nigelpoulton/ddd-book\\n28ad2149d870: Mounted from nigelpoulton/ddd-book\\n4f4fb700ef54: Mounted from nigelpoulton/ddd-book\\n5e1fc7f5df34: Mounted from nigelpoulton/ddd-book\\nsigned: digest: sha256:b65f9a1aa4e670bbafd0fbb91281ea95f9cdc5728aa546579e248dfbc0ea4bde\\nSigning and pushing trust metadata\\nEnter passphrase for nigel key with ID 92330ea:\\nSuccessfully signed docker.io/nigelpoulton/ddd-trust:signed\\nThe push operation creates the repo on Docker Hub and then signs and pushes the\\nimage. You can view the repo on Docker Hub, and you can run the following command\\nto inspect its signing data.\\n$ docker trust inspect nigelpoulton/ddd-trust:signed --pretty'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 266}, page_content='image. You can view the repo on Docker Hub, and you can run the following command\\nto inspect its signing data.\\n$ docker trust inspect nigelpoulton/ddd-trust:signed --pretty\\nSignatures for nigelpoulton/ddd-trust:signed\\nSIGNED TAG\\nDIGEST\\nSIGNERS\\nsigned\\n30e6d35703c578ee...4fcbbcbb0f281\\nnigel\\nList of signers and their keys for nigelpoulton/ddd-trust:signed\\nSIGNER\\nKEYS\\nnigel\\n4d6f1bf55702\\nAdministrative keys for nigelpoulton/ddd-trust:signed\\nRepository Key:\\n5e72e54afafb8444f...6b2744b32010ad22\\nRoot Key:\\n40418fc47544ca630...69a2cb89028c22092'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 267}, page_content='16: Docker security\\n261\\nYou can export the DOCKER_CONTENT_TRUST variable with a value of 1 to force a Docker\\nhost to sign and verify all images.\\n$ export DOCKER_CONTENT_TRUST=1\\nOnce enabled, you won’t be able to pull and work with unsigned images.\\nTest it by trying to pull an unsigned image.\\n$ docker pull nigelpoulton/ddd-book:web0.2\\nError: remote trust data does not exist for docker.io/nigelpoulton/ddd-book: notary.docker.io\\ndoes not have trust data for docker.io/nigelpoulton/ddd-book\\nYou can no longer pull images without trust data!\\nDelete the local copy of the image you just signed and pushed so that you can try pulling\\nit from Docker Hub. Your image name will be different.\\n$ docker rmi nigelpoulton/ddd-trust:signed\\nUntagged: nigelpoulton/ddd-trust:signed@sha256...\\n<Snip>\\nNow, try pulling the image.\\n$ docker pull nigelpoulton/ddd-trust:signed\\nPull (1 of 1): nigelpoulton/ddd-trust:signed@sha256:30e6...'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 267}, page_content='Untagged: nigelpoulton/ddd-trust:signed@sha256...\\n<Snip>\\nNow, try pulling the image.\\n$ docker pull nigelpoulton/ddd-trust:signed\\nPull (1 of 1): nigelpoulton/ddd-trust:signed@sha256:30e6...\\ndocker.io/nigelpoulton/ddd-trust@sha256:30e6... Pulling from nigelpoulton/ddd-trust\\n08409d417260: Pull complete\\nDigest: sha256:30e6d35703c578ee703230b9dc87ada2ba958c1928615ac8a674fcbbcbb0f281\\nStatus: Downloaded newer image for nigelpoulton/ddd-trust@sha256:30e6...\\nTagging nigelpoulton/ddd-trust@sha256:30e6d... as nigelpoulton/ddd-trust:signed\\ndocker.io/nigelpoulton/ddd-trust:signed\\nThe pull worked because the image has valid trust data.\\nIn summary, Docker Content Trust is an important technology that helps you verify the\\nintegrity of the images you pull and run. It’s simple to configure in its basic form, but\\nmore advanced features, such as context, can be more complex.\\nDocker Secrets\\nMost applications leverage sensitive data such as passwords, certificates, and SSH keys.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 267}, page_content='more advanced features, such as context, can be more complex.\\nDocker Secrets\\nMost applications leverage sensitive data such as passwords, certificates, and SSH keys.\\nFortunately, Docker lets you wrap them inside secrets to keep them secure.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 268}, page_content='16: Docker security\\n262\\nNote: Secrets only work in swarm mode as they leverage the cluster store.\\nBehind the scenes, Docker encrypts secrets when they’re at rest in the cluster store and\\nwhile they’re in flight on the network. It also uses in-memory filesystems to mount secrets\\ninto containers and operates a least-privilege model, where secrets are only available\\nto services that have been explicitly granted access. There’s even a docker secret\\ncommand.\\nFigure 16.10 shows the high-level workflow of creating a secret and deploying it to\\nservice replicas:\\nFigure 16.10 - Secret workflow\\nLet’s go through the five steps in the diagram. I’ve used a key symbol to show the secret,\\nand it’s only available to the dark containers.\\n1. You create the secret\\n2. Docker stores it in the encrypted cluster store\\n3. You create a service (the dark containers) and grant it access to the secret\\n4. Docker encrypts the secret when sending it over the network to service replicas'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 268}, page_content='3. You create a service (the dark containers) and grant it access to the secret\\n4. Docker encrypts the secret when sending it over the network to service replicas\\n5. Docker mounts the secret into service replicas as an unencrypted file in an in-\\nmemory filesystem\\nThe light-colored containers are part of a different service and cannot access the secret.\\nAs soon as replicas using the secret terminate, Docker destroys the in-memory filesys-\\ntem and flushes the secret from the node.\\nDocker mounts secrets in their unencrypted form so that applications can use them\\nwithout needing keys to decrypt them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 269}, page_content='16: Docker security\\n263\\nYou can create and manage secrets with the docker secret command and attach them\\nto services by passing the --secret flag to the docker service create command.\\nClean up\\nIf you’ve followed along, you’ve created a swarm, added a signer, created a new repo\\non Docker Hub, and exported an environment variable to sign and verify images\\nautomatically.\\nRun the following command to disable Docker Content Trust. You’ll need to run it on\\nevery node where you enabled Docker Content Trust.\\n$ unset DOCKER_CONTENT_TRUST\\nRemove the signer from the repository you created. Your signer and repository will have\\ndifferent names.\\n$ docker trust signer remove nigel nigelpoulton/ddd-trust\\nRemoving signer \"nigel\" from nigelpoulton/ddd-trust...\\nall signed tags are currently revoked, use docker trust sign to fix\\nYou may also want to delete the repositories you created on Docker Hub and delete the\\nlocal key files on your system (usually a .pub file in your home directory)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 269}, page_content='You may also want to delete the repositories you created on Docker Hub and delete the\\nlocal key files on your system (usually a .pub file in your home directory)\\nDelete the swarm by running the following command on all swarm nodes. You should\\nrun it on the swarm managers last.\\n$ docker swarm leave -f\\nChapter Summary\\nYou can configure Docker to be extremely secure. It supports all of the major Linux\\nsecurity technologies such as kernel namespaces, cgroups, capabilities, MAC, and\\nseccomp. It ships with sensible defaults for all of these, but you can customize and even\\ndisable them.\\nIn addition to the Linux security technologies, Docker includes an extensive set of\\nits own security technologies. Swarms are built on TLS and are secure out of the box.\\nDocker Scout performs binary-level image scans and provides detailed reports of\\nknown vulnerabilities and suggested fixes. Docker Content Trust lets you sign and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 269}, page_content='Docker Scout performs binary-level image scans and provides detailed reports of\\nknown vulnerabilities and suggested fixes. Docker Content Trust lets you sign and\\nverify images, and Docker secrets allow you to share sensitive data with swarm services.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 270}, page_content='What next\\nThank you so much for reading my book. You’re on your way to mastering Docker and\\ncontainers, and you’ve learned some skills running local LLMs.\\nGet involved with the community\\nThere’s a vibrant cloud-native community full of helpful people. Get involved with\\nDocker groups and chats on the internet, and look up your local Docker or cloud-native\\nmeetup (search for “Docker meetup near me”).\\nKubernetes\\nNow that you understand Docker, Kubernetes is a great next step. It’s a lot like Swarm\\nbut has a larger scope and a more active community.\\nIf you liked this book, you’ll love my Kubernetes books.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 271}, page_content='What next\\n265\\nFeedback and reviews\\nBooks live and die by Amazon reviews and stars.\\nI live and breathe this book, ensuring you get the most up-to-date content that’s easy to\\nread and understand. So, please take a moment to leave a kind review on Amazon or\\nGoodreads.\\nAlso, ping me at ddd@nigelpoulton.com if you want to suggest content or fixes for\\nfuture editions.\\nConnect with me\\nFinally, thanks for reading my book. Feel free to connect with me on any of the usual\\nplatforms to discuss Docker, Kubernetes, Wasm, AI, and other technologies.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 272}, page_content='Terminology\\nThis glossary defines some of the most common Docker and container-related terms\\nused in the book.\\nIf you think I’ve missed anything important, ping me at ddd@nigelpoulton.com.\\nTerm\\nDefinition (according to Nigel)\\nAI acceleration hardware\\nHardware, such as GPUs, NPUs, and TPUs\\nthat speed up the execution (inference) of AI\\nmodels.\\nAPI\\nApplication Programming Interface. In the\\ncase of Docker, all resources are defined in\\nthe Docker API, which is RESTful and\\nexposed via the Docker Daemon.\\nBase image\\nThe first layer of all container images.\\nCreated by the Dockerfile FROM instruction\\nand usually contains a minimal set of OS\\nconstructs required by an application.\\nBuild\\nThe process of building a new container\\nimage. Docker builds images by stepping\\nthrough a set of instructions defined in a\\nDockerfile.\\nBuild Cloud\\nA subscription service that performs fast and\\nefficient image builds in Docker’s cloud\\ninfrastructure. It allows you to share a\\ncommon build cache among teams for very'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 272}, page_content='Dockerfile.\\nBuild Cloud\\nA subscription service that performs fast and\\nefficient image builds in Docker’s cloud\\ninfrastructure. It allows you to share a\\ncommon build cache among teams for very\\nfast builds.\\nBuildKit\\nDocker’s build engine that implements\\nadvanced build features such as advanced\\ncaching, multi-stage builds, and\\nmulti-architecture builds.\\nBuildx\\nDocker’s latest and greatest build client that\\nsupports all the latest features of BuildKit,\\nsuch as multi-stage builds and\\nmulti-architecture images. Buildx has been\\nDocker’s default build client since Docker\\nEngine v23.0 and Docker Desktop v4.19.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 273}, page_content='Terminology\\n267\\nTerm\\nDefinition (according to Nigel)\\nCapability\\nLinux kernel technology used by Docker to\\ncreate user accounts with the precise set of\\nsystem access they need.\\nChatbot\\nA computer program that can participate in\\ntext-based human conversations and is often\\nindistinguishable from a human.\\nCloud native\\nA loaded term that means different things to\\ndifferent people. Cloud native is a way of\\ndesigning, building, and working with\\nmodern applications and infrastructure. I\\nconsider an application to be cloud native if it\\ncan self-heal, scale on demand, perform\\nrolling updates, and versioned rollbacks.\\nCluster store\\nDocker Swarm’s distributed database that\\nholds the state of the cluster and apps. Based\\non the etcd distributed database, it is\\nautomatically encrypted and automatically\\ndistributed across all swarm managers for\\nhigh availability.\\nCompose\\nAn open specification for defining, deploying,\\nand managing multi-container microservices\\napps. Docker implements the Compose spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 273}, page_content='distributed across all swarm managers for\\nhigh availability.\\nCompose\\nAn open specification for defining, deploying,\\nand managing multi-container microservices\\napps. Docker implements the Compose spec\\nand provides the docker compose command\\nto make it easy to work with Compose apps.\\nContainer\\nA container is a collection of kernel\\nnamespaces organized to look, smell, and feel\\nlike a regular operating system. Each\\ncontainer runs a single application, and\\ncontainers are smaller, faster, and more\\nportable than virtual machines. We\\nsometimes call them Docker containers or OCI\\ncontainers\\nContainer Network Model\\nPluggable interface enabling different\\nnetwork topologies and architectures. Third\\nparties provide CNM plugins for overlay\\nnetworks and BGP networks, as well as\\nvarious implementations of each.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 274}, page_content='Terminology\\n268\\nTerm\\nDefinition (according to Nigel)\\nContainer runtime\\nSoftware running on every Docker node\\nresponsible for pulling container images,\\nstarting containers, stopping containers, and\\nother low-level container operations. Docker\\nuses two runtimes that work together:\\ncontainerd is Docker’s high-level runtime\\nthat manages lifecycle events such as starting\\nand stopping containers, whereas runc is\\nDocker’s low-level runtime that interfaces\\nwith kernel constructs such as namespaces\\nand cgroups.\\ncontainerd\\nIndustry-standard container runtime used by\\nDocker and most Kubernetes clusters.\\nDonated to the CNCF by Docker, Inc.\\nPronounced “container dee”.\\nContainerize\\nThe process of packaging an application and\\nall dependencies into a container image.\\nControl Groups (cgroups)\\nLinux kernel feature that Docker uses to limit\\nthe amount of host CPU, RAM, disk, and\\nnetwork resources a container uses.\\nDesired state\\nHow your cluster and applications should be.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 274}, page_content='Linux kernel feature that Docker uses to limit\\nthe amount of host CPU, RAM, disk, and\\nnetwork resources a container uses.\\nDesired state\\nHow your cluster and applications should be.\\nFor example, the desired state of an application\\nmicroservice might be five replicas of xyz\\ncontainer listening on port 8080/tcp. Vital to\\nreconciliation.\\nDocker\\nPlatform that makes it easy to work with\\ncontainerized apps. It allows you to build\\nimages, as well as run and manage standalone\\ncontainers and multi-container apps.\\nDocker Debug\\nDocker CLI plugin that lets you easily debug\\nslim images and containers that don’t ship\\nwith any debugging tools.\\nDocker Desktop\\nDesktop application for Linux, Mac, and\\nWindows that makes working with Docker\\neasy. It has a slick UI and many advanced\\nfeatures like image management, vulnerability\\nscanning, and Wasm support.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 275}, page_content='Terminology\\n269\\nTerm\\nDefinition (according to Nigel)\\nDocker Hub\\nHigh-performance OCI-compliant image\\nregistry. Docker Hub has over 57PB of\\nstorage and handles an average of 30K\\nrequests per second.\\nDocker, Inc.\\nUS-based technology company making it easy\\nfor developers to build, ship, and run\\ncontainerized applications. The company\\nbehind the Docker platform.\\nDocker init\\nA new Docker CLI plugin that creates\\nhigh-fidelity Dockerfiles and makes it easy to\\nscaffold Compose apps.\\nDocker Model Runner\\nDocker’s native tool for running local AI\\nmodels directly on host hardware (outside of\\ncontainers). Exposes OpenAI-compatible\\nendpoints.\\nDocker Scout\\nDocker’s native vulnerability scanning service.\\nScout is a subscription service that integrates\\nwith the Docker CLI, Docker Desktop,\\nDocker Hub, and other image registries.\\nDockerfile\\nPlain text file with instructions telling Docker\\nhow to build an application into a container\\nimage.\\netcd\\nThe open-source distributed database used by\\nDocker Swarm.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 275}, page_content='Dockerfile\\nPlain text file with instructions telling Docker\\nhow to build an application into a container\\nimage.\\netcd\\nThe open-source distributed database used by\\nDocker Swarm.\\nGGUF\\nBinary file format for storing LLM weights\\nand metadata.\\nGPU\\nGraphics Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nImage\\nArchive containing application code, all\\ndependencies, and the metadata required to\\nstart a single application as a container. We\\nsometimes call them OCI images, container\\nimages, or Docker images.\\nIngress network\\nHidden network on all Docker Swarm\\nclusters used to publish services to external\\nclients.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 276}, page_content='Terminology\\n270\\nTerm\\nDefinition (according to Nigel)\\nKernel namespace\\nFeature of the Linux kernel used by Docker to\\nisolate containers from processes running on\\nthe host and in other containers.\\nllama.cpp\\nPopular core inference engine (LLM runtime)\\nused by model servers like Docker Model\\nRunner and Ollama. Open source project that\\ncan run LLMs on low-grade consumer CPUs\\nas well as some high-performance GPUs.\\nLarge Language Model (LLM)\\nAn AI application that can participate in\\nhuman conversations and create human-like\\nanswers and ideas. The book’s AI chatbot app\\nuses an LLM that is trained as a coding\\nassistant that can help answer coding\\nquestions and provide coding samples.\\nLayer\\nImage layers contain modifications to the\\nbase image or the layer below them. Docker\\nbuilds images by stacking layers, each\\ncontaining changes to the layer below it. A\\nsimple example is a base layer that has basic\\nOS constructs, followed by a layer with the\\napplication. The two combined layers create'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 276}, page_content='containing changes to the layer below it. A\\nsimple example is a base layer that has basic\\nOS constructs, followed by a layer with the\\napplication. The two combined layers create\\nthe image with the OS and app.\\nlibcontainer\\nA Go library that uses namespaces, cgroups,\\nand capabilities to build containers. Docker\\nuses libcontainer via the runc low-level\\nruntime that is a CLI wrapper around\\nlibcontainer.\\nlibnetwork\\nThe Go library used by Docker to create and\\nmanage container networks.\\nManifest (OCI)\\nJSON document describing the configuration\\nand layers of OCI artifacts such as images and\\nmodels.\\nMicroservices\\nDesign pattern for modern applications.\\nIndividual application features are developed\\nas their own small applications\\n(microservices/containers) and communicate\\nvia APIs. They work together to form a useful\\napplication.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 277}, page_content='Terminology\\n271\\nTerm\\nDefinition (according to Nigel)\\nModel\\nAI program that has been pre-trained to\\naccept prompts and give human-like\\nresponses. We refer to AI programs as models.\\nMLX\\nApple’s machine learning framework that\\ngives AI models access to the unified memory\\narchitecture of Apple’s M series chips.\\nMulti-architecture builds (sometimes called\\nmulti-platform builds)\\nAllows you to build images for multiple\\narchitectures and platforms with a single\\ndocker build command. For example, you\\ncan run a single docker build command on\\nan AMD-based Windows system to build an\\nAMD image and an ARM image.\\nMulti-stage build\\nAllows you to create very small images (slim\\nimages). You build your images in stages and\\nonly carry forward the necessary artifacts for\\neach next stage. Each build stage is\\nrepresented by its own FROM instruction in\\nyour Dockerfile, and later build stages use the\\nCOPY --from instruction to use artifacts from\\nprevious stages and leave everything else\\nbehind.\\nNPU'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 277}, page_content='represented by its own FROM instruction in\\nyour Dockerfile, and later build stages use the\\nCOPY --from instruction to use artifacts from\\nprevious stages and leave everything else\\nbehind.\\nNPU\\nNeural Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nObserved state\\nAlso known as current state or actual state. The\\nmost up-to-date view of the cluster and\\nrunning applications. Docker Swarm is\\nalways working to make observed state match\\ndesired state.\\nOllama\\nOpen-source runtime for running LLMs\\nlocally. A bit like Docker for LLMs — Ollama\\ncan pull and push LLMs and run them locally\\non your computer.\\nOpenAI-compatible endpoint\\nAPI service that accepts requests formatted\\naccording to OpenAI’s API specifications and\\nreturns responses in the same format.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 278}, page_content='Terminology\\n272\\nTerm\\nDefinition (according to Nigel)\\nOpen Container Initiative (OCI)\\nLightweight governance body responsible for\\ncreating and maintaining standards for\\nlow-level container technologies such as\\nimages, runtimes, and registries. Docker\\ncreates OCI-compliant images, implements\\nan OCI-compliant runtime, and Docker Hub\\nis an OCI-compliant registry.\\nOrchestrator\\nSoftware that deploys and manages apps.\\nDocker Swarm and Kubernetes are examples\\nof orchestrators that manage microservices\\napps, keep them healthy, scale them up and\\ndown, and more…\\nOverlay network\\nA large flat layer-2 network that spans\\nmultiple swarm nodes. All containers on the\\nsame overlay network can communicate with\\neach other, even if they’re on different Docker\\nhosts on different networks. The built-in\\noverlay driver creates overlay networks using\\nadvanced VXLAN technologies. Only used by\\nDocker Swarm.\\nPush\\nUpload an image to a registry.\\nPull\\nDownload an image from a registry.\\nQuantization'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 278}, page_content='overlay driver creates overlay networks using\\nadvanced VXLAN technologies. Only used by\\nDocker Swarm.\\nPush\\nUpload an image to a registry.\\nPull\\nDownload an image from a registry.\\nQuantization\\nThe process of reducing the size and memory\\nrequirements of an AI model without\\nsacrificing too much performance and model\\naccuracy.\\nReconciliation\\nThe process of watching the state of an\\napplication and ensuring observed state\\nmatches desired state. Docker Swarm runs\\nreconciliation loops, ensuring applications\\nrun how you want them to.\\nRegistry\\nCentral place for storing and retrieving\\nimages. We sometimes call them OCI registries,\\ncontainer registries, or Docker registries.\\nRepository\\nAn area of a registry where you store related\\ncontainer images. You can set access controls\\nper repository.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 279}, page_content='Terminology\\n273\\nTerm\\nDefinition (according to Nigel)\\nREPL\\nRead, Evaluate, Print, Loop. CLI environment\\nfor testing and interacting with LLMs.\\nSeccomp\\nSecure computing Linux kernel feature used\\nby Docker to restrict the syscalls available to a\\ncontainer.\\nSecret\\nThe way Docker Swarm lets you inject\\nsensitive data into a container at run-time.\\nService\\nCapital “S” is a Docker Swarm feature that\\naugments containers with self-healing,\\nscaling, rollouts, and rollbacks.\\nSpin\\nFramework that makes it easy to build,\\ndeploy, and run Wasm apps. Docker Desktop\\nships with the spin runtime. Created by\\nFermyon Technologies, Inc.\\nSwarm (also known as Docker Swarm)\\nDocker’s native orchestration platform. A\\nlightweight and easy alternative to\\nKubernetes.\\nTPU\\nTensor Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nVolume\\nWhere containers store important data they\\nneed to keep. You can create and delete\\nvolumes independently from containers.\\nWasm (WebAssembly)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 279}, page_content='AI models.\\nVolume\\nWhere containers store important data they\\nneed to keep. You can create and delete\\nvolumes independently from containers.\\nWasm (WebAssembly)\\nNew virtual machine architecture that is\\nsmaller, faster, more portable, and more\\nsecure than traditional containers. Wasm apps\\nrun anywhere with a Wasm runtime.\\nYAML\\nYet Another Markup Language. You write\\nCompose files in YAML. It’s a superset of\\nJSON.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(texts))\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "141e6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ede54af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b5a345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 1}, page_content='Docker Deep Dive\\nZero to Docker in a single book!\\nNigel Poulton\\nThis book is available at https://leanpub.com/dockerdeepdive\\nThis version was published on 2025-05-12\\nISBN 9781916585133\\nThis is a Leanpub book. Leanpub empowers authors and publishers with the Lean\\nPublishing process. Lean Publishing is the act of publishing an in-progress ebook using\\nlightweight tools and many iterations to get reader feedback, pivot until you have the\\nright book and build traction once you do.\\n© 2016 - 2025 Nigel Poulton'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 2}, page_content='Huge thanks to my wife and kids for putting up with a geek in the house who genuinely thinks\\nhe’s a bunch of software running inside of a container on top of midrange biological hardware. It\\ncan’t be easy living with me!\\nMassive thanks as well to everyone who watches my Pluralsight videos. I love connecting with you\\nand really appreciate all the feedback I’ve gotten over the years. This was one of the major reasons\\nI decided to write this book! I hope it’ll be an amazing tool to help you drive your careers even\\nfurther forward.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 3}, page_content='Contents\\nAbout this edition\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n1\\nAbout the author\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n2\\n0: About the book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n3\\nPart 1: The big picture stuff . . . . . . . . . . . . . . . . . . . . .\\n6\\n1: Containers from 30,000 feet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nThe bad old days . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nHello VMware! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nVMwarts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\nHello Containers! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nLinux containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 3}, page_content='7\\nHello Containers! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nLinux containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n8\\nHello Docker! . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\nDocker and Windows . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\nWhat about Wasm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\nDocker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\nWhat about Kubernetes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n2: Docker and container-related standards and projects . . . . . . . . . . . . . . . . 13\\nDocker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nContainer-related standards and projects . . . . . . . . . . . . . . . . . . . . . . . . 15'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 3}, page_content='Docker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nContainer-related standards and projects . . . . . . . . . . . . . . . . . . . . . . . . 15\\n3: Getting Docker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nDocker Desktop\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nInstalling Docker with Multipass\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nInstalling Docker on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4: The big picture\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nThe Ops Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nThe Dev Perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='CONTENTS\\nPart 2: The technical stuff . . . . . . . . . . . . . . . . . . . . . . . 35\\n5: The Docker Engine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\nDocker Engine – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\nThe Docker Engine\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\nThe influence of the Open Container Initiative (OCI) . . . . . . . . . . . . . . . . . 39\\nrunc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\ncontainerd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\nStarting a new container (example) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\\nWhat’s the shim all about? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nHow it’s implemented on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='What’s the shim all about? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nHow it’s implemented on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n6: Working with Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDocker images – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nIntro to images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nPulling images\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nImage registries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nImage naming and tagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nImages and layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\nPulling images by digest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nMulti-architecture images'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='Pulling images by digest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nMulti-architecture images\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nVulnerability scanning with Docker Scout . . . . . . . . . . . . . . . . . . . . . . . . 66\\nDeleting Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\\nImages – The commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\\n7: Working with containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nContainers – The TLDR\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\nContainers vs VMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nImages and Containers\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\nCheck Docker is running . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nStarting a container'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\nCheck Docker is running . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nStarting a container\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\nHow containers start apps\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\\nConnecting to a running container . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\\nInspecting container processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\\nThe docker inspect command . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\nWriting data to a container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\nStopping, restarting, and deleting a container . . . . . . . . . . . . . . . . . . . . . . 85\\nKilling a container’s main process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nDebugging slim images and containers with Docker Debug'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 4}, page_content='Killing a container’s main process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nDebugging slim images and containers with Docker Debug\\n. . . . . . . . . . . . . 89\\nSelf-healing containers with restart policies . . . . . . . . . . . . . . . . . . . . . . . 94\\nContainers – The commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\\n8: Containerizing an app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='CONTENTS\\nContainerizing an app – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\\nContainerize a single-container app\\n. . . . . . . . . . . . . . . . . . . . . . . . . . .100\\nMoving to production with multi-stage builds\\n. . . . . . . . . . . . . . . . . . . . . 111\\nBuildx, BuildKit, drivers, and Build Cloud . . . . . . . . . . . . . . . . . . . . . . . .116\\nMulti-architecture builds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .118\\nA few good practices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\nContainerizing an app – The commands . . . . . . . . . . . . . . . . . . . . . . . . . 124\\n9: Multi-container apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nDocker Compose – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\\nCompose background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='Docker Compose – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\\nCompose background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nInstalling Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nThe sample app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .128\\nCompose files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .130\\nDeploying apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .133\\nManaging apps with Compose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .136\\nDeploying apps with Compose – The commands . . . . . . . . . . . . . . . . . . . .139\\n10: Docker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner background . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='10: Docker and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner background . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nDocker Model Runner Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . .142\\nInstalling Docker Model Runner . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nExplore Docker Model Runner\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .145\\nUse Docker Model Runner with Compose . . . . . . . . . . . . . . . . . . . . . . . .152\\nUse Docker Model Runner with Open WebUI\\n. . . . . . . . . . . . . . . . . . . . .155\\nRunning models in containers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .160\\nDocker Model Runner – The commands . . . . . . . . . . . . . . . . . . . . . . . . .162\\nChapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .163'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='Docker Model Runner – The commands . . . . . . . . . . . . . . . . . . . . . . . . .162\\nChapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .163\\n11: Docker and Wasm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164\\nPre-reqs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .165\\nIntro to Wasm and Wasm containers . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\\nWrite a Wasm app\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .168\\nContainerize a Wasm app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .170\\nRun a Wasm container . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172\\nClean up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173\\nChapter summary\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 5}, page_content='Clean up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173\\nChapter summary\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n12: Docker Swarm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nSwarm primer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175\\nBuild a swarm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .176\\nDeploy Swarm app . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .179\\nDocker Swarm – The Commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='CONTENTS\\n13: Docker Networking\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nDocker Networking – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189\\nDocker networking theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189\\nSingle-host bridge networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .193\\nExternal access via port mappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . .200\\nDocker Networking – The Commands . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\n14: Docker overlay networking\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nDocker overlay networking – The TLDR\\n. . . . . . . . . . . . . . . . . . . . . . . .216\\nDocker overlay networking history . . . . . . . . . . . . . . . . . . . . . . . . . . . .216\\nBuilding and testing Docker overlay networks\\n. . . . . . . . . . . . . . . . . . . . . 217'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='Docker overlay networking history . . . . . . . . . . . . . . . . . . . . . . . . . . . .216\\nBuilding and testing Docker overlay networks\\n. . . . . . . . . . . . . . . . . . . . . 217\\nOverlay networks explained . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDocker overlay networking – The commands . . . . . . . . . . . . . . . . . . . . . .229\\n15: Volumes and persistent data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nVolumes and persistent data – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . 231\\nContainers without volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .232\\nContainers with volumes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .233\\nVolumes and persistent data – The Commands . . . . . . . . . . . . . . . . . . . . .240\\n16: Docker security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='Volumes and persistent data – The Commands . . . . . . . . . . . . . . . . . . . . .240\\n16: Docker security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nDocker security – The TLDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .242\\nKernel Namespaces\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243\\nControl Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .246\\nCapabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .246\\nMandatory Access Control systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\nseccomp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\nDocker security technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nSwarm security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 6}, page_content='Docker security technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nSwarm security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248\\nDocker Scout and vulnerability scanning\\n. . . . . . . . . . . . . . . . . . . . . . . .256\\nSigning and verifying images with Docker Content Trust . . . . . . . . . . . . . . .258\\nDocker Secrets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nWhat next . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\\nTerminology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 7}, page_content='CONTENTS\\n1\\nAbout this edition\\nThis edition was published in May 2025 and is up to date with the latest industry trends\\nand the latest enhancements to Docker.\\nMajor changes include:\\n• Brand new Docker Model Runner chapter with full AI LLM project\\n• Updates to BuildKit, buildx, and the new Docker Build Cloud\\n• Updates to Docker Debug content\\n• Updates to Wasm content\\n• Streamlined Swarm chapter\\nEnjoy the book, and get ready to master containers!\\n&copy 2025 Nigel Poulton Ltd.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 8}, page_content='About the author\\nNigel is a technology geek with a passion for learning new technologies and making\\nthem easier for others to learn. He’s the author of best-selling books on Docker and\\nKubernetes, as is the author of AI Explained: Facts, Fiction, and Future, a brutal read\\ninto the impacts of AI on society and the future of humanity.\\nNigel is a Docker Captain and has held senior technology roles at large and small\\nenterprises.\\nIn his free time, he listens to audiobooks and coaches youth football (soccer). He wishes\\nhe lived in the future and could understand the mysteries of life and the universe. He’s\\npassionate about learning, cars, and football (soccer). He lives in England with his\\nfabulous wife and three children.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 9}, page_content='0: About the book\\nThis May 2025 edition gets you up to speed with Docker and containers fast, no prior\\nexperience necessary.\\nIt has a brand-new chapter covering the latest and greatest Docker Model Runner\\ncontent for running local LLMs through Docker!\\nWhy should I read this book or care about Docker?\\nDocker has already changed how we build, share, and run applications, and it’s now\\nplaying a major role in emerging technologies such as Wasm and AI.\\nSo, if you want the best jobs working with the best technologies, you need a strong\\nDocker skillset.\\nHow I’ve organized the book\\nI’ve divided the book into two main sections:\\n1. The big picture stuff\\n2. The technical stuff\\nThe big picture stuff gets you up to speed with the basics, such as what Docker is, why we\\nuse containers, and fundamental jargon such as cloud-native, microservices, and orchestration.\\nThe technical stuff section covers everything you need to know about images, containers,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 9}, page_content='use containers, and fundamental jargon such as cloud-native, microservices, and orchestration.\\nThe technical stuff section covers everything you need to know about images, containers,\\nmulti-container microservices apps, orchestration, and the increasingly important topics of\\nWebAssembly, running local AI models, vulnerability scanning, debugging containers,\\nand more.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 10}, page_content='0: About the book\\n4\\nChapter breakdown\\n• Chapter 1: Summarizes the history and future of Docker and containers\\n• Chapter 2: Explains the most important container-related standards and projects\\n• Chapter 3: Shows you a few ways to get Docker\\n• Chapter 4: Walks you through deploying your first container\\n• Chapter 5: Deep dive into the Docker Engine architecture\\n• Chapter 6: Deep dive into images and image management\\n• Chapter 7: Deep dive into containers and container management\\n• Chapter 8: Deep dive into containerizing applications\\n• Chapter 9: Walks you through deploying and managing a multi-container AI\\nchatbot app with Docker Compose\\n• Chapter 10: Dives into the exciting new world of running local AI models with\\nDocker Model Runner\\n• Chapter 11: Walks you through building, containerizing, and running a Wasm app\\nwith Docker\\n• Chapter 12: Walks you through building a swarm cluster and deploying apps to it\\n• Chapter 13: Deep dive into Docker networking'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 10}, page_content='with Docker\\n• Chapter 12: Walks you through building a swarm cluster and deploying apps to it\\n• Chapter 13: Deep dive into Docker networking\\n• Chapter 14: Walks you through building and working with overlay networks\\n• Chapter 15: Introduces you to persistent and non-persistent data in Docker\\n• Chapter 16: Covers all the major Linux and Docker security technologies\\nEditions and updates\\nDocker, AI, and the cloud-native ecosystem are evolving fast, and 2-3-year-old books\\nare dangerously outdated. As a result, I’m committed to updating this book at least once\\nper year.\\nIf that sounds excessive, welcome to the new normal. For example, I released a big\\nupdate in January 2025. Then, less than three months later, I was writing a full new\\nchapter on Docker Model Runner for this May 2025 edition! This is hard work, but I’m\\ncommitted to keeping this the best Docker book in the world.\\nThe book is available in hardback, paperback, and e-book on all good book publishing\\nplatforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 11}, page_content='0: About the book\\n5\\nKindle updates\\nUnfortunately, Kindle readers cannot get updates. I have absolutely no control over\\nthis and was devastated when this change happened. Some people have successfully\\ncontacted Kindle Support and had the support team delete the old copy and push the\\nnew edition. However, this doesn’t always work. Please contact the Kindle Support team\\nfor updates, but if they can’t help, feel free to ping me at the book’s email address.\\nFeedback\\nIf you like the book and it helps your career, share the love by recommending it to a\\nfriend and leaving a review on Amazon or Goodreads.\\nIf you spot a typo or want to make a recommendation, drop me a quick email at\\nddd@nigelpoulton.com and I’ll do my best to respond.\\nThat’s everything. Let’s get rocking with Docker!'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 12}, page_content='Part 1: The big picture stuff'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 13}, page_content='1: Containers from 30,000 feet\\nContainers have taken over the world!\\nIn this chapter, you’ll learn why we have containers, what they do for us, and where we\\ncan use them.\\nThe bad old days\\nApplications are the powerhouse of every modern business. When applications break,\\nbusinesses break.\\nMost applications run on servers, and in the past, we were limited to running one\\napplication per server. As a result, the story went something like this:\\nEvery time a business needed a new application, it had to buy a new server. Unfor-\\ntunately, we weren’t very good at modeling the performance requirements of new\\napplications, and we had to guess. This resulted in businesses buying bigger, faster, and\\nmore expensive servers than necessary. After all, nobody wanted underpowered servers\\nincapable of handling the app, resulting in unhappy customers and lost revenue. As\\na result, we ended up with racks and racks of overpowered servers operating as low'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 13}, page_content='incapable of handling the app, resulting in unhappy customers and lost revenue. As\\na result, we ended up with racks and racks of overpowered servers operating as low\\nas 5-10% of their potential capacity. This was a tragic waste of company capital and\\nenvironmental resources.\\nHello VMware!\\nAmid all this, VMware, Inc. gave the world a gift — the virtual machine (VM) — a\\ntechnology that allowed us to run multiple business applications on a single server\\nsafely.\\nIt was a game-changer. Businesses could run new apps on the spare capacity of existing\\nservers, spawning a golden age of maximizing the value of existing assets.\\nVMwarts\\nBut, and there’s always a but! As great as VMs are, they’re far from perfect.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 14}, page_content='1: Containers from 30,000 feet\\n8\\nFor example, every VM needs its own dedicated operating system (OS). Unfortunately,\\nthis has several drawbacks, including:\\n• Every OS consumes CPU, RAM, and other resources we’d rather use on applica-\\ntions\\n• Every VM and OS needs patching\\n• Every VM and OS needs monitoring\\nVMs are also slow to boot and not very portable.\\nHello Containers!\\nWhile most of us were reaping the benefits of VMs, web scalers like Google had already\\nmoved on from VMs and were using containers.\\nA feature of the container model is that every container shares the OS of the host it’s\\nrunning on. This means a single host can run more containers than VMs. For example,\\na host that can run 10 VMs might be able to run 50 containers, making containers far\\nmore efficient than VMs.\\nContainers are also faster and more portable than VMs.\\nLinux containers\\nModern containers started in the Linux world and are the product of incredible work'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 14}, page_content='more efficient than VMs.\\nContainers are also faster and more portable than VMs.\\nLinux containers\\nModern containers started in the Linux world and are the product of incredible work\\nfrom many people over many years. For example, Google contributed many container-\\nrelated technologies to the Linux kernel. It’s thanks to many contributions like these\\nthat we have containers today.\\nSome of the major technologies underpinning modern containers include kernel\\nnamespaces, control groups (cgroups), and capabilities.\\nHowever, despite all this great work, containers were incredibly complicated, and it\\nwasn’t until Docker came along that they became accessible to the masses.\\nNote: I know that many container-like technologies pre-date Docker and\\nmodern containers. However, none of them changed the world the way\\nDocker has.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 15}, page_content='1: Containers from 30,000 feet\\n9\\nHello Docker!\\nDocker was the magic that made Linux containers easy and brought them to the masses.\\nWe’ll talk a lot more about Docker in the next chapter.\\nDocker and Windows\\nMicrosoft worked hard to bring Docker and container technologies to the Windows\\nplatform.\\nAt the time of writing, Windows desktop and server platforms support both of the\\nfollowing:\\n• Windows containers\\n• Linux containers\\nWindows containers run Windows apps and require a host system with a Windows kernel.\\nWindows 10, Windows 11, and all modern versions of Windows Server natively support\\nWindows containers.\\nWindows systems can also run Linux containers via the WSL 2 (Windows Subsystem for\\nLinux) subsystem.\\nThis means Windows 10 and Windows 11 are great platforms for developing and testing\\nWindows and Linux containers.\\nHowever, despite all the work developing Windows containers, almost all containers are'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 15}, page_content='Windows and Linux containers.\\nHowever, despite all the work developing Windows containers, almost all containers are\\nLinux containers. This is because Linux containers are smaller and faster, and more\\ntooling exists for Linux.\\nAll of the examples in this edition of the book are Linux containers.\\nWindows containers vs Linux containers\\nIt’s vital to understand that containers share the kernel of the host they’re running on.\\nThis means containerized Windows apps need a host with a Windows kernel, whereas\\ncontainerized Linux apps need a host with a Linux kernel. However, as mentioned, you\\ncan run Linux containers on Windows systems that have the WSL 2 backend installed.\\nTerminology: A containerized app is an application running as a container.\\nWe’ll cover this in a lot of detail later.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 16}, page_content='1: Containers from 30,000 feet\\n10\\nWhat about Mac containers?\\nThere is no such thing as Mac containers. However, Macs are great platforms for\\nworking with containers, and I do all of my daily work with containers on a Mac.\\nThe most popular way of working with containers on a Mac is Docker Desktop. It works\\nby running Docker inside a lightweight Linux VM on your Mac. Other tools, such as\\nPodman and Rancher Desktop, are also great for working with containers on a Mac.\\nWhat about Wasm\\nWasm (WebAssembly) is a modern binary instruction set that builds applications that are\\nsmaller, faster, more secure, and more portable than containers. You write your app in\\nyour favorite language and compile it as a Wasm binary that will run anywhere you have\\na Wasm runtime.\\nHowever, Wasm apps have many limitations, and we’re still developing many of\\nthe standards. As a result, containers remain the dominant model for cloud-native\\napplications.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 16}, page_content='a Wasm runtime.\\nHowever, Wasm apps have many limitations, and we’re still developing many of\\nthe standards. As a result, containers remain the dominant model for cloud-native\\napplications.\\nThe container ecosystem is also much richer and more mature than the Wasm ecosys-\\ntem.\\nAs you’ll see in the Wasm chapter, Docker and the container ecosystem are adapting\\nto work with Wasm apps, and you should expect a future where VMs, containers, and\\nWasm apps run side-by-side in most clouds and applications.\\nThis book is up-to-date with the latest Wasm and container developments.\\nDocker and AI\\nDevelopers and organizations are using more and more AI apps, and Docker is regularly\\nranked as the No. 1 most-desired and No. 1 most-used developer tool (Stack Overflow\\nAnnual Developer Survey).\\nUnfortunately, exposing GPUs and other AI acceleration hardware to apps running\\ninside containers is very hard. This is because they all have their own drivers and SDKs,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 16}, page_content='Annual Developer Survey).\\nUnfortunately, exposing GPUs and other AI acceleration hardware to apps running\\ninside containers is very hard. This is because they all have their own drivers and SDKs,\\nand it’s too much work for the industry to make them all work with containers. As\\na result, Docker has released Docker Model Runner as a way of running local LLMs\\noutside of containers so they have direct access to the host’s hardware.\\nChapter 10 is dedicated to running local AI models with Docker Model Runner, and it’s\\nvery exciting.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 17}, page_content='1: Containers from 30,000 feet\\n11\\nWhat about Kubernetes\\nKubernetes is the industry standard platform for deploying and managing containerized\\napps.\\nOlder versions of Kubernetes used Docker to start and stop containers. However, newer\\nversions use containerd, which is a stripped-down version of Docker optimized for use\\nby Kubernetes and other platforms.\\nThe important thing to know is that all Docker containers work on Kubernetes.\\nCheck out these books if you need to learn Kubernetes:\\n• Quick Start Kubernetes: This is ∼100 pages and will get you up-to-speed with\\nKubernetes in a single day!\\n• The Kubernetes Book. This is the ultimate book for mastering Kubernetes.\\nI update both books annually to ensure they’re up-to-date with the latest and greatest\\ndevelopments in the cloud native ecosystem.\\nChapter Summary\\nWe used to live in a world where every business application needed a dedicated, over-\\npowered server. VMware came along and allowed us to run multiple applications on'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 17}, page_content='Chapter Summary\\nWe used to live in a world where every business application needed a dedicated, over-\\npowered server. VMware came along and allowed us to run multiple applications on\\nnew and existing servers. However, following the success of VMware and hypervisors,\\na newer, more efficient, and portable virtualization technology called containers came'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 18}, page_content='1: Containers from 30,000 feet\\n12\\nalong. However, containers were complex and hard to implement until Docker came\\nalong and made them easy. Wasm and AI are powering new innovations, and the Docker\\necosystem is evolving to work with both. The book has entire chapters dedicated to\\nworking with AI apps and Wasm apps on Docker.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 19}, page_content='2: Docker and container-related\\nstandards and projects\\nThis chapter introduces you to Docker and some of the most important standards and\\nprojects shaping the container ecosystem. The goal is to lay some foundations that we’ll\\nbuild on in later chapters.\\nThis chapter has two main parts:\\n• Docker\\n• Container-related standards and projects\\nDocker\\nDocker is at the heart of the container ecosystem. However, the term Docker can mean\\ntwo things:\\n1. The Docker platform\\n2. Docker, Inc.\\nThe Docker platform is a neatly packaged collection of technologies for creating, manag-\\ning, and orchestrating containers. Docker, Inc. is the company that created the Docker\\nplatform and continues to be the driving force behind developing new features.\\nLet’s dive a bit deeper.\\nDocker, Inc.\\nDocker, Inc. is a technology company based out of Palo Alto and founded by French-\\nborn American developer and entrepreneur Solomon Hykes. Solomon is no longer at\\nthe company.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 19}, page_content='Docker, Inc.\\nDocker, Inc. is a technology company based out of Palo Alto and founded by French-\\nborn American developer and entrepreneur Solomon Hykes. Solomon is no longer at\\nthe company.\\nThe company started as a platform as a service (PaaS) provider called dotCloud. Behind the\\nscenes, dotCloud delivered its services on top of containers and had an in-house tool to\\nhelp them deploy and manage those containers. They called this in-house tool Docker.\\nThe word Docker is a British expression short for dock worker referring to someone who\\nloads and unloads cargo from ships.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 20}, page_content='2: Docker and container-related standards and projects\\n14\\nIn 2013, dotCloud dropped the struggling PaaS side of the business, rebranded as\\nDocker, Inc., and focused on bringing Docker and containers to the world.\\nThe Docker technology\\nThe Docker platform makes it easy to build, share, and run containers.\\nAt a high level, there are two major parts to the Docker platform:\\n• The CLI (client)\\n• The engine (server)\\nThe CLI is the familiar docker command-line tool for deploying and managing contain-\\ners. It converts simple commands into API requests and sends them to the engine.\\nThe engine comprises all the server-side components that run and manage containers.\\nFigure 2.1 shows the high-level architecture. The client and engine can be on the same\\nhost or connected over the network.\\nFigure 2.1 - Docker client and engine.\\nIn later chapters, you’ll see that the client and engine are complex and comprise a lot of'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 20}, page_content='host or connected over the network.\\nFigure 2.1 - Docker client and engine.\\nIn later chapters, you’ll see that the client and engine are complex and comprise a lot of\\nsmall specialized parts. Figure 2.2 gives you an idea of some of the complexity behind\\nthe engine. However, the client hides all this complexity so you don’t have to care. For\\nexample, you type friendly docker commands into the CLI, the CLI converts them to\\nAPI requests and sends them to the daemon, and the daemon takes care of everything\\nelse.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 21}, page_content='2: Docker and container-related standards and projects\\n15\\nFigure 2.2 - Docker CLI and daemon hiding complexity.\\nLet’s switch focus and briefly look at some standards and governance bodies.\\nContainer-related standards and projects\\nSeveral important standards and governance bodies influence container development\\nand the container ecosystem. Some of these include:\\n• The OCI\\n• The CNCF\\n• The Moby Project\\nThe Open Container Initiative (OCI)\\nThe Open Container Initiative (OCI)1 is a governance council responsible for low-level\\ncontainer-related standards.\\nIt operates under the umbrella of the Linux Foundation2 and was founded in the early\\ndays of the container ecosystem when some of the people at a company called CoreOS\\ndidn’t like the way Docker was dominating the ecosystem. In response, CoreOS created\\nan open standard called appc3 that defined specifications for things such as image\\nformat and container runtime. They also created a reference implementation called rkt\\n(pronounced “rocket”).'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 21}, page_content='an open standard called appc3 that defined specifications for things such as image\\nformat and container runtime. They also created a reference implementation called rkt\\n(pronounced “rocket”).\\nThe appc standard did things differently from Docker and put the ecosystem in an\\nawkward position with two competing standards.\\nWhile competition is usually a good thing, competing standards are generally bad, as they\\ngenerate confusion that slows down user adoption. Fortunately, the main players in the\\n1https://www.opencontainers.org\\n2https://www.linuxfoundation.org/projects\\n3https://github.com/appc/spec/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 22}, page_content='2: Docker and container-related standards and projects\\n16\\necosystem came together and formed the OCI as a vendor-neutral lightweight council\\nto govern container standards. This allowed us to archive the appc project and place all\\nlow-level container-related specifications under the OCI’s governance.\\nAt the time of writing, the OCI maintains three standards called specs:\\n• The image-spec4\\n• The runtime-spec5\\n• The distribution-spec6\\nWe often use a rail tracks analogy when explaining the OCI standards:\\nWhen the size and properties of rail tracks were standardized, it gave entrepreneurs\\nin the rail industry confidence the trains, carriages, signaling systems, platforms, and\\nother products they built would work with the standardized tracks — nobody wanted\\ncompeting standards for track sizes.\\nThe OCI specifications did the same thing for the container ecosystem and it’s flour-\\nished ever since. Docker has also changed a lot since the formation of the OCI, and all'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 22}, page_content='The OCI specifications did the same thing for the container ecosystem and it’s flour-\\nished ever since. Docker has also changed a lot since the formation of the OCI, and all\\nmodern versions of Docker implement all three OCI specs. For example:\\n• The Docker builder (BuildKit) creates OCI compliant-images\\n• Docker uses an OCI-compliant runtime to create OCI-compliant containers\\n• Docker Hub implements the OCI distribution spec and is an OCI-compliant registry\\nDocker, Inc. and many other companies have people serving on the OCI’s technical\\noversight board (TOB).\\nThe Cloud Native Computing Foundation (CNCF)\\nThe Cloud Native Computing Foundation (CNCF)7 is another Linux Foundation\\nproject that is influential in the container ecosystem. It was founded in 2015 with the\\ngoal of “…advancing container technologies… and making cloud native computing ubiquitous”.\\nInstead of creating and maintaining container-related specifications, the CNCF hosts'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 22}, page_content='goal of “…advancing container technologies… and making cloud native computing ubiquitous”.\\nInstead of creating and maintaining container-related specifications, the CNCF hosts\\nimportant projects such as Kubernetes, containerd, Notary, Prometheus, Cilium, and\\nlots more.\\nWhen we say the CNCF hosts these projects, we mean it provides a space, structure, and\\nsupport for projects to grow and mature. For example, all CNCF projects pass through\\nthe following three phases or stages:\\n4https://github.com/opencontainers/image-spec\\n5https://github.com/opencontainers/runtime-spec\\n6https://github.com/opencontainers/distribution-spec\\n7https://www.cncf.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 23}, page_content='2: Docker and container-related standards and projects\\n17\\n• Sandbox\\n• Incubating\\n• Graduated\\nEach phase increases a project’s maturity level by requiring higher standards of gov-\\nernance, documentation, auditing, contribution tracking, marketing, community\\nengagement, and more. For example, new projects accepted as sandbox projects may\\nhave great ideas and great technology but need help and resources to create strong\\ngovernance, etc. The CNCF helps with all of that.\\nGraduated projects are considered ready for production and are guaranteed to have strong\\ngovernance and implement good practices.\\nIf you look back to Figure 2.2, you’ll see that Docker uses at least two CNCF technolo-\\ngies — containerd and Notary.\\nThe Moby Project\\nDocker created the Moby project as a community-led place for developers to build\\nspecialized tools for building container platforms.\\nPlatform builders can pick the specific Moby tools they need to build their container'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 23}, page_content='specialized tools for building container platforms.\\nPlatform builders can pick the specific Moby tools they need to build their container\\nplatform. They can even compose their platforms using a mix of Moby tools, in-house\\ntools, and tools from other projects.\\nDocker, Inc. originally created the Moby project, but it now has members including\\nMicrosoft, Mirantis, and Nvidia.\\nThe Docker platform is built using tools from various projects, including the Moby\\nproject, the CNCF, and the OCI.\\nChapter summary\\nThis chapter introduced you to Docker and some of the major influences in the\\ncontainer ecosystem.\\nDocker, Inc., is a technology company based in Palo Alto that is changing how we do\\nsoftware. They were the first movers and instigators of the modern container revolution.\\nThe Docker platform focuses on running and managing application containers. It runs\\non Linux and Windows, can be installed almost anywhere, and offers a variety of free\\nand paid-for products.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 23}, page_content='The Docker platform focuses on running and managing application containers. It runs\\non Linux and Windows, can be installed almost anywhere, and offers a variety of free\\nand paid-for products.\\nThe Open Container Initiative (OCI) governs low-level container standards and\\nmaintains specifications for runtimes, image format, and registries.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 24}, page_content='2: Docker and container-related standards and projects\\n18\\nThe CNCF provides support for important cloud-native projects and helps them mature\\ninto production-grade tools.\\nThe Moby project hosts low-level tools developers can use to build container platforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 25}, page_content='3: Getting Docker\\nThere are lots of ways to get Docker and work with containers. This chapter will show\\nyou the following ways:\\n• Docker Desktop\\n• Multipass\\n• Server installs on Linux\\nI strongly recommend you install and use Docker Desktop. It’s the best way to work\\nwith Docker, and you’ll be able to use it to follow most of the examples in the book. I\\nuse it every day.\\nIf you can’t use Docker Desktop, we’ll show you how to install Docker in a Multipass\\nVM, as well as how to perform a simple installation on Linux. However, these installa-\\ntions don’t have all the features of Docker Desktop.\\nDocker Desktop\\nDocker Desktop is a desktop app from Docker, Inc. and is the best way to work with\\ncontainers. You get the Docker Engine, a slick UI, all the latest plugins and features,\\nand an extension system with a marketplace. You even get Docker Compose and a\\nKubernetes cluster if you want to learn Kubernetes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 25}, page_content='and an extension system with a marketplace. You even get Docker Compose and a\\nKubernetes cluster if you want to learn Kubernetes.\\nIt’s free for personal use and education, but you’ll have to pay a license fee if you use it\\nfor work and your company has over 250 employees or does more than $10M in annual\\nrevenue.\\nDocker Desktop on Windows 10 and Windows 11 Professional and Enterprise editions\\nsupports Windows containers and Linux containers. Docker Desktop on Mac, Linux, and\\nHome editions of Windows only support Linux containers. All of the examples in the\\nbook and almost all of the containers in the real world are Linux containers.\\nLet’s install Docker Desktop on Windows and MacOS.\\nWindows prereqs\\nDocker Desktop on Windows requires all of the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 26}, page_content='3: Getting Docker\\n20\\n• 64-bit version of Windows 10/11\\n• Hardware virtualization support must be enabled in your system’s BIOS\\n• WSL 2\\nBe very careful changing anything in your system’s BIOS.\\nInstalling Docker Desktop on Windows 10 and 11\\nSearch the internet for “install Docker Desktop on Windows”. This will take you to the\\nrelevant download page, where you can download the installer and follow the instruc-\\ntions. When prompted, you should install and enable the WSL 2 backend (Windows\\nSubsystem for Linux).\\nOnce the installation is complete, you need to manually start Docker Desktop from the\\nWindows Start menu. It may take a minute to start, but you can watch the start progress\\nvia the animated whale icon on the Windows taskbar at the bottom of the screen.\\nOnce it’s running, you can open a terminal and type some simple docker commands.\\n$ docker version\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nGo version:\\ngo1.23.8'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 26}, page_content='$ docker version\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nGo version:\\ngo1.23.8\\nOS/Arch:\\nlinux/amd64\\n<Snip>\\nCongratulations. You now have a working installation of Docker on your Windows\\nmachine.\\nNotice how the Server output shows OS/Arch: linux/amd64. This is because a default\\ninstallation assumes you’ll be working with Linux containers.\\nSome versions of Windows let you switch to Windows containers by right-clicking the\\nDocker whale icon in the Windows notifications tray and selecting Switch to Windows\\ncontainers…. Doing this keeps existing Linux containers running in the background,\\nbut you won’t be able to see or manage them until you switch back to Linux containers\\nmode.\\nMake sure you’re running in Linux containers mode so you can follow along with the\\nexamples later in the book.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 27}, page_content='3: Getting Docker\\n21\\nInstalling Docker Desktop on Mac\\nDocker Desktop for Mac is like Docker Desktop for Windows — a packaged product\\nwith a slick UI that gets you the full Docker experience on your laptop.\\nBefore proceeding with the installation, you need to know that Docker Desktop on\\nMac installs the daemon and server-side components inside a lightweight Linux VM\\nthat seamlessly exposes the API to your local Mac environment. This means you can\\nopen a terminal on your Mac and run docker commands without ever knowing it’s all\\nrunning in a hidden VM. This is also why Mac versions of Docker Desktop only work\\nwith Linux containers — everything’s running inside a Linux VM.\\nFigure 3.1 shows the high-level architecture for Docker Desktop on Mac.\\nFigure 3.1\\nThe simplest way to install Docker Desktop on your Mac is to search the web for “install\\nDocker Desktop on MacOS”, follow the links to the download, and then complete the\\nsimple installer.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 27}, page_content='Figure 3.1\\nThe simplest way to install Docker Desktop on your Mac is to search the web for “install\\nDocker Desktop on MacOS”, follow the links to the download, and then complete the\\nsimple installer.\\nWhen the installer finishes, you’ll have to start Docker Desktop from the MacOS\\nLaunchpad. It may take a minute to start, but you can watch the animated Docker whale\\nicon in the status bar at the top of your screen. Once it’s started, you can click the whale\\nicon to manage Docker Desktop.\\nOpen a terminal window and run some regular Docker commands. Try the following.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 28}, page_content='3: Getting Docker\\n22\\n$ docker version\\nClient:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49\\nOS/Arch:\\ndarwin/arm64\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nOS/Arch:\\nlinux/arm64\\ncontainerd:\\nVersion:\\n1.7.21\\nrunc:\\nVersion:\\n1.2.5\\ndocker-init:\\nVersion:\\n0.19.0\\n<Snip>\\nNotice that the OS/Arch: for the Server component shows as linux/amd64 or lin-\\nux/arm64. This is because the daemon runs inside the Linux VM mentioned earlier. The\\nClient component is a native Mac application and runs directly on the Mac OS Darwin\\nkernel. This is why it shows as darwin/amd64 or darwin/arm64.\\nYou can now use Docker on your Mac.\\nInstalling Docker with Multipass\\nOnly consider this section if you can’t use Docker Desktop.\\nMultipass installations don’t ship with out-of-the-box support for features such as\\ndocker scout, docker debug, and docker init.\\nMultipass is a free tool for creating cloud-style Linux VMs on your Linux, Mac, or'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 28}, page_content='docker scout, docker debug, and docker init.\\nMultipass is a free tool for creating cloud-style Linux VMs on your Linux, Mac, or\\nWindows machine and is incredibly easy to install and use. It’s an easy way to create\\nmulti-node production-like Docker clusters.\\nGo to https://multipass.run/install and install the right edition for your hardware\\nand OS.\\nOnce installed, you only need three commands:\\n$ multipass launch\\n$ multipass ls\\n$ multipass shell\\nRun the following command to create a new VM called node1 based on the docker\\nimage. The docker image has Docker pre-installed and ready to go.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 29}, page_content='3: Getting Docker\\n23\\n$ multipass launch docker --name node1\\nIt’ll take a minute or two to download the image and launch the VM.\\nList VMs to make sure yours launched properly.\\n$ multipass ls\\nName\\nState\\nIPv4\\nImage\\nnode1\\nRunning\\n192.168.64.37\\nUbuntu 24.04 LTS\\n172.17.0.1\\n172.18.0.1\\nYou’ll use the 192.168.x.x IP address when working with the examples later in the book.\\nConnect to the VM with the following command.\\n$ multipass shell node1\\nOnce connected, you can run the following commands to check your Docker version\\nand list installed CLI plugins.\\n$ docker --version\\nDocker version 26.1.0, build 9714adc\\n$ docker info\\nClient: Docker Engine - Community\\nVersion:\\n27.3.1\\nContext:\\ndefault\\nDebug Mode: false\\nPlugins:\\nbuildx: Docker Buildx (Docker Inc.)\\nVersion:\\nv0.17.1\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-buildx\\ncompose: Docker Compose (Docker Inc.)\\nVersion:\\nv2.29.7\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-compose\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 29}, page_content='Version:\\nv0.17.1\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-buildx\\ncompose: Docker Compose (Docker Inc.)\\nVersion:\\nv2.29.7\\nPath:\\n/usr/libexec/docker/cli-plugins/docker-compose\\n<Snip>\\nYou can type exit to log out of the VM, and multipass shell node1 to log back in.\\nYou can also type multipass delete node1 and then multipass purge to delete it.\\nInstalling Docker on Linux\\nOnly consider this section if you can’t use Docker Desktop, as it doesn’t give you access\\nto docker scout, docker debug, or docker init.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 30}, page_content='3: Getting Docker\\n24\\nThese instructions show you how to install Docker on Ubuntu Linux 24.04 and are just\\nfor guidance purposes. Lots of other installation methods exist, and you should search\\nthe web for the latest instructions.\\n$ sudo snap install docker\\n<Snip>\\ndocker 27.2.0 from Canonical✓installed\\nRun some commands to test the installation. You’ll have to prefix them with sudo.\\n$ sudo docker --version\\nDocker version 27.2.0, build 3ab4256\\n$ sudo docker info\\n<Snip>\\nServer:\\nContainers: 0\\nRunning: 0\\nPaused: 0\\nStopped: 0\\nImages: 0\\nServer Version: 27.2.0\\n<Snip>\\nIf you don’t like adding sudo before Docker commands, you can run the following\\ncommands to create a docker group and add your user account to it.\\n$ sudo groupadd docker\\n$ sudo usermod -aG docker $(whoami)\\nYou’ll need to restart Docker for the changes to take effect. This is how you restart\\nDocker on many Ubuntu Linux distributions. Yours may be different.\\n$ sudo service docker start\\nChapter Summary'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 30}, page_content='You’ll need to restart Docker for the changes to take effect. This is how you restart\\nDocker on many Ubuntu Linux distributions. Yours may be different.\\n$ sudo service docker start\\nChapter Summary\\nYou can run Docker almost anywhere, and installing it’s easier than ever.\\nDocker Desktop gives you a fully functional Docker environment on your Linux, Mac,\\nor Windows machine and is the best way to get a Docker development environment on\\nyour local machine. It’s easy to install, includes the Docker Engine, has a slick UI, and\\nhas a marketplace with lots of extensions to extend its capabilities. It works with docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 31}, page_content='3: Getting Docker\\n25\\nscout, docker debug, and docker init, and it even lets you spin up a Kubernetes\\ncluster.\\nMultipass is a great way to spin up a local VM running Docker, and there are lots of\\nways to install Docker on Linux servers. These give you access to most of the free\\nDocker features but lack some of the features of Docker Desktop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 32}, page_content='4: The big picture\\nThis chapter will give you some hands-on experience and a high-level view of images\\nand containers. The goal is to prepare you for more detail in the upcoming chapters.\\nWe’ll break this chapter into two parts:\\n• The Ops perspective\\n• The Dev perspective\\nThe ops perspective focuses on starting, stopping, deleting containers, and executing\\ncommands inside them.\\nThe dev perspective focuses more on the application side of things and runs through\\ntaking application source code, building it into a container image, and running it as a\\ncontainer.\\nI recommend you read both sections and follow the examples, as this will give you the\\ndev and ops perspectives. DevOps anyone?\\nThe Ops Perspective\\nIn this section, you’ll complete all of the following:\\n• Check Docker is working\\n• Download an image\\n• Start a container from the image\\n• Execute a command inside the container\\n• Delete the container\\nA typical Docker installation installs the client and the engine on the same machine and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 32}, page_content='• Start a container from the image\\n• Execute a command inside the container\\n• Delete the container\\nA typical Docker installation installs the client and the engine on the same machine and\\nconfigures them to talk to each other.\\nRun a docker version command to ensure both are installed and running.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 33}, page_content='4: The big picture\\n27\\n$ docker version\\nClient:\\n<<--- Start of client response\\nVersion:\\n28.1.1\\n----┐\\nAPI version:\\n1.49\\n|\\nGo version:\\ngo1.23.8\\n| Client info block\\nOS/Arch:\\ndarwin/arm64\\n|\\nContext:\\ndesktop-linux\\n----┘\\nServer: Docker Desktop 4.42.0 (192140)\\n<<--- Start of server response\\nEngine:\\n----┐\\nVersion:\\n28.11\\n|\\nAPI version:\\n1.49 (minimum version 1.24) |\\nGo version:\\ngo1.23.8\\n|\\nOS/Arch:\\nlinux/arm64\\n|\\ncontainerd:\\n| Server block\\nVersion:\\n1.7.27\\n|\\nrunc:\\n|\\nVersion:\\n1.2.5\\n|\\ndocker-init:\\n|\\nVersion:\\n0.19.0\\n----┘\\nIf your response from the client and server looks like the output in the book, everything\\nis working as expected.\\nIf you’re on Linux and get a permission denied while trying to connect to the\\nDocker daemon... error, try again with sudo in front of the command — sudo docker\\nversion. If it works with sudo, you’ll need to prefix all future docker commands with\\nsudo.\\nDownload an image\\nImages are objects that contain everything an app needs to run. This includes an OS'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 33}, page_content='version. If it works with sudo, you’ll need to prefix all future docker commands with\\nsudo.\\nDownload an image\\nImages are objects that contain everything an app needs to run. This includes an OS\\nfilesystem, the application, and all dependencies. If you work in operations, they’re\\nsimilar to VM templates. If you’re a developer, they’re similar to classes.\\nRun a docker images command.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nIf you are working from a clean installation, you’ll have no images, and your output\\nwill be the same as the book. If you’re working with Multipass, you might see an image\\ncalled portainer/portainer-ce.\\nCopying new images onto your Docker host is called pulling. Pull the ubuntu:latest\\nimage.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 34}, page_content='4: The big picture\\n28\\n$ docker pull nginx:latest\\nlatest: Pulling from library/nginx\\nad5932596f78: Download complete\\ne4bc5c1a6721: Download complete\\n1bd52ec2c0cb: Download complete\\n411a98463f95: Download complete\\ndf25b2e5edb3: Download complete\\ne93f7200eab8: Download complete\\nDigest: sha256:fb197595ebe76b9c0c14ab68159fd3c08bd067ec62300583543f0ebda353b5be\\nStatus: Downloaded newer image for nginx:latest\\ndocker.io/library/nginx:latest\\nRun another docker images to confirm your pull command worked.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnginx\\nlatest\\nfb197595ebe7\\n10 days ago\\n280MB\\nWe’ll discuss where the image is stored and what’s inside it in later chapters. For now, all\\nyou need to know is that images contain enough of an operating system (OS) and all the\\ncode and dependencies required to run a desired application. The NGINX image you\\npulled includes a stripped-down version of Linux and the NGINX web server app.\\nStart a container from the image'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 34}, page_content='code and dependencies required to run a desired application. The NGINX image you\\npulled includes a stripped-down version of Linux and the NGINX web server app.\\nStart a container from the image\\nIf you’ve been following along, you’ll have a copy of the nginx:latest image and you\\ncan use the docker run command to start a container from it.\\nRun the following docker run command to start a new container called test from the\\nubuntu:latest image.\\n$ docker run --name test -d -p 8080:80 nginx:latest\\ne08c3535...30557225\\nThe long number confirms the container was created.\\nLet’s quickly examine that docker run command.\\ndocker run tells Docker to start a new container. The --name flag told Docker to\\ncall this container test and the -d flag told it to start the container in the background\\n(detached mode) so it doesn’t take over your terminal. The -p flag told Docker to map\\nport 80 in the container to port 8080 on your Docker host. Finally, the command told'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 34}, page_content='(detached mode) so it doesn’t take over your terminal. The -p flag told Docker to map\\nport 80 in the container to port 8080 on your Docker host. Finally, the command told\\nDocker to base the container on the nginx:latest image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 35}, page_content='4: The big picture\\n29\\nRun a docker ps command to see the running container.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\ne08c35352ff3\\nnginx:latest\\n\"/docker...\"\\n3 mins ago\\nUp 2 mins\\n0.0.0.0:8080->80/tcp\\ntest\\nYou should recognize the CONTAINER ID from the long number printed after the docker\\nrun command. You should also recognize the IMAGE, PORTS, and NAMES columns from\\nthe flags in the docker run command. The COMMAND field lists the command Docker\\nexecuted to start the NGINX app inside the container.\\nExecute a command inside the container\\nRun the following command to attach your shell to a new Bash process inside the\\ncontainer.\\n$ docker exec -it test bash\\nroot@e08c35352ff3:/#\\nYour shell prompt will change to indicate you’re connected to the container.\\nRun the following command to list files in your current directory.\\nroot@e08c35352ff3:/# ls -l\\ntotal 64\\nlrwxrwxrwx\\n1 root root\\n7 Jan\\n2 00:00 bin -> usr/bin\\ndrwxr-xr-x\\n2 root root 4096 Oct 31 11:04 boot\\ndrwxr-xr-x'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 35}, page_content='root@e08c35352ff3:/# ls -l\\ntotal 64\\nlrwxrwxrwx\\n1 root root\\n7 Jan\\n2 00:00 bin -> usr/bin\\ndrwxr-xr-x\\n2 root root 4096 Oct 31 11:04 boot\\ndrwxr-xr-x\\n5 root root\\n340 Jan 12 15:09 dev\\ndrwxr-xr-x\\n1 root root 4096 Jan\\n3 02:56 docker-entrypoint.d\\n-rwxr-xr-x\\n1 root root 1620 Jan\\n3 02:56 docker-entrypoint.sh\\ndrwxr-xr-x\\n1 root root 4096 Jan 12 15:09 etc\\n<Snip>\\nIf you’re familiar with Linux, you’ll recognize these are regular Linux files and directo-\\nries.\\nTry running a ps command to list running processes.\\nroot@e08c35352ff3:/# ps -elf\\nbash: ps: command not found\\nThe command is not found because most containers only ship with essential apps and\\ntools to keep them small and reduce attack vectors. Later in the book, we’ll show you'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 36}, page_content='4: The big picture\\n30\\nhow to use Docker Desktop and Docker Debug to connect to running containers and\\nexecute commands not included as part of the container.\\nType exit to terminate your bash process and connect your shell back to your local\\nterminal. Your shell prompt will revert.\\nRun the following command to verify the test container is still running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\ne08c35352ff3\\nnginx:latest\\n\"/docker...\"\\n7 mins ago\\nUp 7 mins\\n0.0.0.0:8080->80\\ntest\\nThe container is still running, and you can see it was created 7 minutes ago and has been\\nrunning for 7 minutes.\\nDelete the container\\nStop and kill the container using the docker stop and docker rm commands.\\n$ docker stop test\\ntest\\nIt can take a few seconds for the container to stop.\\n$ docker rm test\\ntest\\nVerify the container deleted properly by running the docker ps command with the -a\\nflag to list all containers, even those in the stopped state.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 36}, page_content='test\\nVerify the container deleted properly by running the docker ps command with the -a\\nflag to list all containers, even those in the stopped state.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nCongratulations, you’ve pulled a Docker image, started a container from it, logged in to\\nit, executed a command inside it, stopped it, and deleted it.\\nThe Dev Perspective\\nContainers are all about applications.\\nYou’ll complete all of the following steps in this section:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 37}, page_content=\"4: The big picture\\n31\\n• Clone an app from a GitHub repo\\n• Inspect the app’s Dockerfile\\n• Containerize the app\\n• Run the app as a container\\nRun the following command to make a local clone of the repo. This will copy the\\napplication code to your machine so you can containerize it in a future step. You’ll need\\nthe git CLI for this to work.\\n$ git clone https://github.com/nigelpoulton/psweb.git\\nCloning into 'psweb'...\\nremote: Enumerating objects: 63, done.\\nremote: Counting objects: 100% (34/34), done.\\nremote: Compressing objects: 100% (22/22), done.\\nremote: Total 63 (delta 13), reused 25 (delta 9), pack-reused 29\\nReceiving objects: 100% (63/63), 13.29 KiB | 4.43 MiB/s, done.\\nResolving deltas: 100% (21/21), done.\\nChange into the psweb directory and list its contents.\\n$ cd psweb\\n$ ls -l\\ntotal 32\\n-rw-r--r--@ 1 nigelpoulton\\nstaff\\n324\\n5 Feb 12:31 Dockerfile\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n378\\n5 Feb 12:31 README.md\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n341\\n5 Feb 12:31 app.js\\n-rw-r--r--@ 1 nigelpoulton\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 37}, page_content='-rw-r--r--@ 1 nigelpoulton\\nstaff\\n324\\n5 Feb 12:31 Dockerfile\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n378\\n5 Feb 12:31 README.md\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n341\\n5 Feb 12:31 app.js\\n-rw-r--r--@ 1 nigelpoulton\\nstaff\\n355\\n5 Feb 12:47 package.json\\ndrwxr-xr-x\\n3 nigelpoulton\\nstaff\\n96\\n5 Feb 12:31 views\\nThe app is a simple Node.js web app running some static HTML.\\nInspect the app’s Dockerfile\\nThe Dockerfile is a plain-text document that tells Docker how to build the app and\\ndependencies into an image.\\nList the contents of the application’s Dockerfile.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 38}, page_content='4: The big picture\\n32\\n$ cat Dockerfile\\nFROM alpine\\nLABEL maintainer=\"nigelpoulton@hotmail.com\"\\nRUN apk add --update nodejs npm curl\\nCOPY . /src\\nWORKDIR /src\\nRUN\\nnpm install\\nEXPOSE 8080\\nENTRYPOINT [\"node\", \"./app.js\"]\\nYou’ll learn more about Dockerfiles later in the book. Right now, all you need to know is\\nthat each line represents an instruction Docker executes to build the app into an image.\\nIf you’ve been following along, you’ve pulled the application code from a remote Git\\nrepo and looked at the application’s Dockerfile.\\nContainerize the app\\nRun the following docker build command to create a new image based on the instruc-\\ntions in the Dockerfile. It will create a new Docker image called test:latest.\\nBe sure to run the command from within the psweb directory and include the trailing\\nperiod.\\n$ docker build -t test:latest .\\n[+] Building 36.2s (11/11) FINISHED\\n=> [internal] load .dockerignore\\n0.0s\\n=> => transferring context: 2B\\n0.0s\\n=> [internal] load build definition from Dockerfile'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 38}, page_content='$ docker build -t test:latest .\\n[+] Building 36.2s (11/11) FINISHED\\n=> [internal] load .dockerignore\\n0.0s\\n=> => transferring context: 2B\\n0.0s\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n<Snip>\\n=> => naming to docker.io/library/test:latest\\n0.0s\\n=> => unpacking to docker.io/library/test:latest\\n0.7s\\nWhen the build completes, check that you have an image called test:latest.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\ntest\\nlatest\\n0435f2738cf6\\n21 seconds ago\\n160MB\\nCongratulations, you’ve containerized the app. That’s jargon for building it into a\\ncontainer image that contains the app and all dependencies.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 39}, page_content='4: The big picture\\n33\\nRun the app as a container\\nRun the following command to start a container called web1 from the image. If you’re\\non a Windows machine, you’ll need to replace the backslashes with backticks or run the\\ncommand on a single line without the backslashes.\\n$ docker run -d \\\\\\n--name web1 \\\\\\n--publish 8080:8080 \\\\\\ntest:latest\\nOpen a web browser and navigate to the DNS name or IP address of your Docker host\\non port 8080. If you’re following along on Docker Desktop, connect to localhost:8080\\nor 127.0.0.1:8080. If you’re following along on Multipass, connect to your Multipass\\nVM’s 192.168 address on port 8080. Run an ip a | grep 192 command from within\\nthe Multipass VM, or run a multipass ls from your local machine to find the address.\\nYou will see the following web page.\\nFigure 4.1\\nCongratulations. You’ve copied some application code from a remote Git repo, built it\\ninto a Docker image, and run it as a container. We call this containerizing an app.\\nClean up'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 39}, page_content='Figure 4.1\\nCongratulations. You’ve copied some application code from a remote Git repo, built it\\ninto a Docker image, and run it as a container. We call this containerizing an app.\\nClean up\\nRun the following commands to terminate the container and delete the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 40}, page_content='4: The big picture\\n34\\n$ docker rm web1 -f\\nweb1\\n$ docker rmi test:latest\\nUntagged: test:latest\\nDeleted: sha256:0435f27...cac8e2b\\nChapter Summary\\nIn the Ops section of the chapter, you downloaded a Docker image, launched a container\\nfrom it, logged into the container, executed a command inside of it, and then stopped\\nand deleted the container.\\nIn the Dev section, you containerized a simple application by pulling source code from\\nGitHub and building it into an image using instructions in a Dockerfile. You then ran\\nthe app as a container.\\nThe things you’ve learned in this chapter will help you in the upcoming chapters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 41}, page_content='Part 2: The technical stuff'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 42}, page_content='5: The Docker Engine\\nIn this chapter, we’ll look under the hood of the Docker Engine.\\nThis chapter has a strong operations focus, and you can use Docker without knowing\\neverything you’re about to learn. However, to truly master something, you need to\\nunderstand what’s going on under the hood. So, if you want to master Docker, you\\nshould read this chapter.\\nI’ve divided the chapter into the following sections:\\n• Docker Engine – The TLDR\\n• The Docker Engine\\n• The influence of the Open Container Initiative (OCI)\\n• runc\\n• containerd\\n• Starting a new container (example)\\n• What’s the shim all about\\n• How it’s implemented on Linux\\nLet’s learn about the Docker Engine.\\nDocker Engine – The TLDR\\nDocker Engine is jargon for the server-side components of Docker that run and manage\\ncontainers. If you’ve ever worked with VMware, the Docker Engine is similar to ESXi.\\nThe Docker Engine is modular and built from many small specialized components'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 42}, page_content='containers. If you’ve ever worked with VMware, the Docker Engine is similar to ESXi.\\nThe Docker Engine is modular and built from many small specialized components\\npulled from projects such as the OCI, the CNCF, and the Moby project.\\nIn many ways, the Docker Engine is like a car engine:\\n• A car engine is made from many specialized parts that work together to make a car\\ndrive — intake manifolds, throttle bodies, cylinders, pistons, spark plugs, exhaust\\nmanifolds, and more.\\n• The Docker Engine is made from many specialized tools that work together to\\ncreate and run containers — the API, image builder, high-level runtime, low-level\\nruntime, shims, etc.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 43}, page_content='5: The Docker Engine\\n37\\nFigure 5.1 shows the components of the Docker Engine that create and run containers.\\nOther components exist, but this simplified diagram focuses on the components that\\nstart and run containers.\\nFigure 5.1\\nThroughout the book, we’ll refer to runc and containerd with lowercase “r” and “c”, which\\nis how they’re both written in the official project documentation. This means sentences\\nstarting with either runc or containerd will not begin with a capital letter.\\nThe Docker Engine\\nWhen Docker was first released, the Docker Engine had two major components:\\n• The Docker daemon (sometimes referred to as just “the daemon”)\\n• LXC\\nThe daemon was a monolithic binary containing all the code for the API, image builders,\\ncontainer execution, volumes, networking, and more.\\nLXC did the hard work of interfacing with the Linux kernel and constructing the\\nrequired namespaces and cgroups to build and start containers.\\nReplacing LXC'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 43}, page_content='LXC did the hard work of interfacing with the Linux kernel and constructing the\\nrequired namespaces and cgroups to build and start containers.\\nReplacing LXC\\nRelying on LXC posed several problems for the Docker project.\\nFirst, LXC is Linux-specific, and Docker had aspirations of being multi-platform.\\nSecond, Docker was evolving fast, and there was no way of ensuring LXC evolved in the\\nways Docker needed.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 44}, page_content='5: The Docker Engine\\n38\\nTo improve the experience and help the project evolve more quickly, Docker replaced\\nLXC with its own tool, libcontainer. The goal of libcontainer was to be a platform-\\nagnostic tool that gave Docker access to the fundamental container building blocks in\\nthe host kernel.\\nLibcontainer replaced LXC in Docker a very long time ago.\\nBreaking up the monolithic Docker daemon\\nAs previously mentioned, the Docker Engine was originally a monolith with almost all\\nfunctionality coded into the daemon. However, as time passed, this became more and\\nmore problematic for the following reasons:\\n1. It got slower\\n2. It wasn’t what the ecosystem wanted\\n3. It’s hard to innovate on monolithic software\\nThe project recognized these challenges and began a long-running program to break\\napart and refactor the Engine so that every feature became its own small specialized tool.\\nPlatform builders could then re-use these tools to build other platforms.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 44}, page_content='apart and refactor the Engine so that every feature became its own small specialized tool.\\nPlatform builders could then re-use these tools to build other platforms.\\nThis work of breaking apart the Docker daemon is an ongoing process, and all of the\\ncode for building images and executing containers has been removed and refactored\\ninto small, specialized tools. Notable examples include removing the high-level and\\nlow-level runtime functionality and re-implementing them in separate tools called\\ncontainerd and runc, both of which are used by many different projects, including\\nDocker, Kubernetes, Firecracker, and Fargate. More recently (starting with Docker\\nDesktop 4.27.0), Docker has removed image management from the daemon and now\\nuses containerd’s image management capabilities.\\nFigure 5.2 shows another view of the Docker Engine components that are used to run\\ncontainers and lists the primary responsibilities of each component.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 45}, page_content='5: The Docker Engine\\n39\\nFigure 5.2 - Engine components and responsibilities\\nOther engine components exist.\\nThe influence of the Open Container Initiative (OCI)\\nAround the same time that Docker, Inc. was refactoring the Engine, the OCI8 was in the\\nprocess of defining two container-related standards:\\n1. Image Specification (image-spec)9\\n2. Runtime Specification (runtime-spec)10\\nBoth specifications were released as version 1.0 in July 2017 and are still vital today.\\nThey’ve even added a third specification called the Distribution Specification (distribu-\\ntion-spec) governing how images are distributed via registries.\\nAt the time of writing, the runtime-spec is at version 1.2.0, and the image-spec and\\ndistribution-spec are both at version 1.1.0. This demonstrates the slow-and-steady\\nnature of these low-level specifications that are heavily relied upon by so many other\\nprojects — stability is the name of the game for low-level OCI specs.\\n8https://www.opencontainers.org/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 45}, page_content='nature of these low-level specifications that are heavily relied upon by so many other\\nprojects — stability is the name of the game for low-level OCI specs.\\n8https://www.opencontainers.org/\\n9https://github.com/opencontainers/image-spec\\n10https://github.com/opencontainers/runtime-spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 46}, page_content='5: The Docker Engine\\n40\\nDocker, Inc. was a founding member of the OCI and was heavily involved in defining\\nthe original specifications. It continues to be involved by contributing code and helping\\nguide the future of the specifications.\\nAll versions of Docker since 2016 have implemented the OCI specifications. For\\nexample, Docker uses runc, the reference implementation of the OCI runtime-spec, to\\ncreate OCI-compliant containers (runtime-spec). It also uses BuildKit to build OCI-\\ncompliant images (image-spec), and Docker Hub is an OCI-compliant registry (registry-\\nspec).\\nrunc\\nAs previously mentioned, runc11 (pronounced “run see” and always written with a\\nlowercase “r”) is the reference implementation of the OCI runtime-spec. Docker, Inc.\\nwas heavily involved in defining the spec and contributed the initial code for runc.\\nrunc is a lightweight CLI wrapper for libcontainer that you can download and use\\nto manage OCI-compliant containers. However, it’s a very low-level tool and lacks'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 46}, page_content='runc is a lightweight CLI wrapper for libcontainer that you can download and use\\nto manage OCI-compliant containers. However, it’s a very low-level tool and lacks\\nalmost all of the features and add-ons you get with the Docker Engine. Fortunately, as\\npreviously shown in Figure 5.2, Docker uses runc as its low-level runtime. This means\\nyou get OCI-compliant containers and the feature-rich Docker user experience.\\nOn the jargon front, we sometimes say that runc operates at the OCI layer, and we often\\nrefer to it as a low-level runtime.\\nDocker and Kubernetes both use runc as their default low-level runtime, and both pair it\\nwith the containerd high-level runtime:\\n• containerd operates as the high-level runtime managing lifecycle events\\n• runc operates as the low-level runtime executing lifecycle events by interfacing\\nwith the kernel to do the work of actually building containers and deleting them\\nYou can see the latest releases here:\\n• https://github.com/opencontainers/runc/releases'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 46}, page_content='with the kernel to do the work of actually building containers and deleting them\\nYou can see the latest releases here:\\n• https://github.com/opencontainers/runc/releases\\ncontainerd\\ncontainerd (pronounced “container dee” and always written with a lowercase “c”) is\\nanother tool that Docker created while stripping functionality out of the daemon.\\n11https://github.com/opencontainers/runc'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 47}, page_content='5: The Docker Engine\\n41\\nWe refer to containerd as a high-level runtime as it manages lifecycle events such as\\nstarting, stopping, and deleting containers. However, it needs a low-level runtime to\\nperform the actual work. Most of the time, containerd is paired with runc as its low-\\nlevel runtime. However, as you saw in Figure 5.3, it uses shims that make it possible to\\nreplace runc with other low-level runtimes. We’ll go into more detail in the WebAssem-\\nbly chapter when you’ll see how to use Docker to run WebAssembly apps.\\nThe original plan was for containerd to be a small specialized tool for managing\\ncontainer lifecycle events. However, it has since grown to include the ability to manage\\nimages, networks, and volumes.\\nOne reason for adding more functionality is for projects such as Kubernetes that want\\ncontainerd to be able to push and pull images. Fortunately, this extra functionality is\\nmodular, meaning projects like Kubernetes can include containerd but only take the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 47}, page_content='containerd to be able to push and pull images. Fortunately, this extra functionality is\\nmodular, meaning projects like Kubernetes can include containerd but only take the\\npieces they need.\\ncontainerd was originally developed by Docker, Inc. and donated to the Cloud Native\\nComputing Foundation (CNCF). At the time of writing, containerd is a graduated\\nCNCF project, meaning it’s stable and production-ready. You can see the latest releases\\nhere:\\n• https://github.com/containerd/containerd/releases\\nStarting a new container (example)\\nNow that you’ve seen the big picture, let’s see how to use Docker to create a new\\ncontainer.\\nThe most common way of starting containers is using the Docker CLI. Feel free to run\\nthe following command to start a new container called ctr1 based on the nginx image.\\n$ docker run -d --name ctr1 nginx\\nRun a docker ps command to see if the container is running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\n9cfb0c9aacb2\\nnginx\\n\"/docker-entrypoint.…\"'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 47}, page_content='Run a docker ps command to see if the container is running.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\n9cfb0c9aacb2\\nnginx\\n\"/docker-entrypoint.…\"\\n9 seconds ago\\nUp 9 seconds\\n80/tcp\\nctr1\\nWhen you run commands like this, the Docker client converts them into API requests\\nand sends them to the API exposed by the daemon.\\nThe daemon can expose the API on a local socket or over the network. On Linux, the\\nlocal socket is /var/run/docker.sock and on Windows it’s \\\\pipe\\\\docker_engine.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 48}, page_content='5: The Docker Engine\\n42\\nThe daemon receives the request, interprets it as a request to create a new container,\\nand passes it to containerd. Remember that the daemon no longer contains any code\\nto create containers.\\nThe daemon communicates with containerd via a CRUD-style API over gRPC12.\\nDespite its name, even containerd cannot create containers. It converts the required\\nDocker image into an OCI bundle and tells runc to use this to create a new container.\\nrunc interfaces with the OS kernel to pull together all the constructs necessary to create\\na container (namespaces, cgroups, etc.). The container starts as a child process of runc,\\nand as soon as the container starts, runc exits.\\nFigure 5.3 summarizes the process.\\nFigure 5.3\\nDecoupling the container creation and management from the Docker daemon and\\nimplementing it in containerd and runc makes it possible to stop, restart, and even\\nupdate the daemon without impacting running containers. We sometimes call this\\ndaemonless containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 48}, page_content='implementing it in containerd and runc makes it possible to stop, restart, and even\\nupdate the daemon without impacting running containers. We sometimes call this\\ndaemonless containers.\\n12https://grpc.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 49}, page_content='5: The Docker Engine\\n43\\nIf you started the NGINX container earlier, you should delete it using the following\\ncommand.\\n$ docker rm ctr1 -f\\nWhat’s the shim all about?\\nSome of the diagrams in the chapter have shown a shim component.\\nShims are a popular software engineering pattern, and the Docker Engine uses them in\\nbetween containerd and the OCI layer, bringing the following benefits:\\n• Daemonless containers\\n• Improved efficiency\\n• Pluggable OCI layer\\nWe’ve already said that daemonless containers is the ability to stop, restart, and even\\nupdate the Docker daemon without impacting running containers.\\nOn the efficiency front, containerd forks a shim and a runc process for every new\\ncontainer. However, each runc process exits as soon as the container starts running,\\nleaving the shim process as the container’s parent process. The shim is lightweight\\nand sits between containerd and the container. It reports on the container’s status and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 49}, page_content='leaving the shim process as the container’s parent process. The shim is lightweight\\nand sits between containerd and the container. It reports on the container’s status and\\nperforms low-level tasks such as keeping the container’s STDIN and STDOUT streams\\nopen.\\nShims also make it possible to replace runc with other low-level runtimes.\\nHow it’s implemented on Linux\\nOn a Linux system, Docker implements the components we’ve discussed as the follow-\\ning separate binaries:\\n• /usr/bin/dockerd (the Docker daemon)\\n• /usr/bin/containerd\\n• /usr/bin/containerd-shim-runc-v2\\n• /usr/bin/runc\\nYou can see all of these on a Linux-based Docker host by running a ps command. Some\\nof the processes will only be present when the system has running containers, and you\\ncan’t see them if you’re using Docker Desktop on a Mac because the Docker Engine is\\nrunning inside a VM.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 50}, page_content='5: The Docker Engine\\n44\\nDo we still need the daemon\\nAt the time of writing, Docker has stripped most of the functionality out of the daemon.\\nHowever, it still serves the Docker API.\\nChapter summary\\nThe Docker Engine comprises the server-side components of Docker and implements\\nmost of the code to build, share, and run containers. It implements the OCI standards\\nand is a modular app comprising many small, specialized components.\\nThe Docker daemon component implements the Docker API, but most other functionality\\nhas been stripped out and implemented as standalone composable tools such as\\ncontainerd and runc.\\ncontainerd performs image management tasks and oversees container lifecycle manage-\\nment, such as starting, stopping, and deleting containers. Docker, Inc. originally wrote it\\nand then contributed to the CNCF. It’s classed as a high-level runtime and used by many\\nother projects, including Kubernetes, Firecracker, and Fargate.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 50}, page_content='and then contributed to the CNCF. It’s classed as a high-level runtime and used by many\\nother projects, including Kubernetes, Firecracker, and Fargate.\\ncontainerd relies on a low-level runtime called runc to interface with the host kernel and\\nbuild containers. runc is the reference implementation of the OCI runtime-spec and\\nexpects to start containers from OCI-compliant bundles. containerd talks to runc and\\nensures Docker images are presented to runc as OCI-compliant bundles.\\nrunc is based on code from libcontainer, you can run it as a standalone CLI tool to\\ncreate containers, and it’s used almost everywhere that containerd is used.\\nShims make it possible to use containerd with other low-level runtimes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 51}, page_content='6: Working with Images\\nThis chapter is a dive deep into Docker images. You’ll learn what images are, how to\\nwork with them, and how they work under the hood. You’ll learn how to build your own\\nin Chapter 8: Containerizing an application.\\nI’ve arranged the chapter as follows:\\n• Docker images – The TLDR\\n• Intro to images\\n• Pulling images\\n• Image registries\\n• Image naming and tagging\\n• Images and layers\\n• Pulling images by digest\\n• Multi-architecture images\\n• Vulnerability scanning with Docker Scout\\n• Deleting images\\nDocker images – The TLDR\\nBefore getting started, all of the following terms mean the same thing, and we’ll use\\nthem interchangeably: Image, Docker image, container image, and OCI image.\\nAn image is a read-only package containing everything you need to run an application.\\nThis means they include application code, dependencies, a minimal set of OS constructs,\\nand metadata. You can start multiple containers from a single image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 51}, page_content='This means they include application code, dependencies, a minimal set of OS constructs,\\nand metadata. You can start multiple containers from a single image.\\nIf you’re familiar with VMware, images are a bit like VM templates — a VM template is\\nlike a stopped VM, whereas an image is like a stopped container. If you’re a developer,\\nimages are similar to classes — you can create one or more objects from a class, whereas\\nyou can create one or more containers from an image.\\nThe easiest way to get an image is to pull one from a registry. Docker Hub13 is the most\\ncommon registry, and pulling an image downloads it to your local machine where\\n13https://hub.docker.com'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 52}, page_content='6: Working with Images\\n46\\nDocker can use it to start one or more containers. Other registries exist, and Docker\\nworks with them all.\\nDocker creates images by stacking independent layers and representing them as a single\\nunified object. One layer might have the OS components, another layer might have\\napplication dependencies, and another layer might have the application. Docker stacks\\nthese layers and makes them look like a unified system.\\nImages are usually small. For example, the official NGINX image is around 80MB, and\\nthe official Redis image is around 40MB. However, Windows images can be huge.\\nThat’s the elevator pitch. Let’s dig a little deeper.\\nIntro to images\\nWe’ve already said that images are like stopped containers. You can even stop a con-\\ntainer and create a new image from it. With this in mind, images are build-time con-\\nstructs, whereas containers are run-time constructs. Figure 6.1 shows the build and run'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 52}, page_content='tainer and create a new image from it. With this in mind, images are build-time con-\\nstructs, whereas containers are run-time constructs. Figure 6.1 shows the build and run\\nnature of each and that you can start multiple containers from a single image.\\nFigure 6.1\\nThe docker run command is the most common way to start a container from an image.\\nOnce the container is running, the image and the container are bound, and you cannot\\ndelete the image until you stop and delete the container. If multiple containers use the\\nsame image, you can only delete the image after you’ve deleted all the containers using\\nit.\\nContainers are designed to run a single application or microservice. As such, they\\nshould only contain application code and dependencies. You should not include non-\\nessentials such as build tools or troubleshooting tools.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 53}, page_content='6: Working with Images\\n47\\nFor example, the official Alpine Linux image is currently about 3MB. This is because it\\ndoesn’t ship with six different shells, three different package managers, and a bunch of\\ntools you “might” need once every ten years. In fact, it’s increasingly common for images\\nto ship without a shell or a package manager — if the application doesn’t need it at run-\\ntime, the image doesn’t include it. We call these slim images.\\nAnother thing that keeps images small is the lack of an OS kernel. This is because con-\\ntainers use the kernel of the host they’re running on. The only OS-related components\\nin most images are filesystem objects, and you’ll sometimes hear people say images\\ncontain just enough OS.\\nUnfortunately, Windows images can be huge. For example, some Windows-based\\nimages can be gigabytes in size and take a long time to push and pull.\\nPulling images\\nA clean Docker installation has an empty local repository.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 53}, page_content='images can be gigabytes in size and take a long time to push and pull.\\nPulling images\\nA clean Docker installation has an empty local repository.\\nLocal repository is jargon for an area on your local machine where Docker stores images\\nfor more convenient access. We sometimes call it the image cache, and on Linux it’s\\nusually located in /var/lib/docker/<storage-driver>. However, if you’re using\\nDocker Desktop, it will be inside the Docker VM.\\nRun the following command to inspect the contents of your local repository. This\\nexample has three images relating to three Docker Desktop extensions I’m running.\\nYours will be different and may be empty.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\ndocker/disk-usage-extension\\n0.2.9\\nf4c95478a537\\n26 hours ago\\n3.64MB\\ndocker/logs-explorer-extension\\n0.2.6\\n417dd9a8f96d\\n26 hours ago\\n17.9MB\\nportainer/portainer-docker-extension\\n2.19.4\\n908d04d20e86\\n2 months ago\\n364MB\\nThe process of getting images is called pulling.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 53}, page_content='docker/logs-explorer-extension\\n0.2.6\\n417dd9a8f96d\\n26 hours ago\\n17.9MB\\nportainer/portainer-docker-extension\\n2.19.4\\n908d04d20e86\\n2 months ago\\n364MB\\nThe process of getting images is called pulling.\\nRun the following commands to pull the redis image and verify it exists in your local\\nrepository.\\nNote: If you are following along on Linux and haven’t added your user\\naccount to the local docker Unix group, you may need to add sudo to the\\nbeginning of all the following commands.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 54}, page_content=\"6: Working with Images\\n48\\n$ docker pull redis\\nUsing default tag: latest\\n<<---- Assume the 'latest' tag\\nlatest: Pulling from library/redis\\n<<---- Assume you want to pull from Docker Hub\\n08df40659127: Download complete\\n<<---- Pulling layer\\n4f4fb700ef54: Already exists\\n<<---- Pulling layer (local copy must exist)\\n4fe7fa4aab04: Download complete\\n<<---- Pulling layer\\n57dea0f129a5: Download complete\\n<<---- Pulling layer\\nf546e941f15b: Download complete\\n<<---- Pulling layer\\nf7f7da262cdb: Download complete\\n<<---- Pulling layer\\nf45ab649e450: Download complete\\n<<---- Pulling layer\\n983f900bbc88: Download complete\\n<<---- Pulling layer\\nDigest: sha256:76d5908f5e19fcdd73daf956a38826f790336ee4707d9028f32b24ad9ac72c08\\nStatus: Downloaded newer image for redis:latest\\ndocker.io/library/redis:latest\\n<<---- docker.io = Docker Hub\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nlatest\\n11c3e418c296\\n2 weeks ago\\n223MB\\n<Snip>\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 54}, page_content='docker.io/library/redis:latest\\n<<---- docker.io = Docker Hub\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nlatest\\n11c3e418c296\\n2 weeks ago\\n223MB\\n<Snip>\\nThe image now exists in your local repository. However, I’ve annotated a few interesting\\nlines from the docker pull output. We’ll cover them in more detail later in the chapter\\nbut they’re worth a quick mention now.\\nDocker is opinionated and made two assumptions when pulling the image:\\n1. It assumed you wanted to pull the image tagged as latest\\n2. It assumed you wanted to pull the image from Docker Hub\\nYou can override both, but Docker will use these as defaults if you don’t override them.\\nThe Redis image in the example has eight layers. However, Docker only pulled seven\\nlayers because it already had a local copy of one of them. This is because my system\\nruns the Portainer Docker Desktop extension, which is based on an image that shares a\\ncommon layer with the Redis image. You’ll learn about this very soon, but images can'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 54}, page_content='runs the Portainer Docker Desktop extension, which is based on an image that shares a\\ncommon layer with the Redis image. You’ll learn about this very soon, but images can\\nshare layers, and Docker is clever enough only to pull the layers it doesn’t already have.\\nImage registries\\nWe store images in centralized places called registries. The job of a registry is to securely\\nstore images and make them easy to access from different environments.\\nFigure 6.2 shows the central nature of registries in the build > share > run pipeline.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 55}, page_content='6: Working with Images\\n49\\nFigure 6.2\\nMost modern registries implement the OCI distribution-spec, and we sometimes call\\nthem OCI registries. Most registries also implement the Docker Registry v2 API, meaning\\nyou can use the Docker CLI and other API tools to query them and work with them in\\nstandard ways. Some offer advanced features such as image scanning and integration\\nwith build pipelines.\\nThe most common registry is Docker Hub, but others exist, including 3rd-party\\ninternet-based registries and secure on-premises registries. However, as previously\\nmentioned, Docker is opinionated and will default to Docker Hub unless you tell it\\nthe name of a different registry. We’ll use Docker Hub for the rest of the book, but the\\nprinciples apply to other registries.\\nImage registries contain one or more image repositories, and image repositories contain\\none or more images. Figure 6.3 shows an image registry with three repositories, each\\nwith one or more images.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 56}, page_content='6: Working with Images\\n50\\nFigure 6.3 - Registry architecture\\nOfficial repositories\\nDocker Hub has the concept of official repositories that are home to images vetted and\\ncurated by Docker and the application vendor. This means they should contain up-to-\\ndate high-quality code that is secure, well-documented, and follows good practices.\\nMost of the popular applications and operating systems have official repositories on\\nDocker Hub, and they’re easy to identify because they live at the top level of the Docker\\nHub namespace and have a green Docker Official Image badge. The following list shows\\na few official repositories and their URLs that exist at the top level of the Docker Hub\\nnamespace:\\n• nginx: https://hub.docker.com/_/nginx/\\n• busybox: https://hub.docker.com/_/busybox/\\n• redis: https://hub.docker.com/_/redis/\\n• mongo: https://hub.docker.com/_/mongo/\\nFigure 6.4 shows the official Alpine and NGINX repositories on Docker Hub. Both have'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 56}, page_content='• redis: https://hub.docker.com/_/redis/\\n• mongo: https://hub.docker.com/_/mongo/\\nFigure 6.4 shows the official Alpine and NGINX repositories on Docker Hub. Both have\\nthe green Docker Official Image badge and have over a billion pulls each. Also, notice how\\nboth are available for a wide range of CPU architectures.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 57}, page_content='6: Working with Images\\n51\\nFigure 6.4 - Official repos on Docker Hub\\nUnofficial repositories\\nThe next list shows two of my personal repositories in the “wild west” of unofficial\\nrepositories that you should be very careful when using.\\n• nigelpoulton/gsd — https://hub.docker.com/r/nigelpoulton/gsd-book/\\n• nigelpoulton/k8sbook — https://hub.docker.com/r/nigelpoulton/k8sbook/\\nNotice how they exist below the nigelpoulton second-level namespace. This is one of\\nseveral indications they are not official repositories.\\nWhile there are lots of great images in unofficial repositories, you should always start\\nwith the assumption that anything from an unofficial repository is unsafe. This is based\\non the good practice of never trusting software from the internet. In fact, you should\\nalso exercise caution when downloading and using Docker Official Images.\\nImage naming and tagging\\nMost of the time, you’ll work with images based on their names, and you can learn'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 57}, page_content='also exercise caution when downloading and using Docker Official Images.\\nImage naming and tagging\\nMost of the time, you’ll work with images based on their names, and you can learn\\na lot about an image from its name. Figure 6.5 shows a fully qualified image name,\\nincluding the registry name, user/organization name, repository name, and tag. Docker\\nautomatically populates the registry and tag values if you don’t specify them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 58}, page_content=\"6: Working with Images\\n52\\nFigure 6.5 - Fully qualified image name\\nAddressing images from official repositories is easy. All you need to supply is the\\nrepository name and image name separated by a colon. Sometimes we call the image\\nname the tag. The format for a docker pull command pulling an image from an official\\nrepository is:\\n$ docker pull <repository>:<tag>\\nThe example from earlier pulled the Redis image with the following command. It pulled\\nthe image tagged as latest from the top-level redis repository.\\n$ docker pull redis:latest\\nThe following examples show how to pull a few different official images.\\n$ docker pull redis:8.0-M02\\n//Pulls the image tagged as '8.0-M02' from the official 'redis' repository.\\n$ docker pull busybox:glibc\\n//Pulls the image tagged as 'glibc' from the official 'busybox' repository.\\n$ docker pull alpine\\n//Pulls the image tagged as 'latest' from the official 'alpine' repository.\\nA couple of things are worth noting.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 58}, page_content=\"$ docker pull alpine\\n//Pulls the image tagged as 'latest' from the official 'alpine' repository.\\nA couple of things are worth noting.\\n• As previously mentioned, if you don’t specify an image tag after the repository\\nname, Docker assumes you want the image tagged as latest. The command will\\nfail if the repository has no image tagged as latest.\\n• Images tagged as latest are not guaranteed to be the most up-to-date in the\\nrepository.\\nPulling images from unofficial repositories is almost the same as pulling from official\\nrepositories — you just need to add a Docker Hub username or organization name\\nbefore the repository name. The following example shows how to pull the v2 image\\nfrom the tu-demo repository owned by a not-to-be-trusted person whose Docker Hub\\nID is nigelpoulton.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 59}, page_content='6: Working with Images\\n53\\n$ docker pull nigelpoulton/tu-demo:v2\\nTo pull an image from a different registry, you just add the registry’s DNS name before\\nthe repository name. For example, the following command pulls the latest image from\\nBrandon Mitchell’s regclient/regsync repo on GitHub Container Registry (ghcr.io).\\n$ docker pull ghcr.io/regclient/regsync:latest\\nlatest: Pulling from regclient/regsync\\nf140ae7f526a: Download complete\\nc1cb552669af: Download complete\\nDigest: sha256:88b3d4dc3d7bf2d8ea6f641bea2be15142a9222db66d4b6f2043fc5cc19eead8\\nStatus: Downloaded newer image for ghcr.io/regclient/regsync:latest\\nghcr.io/regclient/regsync:latest\\nNotice how the pull looks the same as it did with Docker Hub. This is because GHCR\\nsupports the OCI registry-spec and implements the Docker Registry v2 API.\\nImages with multiple tags\\nYou can give a single image as many tags as you want.\\nAt first glance, the following output might look like it’s listing three images. However,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 59}, page_content='Images with multiple tags\\nYou can give a single image as many tags as you want.\\nAt first glance, the following output might look like it’s listing three images. However,\\non closer inspection it’s just two — the b4210d0aa52f image is tagged as latest and v1.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/tu-demo\\nlatest\\nb4210d0aa52f\\n2 days ago\\n115MB\\nnigelpoulton/tu-demo\\nv1\\nb4210d0aa52f\\n2 days ago\\n115MB\\nnigelpoulton/tu-demo\\nv2\\n6ba12825d092\\n12 minutes ago\\n115MB\\nThis is a great example of the latest tag not relating to the newest image in the repo.\\nIn this example, the latest tag refers to the same image as the v1 tag, which is actually\\nolder than the v2 image.\\nImages and layers\\nAs already mentioned, images are a collection of loosely connected read-only layers\\nwhere each layer comprises one or more files.\\nFigure 6.6 shows an image with four layers. Docker takes care of stacking them and\\nrepresenting them as a single unified image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 60}, page_content='6: Working with Images\\n54\\nFigure 6.6 - Image and stacked layers\\nYou’re about to look at all of the following ways to inspect layer information:\\n• Pull operations\\n• The docker inspect command\\n• The docker history command\\nRun the following command to pull the node:latest image and observe it pulling the\\nindividual layers. Some newer versions may have more or less layers, but the principle is\\nthe same.\\n$ docker pull node:latest\\nlatest: Pulling from library/ubuntu\\n952132ac251a: Pull complete\\n82659f8f1b76: Pull complete\\nc19118ca682d: Pull complete\\n8296858250fe: Pull complete\\n24e0251a0e2c: Pull complete\\nDigest: sha256:f4691c96e6bbaa99d...28ae95a60369c506dd6e6f6ab\\nStatus: Downloaded newer image for node:latest\\ndocker.io/node:latest\\nEach line ending with Pull complete represents a layer that Docker pulled. This image has\\nfive layers and is shown in Figure 6.7 with layer IDs.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 61}, page_content='6: Working with Images\\n55\\nFigure 6.7 - Image layers and IDs\\nAnother way to see image layers is to inspect the image with the docker inspect\\ncommand. The following example inspects the same node:latest image pulled in the\\nprevious step.\\n$ docker inspect node:latest\\n[\\n{\\n\"Id\": \"sha256:bd3d4369ae.......fa2645f5699037d7d8c6b415a10\",\\n\"RepoTags\": [\\n\"node:latest\"\\n<Snip>\\n\"RootFS\": {\\n\"Type\": \"layers\",\\n\"Layers\": [\\n\"sha256:c8a75145fc...894129005e461a43875a094b93412\",\\n\"sha256:c6f2b330b6...7214ed6aac305dd03f70b95cdc610\",\\n\"sha256:055757a193...3a9565d78962c7f368d5ac5984998\",\\n\"sha256:4837348061...12695f548406ea77feb5074e195e3\",\\n\"sha256:0cad5e07ba...4bae4cfc66b376265e16c32a0aae9\"\\n]\\n}\\n}\\n]\\nThe trimmed output shows the five layers. However, it shows their SHA256 hashes,\\nwhich are different from the short IDs shown in the docker pull output.\\nThe docker inspect command is great for getting detailed image information.\\nYou can also use the docker history command to inspect an image and see its layer'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 61}, page_content='The docker inspect command is great for getting detailed image information.\\nYou can also use the docker history command to inspect an image and see its layer\\ndata. However, this command shows the build history of an image and is not a strict list'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 62}, page_content='6: Working with Images\\n56\\nof layers in the final image. For example, some Dockerfile instructions (ENV, EXPOSE, CMD,\\nand ENTRYPOINT) only add metadata and don’t create layers.\\nBase layers\\nAll Docker images start with a base layer, and every time you add new content, Docker\\nadds a new layer.\\nConsider the following oversimplified example of building a simple Python application.\\nYour corporate policy mandates all applications be built on top of the official Ubuntu\\n24:04 image. This means the official Ubuntu 24:04 image will be the base layer for this\\napp. Installing your company’s approved version of Python will add a second layer, and\\nyour application source code will add a third. The final image will have three layers, as\\nshown in Figure 6.8. Remember, this is an oversimplified example for demonstration\\npurposes.\\nFigure 6.8\\nIt’s important to understand that an image is the combination of all layers stacked in the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 62}, page_content='shown in Figure 6.8. Remember, this is an oversimplified example for demonstration\\npurposes.\\nFigure 6.8\\nIt’s important to understand that an image is the combination of all layers stacked in the\\norder they were built. Figure 6.9 shows an image with two layers. Each layer has three\\nfiles, meaning the image has six files.\\nIt also shows that the layers are stored as independent objects, and the image is just\\nmetadata identifying the required layers and explaining how to stack them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 63}, page_content='6: Working with Images\\n57\\nFigure 6.9\\nIn the slightly more complex example of the three-layer image in Figure 6.10, the overall\\nimage only presents six files in the unified view. This is because File 7 in the top layer\\nis an updated version of File 5 directly below (inline). In this situation, the file in the\\nhigher layer obscures the file directly below it. This means you update files and make\\nother changes to images by adding new layers containing the changes.\\nFigure 6.10 - Stacking layers\\nUnder the hood, Docker uses storage drivers to stack layers and present them as a\\nunified filesystem and image. Almost all Docker setups use the overlay2 driver, but zfs,\\nbtrfs, and vfs are alternative options. However, whichever storage driver you use, the\\ndeveloper and user experience are always the same.\\nFigure 6.11 shows how the three-layer image from Figure 6.10 will appear on the system\\n— all three layers stacked and merged into a single unified view.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 64}, page_content='6: Working with Images\\n58\\nFigure 6.11 - Unified view of multi-layer image\\nSharing image layers\\nAs previously mentioned, images can share layers, leading to efficiencies in space and\\nperformance.\\nOne of the earlier docker pull commands generated an Already exists message for one\\nof the layers it pulled. This occurred because one of my Docker Desktop extensions had\\nalready pulled an image that used the exact same layer. As a result, Docker skipped that\\nlayer as it already had a local copy.\\nHere’s the code from earlier, and Figure 6.12 shows two images sharing the same layer.\\n$ docker pull redis:latest\\nlatest: Pulling from library/redis\\n25d3892798f8: Download complete\\ne5d458cf0bea: Download complete\\n4f4fb700ef54: Already exists\\n<<---- This line\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 65}, page_content='6: Working with Images\\n59\\nFigure 6.12 - Two images sharing a layer\\nLayers are also shared on the registry side. This means you can store lots of similar\\nimages in a registry, and the registry will save space by never storing more than a single\\ncopy of any layer.\\nPulling images by digest\\nSo far, you’ve seen how to pull and work with images using names (tags). While this\\nis the most common method, it has a problem — tags are arbitrary and mutable. This\\nmeans it’s possible to tag an image incorrectly or give a new image the same tag as an\\nolder one. An extremely common example is the latest tag. For example, pulling the\\nalpine:latest tag a year ago will not pull the same image as pulling the same tag today.\\nConsider a quick example outlining one potential implication of trusting mutable tags.\\nImagine you have an image called golftrack:1.5 and you get a warning that it has a\\ncritical vulnerability. You build a new image containing the fix and push the new image'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 65}, page_content='Imagine you have an image called golftrack:1.5 and you get a warning that it has a\\ncritical vulnerability. You build a new image containing the fix and push the new image\\nto the same repository with the same tag.\\nTake a moment to consider what just happened and the implications.\\nYou have an image called golftrack:1.5 that’s being used by lots of containers in your\\nproduction environment, and it has a critical bug. You create a new version containing\\nthe fix. So far, so good, but then you make the mistake. You push the new image to\\nthe same repository with the same tag as the vulnerable image. This overwrites the\\noriginal image and leaves you without a great way of knowing which of your production'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 66}, page_content='6: Working with Images\\n60\\ncontainers are using the vulnerable image and which are using the fixed image — both\\nimages have the same tag!\\nThis is where image digests come to the rescue.\\nDocker uses a content addressable storage model where every image gets a cryptographic\\ncontent hash that we usually call the digest. As these are hashes of an image’s contents,\\nit’s impossible for two different images to have the same digest. It’s also impossible to\\nchange an image without creating a new digest. Fortunately, Docker lets you work with\\nimage digests instead of just names.\\nIf you’ve already pulled an image by name, you can see its digest by running a docker\\nimages command with the --digests flag as shown.\\n$ docker images --digests alpine\\nREPOSITORY\\nTAG\\nDIGEST\\nIMAGE ID\\nCREATED\\nSIZE\\nalpine\\nlatest\\nsha256:c5b1261d...8e1ad6b\\nc5b1261d6d3e\\n2 weeks ago\\n11.8MB\\nIf you want to find an image’s digest before pulling it, you can use the docker buildx'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 66}, page_content='TAG\\nDIGEST\\nIMAGE ID\\nCREATED\\nSIZE\\nalpine\\nlatest\\nsha256:c5b1261d...8e1ad6b\\nc5b1261d6d3e\\n2 weeks ago\\n11.8MB\\nIf you want to find an image’s digest before pulling it, you can use the docker buildx\\nimagetools command. The following example retrieves the image digest for the\\nnigelpoulton/k8sbook/latest image on Docker Hub.\\n$ docker buildx imagetools inspect nigelpoulton/k8sbook:latest\\nName:\\ndocker.io/nigelpoulton/k8sbook:latest\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\\nDigest:\\nsha256:13dd59a0c74e9a147800039b1ff4d61201375c008b96a29c5bd17244bce2e14b\\n<Snip>\\nYou can now use the digest to pull the image. I’ve trimmed the command and the output\\nfor readability.\\n$ docker pull nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b\\ndocker.io/nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b: Pulling from nigelpoulton/k8sbook\\n59f1664fb787: Download complete\\na052f1888b3e: Download complete\\n94a9f4dfa0e5: Download complete\\nbb7e600677fa: Download complete\\nedfb0c26f1fb: Download complete'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 66}, page_content='59f1664fb787: Download complete\\na052f1888b3e: Download complete\\n94a9f4dfa0e5: Download complete\\nbb7e600677fa: Download complete\\nedfb0c26f1fb: Download complete\\n5b1423465504: Download complete\\n2f232a362cd9: Download complete\\nDigest: sha256:13dd59a0...bce2e14b\\nStatus: Downloaded newer image for nigelpoulton/k8sbook@sha256:13dd59a0...bce2e14b\\ndocker.io/nigelpoulton/k8sbook:latest@sha256:13dd59a0...bce2e14b\\nIt’s also possible to directly query the registry API for image data, including digest. The\\nfollowing curl command queries Docker Hub for the digest of the same image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 67}, page_content='6: Working with Images\\n61\\n$ curl \"https://hub.docker.com/v2/repositories/nigelpoulton/k8sbook/tags/?name=latest\" \\\\\\n|jq \\'.results[].digest\\'\\n\"sha256:13dd59a0c74e9a147800039b1ff4d61201375c008b96a29c5bd17244bce2e14b\"\\nImage hashes and layer hashes\\nYou already know that images are just a loose collection of independent layers. This\\nmeans an image is just a manifest file with some metadata and a list of layers. The actual\\napplication and all its dependencies live in the layers that are fully independent and have\\nno concept of being part of an image.\\nWith this in mind, images and layers have their own digests as follows:\\n• Images digests are a crypto hash of the image’s manifest file\\n• Layer digests are a crypto hash of the layer’s contents\\nThis means all changes to layers or image manifests result in new hashes, giving us an\\neasy and reliable way to know if changes have been made.\\nContent hashes vs distribution hashes'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 67}, page_content='This means all changes to layers or image manifests result in new hashes, giving us an\\neasy and reliable way to know if changes have been made.\\nContent hashes vs distribution hashes\\nDocker compares hashes before and after every push and pull to ensure no tampering\\noccurs while data is crossing the network. However, it also compresses images during\\npush and pull operations to save network bandwidth and storage space on the registry.\\nAs a result of this compression, the before and after hashes won’t match.\\nTo get around this, each layer gets two hashes:\\n• Content hash (uncompressed)\\n• Distribution hash (compressed)\\nEvery time Docker pushes or pulls a layer from a registry, it includes the layer’s distri-\\nbution hash and uses this to verify no tampering occurred. This is one reason why the\\nhashes in different CLI and registry outputs don’t always match — sometimes you’re\\nlooking at the content hash, and other times you’re looking at the distribution hash.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 68}, page_content='6: Working with Images\\n62\\nMulti-architecture images\\nOne of the best things about Docker is its simplicity. However, as technologies grow,\\nthey inevitably get more complex. This happened for Docker when it started supporting\\ndifferent platforms and architectures, such as Windows and Linux on variations of\\nARM, x64, PowerPC, s390x and more. Suddenly, there were multiple versions of\\nthe same image for all the different architectures, and developers and users had to\\nput in significant extra work to get the right version. This broke the smooth Docker\\nexperience.\\nMulti-architecture images to the rescue!\\nFortunately, Docker and the registry API adapted and became clever enough to hide\\nimages for multiple architectures behind a single tag. This means you can do a docker\\npull alpine on any architecture and get the correct version of the image. For example,\\nif you’re on an AMD64 machine, you’ll get the AMD64 image.\\nTo make this happen, the Registry API supports two important constructs:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 68}, page_content='if you’re on an AMD64 machine, you’ll get the AMD64 image.\\nTo make this happen, the Registry API supports two important constructs:\\n• Manifest lists\\n• Manifests\\nThe manifest list is exactly what it sounds like — a list of architectures supported by an\\nimage tag. Each supported architecture then has its own manifest that lists the layers\\nused to build it.\\nRun the following command to see the different architectures supported behind the\\nalpine:latest tag.\\n$ docker buildx imagetools inspect alpine\\nName:\\ndocker.io/library/alpine:latest\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json\\nDigest:\\nsha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nManifests:\\nName:\\ndocker.io/library/alpine:latest@sha256:6457d53f...628977d0\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/amd64\\nName:\\ndocker.io/library/alpine:latest@sha256:b229a851...d144c1d8\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 68}, page_content='Platform:\\nlinux/amd64\\nName:\\ndocker.io/library/alpine:latest@sha256:b229a851...d144c1d8\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm/v6\\nName:\\ndocker.io/library/alpine:latest@sha256:ec299a7b...33b4c6fe\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm/v7'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 69}, page_content='6: Working with Images\\n63\\nName:\\ndocker.io/library/alpine:latest@sha256:a0264d60...93467a46\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/arm64/v8\\nName:\\ndocker.io/library/alpine:latest@sha256:15c46ced...ab073171\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/386\\nName:\\ndocker.io/library/alpine:latest@sha256:b12b826d...ba52a3a2\\nMediaType: application/vnd.docker.distribution.manifest.v2+json\\nPlatform:\\nlinux/ppc64le\\nYour output may include additional annotations, but if you look closely, you’ll see a\\nsingle manifest list pointing to six manifests.\\nMediaType: application/vnd.docker.distribution.manifest.list.v2+json is the\\nmanifest list.\\nEach MediaType: application/vnd.docker.distribution.manifest.v2+json line\\nrefers to a manifest for each specific architecture.\\nFigure 6.13 shows how manifest lists and manifests are related. On the left, you can see'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 69}, page_content='refers to a manifest for each specific architecture.\\nFigure 6.13 shows how manifest lists and manifests are related. On the left, you can see\\na manifest list with entries for the different architectures supported by the image. The\\narrows show that each entry in the manifest list points to a manifest defining the image\\nconfig and the list of layers making up the image for that architecture.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 70}, page_content='6: Working with Images\\n64\\nFigure 6.13 - Manifest lists and manifests\\nLet’s step through a quick example.\\nAssume you’re using Docker Desktop on an M4 Mac where Docker runs inside a\\nlinux/arm VM. You ask Docker to pull an image, and Docker makes the relevant calls to\\nthe Registry API to request the appropriate manifest list. Assuming it exists, Docker then\\nparses it for a linux/arm entry. If linux/arm entry exists, Docker retrieves its manifest,\\nparses it for the crypto IDs of its layers, pulls each layer, and assembles them into the\\nimage.\\nLet’s see it in action.\\nThe following examples are from Docker Desktop on an ARM-based Mac and Docker\\nDesktop on an AMD-based Windows machine running in Windows containers mode.\\nBoth start a new container based the official golang image and execute the go version\\ncommand. The outputs show the version of Go and the host’s platform and CPU\\narchitecture. Notice how both commands are exactly the same, and Docker takes care\\nof pulling the correct image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 70}, page_content='command. The outputs show the version of Go and the host’s platform and CPU\\narchitecture. Notice how both commands are exactly the same, and Docker takes care\\nof pulling the correct image.\\nBoth images are large and may take a while to download. You do not need to complete\\nthese commands yourself.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 71}, page_content='6: Working with Images\\n65\\nLinux on arm64 example:\\n$ docker run --rm golang go version\\n<Snip>\\ngo version go1.23.4 linux/arm64\\nWindows on x64 example:\\n> docker run --rm golang go version\\n<Snip>\\ngo version go1.23.4 windows/amd64\\nYou’ve already seen how to use the docker buildx imagetools command to see the\\nmanifest list and manifests for an image. You can get similar information from the\\ndocker manifest command. The following example inspects the manifest list for\\nthe official golang image on Docker Hub. You can see it has images for Linux and\\nWindows on a variety of CPU architectures. You can run the same command without\\nthe grep filter to see the full JSON manifest list. Windows users should replace the grep\\ncommand with Select-String architecture,os\\n$ docker manifest inspect golang | grep \\'architecture\\\\|os\\'\\n\"architecture\": \"amd64\",\\n\"os\": \"linux\"\\n\"architecture\": \"arm\",\\n\"os\": \"linux\",\\n\"architecture\": \"arm64\",\\n\"os\": \"linux\",\\n\"architecture\": \"386\",\\n\"os\": \"linux\"\\n\"architecture\": \"mips64le\",'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 71}, page_content='\"architecture\": \"amd64\",\\n\"os\": \"linux\"\\n\"architecture\": \"arm\",\\n\"os\": \"linux\",\\n\"architecture\": \"arm64\",\\n\"os\": \"linux\",\\n\"architecture\": \"386\",\\n\"os\": \"linux\"\\n\"architecture\": \"mips64le\",\\n\"os\": \"linux\"\\n\"architecture\": \"ppc64le\",\\n\"os\": \"linux\"\\n\"architecture\": \"s390x\",\\n\"os\": \"linux\"\\n\"architecture\": \"amd64\",\\n\"os\": \"windows\",\\n\"os.version\": \"10.0.20348.2227\"\\n\"architecture\": \"amd64\",\\n\"os\": \"windows\",\\n\"os.version\": \"10.0.17763.5329\"\\nPulling the right image for your system is one thing, but what about building images for\\nall these different architectures?\\nThe docker buildx command makes it easy to create multi-architecture images. For\\nexample, you can use Docker Desktop on linux/arm to build images for linux/amd'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 72}, page_content='6: Working with Images\\n66\\nand possibly other architectures. We’ll perform builds like these in future chapters, but\\ndocker buildx offers two ways to create multi-architecture images:\\n• Emulation\\n• Build Cloud\\nEmulation mode performs builds for different architectures on your local machine by\\nrunning the build inside a QEMU virtual machine emulating the target architecture. It\\nworks most of the time but is slow and doesn’t have a shared cache.\\nBuild Cloud is a service from Docker, Inc. that performs builds in the cloud on native\\nhardware without requiring emulation. It’s very fast, lets you share a common build\\ncache with teammates, and is seamlessly integrated into Docker Desktop and any\\nversion of the Docker Engine using a version of buildx supporting the cloud driver.\\nIt also integrates with GitHub actions and other CI solutions. At the time of writing,\\nDocker Build Cloud is a subscription service you have to pay for.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 72}, page_content='It also integrates with GitHub actions and other CI solutions. At the time of writing,\\nDocker Build Cloud is a subscription service you have to pay for.\\nWe’ll use both in future chapters, but I ran the following command to build AMD and\\nARM versions of the nigelpoulton/tu-demo image using Docker Build Cloud.\\n$ docker buildx build \\\\\\n--builder=cloud-nigelpoulton-ddd-cloud \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/tu-demo:latest --push .\\nVulnerability scanning with Docker Scout\\nLots of tools and plugins exist that scan images for known vulnerabilities.\\nWe’ll look at Docker Scout, as it’s built into almost every level of Docker, including the\\nCLI, Docker Desktop, Docker Hub, and the scout.docker.com portal. It’s a very slick\\nservice, but it requires a paid subscription. Other similar products and services exist, but\\nmost require paid subscriptions.\\nRecent versions of Docker Desktop have the Scout CLI plugin pre-installed and ready'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 72}, page_content='most require paid subscriptions.\\nRecent versions of Docker Desktop have the Scout CLI plugin pre-installed and ready\\nto go. If you’re running a different version of Docker, you may be able to install the CLI\\nplugin from the GitHub repo14.\\nYou can use the docker scout quickview command to get a quick vulnerability\\noverview of an image. The following command analyses the nigelpoulton/tu-\\ndemo:latest image. If a local copy doesn’t exist, it pulls it from Docker Hub and\\nperforms the analysis locally.\\n14https://github.com/docker/scout-cli'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 73}, page_content='6: Working with Images\\n67\\n$ docker scout quickview nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\n│\\n0C\\n1H\\n1M\\n0L\\ndigest\\n│\\nb4210d0aa52f\\n│\\nBase image\\n│\\npython:3-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\nUpdated base image │\\npython:3.11-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\n│\\n│\\nThe output shows zero critical vulnerabilities (0C), one high (1H), one medium (1M),\\nand zero low (0L).\\nYou can use the docker scout cves command to get more detailed information,\\nincluding remediation advice.\\n$ docker scout cves nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\n\\uffffDetected 1 vulnerable package with 2 vulnerabilities\\n## Overview\\n│\\nAnalyzed Image\\n────────────────────┼────────────────────────────────\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64/v8\\nvulnerabilities │\\n0C\\n1H\\n1M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 73}, page_content='Target\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64/v8\\nvulnerabilities │\\n0C\\n1H\\n1M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2\\npkg:apk/alpine/expat@2.5.0-r2?os_name=alpine&os_version=3.19\\n\\uffffHIGH CVE-2023-52425\\nhttps://scout.docker.com/v/CVE-2023-52425\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n<Snip>\\nI’ve snipped the output so it only shows the critical and high vulnerabilities, but several\\nthings are clear:\\n• It has detected one vulnerable package containing two vulnerabilities\\n• The affected package is called expat and the vulnerable version we’re running is\\n2.5.0-r2\\n• It lists the vulnerability as CVE-2023-52425'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 74}, page_content='6: Working with Images\\n68\\n• It includes a link to a Scout report containing more info\\n• It suggests we update to version 2.6.0-r0 which contains the fix\\nFigure 6.14 shows how this looks in Docker Desktop, and you get similar integrations\\nand views in Docker Hub.\\nFigure 6.14 - Docker Scout integration with Docker Desktop\\nThe scout.docker.com portal provides an overview dashboard, allows you to configure\\npolicies, and lets you set up integrations with Docker Hub and other registries to\\nremotely scan and monitor multiple repositories.\\nDeleting Images\\nYou can delete images using the docker rmi command. rmi is short for remove image.\\nDeleting images removes them from your local repository and they’ll no longer show up\\nin your docker images commands. The operation also deletes all directories on your\\nlocal filesystem containing layer data. However, Docker won’t delete layers shared by\\nmultiple images until you delete all images that reference them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 74}, page_content='local filesystem containing layer data. However, Docker won’t delete layers shared by\\nmultiple images until you delete all images that reference them.\\nYou can delete images by name, short ID, or SHA. You can also delete multiple images\\nwith the same command.\\nThe following command deletes three images — one by name, one by short ID, and one\\nby SHA. I’ve trimmed the output for easier reading.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 75}, page_content='6: Working with Images\\n69\\n$ docker rmi redis:latest af111729d35a sha256:c5b1261d...f8e1ad6b\\nUntagged: redis:latest\\nDeleted: sha256:76d5908f5e19fcdd73daf956a38826f790336ee4707d9028f32b24ad9ac72c08\\nUntagged: nigelpoulton/tu-demo:v2\\nDeleted: sha256:af111729d35a09fd24c25607ec045184bb8d76e37714dfc2d9e55d13b3ebbc67\\nUntagged: alpine:latest\\nDeleted: sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nDocker will prevent the delete operation if the image is being used by a container or\\nreferenced by more than one tag. However, you can force the operation with the -f\\nflag, but you should do so with caution, as forcing Docker to delete an image in use by\\na container will untag the image and leave it on the system as a dangling image.\\nA handy way to delete all images is to pass a list of all local image IDs to the docker rmi\\ncommand. You should use this command with caution, and if you’re following along on\\nWindows, it will only work in a PowerShell terminal.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 75}, page_content='command. You should use this command with caution, and if you’re following along on\\nWindows, it will only work in a PowerShell terminal.\\n$ docker rmi $(docker images -q) -f\\nTo understand how this works, download a couple of images and then run docker\\nimages -q.\\n$ docker pull alpine\\n<Snip>\\n$ docker pull ubuntu\\n<Snip>\\n$ docker images -q\\n44dd6f223004\\n3f5ef9003cef\\nSee how the docker images -q returns a list of local image IDs. Passing this list to\\ndocker rmi will delete all images on the system as shown next.\\n$ docker rmi $(docker images -q) -f\\nUntagged: alpine:latest\\nUntagged: alpine@sha256:02bb6f428431fb...a33cb1af4444c9b11\\nDeleted: sha256:44dd6f2230041...09399391535c0c0183b\\nDeleted: sha256:94dd7d531fa56...97252ba88da87169c3f\\nUntagged: ubuntu:latest\\nUntagged: ubuntu@sha256:dfd64a3b4296d8...9ee20739e8eb54fbf\\nDeleted: sha256:3f5ef9003cefb...79cb530c29298550b92\\nDeleted: sha256:b49483f6a0e69...f3075564c10349774c3\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 75}, page_content='Deleted: sha256:3f5ef9003cefb...79cb530c29298550b92\\nDeleted: sha256:b49483f6a0e69...f3075564c10349774c3\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nLet’s remind ourselves of some of the commands we’ve used.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 76}, page_content='6: Working with Images\\n70\\nImages – The commands\\n• docker pull is the command to download images from remote registries. It\\ndefaults to Docker Hub but works with other registries. The following command\\nwill pull the image tagged as latest from the alpine repository on Docker Hub:\\ndocker pull alpine:latest.\\n• docker images lists all the images in your Docker host’s local repository (image\\ncache). You can add the --digests flag to see the SHA256 hashes.\\n• docker inspect gives you a wealth of image-related metadata in a nicely format-\\nted view.\\n• docker manifest inspect lets you inspect the manifest list of images stored\\nin registries. The following command will show the manifest list for the regctl\\nimage on GitHub Container Registry (GHCR): docker manifest inspect\\nghcr.io/regclient/regctl.\\n• docker buildx is a Docker CLI plugin that works with Docker’s latest build\\nengine features. You saw how to use the imagetools sub-command to query\\nmanifest-related data from images.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 76}, page_content='• docker buildx is a Docker CLI plugin that works with Docker’s latest build\\nengine features. You saw how to use the imagetools sub-command to query\\nmanifest-related data from images.\\n• docker scout is a Docker CLI plugin that integrates with the Docker Scout\\nbackend to perform image vulnerability scanning. It scans images, provides\\nreports on vulnerabilities, and even suggests remediation actions.\\n• docker rmi is the command to delete images. It deletes all layer data stored in the\\nlocal filesystem, and you cannot delete images that are in use by containers.\\nChapter summary\\nThis chapter taught you the important theory and fundamentals of images.\\nYou learned that images contain everything needed to run an application as a container.\\nThis includes just enough OS, source code, dependencies, and metadata.\\nYou can start one or more containers from a single image.\\nUnder the hood, Docker constructs images by stacking one or more read-only layers'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 76}, page_content='You can start one or more containers from a single image.\\nUnder the hood, Docker constructs images by stacking one or more read-only layers\\nand presenting them as a unified object. Every image has a manifest that lists the layers\\nthat make up the image and how to stack them.\\nYou learned that image names are also called tags, they’re mutable, and they don’t always\\npull the same image. For example, pulling the alpine:latest tag today will not pull\\nthe same image as it will a year from now. Fortunately, every image gets an immutable\\ndigest that you can use to guarantee you always pull the intended image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 77}, page_content='6: Working with Images\\n71\\nDocker Hub has the notion of curated official images that should be safer to use than\\nunofficial images. However, you should always exercise caution when downloading\\nsoftware from the internet, even official images from Docker Hub.\\nImages can share layers for efficiency, and Docker makes it easy to build and pull images\\nfor lots of different CPU architectures, such as ARM and AMD.\\nDocker Scout scans images for known vulnerabilities and provides remediation advice.\\nIt requires a Docker subscription and is integrated into the docker CLI, Docker Hub,\\nand Docker Desktop.\\nIn the next chapter, we’ll take a similar tour of containers — the run-time sibling of\\nimages.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 78}, page_content='7: Working with containers\\nDocker implements the Open Container Initiative (OCI) specifications. This means\\nsome of the things you’ll learn in this chapter will apply to other container runtimes and\\nplatforms that implement the OCI specifications.\\nI’ve divided the chapter into the following sections:\\n• Container – The TLDR\\n• Containers vs VMs\\n• Images and containers\\n• Check Docker is running\\n• Starting a container\\n• How containers start apps\\n• Connecting to a running container\\n• Inspecting container processes\\n• The docker inspect command\\n• Writing data to a container\\n• Stopping, restarting, and deleting a container\\n• Killing a container’s main process\\n• Debugging slim images and containers with Docker Debug\\n• Self-healing containers with restart policies\\n• The commands\\nContainers – The TLDR\\nContainers are run-time instances of images, and you can start one or more containers\\nfrom a single image.\\nFigure 7.1 shows multiple containers started from a single image. The shared image is'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 78}, page_content='Containers are run-time instances of images, and you can start one or more containers\\nfrom a single image.\\nFigure 7.1 shows multiple containers started from a single image. The shared image is\\nread-only, but you can write to the containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 79}, page_content='7: Working with containers\\n73\\nFigure 7.1\\nYou can start, stop, restart, and delete containers just like you can with VMs. However,\\ncontainers are smaller, faster, and more portable than VMs. They’re also designed to\\nbe stateless and ephemeral, whereas VMs are designed to be long-running and can be\\nmigrated with their state and data.\\nContainers are also designed to be immutable. This means you shouldn’t change them\\nafter you’ve deployed them — if a container fails, you replace it with a new one instead\\nof connecting to it and making a live fix.\\nContainers should only run a single process and we use them to build microservices\\napps. For example, an application with four features, such as a web server, auth, catalog,\\nand store, will have four containers — one running the web server, one running the auth\\nservice, one running the catalog, and another running the store.\\nContainers vs VMs\\nContainers and VMs are both virtualization technologies for running applications. They'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 79}, page_content='service, one running the catalog, and another running the store.\\nContainers vs VMs\\nContainers and VMs are both virtualization technologies for running applications. They\\nboth work on your laptop, bare metal servers, in the cloud, and more. However, the\\nways they virtualize are very different:\\n• VMs virtualize hardware\\n• Containers virtualize operating systems\\nIn the VM model, you power on a server and a hypervisor boots. When the hypervisor\\nboots, it claims all hardware resources such as CPU, RAM, storage, and network\\nadapters. To deploy an app, you ask the hypervisor to create a virtual machine. It does\\nthis by carving up the hardware resources into virtual versions, such as virtual CPUs\\nand Virtual RAM, and packaging them into a VM that looks exactly like a physical\\nserver. Once you have the VM, you install an OS and then an app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 80}, page_content='7: Working with containers\\n74\\nIn the container model, you power on the same server and an OS boots and claims all\\nhardware resources. You then install a container runtime such as Docker. To deploy\\nan app, you ask Docker to create a container. It does this by carving up OS resources\\nsuch as process trees and filesystems into virtual versions and then packaging them as a\\ncontainer that looks exactly like a regular OS. You then tell Docker to run the app inside\\nthe container.\\nFigure 7.2 shows the two models side by side and attempts to demonstrate the more\\nefficient nature of containers with the same server running 3x more containers than\\nVMs.\\nFigure 7.2\\nIn summary, hypervisors perform hardware virtualization where they divide hardware\\nresources into virtual versions and package them as VMs. Container runtimes perform\\nOS virtualization where they divide OS resources into virtual versions and package them'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 80}, page_content='resources into virtual versions and package them as VMs. Container runtimes perform\\nOS virtualization where they divide OS resources into virtual versions and package them\\nas containers. VMs look and feel exactly like physical servers. Containers look and feel\\nexactly like regular operating systems.\\nThe VM tax\\nOne of the biggest problems with the virtual machine model is that you need to\\ninstall an OS on every VM — every OS consumes CPU, RAM, and storage and takes a\\nrelatively long time to boot.\\nContainers get around all of this by sharing a single OS on the host they’re running on.\\nThis gives containers all of the following benefits over VMs:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 81}, page_content='7: Working with containers\\n75\\n• Containers are smaller and more portable\\n• You can run more containers on your infrastructure\\n• Containers start faster\\n• Containers reduce the number of operating systems you need to manage (patch,\\nupdate, etc.)\\n• Containers present a smaller attack surface\\nLet’s briefly expand on each point.\\nContainers are smaller than VMs because they only contain application code and a\\nminimal set of OS-related constructs such as essential filesystem objects. Because of this,\\nthey’re typically only a few megabytes in size. On the other hand, every VM needs a full\\nOS, meaning they’re usually hundreds or thousands of megabytes.\\nBecause containers don’t contain their own OS, you can run a lot more containers\\nthan VMs. For example, deploying 100 applications as VMs will require 100 operating\\nsystems, each consuming CPU, memory, and storage, and each needing to be patched\\nand managed. However, deploying the same 100 applications as containers requires no'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 81}, page_content='systems, each consuming CPU, memory, and storage, and each needing to be patched\\nand managed. However, deploying the same 100 applications as containers requires no\\nadditional operating systems. This drastically reduces your OS management overhead\\nand allows you to allocate more system resources to applications instead of operating\\nsystems.\\nContainers also start faster than VMs because they use the host’s OS which is already\\nbooted. On the other hand, VMs need to go through a full OS bootstrapping process\\nbefore starting the app.\\nOne of the early concerns about containers centered around the shared kernel model\\nwhere all containers on the same host share the host’s kernel. While this offers perfor-\\nmance and portability benefits, it’s less secure than the VM model where every VM has\\nits own dedicated kernel. For example, a rogue container that exploits a vulnerability\\nin the host’s kernel might be able to impact every other container on the same host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 81}, page_content='its own dedicated kernel. For example, a rogue container that exploits a vulnerability\\nin the host’s kernel might be able to impact every other container on the same host.\\nFortunately, this is much less of a concern now that container platforms have matured\\nand ship with class-leading tools that can make them more secure than non-container\\nplatforms. For example, most container engines and platforms implement sensible\\ndefaults for security-related technologies such as SELinux, AppArmor, seccomp, capabilities,\\nand more. You can even configure these to make containers more secure than VMs.\\nOther technologies, such as image vulnerability scanning, give you more control over\\nthe security of your software than you ever had before.\\nAt the time of writing, containers are the go-to solution for the vast majority of new\\napplications.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 82}, page_content='7: Working with containers\\n76\\nPre-reqs\\nYou’ll need a working Docker environment to follow along with the examples, and I\\nrecommend Docker Desktop. Other Docker setups should work, but you may have\\nto manually install the Docker Debug plugin if you want to follow along with those\\nexamples.\\nImages and Containers\\nAs previously mentioned, you can start multiple containers from a single image. The\\nimage is read-only in this relationship, but each container is read-write. As shown\\nin Figure 7.3, Docker accomplishes this by creating a thin read-write layer for each\\ncontainer and placing it on top of the shared image.\\nFigure 7.3 - Container R/W layers\\nIn this example, each container has its own thin R/W layer but shares the same image.\\nThe containers can see and access the files and apps in the image through their own R/W\\nlayer, and if they make any changes, these get written to their R/W layer. When you stop'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 82}, page_content='The containers can see and access the files and apps in the image through their own R/W\\nlayer, and if they make any changes, these get written to their R/W layer. When you stop\\na container, Docker keeps the R/W layer and restores it when you restart the container.\\nHowever, when you delete a container, Docker deletes its R/W layer. This way, each\\ncontainer can make and keep its own changes without requiring write access to the\\nshared image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 83}, page_content='7: Working with containers\\n77\\nCheck Docker is running\\nRun a docker version to check Docker is running. It’s a good command because it\\nchecks the CLI and engine components.\\n$ docker version\\nClient:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49\\nOS/Arch:\\ndarwin/arm64\\n<Snip>\\nServer: Docker Desktop 4.42.0 (192140)\\nEngine:\\nVersion:\\n28.1.1\\nAPI version:\\n1.49 (minimum version 1.24)\\nOS/Arch:\\nlinux/arm64\\n<Snip>\\nAs long as you get a response from the Client and Server, you’re good to go and can\\nskip to the next section.\\nIf you get an error code in the Server section, this usually means your Docker daemon\\n(server) isn’t running or your user account doesn’t have permission to access it. If\\nyou’re running on Linux, you’ll need to ensure your user account is a member of the\\nlocal docker Unix group. If it isn’t, you can add it by running usermod -aG docker\\n<username> and restarting your shell. Alternatively, you can prefix all docker commands\\nwith sudo.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 83}, page_content='local docker Unix group. If it isn’t, you can add it by running usermod -aG docker\\n<username> and restarting your shell. Alternatively, you can prefix all docker commands\\nwith sudo.\\nYour account needs to be a member of the docker group so it can access the API, which\\nis exposed on a privileged local Unix socket at /var/run/docker.sock. It’s also possible\\nto expose the API over the network.\\nIf your user account is already a member of the local docker group and you still get an\\nerror from the daemon, there’s a good chance the Docker daemon isn’t running. Run\\none of the following commands to check the status of the daemon.\\nLinux systems not using Systemd.\\n$ service docker status\\ndocker start/running, process 29393\\nLinux systems using Systemd.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 84}, page_content=\"7: Working with containers\\n78\\n$ systemctl is-active docker\\nactive\\nIf the daemon isn’t running, start it with the appropriate command for your system.\\nStarting a container\\nThe docker run command is the simplest and most common way to start a new\\ncontainer.\\nRun the following command to start a new container called webserver.\\n$ docker run -d --name webserver -p 5005:8080 nigelpoulton/ddd-book:web0.1\\nUnable to find image 'nigelpoulton/ddd-book:web0.1' locally\\nweb0.1: Pulling from nigelpoulton/ddd-book\\n4f4fb700ef54: Already exists\\ncf2a607f33f7: Download complete\\n0a1f0c111e9a: Download complete\\nc1af4b5db242: Download complete\\nDigest: sha256:3f5b281b914b1e39df8a1fbc189270a5672ff9e98bfac03193b42d1c02c43ef0\\nStatus: Downloaded newer image for nigelpoulton/ddd-book:web0.1\\nb5594b3b8b3fdce544d2ca048e4340d176bce9f5dc430812a20f1852c395e96b\\nLet’s take a closer look at the command and the output.\\ndocker run tells Docker to run a new container\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 84}, page_content='b5594b3b8b3fdce544d2ca048e4340d176bce9f5dc430812a20f1852c395e96b\\nLet’s take a closer look at the command and the output.\\ndocker run tells Docker to run a new container\\nThe -d flag tells Docker to run it in the background as a daemon process and detached\\nfrom your local terminal\\nThe name flag tells Docker to name this container webserver.\\nThe -p 5005:8080 flag maps port 5005 on your local system to port 8080 inside the\\ncontainer. This works because the container’s web server is listening on port 8080.\\nThe nigelpoulton/ddd-book:web0.1 argument tells Docker which image to use to start\\nthe container.\\nWhen you hit Return, the Docker client converted the command into an API request\\nand posted it to the Docker API exposed by the Docker daemon. The Docker daemon\\naccepted the command and searched its local image repository for a copy of the\\nnigelpoulton/ddd-book:web0.1 image. It didn’t find one, so it searched Docker Hub.\\nIn the example, it found one on Docker Hub and pulled a local copy.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 84}, page_content='nigelpoulton/ddd-book:web0.1 image. It didn’t find one, so it searched Docker Hub.\\nIn the example, it found one on Docker Hub and pulled a local copy.\\nOnce it had a local copy of the image, the daemon made a request to containerd asking\\nfor a new container. containerd then instructed runc to create the container and start\\nthe app. It also performed the port mapping.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 85}, page_content='7: Working with containers\\n79\\nRun the following commands to verify Docker pulled the image and started the\\nwebserver container.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nweb0.1\\n3f5b281b914b\\n12 minutes ago\\n159MB\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\nb5594b3b8b3f\\nnigelpoulton...\\n\"node ./app.js\"\\nUp 2 mins\\n0.0.0.0:80->8080/tcp\\nwebserver\\nYou can also test the app by connecting a browser to port 5005 on your Docker host.\\nIf you’re using Docker Desktop, point your browser to localhost:5005. If you’re not\\nrunning Docker Desktop, you may need to substitute localhost with the name or IP of\\nthe host Docker is running on.\\nFigure 7.4 - Web app running in container\\nCongratulations. Docker pulled a local copy of the image and started a container\\nrunning the app shown in the image.\\nHow containers start apps\\nIn the previous section, you created a container running a web app. But how did the\\ncontainer know to start a web app?'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 85}, page_content='running the app shown in the image.\\nHow containers start apps\\nIn the previous section, you created a container running a web app. But how did the\\ncontainer know to start a web app?\\nThere are three ways you can tell Docker how to start an app in a container:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 86}, page_content='7: Working with containers\\n80\\n1. An Entrypoint instruction in the image\\n2. A Cmd instruction in the image\\n3. A CLI argument\\nYou’ll learn more about these in the next chapter, but the Entrypoint and Cmd instruc-\\ntions are optional image metadata where you can store the command you want Docker\\nto run to start the default app. Then, whenever you start a container from the image,\\nDocker checks the Entrypoint or Cmd instruction and executes the stored command.\\nEntrypoint instructions cannot be overridden on the CLI, and anything you pass in via\\nthe CLI will be appended to the Entrypoint instruction as an argument.\\nCmd instructions are overridden by CLI arguments.\\nRun the following command to see if the nigelpoulton/ddd-book:web0.1 image has\\nan Entrypoint instruction. The command searches the image metadata and returns any\\nlines containing the word “Entrypoint” as well as the three lines immediately following it.\\nWindows users will need to replace the grep command with Select-String -Pattern'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 86}, page_content='lines containing the word “Entrypoint” as well as the three lines immediately following it.\\nWindows users will need to replace the grep command with Select-String -Pattern\\n\\'Entrypoint\\' -Context 0,3.\\n$ docker inspect nigelpoulton/ddd-book:web0.1 | grep Entrypoint -A 3\\n<Snip>\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"\\n],\\nThis image has an Entrypoint instruction that translates into the following command\\n— node ./app.js. If you’re not familiar with Node.js, it’s a simple command telling the\\nNode.js runtime to execute the code in the app.js file.\\nIf an image doesn’t have an Entrypoint instruction, you can search for the presence of a\\nCmd instruction.\\nIf an image doesn’t have either, you’ll need to pass an argument on the CLI.\\nThe format of the docker run command is:\\ndocker run <arguments> <image> <command>\\nAs mentioned, the <command> is optional; you don’t need it if the image has a Cmd or\\nEntrypoint instruction. If you specify a <command>, it will override a Cmd instruction'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 86}, page_content='As mentioned, the <command> is optional; you don’t need it if the image has a Cmd or\\nEntrypoint instruction. If you specify a <command>, it will override a Cmd instruction\\nbut will be appended to an Entrypoint instruction.\\nThe following command starts a new background container based on the Alpine image\\nand tells it to run the sleep 60 command, causing it to run for 60 seconds and then exit.\\nThe --rm flag cleans up the exited container so you don’t have to delete it manually.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 87}, page_content='7: Working with containers\\n81\\n$ docker run --rm -d alpine sleep 60\\nIf you run a docker ps command before the 60-second sleep timer expires, you’ll see\\nthe container in the output. If you run it after 60 seconds, the container will be gone.\\nThe --rm argument automatically cleans up the exited container.\\nMost production images will specify an Entrypoint or Cmd instruction.\\nConnecting to a running container\\nYou can use the docker exec command to execute commands in running containers,\\nand it has two modes:\\n• Interactive\\n• Remote execution\\nInteractive exec sessions connect your terminal to a shell process in the container and\\nbehave like remote SSH sessions. Remote execution mode lets you send commands to a\\nrunning container and prints the output to your local terminal.\\nRun the following command to start an interactive exec session by creating a new\\nshell process (sh) inside the webserver container that is already running. The -it flag'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 87}, page_content='Run the following command to start an interactive exec session by creating a new\\nshell process (sh) inside the webserver container that is already running. The -it flag\\nmakes it an interactive exec session, and the sh argument starts a new sh process inside the\\ncontainer. sh is a minimal shell program installed in the container.\\n$ docker exec -it webserver sh\\n/src #\\nNotice how your shell prompt changed. This proves your terminal is connected to the\\nshell process inside the container.\\nTry executing a few common Linux commands. Some will work, and some won’t. This\\nis because container images are usually optimized to be lightweight and don’t have all of\\nthe normal commands and packages installed. The following example shows a couple of\\ncommands — one succeeds, and the other one fails.\\nThe examples list the contents of your current directory and try to edit the app.js file\\nwith the vim editor.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 88}, page_content='7: Working with containers\\n82\\n/src # ls -l\\ntotal 100\\n-rw-r--r--\\n1 root\\nroot\\n324 Feb 20 12:35 Dockerfile\\n-rw-r--r--\\n1 root\\nroot\\n377 Feb 20 12:35 README.md\\n-rw-r--r--\\n1 root\\nroot\\n341 Feb 20 12:35 app.js\\ndrwxr-xr-x\\n183 root\\nroot\\n4096 Feb 20 12:41 node_modules\\n-rw-r--r--\\n1 root\\nroot\\n74342 Feb 20 12:41 package-lock.json\\n-rw-r--r--\\n1 root\\nroot\\n404 Feb 20 12:38 package.json\\ndrwxr-xr-x\\n2 root\\nroot\\n4096 Feb 20 12:35 views\\n<Snip>\\n/src # vim app.js\\nsh: vim: not found\\nThe vim command fails because it isn’t installed in the container.\\nInspecting container processes\\nMost containers only run a single process. This is the container’s main app process and\\nis always PID 1.\\nRun a ps command to see the processes running in your container. You’ll need to be\\nconnected to the exec session from the previous section for these commands to work.\\n/src # ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n13 root\\n0:00 sh\\n22 root\\n0:00 ps\\nThe output shows three processes:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 88}, page_content='/src # ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n13 root\\n0:00 sh\\n22 root\\n0:00 ps\\nThe output shows three processes:\\n• PID 1 is the main application process running the Node.js web app\\n• PID 13 is the shell process your interactive exec session is connected to\\n• PID 22 is the ps command you just ran\\nThe ps process terminated as soon as it displayed the output, and the sh process will\\nterminate when you exit the exec session. This means the only long-running process is\\nPID 1 running the Node app.\\nIf you kill the container’s main process (PID 1), you’ll also kill the container. This is\\nbecause containers only run while their main process is executing — when that process\\nis no longer running, there’s no reason for the container to run. We’ll demonstrate this\\nlater.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 89}, page_content='7: Working with containers\\n83\\nType exit to quit the exec session and return to your local terminal.\\nRun another docker exec command without specifying the -it flags. This will\\nremotely execute the command without creating an interactive session. The format of\\nthe command is docker exec <container> <command>, and it will only work if the\\ncontainer has the command you’re trying to execute.\\n$ docker exec webserver ps\\nPID\\nUSER\\nTIME\\nCOMMAND\\n1 root\\n0:00 node ./app.js\\n42 root\\n0:00 ps\\nThis time, only two processes are running because you terminated the sh process when\\nyou typed exit to quit the previous interactive exec session.\\nThe docker inspect command\\nYou’ll love the docker inspect command as it’s a treasure trove of detailed information\\nabout images and containers.\\nThe following command retrieves full details of the running webserver container, and\\nI’ve snipped the output to highlight a few interesting things. However, I recommend'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 89}, page_content='about images and containers.\\nThe following command retrieves full details of the running webserver container, and\\nI’ve snipped the output to highlight a few interesting things. However, I recommend\\nrunning the command on your system and studying the output.\\n$ docker inspect webserver\\n<Snip>\\n\"State\": {\\n\"Status\": \"running\"\\n},\\n\"Name\": \"/webserver\",\\n\"PortBindings\": {\\n\"8080/tcp\": [\\n{\\n\"HostIp\": \"\",\\n\"HostPort\": \"5005\"\\n}\\n]\\n},\\n\"RestartPolicy\": {\\n\"Name\": \"no\",\\n\"MaximumRetryCount\": 0\\n\"Image\": \"nigelpoulton/ddd-book:web0.1\",\\n\"WorkingDir\": \"/src\",\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 90}, page_content='7: Working with containers\\n84\\n],\\n}\\n<Snip>\\nThe snipped output shows the container is running, is called webserver, is binding port\\n8080 in the container to 5005 on the host, has no restart policy, and is based on the\\nnigelpoulton/ddd-book:web0.1 image. The Entrypoint block lists the command that\\nautomatically runs every time the container starts.\\nWe’ll cover this in more detail later, but this container inherited its Entrypoint instruc-\\ntion from the image you started it from. You can verify this by running the following\\ndocker inspect command against the image. I’ve snipped the output to highlight the\\nrelevant section.\\n$ docker inspect nigelpoulton/ddd-book:web0.1\\n<Snip>\\n\"Config\": {\\n\"WorkingDir\": \"/src\",\\n\"Entrypoint\": [\\n\"node\",\\n\"./app.js\"\\n],\\n<Snip>\\nI recommend you take time to investigate the output of docker inspect commands.\\nYou’ll learn a lot.\\nWriting data to a container\\nIn this section, you’ll exec onto the webserver container and edit the web server'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 90}, page_content='You’ll learn a lot.\\nWriting data to a container\\nIn this section, you’ll exec onto the webserver container and edit the web server\\nconfiguration to display a new message on the home page. In the next section, you’ll\\nstop and restart the container and verify your changes aren’t lost.\\nWARNING: This section is for demonstration purposes only. In the real\\nworld, you shouldn’t change live containers like this. Any time you need to\\nchange a live container, you should create and test a new container with the\\nrequired changes and then replace the existing container with the new one.\\nOpen a new interactive exec session to the webserver container with the following\\ncommand.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 91}, page_content='7: Working with containers\\n85\\n$ docker exec -it webserver sh\\n/src #\\nThe container runs a simple Node.js web app that uses the views/home.pug file to build\\nthe app’s home page.\\nRun the following command to open the home.pug file in the vi editor. Windows users\\ncan use Notepad or another editor.\\n/src # vi views/home.pug\\nIf you know how to use vi, you can go ahead and change the text on line 8 after the h1\\ntag to anything you like and save your changes.\\nCarefully follow these steps if you’re not familiar with vi:\\n1. Press the i key to put vi into insert mode\\n2. Use the arrow keys to navigate to line 8\\n3. Use your delete key to delete the text after the h1 tag on line 8\\n4. Type a new message of your choice\\n5. Press the escape key to exit insert mode and return to command mode\\n6. type :wq and press enter save your changes and exit (:wq is short for write and\\nquit)\\nOnce you’ve saved your changes, refresh your browser to see the updates.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 91}, page_content='6. type :wq and press enter save your changes and exit (:wq is short for write and\\nquit)\\nOnce you’ve saved your changes, refresh your browser to see the updates.\\nType exit to quit the exec session and return to your local terminal.\\nCongratulations, you’ve updated the web server config.\\nStopping, restarting, and deleting a container\\nIn this section, you’ll execute the typical container lifecycle events and see how they\\nimpact the changes you’ve made to the container.\\nThe following commands will only work if you’ve quit the interactive exec session.\\nCheck your container is still running.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 92}, page_content='7: Working with containers\\n86\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\nb5594b3b8b3f\\nnigelpoulton...\\n\"node ./app.js\"\\nUp 51 mins\\n0.0.0.0:80->8080\\nwebserver\\nStop it with the docker stop command. It will take up to 10 seconds to gracefully stop.\\n$ docker stop webserver\\nwebserver\\nRun another docker ps command.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nThe container no longer shows in the list of running containers. However, you can see it\\nif you run the same command with the -a flag to show all containers, including stopped\\nones.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nb5594b3b8b3f\\nnigelpou...\\n\"node ./app.js\"\\nExited (137) About a minute ago\\nwebserver\\nAs you can see in the output, it still exists but is in the Exited state. Restart it with the\\nfollowing command.\\n$ docker restart webserver\\nwebserver\\nIf you run another docker ps, you’ll see it in the Up state.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 92}, page_content='following command.\\n$ docker restart webserver\\nwebserver\\nIf you run another docker ps, you’ll see it in the Up state.\\nRefresh your browser to see if Docker has saved your changes to the home page or\\nreverted to the original.\\nDocker has saved your changes!\\nYou can also run the following command to return the contents of the file directly from\\nthe container’s filesystem.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 93}, page_content=\"7: Working with containers\\n87\\n$ docker exec webserver cat views/home.pug\\nhtml\\nhead\\ntitle='Docker FTW'\\nlink(rel='stylesheet', href='https://stackpath.bootstrapcdn.com/....\\nbody\\ndiv.container\\ndiv.jumbotron\\nh1 Everybody loves containers!\\n<<---- I changed this line\\n<Snip>\\nSo far, you’ve seen that starting and stopping containers doesn’t lose changes. You also\\nsaw that restarting them is very fast.\\nRun the following command to delete the container. The -f flag forces the operation\\nand doesn’t allow the app the usual 10-second grace period to flush buffers and grace-\\nfully quit. Be careful forcing operations like this, as Docker doesn’t ask you to confirm.\\n$ docker rm webserver -f\\nwebserver\\nRun a docker ps -a to see if there’s any sign of the container.\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nAll signs of the container are gone and you cannot restart it. You can start a new\\ninstance by executing another docker run command and specifying the same image,\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 93}, page_content='COMMAND\\nCREATED\\nSTATUS\\nPORTS\\nNAMES\\nAll signs of the container are gone and you cannot restart it. You can start a new\\ninstance by executing another docker run command and specifying the same image,\\nbut it won’t have the changes you made.\\nWARNING: As previously mentioned, changing live containers like this is an\\nanti-pattern and you shouldn’t do it. We only showed it here to demonstrate\\nhow containers work and how changes to the container’s filesystem (made\\nto the container’s own thin R/W layer) persist across restarts. An anti-pattern\\nis something that works but isn’t a good practice as it can have unintended\\nconsequences.\\nKilling a container’s main process\\nEarlier in the chapter, we learned that containers are designed to run a single process,\\nand we said that killing this process also kills the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 94}, page_content=\"7: Working with containers\\n88\\nLet’s test if that’s true.\\nRun the following command to start a new interactive container called ddd-ctr based on\\nthe Ubuntu image and tell it to run a Bash shell as its main process.\\n$ docker run --name ddd-ctr -it ubuntu:24.04 bash\\nUnable to find image 'ubuntu:24.04' locally\\n24.04: Pulling from library/ubuntu\\n51ae9e2de052: Download complete\\nDigest: sha256:ff0b5139e774bb0dee9ca8b572b4d69eaec2795deb8dc47c8c829becd67de41e\\nStatus: Downloaded newer image for ubuntu:24.04\\nroot@d3c892ad0eb3:/#\\nThe command pulls the Ubuntu image and attaches your terminal to the container’s\\nBash shell process.\\nRun a ps command to list all running processes.\\nroot@d3c892ad0eb3:/# ps\\nPID TTY\\nTIME CMD\\n1 pts/0\\n00:00:00 bash\\n9 pts/0\\n00:00:00 ps\\nPID 1 is the container’s main process and is the Bash shell you told the container to run.\\nThe other one is the ps command and has already exited. This means the Bash process is\\nthe only process running in the container.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 94}, page_content='The other one is the ps command and has already exited. This means the Bash process is\\nthe only process running in the container.\\nIf you type exit, you’ll terminate the Bash process and kill the container. This is because\\ncontainers only run while their main process executes.\\nTest this by typing exit to return to your local terminal and then running a docker ps\\n-a command to see if the container terminated.\\nroot@d3c892ad0eb3:/# exit\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nd3c892ad0eb3\\nubuntu:24.04\\n\"bash\"\\nExited (0) 3 secs ago\\nddd-ctr\\nAs expected, the container is in the exited state and not running. However, you can run\\nthe following two commands to restart it and attach your shell to its main process.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 95}, page_content='7: Working with containers\\n89\\n$ docker restart ddd-ctr\\nddd-ctr\\n$ docker attach ddd-ctr\\nroot@d3c892ad0eb3:/#\\nYour terminal is once again attached to the Bash shell in the container.\\nYou can type Ctrl PQ to exit a container without killing the process you’re attached to.\\nType Ctrl PQ to exit the container and run another docker ps command to verify the\\ncontainer is still running this time.\\nroot@d3c892ad0eb3:/# <Ctrl PQ>\\nread escape sequence\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nSTATUS\\nNAMES\\nd3c892ad0eb3\\nubuntu:24.04\\n\"bash\"\\nUp 27 seconds\\nddd-ctr\\nThe container is still up.\\nNow that you know how to exit containers without killing them, let’s switch focus and\\nsee how to use Docker Debug to debug slim containers and images.\\nDebugging slim images and containers with Docker\\nDebug\\nAt the time of writing, Docker Debug is only included as part of Docker Desktop and\\nrequires a Pro, Team, or Business subscription.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 95}, page_content='Debugging slim images and containers with Docker\\nDebug\\nAt the time of writing, Docker Debug is only included as part of Docker Desktop and\\nrequires a Pro, Team, or Business subscription.\\nIt’s a widely accepted good practice to deploy slim images that only contain app code and\\ndependencies. This means no shell or debugging tools and is a big part of making images\\nand containers small and secure. However, it also makes it difficult to debug them when\\nthings go wrong.\\nThis is where Docker Debug comes to the rescue by allowing you to get shell access\\nto images and containers that don’t include a shell and seamlessly inject powerful\\ndebugging tools into them.\\nAt a high level, Docker Debug works by attaching a shell to a container and mounting a\\ntoolbox loaded with debugging tools. This toolbox is mounted as a directory called /nix\\nand is available during your debugging session but is never visible to the container. As'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 95}, page_content='toolbox loaded with debugging tools. This toolbox is mounted as a directory called /nix\\nand is available during your debugging session but is never visible to the container. As\\nsoon as you exit the Docker Debug session, the /nix directory is removed. If you’re\\ndebugging a running container, any changes you make are immediately visible to the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 96}, page_content='7: Working with containers\\n90\\ncontainer and persist across container restarts. For example, updating an index.html\\nduring a Docker Debug session will immediately update the running web app, and the\\nchanges will persist if the container is stopped and restarted. If you’re debugging an\\nimage or stopped container, the Docker Debug session creates a debug sandbox and\\nadds it to the image as a R/W layer to make it feel like a running container. However,\\nchanges you make while debugging an image or stopped container are not persisted and\\nare lost as soon as you quit the debug session.\\nIf you’ve been following along, you’ll have a running container called ddd-ctr. If you\\ndon’t, you can start one by running docker run --name ddd-ctr -it ubuntu:24.04\\nbash.\\nRun the following commands to attach to the container and see if it has any debugging\\ntools. The following docker attach command is similar to the docker exec commands'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 96}, page_content='bash.\\nRun the following commands to attach to the container and see if it has any debugging\\ntools. The following docker attach command is similar to the docker exec commands\\nyou learned earlier but automatically connects to a container’s main process. You don’t\\nneed to run the docker attach command if you’re already connected to the container.\\n$ docker attach ddd-ctr\\nroot@d3c892ad0eb3:/#\\nroot@d3c892ad0eb3:/# ping nigelpoulton.com\\nbash: ping: command not found\\nroot@d3c892ad0eb3:/# nslookup nigelpoulton.com\\nbash: nslookup: command not found\\nroot@d3c892ad0eb3:/# vim\\nbash: vim: command not found\\nThe commands all failed because none of the tools are installed in this container. This\\nwould make debugging this container difficult without Docker Debug.\\nType Ctrl PQ to gracefully disconnect from the container without killing the Bash\\nprocess.\\nIn the following steps, you’ll use Docker Debug to get a shell session to the container'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 96}, page_content='Type Ctrl PQ to gracefully disconnect from the container without killing the Bash\\nprocess.\\nIn the following steps, you’ll use Docker Debug to get a shell session to the container\\nand run commands that aren’t installed in the container. You can even use Docker\\nDebug to get shell access to containers and images that don’t include a shell.\\nYou need to log in to Docker to use Docker Debug, and it only works if you have a Pro,\\nTeam, or Business license.\\n$ docker login\\nAuthenticating with existing credentials...\\nLogin Succeeded\\nRun the following command to check if you have the Docker Debug CLI plugin. All\\nmodern versions of Docker Desktop include this by default. Other Docker installations\\nmay not have it, but you may be able to install it manually.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 97}, page_content='7: Working with containers\\n91\\n$ docker info\\nClient:\\nVersion:\\n26.1.1\\nContext:\\ndesktop-linux\\nDebug Mode: false\\nPlugins:\\ndebug: Get a shell into any image or container. (Docker Inc.)\\nVersion:\\n0.0.29\\nPath:\\n/Users/nigelpoulton/.docker/cli-plugins/docker-debug\\n<Snip>\\nOnce you’re logged in and have the plugin installed, you’re ready to continue.\\nThe format of the command is docker debug <image>|<container>. We’ll open a\\nDocker Debug session to the running container called ddd-ctr.\\n$ docker debug ddd-ctr\\nThis is an attach shell, i.e.:\\n- Any changes to the container filesystem are visible to the container directly.\\n- The /nix directory is invisible to the actual container.\\nVersion: 0.0.37 (BETA)\\nroot@d3c892ad0eb3 / [ddd-ctr]\\ndocker >\\nYou’ve successfully connected to the running container and got a new shell prompt\\n(docker >). You also got some helpful info displaying the short ID and name of the\\ncontainer you’re debugging, as well as a reminder that any changes you make will be'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 97}, page_content='(docker >). You also got some helpful info displaying the short ID and name of the\\ncontainer you’re debugging, as well as a reminder that any changes you make will be\\nvisible to the container.\\nTry running the ping, nslookup, and vim commands that failed in the previous section.\\nIf you get stuck in the vim session, just type :q and press Enter.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 98}, page_content='7: Working with containers\\n92\\ndocker > ping nigelpoulton.com\\nPING nigelpoulton.com (192.124.249.126) 56(84) bytes of data.\\n64 bytes from cloudproxy10126.sucuri.net (192.124.249.126): icmp_seq=1 ttl=63 time=211 ms\\n64 bytes from cloudproxy10126.sucuri.net (192.124.249.126): icmp_seq=2 ttl=63 time=58.3 ms\\n^C\\ndocker > nslookup nigelpoulton.com\\nzsh: command not found: nslookup\\ndocker > vim\\n~\\nVIM\\n- Vi IMproved\\n~\\nversion 9.0.1441\\n~\\nby Bram Moolenaar et al.\\n~\\nVim is open source and freely distributable\\n<Snip>\\n:q\\nThe ping and vim commands worked, but the nslookup still failed. This is because the\\ndefault Docker Debug toolbox includes ping and vim but doesn’t include nslookup. Don’t\\nworry, though. You can use Docker Debug’s built-in install command to add any\\npackage listed on search.nixos.org.\\nRun the following command to install the bind package (which includes the nslookup\\ntool), and then run the nslookup command again.\\ndocker > install bind'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 98}, page_content=\"package listed on search.nixos.org.\\nRun the following command to install the bind package (which includes the nslookup\\ntool), and then run the nslookup command again.\\ndocker > install bind\\nTip: You can install any package available at: https://search.nixos.org/packages.\\ninstalling 'bind-9.18.19'\\n<Snip>\\ndocker > nslookup nigelpoulton.com\\nServer:\\n192.168.65.7\\nAddress:\\n192.168.65.7#53\\nNon-authoritative answer:\\nName:\\nnigelpoulton.com\\nAddress:\\n192.124.249.126\\nThe command worked, and nslookup is now installed in your toolbox and will be\\navailable in future Docker Debug sessions.\\nCongratulations, you’ve used Docker Debug to attach to a running container and run\\ntroubleshooting commands that aren’t part of the container. You’ve also seen how to\\ninstall additional tools to your Docker Debug toolbox. Remember, any changes you\\nmake to running containers are immediately visible to the container and persist after\\nyou close the session.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 98}, page_content='install additional tools to your Docker Debug toolbox. Remember, any changes you\\nmake to running containers are immediately visible to the container and persist after\\nyou close the session.\\nType exit to terminate the debug session and return to your local shell.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 99}, page_content='7: Working with containers\\n93\\nRun the following command to create a new Docker Debug session that debugs the\\nnigelpoulton/ddd-book:web0.1 image. Docker will automatically pull the image from\\nDocker Hub if you don’t have a local copy.\\n$ docker debug nigelpoulton/ddd-book:web0.1\\nNote: This is a sandbox shell. All changes will not affect the actual image.\\nVersion: 0.0.37 (BETA)\\nroot@3f5b281b914b /src [nigelpoulton/ddd-book:web0.1]\\ndocker >\\nNotice the different message this time. Debugging images creates a sandbox shell and\\nchanges won’t affect the actual image. This reminds you that debugging images and\\nstopped containers behaves differently from debugging running containers:\\n• Changes made while debugging a live container are persisted\\n• Changes made while debugging images or stopped containers are deleted when\\nyou quit the debug session\\nRun an nslookup command to prove the tool is saved to your toolbox and available for\\nuse without re-installing.\\ndocker > nslookup craigalanson.com'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 99}, page_content='you quit the debug session\\nRun an nslookup command to prove the tool is saved to your toolbox and available for\\nuse without re-installing.\\ndocker > nslookup craigalanson.com\\nServer:\\n192.168.65.7\\nAddress:\\n192.168.65.7#53\\nNon-authoritative answer:\\nName:\\ncraigalanson.com\\nAddress:\\n198.185.159.144\\n<Snip>\\nDocker Debug has a built-in entrypoint command that lets you print, lint, and test an\\nimage or container’s Entrypoint or Cmd command. These are the commands Docker\\nexecutes to start the container’s app.\\nRun the following entrypoint command to reveal the default command this container\\nwill run when it starts.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 100}, page_content='7: Working with containers\\n94\\ndocker > entrypoint --print\\nnode ./app.js\\nThe entrypoint command is clever enough to look for Entrypoint and Cmd instruc-\\ntions.\\nType exit to quit the debug session.\\nIn summary, Docker Debug is a fantastic tool for debugging slim images and containers.\\nIt gets you shell access to containers and images that don’t include a shell, and you can\\nrun troubleshooting tools that aren’t available in the container or image. Any changes\\nyou make to running containers take immediate effect and persist across stop and restart\\noperations. However, changes made while debugging images and stopped containers are\\nlost when you close the session. In all cases, the tools you install and use are never part\\nof the container or image.\\nSelf-healing containers with restart policies\\nContainer restart policies are a simple form of self-healing that allows the local Docker\\nEngine to automatically restart failed containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 100}, page_content='Self-healing containers with restart policies\\nContainer restart policies are a simple form of self-healing that allows the local Docker\\nEngine to automatically restart failed containers.\\nYou apply restart policies per container, and Docker supports the following four policies:\\n• no (default)\\n• on-failure\\n• always\\n• unless-stopped\\nThe following table shows how each policy reacts to different scenarios. A Y indicates\\nthe policy will attempt a container restart, whereas an N indicates it won’t.\\nRestart\\nRestart\\nNon-zero\\nZero\\ndocker stop\\nwhen Daemon\\npolicy\\nexit code\\nexit code\\ncommand\\nrestarts\\nno\\nN\\nN\\nN\\nN\\non-failure\\nY\\nN\\nN\\nY\\nalways\\nY\\nY\\nN\\nY\\nunless-stopped\\nY\\nY\\nN\\nN\\nNon-zero exit codes indicate a failure occurred. Zero exit codes indicate the container\\nexited normally without an error.\\nWe’ll demo some examples, but you should also do your own testing.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 101}, page_content='7: Working with containers\\n95\\nLet’s demonstrate the always policy by starting a new interactive container with the --\\nrestart always flag and telling it to run a shell process. We’ll then type exit to kill the\\nshell process and the container to see what happens.\\nRun the following command to start an interactive container called neversaydie with\\nthe always restart policy.\\n$ docker run --name neversaydie -it --restart always alpine sh\\n/#\\nYour terminal will automatically connect to the shell process inside the container.\\nType exit to kill the shell process and return to your local terminal. This will cause the\\ncontainer to exit with a zero exit code, indicating a normal exit without any failures.\\nAccording to the previous table, the always restart policy should automatically restart\\nthe container.\\nRun a docker ps command to see if this happened.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\n1933623830bb\\nalpine\\n\"sh\"\\n35 seconds ago\\nUp 2 seconds\\nneversaydie'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 101}, page_content='the container.\\nRun a docker ps command to see if this happened.\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\n1933623830bb\\nalpine\\n\"sh\"\\n35 seconds ago\\nUp 2 seconds\\nneversaydie\\nThe container is running as expected. However, you can see it was created 35 seconds\\nago but has only been running for 2 seconds. This is because you forced it to exit\\nwhen you killed the shell process, and then Docker automatically restarted it. It’s also\\nimportant to know that Docker restarted the same container and didn’t create a new\\none. In fact, if you run a docker inspect against it, you’ll see the RestartCount has\\nbeen incremented to 1. Remember to replace grep with Select-String -Pattern\\n\\'RestartCount\\' if you’re on Windows using PowerShell.\\n$ docker inspect neversaydie | grep RestartCount\\n\"RestartCount\": 1,\\nAn interesting feature of the --restart always policy is that if you stop a container\\nwith docker stop and then restart the Docker daemon, Docker will restart the con-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 101}, page_content='\"RestartCount\": 1,\\nAn interesting feature of the --restart always policy is that if you stop a container\\nwith docker stop and then restart the Docker daemon, Docker will restart the con-\\ntainer when the daemon comes up. To be clear:\\n1. You start a new container with the --restart always policy\\n2. You manually stop it with the docker stop command\\n3. You restart Docker (or an event causes Docker to restart)\\n4. When Docker comes back up, it starts the stopped container\\nIf you don’t want this behavior, you should try the unless-stopped policy.\\nIf you are working with Docker Compose or Docker Stacks, you can apply restart\\npolicies to services as follows. We’ll cover these in more detail in later chapters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 102}, page_content='7: Working with containers\\n96\\nservices:\\nmyservice:\\n<Snip>\\nrestart_policy:\\ncondition: always | unless-stopped | on-failure\\nClean up\\nYou can run docker images and docker ps -a commands to see the images you pulled\\nand the containers you created as part of this chapter. Your output will be similar to this.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nweb0.1\\n3f5b281b914b\\n4 days ago\\n159MB\\nubuntu\\n24.04\\nff0b5139e774\\n13 days ago\\n138MB\\nalpine\\nlatest\\nc5b1261d6d3e\\n4 weeks ago\\n11.8MB\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAMES\\nac165419214f\\nalpine\\n\"sh\"\\n33 secs ago\\nUp 24 seconds\\nneversaydie\\n5bd3741185fa\\nubuntu:24.04\\n\"bash\"\\n3 mins ago\\nExited (0) ~1min ago\\nddd-ctr\\nYou can delete individual containers with the docker rm <container> -f command\\nand images with the docker rmi command, and you should always delete containers\\nbefore images.\\nYou can also delete all containers and all images with the following two commands. Be'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 102}, page_content='and images with the docker rmi command, and you should always delete containers\\nbefore images.\\nYou can also delete all containers and all images with the following two commands. Be\\nwarned though, Docker will not prompt you for confirmation.\\n$ docker rm $(docker ps -aq) -f\\nac165419214f\\n5bd3741185fa\\n$ docker rmi $(docker images -q)\\nUntagged: nigelpoulton/ddd-book:web0.1\\nDeleted: sha256:3f5b281b914b1e39df8a1fbc189270a5672ff9e98bfac03193b42d1c02c43ef0\\nUntagged: ubuntu:24.04\\nDeleted: sha256:ff0b5139e774bb0dee9ca8b572b4d69eaec2795deb8dc47c8c829becd67de41e\\nUntagged: alpine:latest\\nDeleted: sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b\\nBoth commands work by passing a list of all container/image IDs to the delete com-\\nmand.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 103}, page_content='7: Working with containers\\n97\\nContainers – The commands\\n• docker run is the command to start new containers. You give it the name of an\\nimage and it starts a container from it. This example starts an interactive container\\nfrom the Ubuntu image and tells it to run the Bash shell: docker run -it ubuntu\\nbash.\\n• Ctrl-PQ is how you detach from a container without killing the process you’re\\nattached to. You’ll use it frequently to detach from running containers without\\nkilling them.\\n• docker ps lists all running containers, and you can add the -a flag to also see\\ncontainers in the stopped (Exited) state.\\n• docker exec allows you to run commands inside containers. The following\\ncommand will start a new Bash shell inside a running container and connect\\nyour terminal to it: docker exec -it <container-name> bash. This next\\ncommand runs a ps command inside a running container without opening an\\ninteractive shell session: docker exec <container-name> ps. For these to work,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 103}, page_content='command runs a ps command inside a running container without opening an\\ninteractive shell session: docker exec <container-name> ps. For these to work,\\nthe container must include the Bash shell.\\n• docker stop stops a running container and puts it in the Exited (137) state. It\\nissues a SIGTERM to the container’s PID 1 process and allows the container 10\\nseconds to gracefully quit. If the process hasn’t cleaned up and stopped within 10\\nseconds, it sends a SIGKILL to force the container to terminate immediately.\\n• docker restart restarts a stopped container.\\n• docker rm deletes a stopped container. You can add the -f flag to delete the\\ncontainer without having to stop it first.\\n• docker inspect shows you detailed configuration and run-time information\\nabout a container.\\n• docker debug attaches a debug shell to a container or image and lets you run\\ncommands that aren’t available inside the container or image. It requires a Pro,\\nTeam, or Business Docker subscription.\\nChapter summary'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 103}, page_content='commands that aren’t available inside the container or image. It requires a Pro,\\nTeam, or Business Docker subscription.\\nChapter summary\\nIn this chapter, you learned some of the major differences between VMs and containers,\\nincluding that containers are smaller, faster, and more portable.\\nYou learned how to start, stop, and restart containers with the docker CLI, and you saw\\nthat changes to a container’s filesystem persist across restarts.\\nYou learned that containers run a single process and terminate if this process is killed.\\nYou also saw the three ways of telling a container which app to run and how to start it —\\nvia Entrypoint or Cmd instructions in the image metadata or via the docker run CLI.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 104}, page_content='7: Working with containers\\n98\\nYou learned about Docker Debug and how it allows you to get a shell to slim containers\\nand run troubleshooting commands that don’t exist in the container.\\nFinally, you learned how to attach restart policies to containers and how the different\\nrestart policies work.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 105}, page_content='8: Containerizing an app\\nDocker makes it easy to package applications as images and run them as containers.\\nWe call this process containerization, and this chapter will walk you through the entire\\nprocess.\\nI’ve divided the chapter as follows:\\n• Containerizing an app – The TLDR\\n• Containerize a single-container app\\n• Moving to production with multi-stage-builds\\n• Buildx, BuildKit, drivers, and Build Cloud\\n• Multi-architecture builds\\n• A few good practices\\nContainerizing an app – The TLDR\\nDocker aims to make it easy to build, share, and run applications. We call this containeriza-\\ntion and the process looks like this:\\n1. Write your applications and create the list of dependencies\\n2. Create a Dockerfile that tells Docker how to build and run the app\\n3. Build the app into an image\\n4. Push the image to a registry (optional)\\n5. Run a container from the image\\nYou can see these five steps in Figure 8.1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 106}, page_content='8: Containerizing an app\\n100\\nFigure 8.1 - Basic flow of containerizing an app\\nContainerize a single-container app\\nIn this section, you’ll complete the following steps to containerize a simple Node.js app:\\n• Get the application code from GitHub\\n• Create the Dockerfile\\n• Containerize the app\\n• Run the app\\n• Test the app\\n• Look a bit closer\\nI recommend you follow along with Docker Desktop. This is because we’ll be using\\nthe new docker init command, which might not be installed on other versions of\\nDocker. Don’t worry if your Docker installation doesn’t have docker init, we include\\ninstructions for you as well.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 107}, page_content=\"8: Containerizing an app\\n101\\nGet the application code\\nThe application we’ll use is a Node.js web app that serves a web page on port 8080.\\nYou’ll need a copy of the book’s GitHub repo containing the application code. If you\\ndon’t already have it, run the following command to get it. You’ll need git installed, and\\nthe command will create a new directory called ddd-book.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nCloning into 'ddd-book'...\\nremote: Enumerating objects: 47, done.\\nremote: Counting objects: 100% (47/47), done.\\nremote: Compressing objects: 100% (32/32), done.\\nremote: Total 47 (delta 11), reused 44 (delta 11), pack-reused 0\\nReceiving objects: 100% (47/47), 167.30 KiB | 1.66 MiB/s, done.\\nResolving deltas: 100% (11/11), done.\\nChange into the ddd-book/node-app directory and list its contents.\\n$ cd ddd-book/node-app\\n$ ls -l\\ntotal 98\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n341 20 Feb 12:35 app.js\\ndrwxr-xr-x\\n103 nigelpoulton\\nstaff\\n3296 12 Mar 16:18 node_modules\\n-rw-r--r--\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 107}, page_content='$ cd ddd-book/node-app\\n$ ls -l\\ntotal 98\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n341 20 Feb 12:35 app.js\\ndrwxr-xr-x\\n103 nigelpoulton\\nstaff\\n3296 12 Mar 16:18 node_modules\\n-rw-r--r--\\n1 nigelpoulton\\nstaff\\n39975 12 Mar 16:18 package-lock.json\\n-rw-r--r--@\\n1 nigelpoulton\\nstaff\\n355\\n8 Mar 10:10 package.json\\ndrwxr-xr-x\\n3 nigelpoulton\\nstaff\\n96 20 Feb 12:35 views\\nThis directory is your build context because it contains the application source code and\\nthe files listing dependencies.\\nFor Docker to containerize it, it needs a Dockerfile with build instructions. Let’s create it.\\nCreate the Dockerfile\\nIn the past, you had to create Dockerfiles manually. Fortunately, newer versions of\\nDocker support the docker init command that reads your build context, analyzes your\\napplication, and automatically creates a Dockerfile implementing good practices.\\nRun the following command to create a Dockerfile for the app. If your Docker installa-\\ntion doesn’t have the docker init plugin, you’ll have to skip this step.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 107}, page_content='Run the following command to create a Dockerfile for the app. If your Docker installa-\\ntion doesn’t have the docker init plugin, you’ll have to skip this step.\\nFeel free to accept a newer version of Node.js, but complete all other prompts as shown.\\nYou’ll need to run it from the node-app directory.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 108}, page_content='8: Containerizing an app\\n102\\n$ docker init\\nWelcome to the Docker Init CLI!\\n<Snip>\\n? What application platform does your project use? Node\\n? What version of Node do you want to use? 23.3.0\\n<<---- Newer versions are OK\\n? Which package manager do you want to use? npm\\n? What command do you want to use to start the app? node app.js\\n? What port does your server listen on? 8080\\nCREATED: .dockerignore\\nCREATED: Dockerfile\\nCREATED: compose.yaml\\nCREATED: README.Docker.md\\n\\uffffYour Docker files are ready!\\nThe process created a new Dockerfile and placed it in your current directory. It looks\\nlike this.\\n1. ARG NODE_VERSION=20.8.0\\n2. FROM node:${NODE_VERSION}-alpine\\n3. ENV NODE_ENV production\\n4. WORKDIR /usr/src/app\\n5. RUN --mount=type=bind,source=package.json,target=package.json \\\\\\n--mount=type=bind,source=package-lock.json,target=package-lock.json \\\\\\n--mount=type=cache,target=/root/.npm \\\\\\nnpm ci --omit=dev\\n6. USER node\\n7. COPY . .\\n8. EXPOSE 8080\\n9. CMD node app.js'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 108}, page_content='--mount=type=bind,source=package-lock.json,target=package-lock.json \\\\\\n--mount=type=cache,target=/root/.npm \\\\\\nnpm ci --omit=dev\\n6. USER node\\n7. COPY . .\\n8. EXPOSE 8080\\n9. CMD node app.js\\nLines 1 and 2 tell Docker to pull the node:23.3.0-alpine image and use it as the base\\nfor the new image.\\nLine 3 tells Node to run in production mode. This is a Node.js optimization that increases\\nperformance while minimizing logging and other common development features.\\nLine 4 sets the working directory for the remaining steps. For example, the RUN and COPY\\ninstructions on lines 5 and 7 will run against the WORKDIR directory, as will the node\\napp.js command on line 9.\\nLine 5 bind mounts the dependency files and installs them with the npm ci --omit-dev\\ncommand.\\nLine 6 ensures Node.js runs the app as a non-root user.\\nLine 7 copies the application’s source code from your build context (the first period)\\ninto the WORKDIR directory (the second period) inside the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 109}, page_content='8: Containerizing an app\\n103\\nLine 8 documents the application’s network port.\\nLine 9 is the command Docker will execute whenever it starts a container from the\\nimage.\\nYou now have everything Docker needs to build the application into a container image\\n— source code, dependencies, and a Dockerfile.\\nContainerize the app\\nIn this section, you’ll build the application into a container image.\\nIf your Docker installation doesn’t have the docker init plugin and you didn’t follow\\nthe previous step, you’ll need to rename the sample-Dockerfile to Dockerfile before\\ncontinuing.\\nRun the following command to build a new image called ddd-book:ch8.node. Be sure to\\ninclude the trailing period (.) as this tells Docker to use your current working directory\\nas the build context. Remember, the build context is the directory where your app files live.\\n$ docker build -t ddd-book:ch8.node .\\n[+] Building 16.2s (12/12) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 109}, page_content='$ docker build -t ddd-book:ch8.node .\\n[+] Building 16.2s (12/12) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n=> => transferring dockerfile: 1.21kB\\n0.0s\\n=> => transferring context: 659B\\n0.0s\\n=> [stage-0 1/4] FROM docker.io/library/node:20.8.0-alpine\\n3s\\n<<---- Base layer\\n=> [stage-0 2/4] WORKDIR /usr/src/app\\n0.2s\\n<<---- New layer\\n=> [stage-0 3/4] RUN --mount=type=bind,source=package...\\n1.1s\\n<<---- New layer\\n=> [stage-0 4/4] COPY . .\\n0.1s\\n<<---- New layer\\n=> exporting to image\\n0.2s\\n=> => exporting layers\\n0.2s\\n=> => writing image sha256:f282569b8bd0f0...016cc1adafc91\\n0.0s\\n=> => naming to docker.io/library/ddd-book:ch8.node\\nI’ve snipped the output, but you can see four numbered steps creating four image layers.\\nThese map to the instructions in the Dockerfile.\\nCheck the image exists in your Docker host’s local repository.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nddd-book\\nch8.node\\n24dd040fa06b\\n18 minutes ago\\n242MB'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 109}, page_content='Check the image exists in your Docker host’s local repository.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nddd-book\\nch8.node\\n24dd040fa06b\\n18 minutes ago\\n242MB\\nCongratulations, you’ve containerized the app as an OCI image!\\nRun a docker inspect ddd-book:ch8.node command to verify the image and see the\\nsettings from the Dockerfile. You should be able to see the image layers and metadata\\nsuch as the Exposed Ports, WorkingDir, and Entrypoint values.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 110}, page_content='8: Containerizing an app\\n104\\n$ docker inspect ddd-book:ch8.node\\n[\\n{\\n\"Id\": \"sha256:24dd040fa06baf6e40144c5a59f99a749159a932ecebb737751f7f862963527a\",\\n\"RepoTags\": [\\n\"ddd-book:ch8.node\"\\n<Snip>\\n\"ExposedPorts\": {\\n\"8080/tcp\": {}\\n\"WorkingDir\": \"/usr/src/app\",\\n\"Cmd\": [\\n\"/bin/sh\",\\n\"-c\",\\n\"node app.js\"\\n],\\n<Snip>\\n\"Layers\": [\\n\"sha256:5f4d9fc4d98de91820d2a9c81e501c8cc6429bc8758b43fcb2cd50f4cab9a324\",\\n\"sha256:6b20c4e93dbab9786f96268bbe32c208d385f2c4490a278ad3b1e55cc79480e4\",\\n\"sha256:012c308a78ec993a47fdb7c4c6d17b53d8ce2649a463be28ae5c48ab1af2e039\",\\n\"sha256:35a839ac7cc922afd896a0297e692141c77ed6e03eff6a70db13bb23f6cd4f8f\",\\n\"sha256:918caa8070410ccfb2c5b3b4d62ca66742c46bf21fe0bd433738b7796c530e68\",\\n\"sha256:a48b3b3d0c5a693840e7e4abd7971f130b4447573483628bcb996091e1e8e8b8\",\\n\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n<Snip>\\nYou might wonder why the image has seven layers when only four Dockerfile instruc-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 110}, page_content='\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n<Snip>\\nYou might wonder why the image has seven layers when only four Dockerfile instruc-\\ntions created layers. This is because the node:20.8.0-alpine base image already had\\nfour layers. Therefore, the FROM instruction pulled a base image with four layers, and\\nthen the WORKDIR, RUN and COPY instructions added three more layers. You can see this\\nin Figure 8.2.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 111}, page_content='8: Containerizing an app\\n105\\nFigure 8.2 - Dockerfile and image layers\\nPush the image to Docker Hub\\nThis is an optional section, and you’ll need a Docker Hub account to follow along. Go to\\nhub.docker.com and sign up for a free one now.\\nYou’ll complete the following steps:\\n1. Login to Docker Hub\\n2. Re-tag the image\\n3. Push the image\\nAfter creating images, you’ll normally push them to a registry where you can keep them\\nsafe and make them accessible to teammates and clients. Lots of registries exist, but\\nDocker Hub is the most common public registry and is where Docker pushes images\\nby default.\\nLog in to Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 112}, page_content=\"8: Containerizing an app\\n106\\n$ docker login\\nUSING WEB-BASED LOGIN\\nTo sign in with credentials on the command line, use 'docker login -u <username>'\\nYour one-time device confirmation code is: PNXK-SGJG\\nPress ENTER to open your browser or submit your device code here: https://login.docker.com/activate\\nLogin Succeeded\\nOnce logged in, you need to re-tag the image. This is because Docker uses the image tag\\nto determine which registry and repository to push it to.\\nIf you run a docker images command, you’ll see an image tagged as ddd-book:ch8.node.\\nIf you push this image, Docker will try to push it to a repository called ddd-book on\\nDocker Hub. However, no such repository exists, and the command will fail.\\nRun the following command to re-tag the image to include your Docker ID. The format\\nof the command is docker tag <current-tag> <new-tag>, and it creates an additional\\ntag for the same image.\\n$ docker tag ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 112}, page_content='of the command is docker tag <current-tag> <new-tag>, and it creates an additional\\ntag for the same image.\\n$ docker tag ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\\nRun another docker images command to see the image with both tags. Notice how\\neverything is identical except the REPO column. This is because it’s the same image with\\ndifferent names.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nch8.node\\n24dd040fa06b\\n38 minutes ago\\n268MB\\nddd-book\\nch8.node\\n24dd040fa06b\\n38 minutes ago\\n268MB\\nPush it to Docker Hub. You’ll need to be logged in with your Docker ID for this to work,\\nand you’ll need to use your Docker ID instead of mine.\\n$ docker push nigelpoulton/ddd-book:ch8.node\\nThe push refers to repository [docker.io/nigelpoulton/ddd-book]\\ne4ef261755c8: Pushed\\nd25f74b85615: Pushed\\n7e1aebde141d: Pushed\\n7b3f8039e3c4: Pushed\\n2a2799ae89a2: Mounted from library/node\\n4927cb899c33: Mounted from library/node\\n579b34f0a95b: Pushed\\nced319b3ffb5: Pushed'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 112}, page_content='d25f74b85615: Pushed\\n7e1aebde141d: Pushed\\n7b3f8039e3c4: Pushed\\n2a2799ae89a2: Mounted from library/node\\n4927cb899c33: Mounted from library/node\\n579b34f0a95b: Pushed\\nced319b3ffb5: Pushed\\nch8.node: digest: sha256:24dd040fa06baf...1f7f862963527a size: 856'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 113}, page_content='8: Containerizing an app\\n107\\nFigure 8.3 shows how Docker figured out where to push the image.\\nFigure 8.3\\nNow that you’ve pushed the image to a registry, you can access it from anywhere with\\nan internet connection. You can also grant other people access to pull it and push\\nchanges.\\nRun the app\\nAs previously mentioned, the application is a web server listening on port 8080.\\nRun the following command to start it as a container. You’ll have to delete the\\nnigelpoulton image prefix or replace it with your ID.\\n$ docker run -d --name c1 \\\\\\n-p 5005:8080 \\\\\\nnigelpoulton/ddd-book:ch8.node\\nThe -d flag runs the container in the background, and the --name flag calls it c1. The\\n-p 5005:8080 maps port 5005 on your Docker host to port 8080 inside the container,\\nwhich means you’ll be able to point a browser to port 5005 and reach the app. The last\\nline tells Docker to base the container on the nigelpoulton/ddd-book:ch8.node image\\nyou just built.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 113}, page_content='which means you’ll be able to point a browser to port 5005 and reach the app. The last\\nline tells Docker to base the container on the nigelpoulton/ddd-book:ch8.node image\\nyou just built.\\nDocker will use the local copy of the image from the previous steps. It only pulls a copy\\nfrom Docker Hub if it doesn’t have a local copy.\\nCheck the container is running and verify the port mapping.\\n$ docker ps\\nID\\nIMAGE\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\n49..\\nddd-book:ch8.node\\n\"node ./app.js\"\\nUP 6 secs\\n0.0.0.0:5005->8080/tcp\\nc1\\nI’ve snipped the output for readability, but the container is running, and port 5005 on\\nthe Docker host maps to port 8080 in the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 114}, page_content='8: Containerizing an app\\n108\\nTest the app\\nOpen a web browser and point it to the DNS name or IP address of your Docker host\\non port 5005. If you’re using Docker Desktop or a similar local environment, you can\\nconnect to localhost:5005. Otherwise, use the IP or DNS of the Docker host on port\\n5005.\\nYou should see the app as shown in Figure 8.4.\\nFigure 8.4\\nYou can try the following if it doesn’t work:\\n1. Run a docker ps command to ensure the c1 container is running\\n2. Check port mapping is correct — 0.0.0.0:5005->8080/tcp\\n3. Check that firewall and other network security settings aren’t blocking traffic to\\nyour Docker host on port 5005\\nCongratulations, the application is containerized and running as a container!\\nLooking a bit closer\\nNow that you’ve containerized the application let’s take a closer look at how some of the\\nmachinery works.\\nThe docker build command parses the Dockerfile one line at a time, starting from the\\ntop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 114}, page_content='Now that you’ve containerized the application let’s take a closer look at how some of the\\nmachinery works.\\nThe docker build command parses the Dockerfile one line at a time, starting from the\\ntop.\\nYou can insert comments by starting a line with the # character, and the builder will\\nignore them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 115}, page_content='8: Containerizing an app\\n109\\nAll non-comment lines are called instructions or steps and take the format <INSTRUCTION>\\n<arguments>. Instruction names are not case-sensitive, but it’s common to write them in\\nUPPERCASE to make the file easier to read.\\nSome instructions create new layers, whereas others add metadata.\\nExamples of instructions that create new layers are FROM, RUN, COPY and WORKDIR.\\nExamples that create metadata include EXPOSE, ENV, CMD, and ENTRYPOINT. The premise\\nis this:\\n• Instructions that add content, such as files and programs, create new layers\\n• Instructions that don’t add content don’t add layers and only create metadata\\nYou can run a docker history command against any image to see the instructions that\\ncreated it.\\n$ docker history ddd-book:ch8.node\\nIMAGE\\nCREATED BY\\nSIZE\\nCOMMENT\\n24dd...a06b\\nCMD [\"/bin/sh\" \"-c\" \"node app.js\"]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nEXPOSE map[8080/tcp:{}]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nCOPY . . # buildkit\\n98kB\\nbuildkit.dockerfile.v0'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 115}, page_content='COMMENT\\n24dd...a06b\\nCMD [\"/bin/sh\" \"-c\" \"node app.js\"]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nEXPOSE map[8080/tcp:{}]\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nCOPY . . # buildkit\\n98kB\\nbuildkit.dockerfile.v0\\n<missing>\\nUSER node\\n0B\\nbuildkit.dockerfile.v0\\n<missing>\\nRUN /bin/sh -c npm ci --omit=dev # buildkit\\n13.6MB\\nbuildkit.dockerfile.v0\\n<missing>\\nWORKDIR /usr/src/app\\n16.4kB\\nbuildkit.dockerfile.v0\\n<missing>\\nENV NODE_ENV=production\\n0B\\nbuildkit.dockerfile.v0\\n<Snip>\\n<missing>\\nADD alpine-minirootfs-3.21.0-aarch64.tar.gz\\n8.84MB\\n8.35MB\\nA few things are worth noting from the output.\\nThe bottom few lines that I’ve snipped from the book related to the history of the\\nnode:23.3.0-alpine base image that was pulled by the FROM instruction.\\nAll lines ending with buildkit.dockerfile.v0 relate to instructions from the Docker-\\nfile used to build the image.\\nThe CREATED BY column lists the exact Dockerfile instruction that created the layer or\\nmetadata.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 115}, page_content='file used to build the image.\\nThe CREATED BY column lists the exact Dockerfile instruction that created the layer or\\nmetadata.\\nLines with a non-zero value in the SIZE column created new layers, whereas the lines\\nwith 0B only added metadata. In this example, three lines/instructions created layers.\\nRun a docker inspect to see the list of image layers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 116}, page_content='8: Containerizing an app\\n110\\n$ docker inspect ddd-book:ch8.node\\n<Snip>\\n},\\n\"RootFS\": {\\n\"Type\": \"layers\",\\n\"Layers\": [\\n\"sha256:5f4d9fc4d98de91820d2a9c81e501c8cc6429bc8758b43fcb2cd50f4cab9a324\",\\n\"sha256:6b20c4e93dbab9786f96268bbe32c208d385f2c4490a278ad3b1e55cc79480e4\",\\n\"sha256:012c308a78ec993a47fdb7c4c6d17b53d8ce2649a463be28ae5c48ab1af2e039\",\\n\"sha256:35a839ac7cc922afd896a0297e692141c77ed6e03eff6a70db13bb23f6cd4f8f\",\\n\"sha256:918caa8070410ccfb2c5b3b4d62ca66742c46bf21fe0bd433738b7796c530e68\",\\n\"sha256:a48b3b3d0c5a693840e7e4abd7971f130b4447573483628bcb996091e1e8e8b8\",\\n\"sha256:ea2d4594dbbef4009441a33dd1dd4c5076d7fe09a171381a6b7583605569dd11\"\\n]\\n},\\nAs previously mentioned, the output shows seven layers because the base image had four\\nlayers, and the Dockerfile added three more.\\nFigure 8.5 maps the Dockerfile instructions to image layers. The bold instructions with\\narrows create layers; the others create metadata. The layer IDs will be different in your\\nenvironment.\\nFigure 8.5'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 116}, page_content='arrows create layers; the others create metadata. The layer IDs will be different in your\\nenvironment.\\nFigure 8.5\\nNote: Older builders didn’t create a layer for WORKDIR instructions. However,\\nthe instruction modifies filesystem permissions and the current builder\\ncreates a very small layer. This behavior may change in the future.\\nIt’s generally considered a good practice to use Docker Official Images and Verified Pub-\\nlisher images as the base layer for new images you create. This is because they maintain a'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 117}, page_content='8: Containerizing an app\\n111\\nhigh standard and quickly implement fixes for known vulnerabilities.\\nMoving to production with multi-stage builds\\nWhen it comes to container images… big is bad! For example:\\n• Big means slow\\n• Big means more potential vulnerabilities\\n• Big means a larger attack surface\\nFor these reasons, your container images should only contain the stuff needed to run\\nyour applications in production.\\nThis is where multi-stage builds come into play.\\nAt a high level, multi-stage builds use a single Dockerfile with multiple FROM instructions\\n— each FROM instruction represents a new build stage. This allows you to have a stage\\nwhere you do the heavy lifting of building the app inside a large image with compilers\\nand other build tools, but then you have another stage where you copy the compiled app\\ninto a slim image for production. The builder can even run different stages in parallel for\\nfaster builds.\\nNote: A slim image is a very small image intended for production use that'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 117}, page_content='into a slim image for production. The builder can even run different stages in parallel for\\nfaster builds.\\nNote: A slim image is a very small image intended for production use that\\nonly contains files and apps that are absolutely necessary to run the applica-\\ntion. They do not include shells, package managers, or troubleshooting tools.\\nFigure 8.6 shows a high-level workflow. Stage 1 builds an image with all the required\\nbuild and compilation tools. Stage 2 copies the app code into the image and builds it.\\nStage 3 creates a small production-ready image containing only the compiled app and\\nanything needed to run it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 118}, page_content='8: Containerizing an app\\n112\\nFigure 8.6\\nLet’s look at an example!\\nWe’ll work with the code in the multi-stage folder of the book’s GitHub repo. It’s a\\nsimple Go app with a client and server borrowed from the Docker samples buildme repo\\non GitHub. Don’t worry if you’re not a Go programmer; you don’t need to be. You only\\nneed to know that it compiles the client and server apps into executable files that do not\\nneed the Go language or any other tools or runtimes to execute.\\nHere’s the Dockerfile:\\nFROM golang:1.23.4-alpine AS base\\n<<---- Stage 0\\nWORKDIR /src\\nCOPY go.mod go.sum .\\nRUN go mod download\\nCOPY . .\\nFROM base AS build-client\\n<<---- Stage 1\\nRUN go build -o /bin/client ./cmd/client\\nFROM base AS build-server\\n<<---- Stage 2\\nRUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod\\n<<---- Stage 3\\nCOPY --from=build-client /bin/client /bin/\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 118}, page_content='RUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod\\n<<---- Stage 3\\nCOPY --from=build-client /bin/client /bin/\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]\\nThe first thing to note is that there are four FROM instructions. Each of these is a distinct\\nbuild stage, and Docker numbers them starting from 0. However, we’ve given each stage a\\nfriendly name:\\n• Stage 0 is called base and builds an image with compilation tools, etc'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='8: Containerizing an app\\n113\\n• Stage 1 is called build-client and compiles the client executable\\n• Stage 2 is called build-server and compiles the server executable\\n• Stage 3 is called prod and copies the client and server executables into a slim image\\nEach stage outputs an intermediate image that later stages can use. However, Docker\\ndeletes them when the final stage completes.\\nThe goal of the base stage is to create a reusable build image with all the tools stages\\n1 and 2 need to build the client and server applications. The image created by this\\nstage is only used to compile the executables and not for production. It pulls the\\ngolang:1.23.4-alpine image, which is over 350MB when uncompressed. It sets the\\nworking directory to /src and copies in the go.mod and go.sum files from your working\\ndirectory. These files list the application dependencies and hashes. After that, it uses the\\nRUN instruction to install the dependencies and then the COPY instruction to copy the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='directory. These files list the application dependencies and hashes. After that, it uses the\\nRUN instruction to install the dependencies and then the COPY instruction to copy the\\napplication source code into the image. All of this creates a large image with three layers\\ncontaining a lot of build stuff but not much app stuff. When this build stage completes, it\\noutputs a large image that later stages can use.\\nThe build-client stage doesn’t pull a new image. Instead, it uses the FROM base AS\\nbuild-client instruction to use the intermediate image created by the base stage. It\\nthen issues a RUN instruction to compile the client app into a binary executable. The goal\\nof this stage is to create an image with the compiled client binary that later stages can\\nreference.\\nThe build-server stage does the same for the server component and outputs a similar\\nimage for use by later stages.\\nThe prod stage pulls the minimal scratch image. It then runs two COPY --from instruc-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='image for use by later stages.\\nThe prod stage pulls the minimal scratch image. It then runs two COPY --from instruc-\\ntions to copy the compiled client app from the build-client stage and the compiled\\nserver app from the build-server stage. It then tells Docker to run the server app when\\nit’s started as a container. This stage outputs the final production image containing just\\nthe client and server binaries inside a tiny scratch image and the metadata telling Docker\\nhow to start the app.\\nThe builder will run the base stage first, then run the build-client and build-server\\nstages in parallel, and finally run the prod stage.\\nIt will always attempt to run stages in parallel, but it can only do this when no depen-\\ndencies exist. For example, the build-client and build-server stages both start with\\nFROM base..., meaning they depend on the base stage and cannot run until that stage\\nis built. However, the build-client and build-server can run in parallel because they'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 119}, page_content='FROM base..., meaning they depend on the base stage and cannot run until that stage\\nis built. However, the build-client and build-server can run in parallel because they\\ndon’t depend on each other. To work out if build stages can run in parallel, start reading\\nthe Dockerfile from the top and check if the FROM instructions reference other FROM\\ninstructions immediately before or after — if they do, they can’t run in parallel.\\nLet’s see it in action.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 120}, page_content='8: Containerizing an app\\n114\\nChange into the multi-stage directory and verify the Dockerfile and associated app\\nfiles exist.\\n$ ls -l\\ntotal 28\\n-rw-rw-r-- 1 ubuntu ubuntu\\n368 Mar 25 10:09 Dockerfile\\n-rw-rw-r-- 1 ubuntu ubuntu\\n433 Mar 25 10:09 Dockerfile-final\\n-rw-rw-r-- 1 ubuntu ubuntu\\n305 Mar 25 10:09 README.md\\ndrwxrwxr-x 4 ubuntu ubuntu 4096 Mar 25 10:09 cmd\\n-rw-rw-r-- 1 ubuntu ubuntu 1013 Mar 25 10:09 go.mod\\n-rw-rw-r-- 1 ubuntu ubuntu 5631 Mar 25 10:09 go.sum\\nBuild the image and watch the build-client and build-server stages execute in\\nparallel. This can significantly improve the performance of large builds.\\n$ docker build -t multi:full .\\n[+] Building 14.6s (15/15) FINISHED\\n=> [internal] load build definition from Dockerfile\\n0.0s\\n=> => transferring dockerfile: 736B\\n0.0s\\n<Snip>\\n=> [build-client 1/1] RUN go build -o /bin/client ./cmd/client\\n5.1s\\n<<---- parallel\\n=> [build-server 1/1] RUN go build -o /bin/server ./cmd/server\\n5.1s\\n<<---- parallel\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 120}, page_content='0.0s\\n<Snip>\\n=> [build-client 1/1] RUN go build -o /bin/client ./cmd/client\\n5.1s\\n<<---- parallel\\n=> [build-server 1/1] RUN go build -o /bin/server ./cmd/server\\n5.1s\\n<<---- parallel\\n<Snip>\\nRun a docker images to see the new image.\\n$ docker images\\nREPO\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nmulti\\nfull\\na7a01440f2b5\\n5 seconds ago\\n26.7MB\\nThe final production image is only 26MB, much smaller than the 350MB+ base image\\npulled by the base stage to build and compile the app. This is because the final prod\\nstage extracted the compiled client and server binaries and placed them in a tiny new\\nscratch image.\\nRun a docker history to see the final production image. It only has two layers — one\\ncreated by copying in the client binary and the other by copying in the server binary.\\nNone of the previous build stages are included in the final production image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 121}, page_content='8: Containerizing an app\\n115\\n$ docker history multi:full\\nIMAGE\\nCREATED\\nCREATED BY\\nSIZE\\na7a01440f2b5\\n2 minutes ago\\nENTRYPOINT [\"/bin/server\"]\\n0B\\n<missing>\\n2 minutes ago\\nCOPY /bin/server /bin/ # buildkit\\n8.64MB\\n<missing>\\n2 minutes ago\\nCOPY /bin/client /bin/ # buildkit\\n8.53MB\\nMulti-stage builds and build targets\\nYou can also build multiple images from a single Dockerfile.\\nThe previous example compiled client and server apps and copied both into the same\\nimage. However, Docker makes it easy to create a separate image for each by splitting\\nthe final prod stage into two stages as follows:\\nFROM golang:1.20-alpine AS base\\nWORKDIR /src\\nCOPY go.mod go.sum .\\nRUN go mod download\\nCOPY . .\\nFROM base AS build-client\\nRUN go build -o /bin/client ./cmd/client\\nFROM base AS build-server\\nRUN go build -o /bin/server ./cmd/server\\nFROM scratch AS prod-client\\n<<---- New stage\\nCOPY --from=build-client /bin/client /bin/\\nENTRYPOINT [ \"/bin/client\" ]\\nFROM scratch AS prod-server\\n<<---- New stage'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 121}, page_content='FROM scratch AS prod-client\\n<<---- New stage\\nCOPY --from=build-client /bin/client /bin/\\nENTRYPOINT [ \"/bin/client\" ]\\nFROM scratch AS prod-server\\n<<---- New stage\\nCOPY --from=build-server /bin/server /bin/\\nENTRYPOINT [ \"/bin/server\" ]\\nI’ve pre-created the Dockerfile and called it Dockerfile-final in the multi-stage\\nfolder, but you can see the only change is splitting the final prod stage into two stages\\n— one for the client build and the other for the server build. With a Dockerfile like this,\\nyou tell a docker build command which of the two final stages to target for the build.\\nLet’s do it.\\nRun the following two commands to create two different images from the same\\nDockerfile-final file. Both commands use the -f flag to tell Docker to use the\\nDockerfile-final file. They also use the --target flag to tell the builder which stage\\nto build from.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 122}, page_content='8: Containerizing an app\\n116\\n$ docker build -t multi:client --target prod-client -f Dockerfile-final .\\n<Snip>\\n$ docker build -t multi:server --target prod-server -f Dockerfile-final .\\n<Snip>\\nCheck the builds and image sizes.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nmulti\\nfull\\na7a01440f2b5\\n4 minutes ago\\n26.7MB\\nmulti\\nserver\\na75778df1b9c\\n4 seconds ago\\n11.7MB\\nmulti\\nclient\\n02b621e9415f\\n12 seconds ago\\n11.9MB\\nYou now have three images, and the client and server images are each about half the\\nsize of the full image. This makes sense because the full image contains the client and\\nserver binaries, whereas the others only include one.\\nBuildx, BuildKit, drivers, and Build Cloud\\nThis section takes a quick look at the major build components.\\nBehind the scenes, Docker’s build system has a client and server:\\n• Client: Buildx\\n• Server: BuildKit\\nBuildx is Docker’s latest and greatest build client. It’s implemented as a CLI plugin and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 122}, page_content='Behind the scenes, Docker’s build system has a client and server:\\n• Client: Buildx\\n• Server: BuildKit\\nBuildx is Docker’s latest and greatest build client. It’s implemented as a CLI plugin and\\nsupports all the latest features of BuildKit, such as multi-stage builds, multi-architecture\\nimages, advanced caching, and more. It’s been the default build client since Docker v23.0\\nand Docker Desktop v4.19. This means every time you run a docker build command,\\nyou’re automatically using the Buildx builder.\\nYou can configure Buildx to talk to multiple BuildKit instances, and we call each\\ninstance of BuildKit a builder. Builders can run on your local machine, in your cloud or\\ndatacenter, or Docker’s Build Cloud.\\nIf you point buildx at a local builder, image builds will be done on your local machine.\\nIf you point it at a remote builder, such as Docker Build Cloud, builds will be done on\\nremote infrastructure.\\nFigure 8.7 shows a Docker environment configured to talk to a local and a remote\\nbuilder.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 123}, page_content='8: Containerizing an app\\n117\\nFigure 8.7 - Docker build architecture\\nIn the diagram, the local builder uses the docker-container driver to create a local\\nBuildKit instance inside a dedicated container. All builds using this driver will run in the\\ndedicated container. The other option uses the cloud driver to send builds to Docker’s\\nBuild Cloud service. Build Cloud offers fast builds and a shared cache but requires a\\npaid subscription.\\nWhen you run a docker build command, buildx interprets the command and sends\\nthe build request to the selected builder. This includes the Dockerfile, command line\\narguments, caching options, export options, and the build context (app and dependency\\nlist). The builder performs the build and exports the image. The Buildx client monitors\\nthe build and reports on progress.\\nRun the following command to see the builders you have configured on your system.\\nI’ve trimmed the output in the book, but you can see a local and a remote builder.\\n$ docker buildx ls'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 123}, page_content='Run the following command to see the builders you have configured on your system.\\nI’ve trimmed the output in the book, but you can see a local and a remote builder.\\n$ docker buildx ls\\nNAME/NODE\\nDRIVER/ENDPOINT\\nPLATFORMS\\nbuilder *\\ndocker-container\\nbuilder0\\ndesktop-linux\\nlinux/arm64, linux/amd64, linux/amd64/v2,\\nlinux/riscv64, linux/ppc64le, linux/s390x,\\nlinux/386, linux/mips64le, linux/mips64,\\nlinux/arm/v7, linux/arm/v6\\ncloud-nigelpoulton-ddd\\ncloud\\nlinux-arm64\\ncloud://nigel...arm64\\nlinux/arm64*\\nlinux-amd64\\ncloud://nigel...amd64\\nlinux/amd64*, linux/amd64/v2,\\nlinux/amd64/v3,linux/amd64/v4\\n<Snip>\\nNotice how the first builder supports more platforms than the cloud builder. This is\\nbecause the docker-container driver utilizes QEMU to emulate target hardware. It\\nusually works but can be slow.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 124}, page_content='8: Containerizing an app\\n118\\nThe second builder is Docker’s Build Cloud, which only supports AMD and ARM builds.\\nBuilds running in Build Cloud run on native hardware and offer a shared cache so that\\nteammates can share a common cache for even faster builds. Complex builds can be\\nmuch quicker when executed on native hardware such as Build Cloud.\\nRun a docker buildx inspect command against one of your builders.\\n$ docker buildx inspect cloud-nigelpoulton-ddd\\nName:\\ncloud-nigelpoulton-ddd\\nDriver:\\ncloud\\nNodes:\\nName:\\nlinux-arm64\\nEndpoint:\\ncloud://nigelpoulton/ddd_linux-arm64\\nStatus:\\nrunning\\nBuildkit:\\nv0.16.0\\nPlatforms: linux/arm64*, linux/arm/v6, linux/arm/v7\\nLabels:\\norg.mobyproject.buildkit.worker.executor:\\noci\\norg.mobyproject.buildkit.worker.hostname:\\nnigelpoulton_ddd-cloud_linux-arm64\\norg.mobyproject.buildkit.worker.network:\\nhost\\norg.mobyproject.buildkit.worker.oci.process-mode: sandbox\\norg.mobyproject.buildkit.worker.selinux.enabled:\\nfalse\\norg.mobyproject.buildkit.worker.snapshotter:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 124}, page_content='host\\norg.mobyproject.buildkit.worker.oci.process-mode: sandbox\\norg.mobyproject.buildkit.worker.selinux.enabled:\\nfalse\\norg.mobyproject.buildkit.worker.snapshotter:\\noverlayfs\\nGC Policy rule#0:\\nAll:\\ntrue\\nKeep Bytes: 25GiB\\n<Snip>\\nLet’s see how to perform multi-architecture builds.\\nMulti-architecture builds\\nYou can use the docker build command to build images for multiple platforms and\\nCPU architectures, including ones different from your local machine. For example:\\n• Docker on an AMD machine can build ARM images\\n• Docker on an ARM machine can build AMD images\\nYou also have the option to perform builds locally or in the cloud. Both work with the\\nstandard docker build command and only require minimal backend configuration.\\nRun the following command to list your current builders. Remember, a builder is an\\ninstance of BuildKit that will perform builds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 125}, page_content='8: Containerizing an app\\n119\\n$ docker buildx ls\\nNAME/NODE\\nDRIVER/ENDPOINT\\nPLATFORMS\\nbuilder *\\ndocker-container\\nbuilder0\\ndesktop-linux\\nlinux/arm64, linux/amd64, linux/amd64/v2,\\nlinux/riscv64, linux/ppc64le, linux/s390x,\\nlinux/386, linux/mips64le, linux/mips64,\\nlinux/arm/v7, linux/arm/v6\\ncloud-nigelpoulton-ddd\\ncloud\\nlinux-arm64\\ncloud://nigel...arm64\\nlinux/arm64*\\nlinux-amd64\\ncloud://nigel...amd64\\nlinux/amd64*, linux/amd64/v2, linux/amd64/v3,\\nlinux/amd64/v4\\n<Snip>\\nThe book’s output shows two builders; the one with the asterisk (*) is the default builder.\\nIn this example, the default builder is called builder and uses the docker-container\\ndriver to perform builds inside a local build container. Unless you specify a different\\nbuilder, all builds will run inside this build container. It supports multiple architectures,\\nincluding AMD, ARM, RISC-V, s390x, and more.\\nIf you don’t already have one, create a new builder called container that uses the docker-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 125}, page_content='including AMD, ARM, RISC-V, s390x, and more.\\nIf you don’t already have one, create a new builder called container that uses the docker-\\ncontainer driver with the following command.\\n$ docker buildx create --driver=docker-container --name=container\\nRun another docker buildx ls to show the new builder. Don’t worry if it shows as\\npresent but inactive.\\nMake it the default builder.\\n$ docker buildx use container\\nChange into the web-app directory and run the following command to build the app\\ninto AMD and ARM images and export them directly to Docker Hub.\\nBe sure to substitute your Docker ID as the command pushes directly to Docker Hub\\nand will fail if you try to push it to my repositories. If you don’t have a Docker Hub\\naccount or don’t want to push the images, you can replace the --push with --load.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 126}, page_content='8: Containerizing an app\\n120\\n$ docker buildx build --builder=container \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n[+] Building 79.3s (26/26) FINISHED\\n<Snip>\\n=> [linux/arm64 2/5] RUN apk add --update nodejs npm curl\\n19.0s\\n=> [linux/amd64 2/5] RUN apk add --update nodejs npm curl\\n17.4s\\n=> [linux/amd64 3/5] COPY . /src\\n0.0s\\n=> [linux/amd64 4/5] WORKDIR /src\\n0.0s\\n=> [linux/amd64 5/5] RUN\\nnpm install\\n7.3s\\n=> [linux/arm64 3/5] COPY . /src\\n0.0s\\n=> [linux/arm64 4/5] WORKDIR /src\\n0.0s\\n=> [linux/arm64 5/5] RUN\\nnpm install\\n5.6s\\n=> exporting to image\\n<Snip>\\n=> => pushing layers\\n31.5s\\n=> => pushing manifest for docker.io/nigelpoulton/ddd-book:web0.2@sha256:8fc61...\\n3.6s\\n=> [auth] nigelpoulton/ddd-book:pull,push token for registry-1.docker.io\\n0.0s\\nI’ve snipped the output, but you can still see two important things:\\n• Each Dockerfile instruction executed twice — once for AMD and once for ARM'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 126}, page_content='0.0s\\nI’ve snipped the output, but you can still see two important things:\\n• Each Dockerfile instruction executed twice — once for AMD and once for ARM\\n• The last few lines show the image layers being pushed directly to Docker Hub\\nNow that you’ve performed a build, the builder will show as active and list the architec-\\ntures it supports.\\nFigure 8.8 shows how the images for both architectures appear on Docker Hub under\\nthe same repository and tag.\\nFigure 8.8 - Multi-platform image\\nYou can also perform the builds using Docker Build Cloud. This is a cloud-based service\\nthat offers fast builds and lets you share your build cache with teammates. It requires a\\npaid subscription.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 127}, page_content='8: Containerizing an app\\n121\\nIf you have a Docker subscription that grants you access to Build Cloud, you can go to\\nbuild.docker.com and configure your first cloud builder. You can also create cloud\\nbuilders from the CLI as follows. If you’re following along, you’ll need to give yours a\\ndifferent name.\\n$ docker buildx create --driver cloud nigelpoulton/ddd\\nOnce you have a cloud builder, you can either make it your default builder with a\\ndocker buildx use <builder> command, or you can specify it when performing\\nindividual builds.\\nThe following command uses the --builder flag to use the cloud-nigelpoulton-ddd\\ncloud builder to build the same images as in the previous steps. Remember to use your\\nown cloud builder if you’re following along.\\n$ docker buildx build \\\\\\n--builder=cloud-nigelpoulton-ddd \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n=> [internal] connected to docker build cloud service\\n0.0s\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 127}, page_content='--builder=cloud-nigelpoulton-ddd \\\\\\n--platform=linux/amd64,linux/arm64 \\\\\\n-t nigelpoulton/ddd-book:ch8.1 --push .\\n=> [internal] connected to docker build cloud service\\n0.0s\\n<Snip>\\nAt the time of writing, Build Cloud supports various AMD and ARM architectures,\\nwhereas the docker-container driver supports more but is slower and less reliable.\\nA few good practices\\nLet’s finish the chapter with a few best practices. This isn’t a full list, and the advice\\napplies to local builds and cloud builds.\\nLeverage the build cache\\nBuildKit uses a cache to speed up builds. The best way to see the impact is to build a\\nnew image on a clean Docker host and then repeat the same build immediately after.\\nThe first build will pull images and take time to build layers. The second build will\\ninstantly complete because the layers and other artifacts from the first build are cached\\nand leveraged by later builds.\\nIf you use a local builder, the cache is only available to other builds you execute on the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 127}, page_content='and leveraged by later builds.\\nIf you use a local builder, the cache is only available to other builds you execute on the\\nsame system. However, your entire team can share the cache on Docker Build Cloud.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 128}, page_content='8: Containerizing an app\\n122\\nFor each build, the builder iterates through the Dockerfile one line at a time, starting\\nfrom the top. For each line, it checks if it already has the layer in its cache. If it does,\\na cache hit occurs, and it uses the cached layer. If it doesn’t, a cache miss occurs, and it\\nbuilds a new layer from the instruction. Cache hits are one of the best ways to make\\nbuilds faster.\\nLet’s take a closer look.\\nAssume the following Dockerfile:\\nFROM alpine\\nRUN apk add --update nodejs npm\\nCOPY . /src\\nWORKDIR /src\\nRUN npm install\\nEXPOSE 8080\\nENTRYPOINT [\"node\", \"./app.js\"]\\nThe first instruction tells Docker to use the alpine:latest image as its base image. If\\nyou already have a copy of this image, the builder moves on to the next instruction. If\\nyou don’t have a copy, it pulls it from Docker Hub.\\nThe next instruction (RUN apk...) runs a command to update package lists and install\\nnodejs and npm. Before executing the instruction, Docker checks the build cache for a'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 128}, page_content='The next instruction (RUN apk...) runs a command to update package lists and install\\nnodejs and npm. Before executing the instruction, Docker checks the build cache for a\\nlayer built from the same base image using the same instruction. In this case, it’s looking\\nfor a layer built by executing the RUN apk add --update nodejs npm instruction\\ndirectly on top of the alpine:latest image.\\nIf it finds a matching layer, it links to that layer and continues the build with the cache\\nintact. If it does not find a matching layer, it invalidates the cache and builds the\\nlayer. Invalidating the cache means the builder must execute all remaining Dockerfile\\ninstructions in full and cannot use the cache.\\nLet’s assume Docker had a cached layer for the RUN instruction and that the layer’s ID is\\nAAA.\\nThe next instruction runs a COPY . /src command to copy the app code into the image.\\nThe previous instruction scored a cache hit, meaning Docker can check if it has a cached'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 128}, page_content='AAA.\\nThe next instruction runs a COPY . /src command to copy the app code into the image.\\nThe previous instruction scored a cache hit, meaning Docker can check if it has a cached\\nlayer built by running a COPY . /src against the AAA layer. If it has a cached layer for\\nthis, it links to the layer and proceeds to the next instruction. If it doesn’t have a cached\\nlayer, it builds it and invalidates the cache for the rest of the build.\\nThis process continues for the rest of the Dockerfile.\\nIt’s important to understand a few things.\\nAny time an instruction results in a cache miss, the cache is invalidated and no longer\\nchecked for the rest of the build. This means you should write your Dockerfiles so that'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 129}, page_content='8: Containerizing an app\\n123\\ninstructions most likely to invalidate the cache go near the end of the Dockerfile. This\\nallows builds to benefit from the cache for as long as possible.\\nYou can force a build to ignore the cache by running docker build with the --no-cache\\noption.\\nIt’s also important to understand that COPY and ADD instructions include logic to ensure\\nthe content you’re copying into the image hasn’t changed since the last build. For exam-\\nple, you might have a cached layer that Docker built by running a COPY . /src against\\nthe AAA image. However, if the files that the COPY . /src instruction copies into the\\nlayer have changed since the cached layer was built, you cannot use the cached layer as\\nyou’d get old versions of the files. To protect against this, Docker performs checksums\\nagainst each file it copies. If the checksums don’t match, the cache is invalidated, and\\nDocker builds a new layer.\\nOnly install essential packages'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 129}, page_content='against each file it copies. If the checksums don’t match, the cache is invalidated, and\\nDocker builds a new layer.\\nOnly install essential packages\\nWe often joke that we install the entire internet when we build apps. As a quick example,\\nthe simple Node.js app used earlier in the chapter depends on two packages:\\n• Express\\n• Pug\\nHowever, these packages depend on other packages, which in turn depend on others.\\nAt the time of writing, building this simple application with two dependencies actually\\ndownloads over 110 packages!\\nFortunately, some package managers provide a way for you to only download and install\\nessential packages instead of the entire internet. One example is the apt package manager\\nthat lets you specify the no-install-recommends flag so that it only installs packages\\nin the depends field and not every recommended and suggested package. Each package\\nmanager does this differently, but it’s worth investigating as it can massively impact the\\nsize of your images.\\nClean up'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 129}, page_content='manager does this differently, but it’s worth investigating as it can massively impact the\\nsize of your images.\\nClean up\\nIf you’ve followed along, you’ll have one running container and several images in your\\nlocal image repository. You should delete the running container and, optionally, the\\nlocal images.\\nRun the following command to delete the container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 130}, page_content='8: Containerizing an app\\n124\\n$ docker rm c1 -f\\nOptionally delete the local images with the following command. Be sure to use the\\nnames of the images in your environment.\\n$ docker rmi \\\\\\nmulti:full multi:client multi:server ddd-book:ch8.node nigelpoulton/ddd-book:ch8.node\\nContainerizing an app – The commands\\n• docker build containerizes applications. It reads a Dockerfile and follows the\\ninstructions to create an OCI image. The -t flag tags the image, and the -f flag\\nlets you specify the name and location of the Dockerfile. The build context is where\\nyour application files exist and can be a directory on your local Docker host or a\\nremote Git repo.\\n• The Dockerfile FROM instruction specifies the base image. It’s usually the first\\ninstruction in a Dockerfile, and it’s considered a good practice to build from\\nDocker Official Images or images from Verified Publishers. FROM is also used to\\nidentify new build stages in multi-stage builds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 130}, page_content='Docker Official Images or images from Verified Publishers. FROM is also used to\\nidentify new build stages in multi-stage builds.\\n• The Dockerfile RUN instruction lets you run commands during a build. It’s com-\\nmonly used to update packages and install dependencies. Every RUN instruction\\ncreates a new image layer.\\n• The Dockerfile COPY instruction adds files to images, and you’ll regularly use it to\\ncopy your application code into a new image. Every COPY instruction creates an\\nimage layer.\\n• The Dockerfile EXPOSE instruction documents an application’s network port.\\n• The Dockerfile ENTRYPOINT and CMD instructions tell Docker how to run the app\\nwhen starting a new container.\\n• Some other Dockerfile instructions include LABEL, ENV, ONBUILD, HEALTHCHECK and\\nmore.\\nChapter summary\\nThis chapter taught you how to containerize an application. This is the process of\\nbuilding an app into a container image and running it as a container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 130}, page_content='more.\\nChapter summary\\nThis chapter taught you how to containerize an application. This is the process of\\nbuilding an app into a container image and running it as a container.\\nYou pulled some application source code from GitHub and used the docker init\\ncommand to auto-generate a Dockerfile with instructions telling Docker how to build'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 131}, page_content='8: Containerizing an app\\n125\\nthe app into a container image. You then used docker build to create the image, docker\\npush to push it to Docker Hub, and docker run to run it as a container.\\nAlong the way, you learned that some Dockerfile instructions add content to an\\nimage and therefore create new layers. Instructions that don’t add content only create\\nmetadata.\\nAfter that, you learned how multi-stage builds allow you to create small and efficient\\nproduction images without the bloat carried over from compiling the app.\\nAfter that, you learned that buildx is the default build client that integrates with the\\nlatest features of the BuildKit build engine. You learned how to create local and remote\\nbuilders (BuildKit instances) and how to use them to perform multi-architecture builds.\\nYou also learned the importance of the build cache for speeding up builds and how to\\noptimize Dockerfiles to leverage the build cache.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 132}, page_content='9: Multi-container apps with Compose\\nIn this chapter, you’ll deploy and manage a multi-container application using Docker\\nCompose. When talking about Docker Compose, we usually shorten it to Compose and\\nalways write it with a capital “C”.\\nI’ve organized the chapter as follows:\\n• Docker Compose – The TLDR\\n• Compose background\\n• Installing Compose\\n• The sample app\\n• Compose files\\n• Deploying apps with Compose\\n• Managing apps with Compose\\nDocker Compose – The TLDR\\nWe create modern cloud-native applications by combining lots of small services that\\nwork together to form a useful app. We call them microservices applications, and they\\nbring a lot of benefits, such as self-healing, autoscaling, and rolling updates. However,\\nthey can be complex.\\nFor example, you might have a microservices app with the following services:\\n• Web front-end\\n• Ordering\\n• Catalog\\n• Back-end datastore\\n• Logging\\n• Authentication\\n• Authorization'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 133}, page_content='9: Multi-container apps with Compose\\n127\\nInstead of hacking together complex scripts and long docker commands, Compose lets\\nyou describe the application in a simple YAML file called a Compose file. You then use the\\nCompose file with the docker compose command to deploy and manage the entire app.\\nThis makes Compose files important parts of your applications that you should host in a\\nversion control system such as Git.\\nThat’s the basics. Let’s dig deeper.\\nCompose background\\nWhen Docker was new, a company called Orchard Labs built a tool called Fig that made\\ndeploying and managing multi-container apps easy. It was a Python tool that ran on\\ntop of Docker and let you define complex multi-container microservices apps in a\\nsimple YAML file. You could even use the fig command-line tool to manage the entire\\napplication lifecycle.\\nBehind the scenes, Fig would read the YAML file and call the appropriate Docker\\ncommands to deploy and manage the app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 133}, page_content='application lifecycle.\\nBehind the scenes, Fig would read the YAML file and call the appropriate Docker\\ncommands to deploy and manage the app.\\nFig was so good that Docker, Inc. acquired Orchard Labs and rebranded Fig as Docker\\nCompose. They renamed the command-line tool from fig to docker-compose, and\\nthen, more recently, they folded it into the main docker CLI with its own compose sub-\\ncommand. You can now run simple docker compose commands to easily manage multi-\\ncontainer microservices apps.\\nThere is also a Compose Specification15 driving Compose as an open standard for multi-\\ncontainer microservices apps. The specification is community-led and kept separate\\nfrom the Docker implementation to maintain better governance and demarcation.\\nHowever, Docker Compose is the reference implementation, and you should expect Docker\\nto implement the full spec.\\nReading the spec is a great way to learn the details.\\nInstalling Compose'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 133}, page_content='However, Docker Compose is the reference implementation, and you should expect Docker\\nto implement the full spec.\\nReading the spec is a great way to learn the details.\\nInstalling Compose\\nAll modern versions of Docker come with Docker Compose pre-installed, and you no\\nlonger need to install it as a separate application.\\nTest it with the following command.\\n15https://www.compose-spec.io/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 134}, page_content=\"9: Multi-container apps with Compose\\n128\\n$ docker compose version\\nDocker Compose version v2.35.1\\nThe sample app\\nWe’ll use the sample app shown in Figure 9.1 with two services, a network, and a\\nvolume.\\nFigure9.1 - Sample app\\nThe web-fe service runs a web server that increments a counter in the redis service\\nevery time it receives a request for the web page. Both services are connected to the\\ncounter-net network and use it to communicate. The redis service mounts the\\ncounter-vol volume.\\nThis is all defined in the compose.yaml file in the multi-container folder of the book’s\\nGitHub repo.\\nIf you haven’t already done so, clone the repo so you have a local copy of everything\\nyou’ll need. You’ll need git installed, and the command will create a new directory\\ncalled ddd-book.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nCloning into 'ddd-book'...\\nremote: Enumerating objects: 67, done.\\nremote: Counting objects: 100% (67/67), done.\\nremote: Compressing objects: 100% (47/47), done.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 134}, page_content=\"Cloning into 'ddd-book'...\\nremote: Enumerating objects: 67, done.\\nremote: Counting objects: 100% (67/67), done.\\nremote: Compressing objects: 100% (47/47), done.\\nremote: Total 67 (delta 17), reused 63 (delta 16), pack-reused 0\\nReceiving objects: 100% (67/67), 173.61 KiB | 1.83 MiB/s, done.\\nResolving deltas: 100% (17/17), done.\\nChange into the ddd-book/multi-container directory and list its contents.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 135}, page_content='9: Multi-container apps with Compose\\n129\\n$ cd ddd-book/multi-container/\\n$ ls -l\\ntotal 20\\ndrwxrwxr-x 4 ubuntu ubuntu 4096 May 21 15:53 app\\n-rw-rw-r-- 1 ubuntu ubuntu\\n288 May 21 15:53 Dockerfile\\n-rw-rw-r-- 1 ubuntu ubuntu\\n18 May 21 15:53 requirements.txt\\n-rw-rw-r-- 1 ubuntu ubuntu\\n355 May 21 15:53 compose.yaml\\n-rw-rw-r-- 1 ubuntu ubuntu\\n332 May 21 15:53 README.md\\nThis directory is your build context and contains all the app code and configuration files\\nDocker needs to deploy and manage the app.\\n• The app folder contains the application code, views, and templates\\n• The Dockerfile describes how to build the image for the web-fe service\\n• The requirements.txt file lists the application dependencies for the web-fe\\nservice\\n• The compose.yaml file tells Docker how to deploy the app\\nFigure 9.2 shows the app in more detail.\\nFigure 9.2 - Detailed view of sample app\\nWhen you deploy the app, you’ll use the docker compose command to send the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 135}, page_content='Figure 9.2 shows the app in more detail.\\nFigure 9.2 - Detailed view of sample app\\nWhen you deploy the app, you’ll use the docker compose command to send the\\ncompose.yaml file to Docker, where Docker parses the file and completes the necessary\\nsteps to deploy the app. These steps include creating the network, volume, image, and\\nservices, and connecting the services to the appropriate network and volume.\\nAs you’ll see later, Docker assigns the app a project name based on the name of your build\\ncontext’s directory. In our example, the build context is the multi-container directory,\\nso Docker will use “multi-container” as the project name. You’ll see why this matters later.\\nNow that you know what the app looks like, let’s take a closer look at the Compose file.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 136}, page_content='9: Multi-container apps with Compose\\n130\\nCompose files\\nCompose uses YAML files to define microservices applications. We call them Compose\\nfiles, and Compose expects you to name them compose.yaml or compose.yml. However,\\nyou can specify a different filename with the -f flag.\\nHere is the Compose file we’ll be using. It’s called compose.yaml from the multi-\\ncontainer folder.\\nservices:\\n<<--- Microservices are defined in the \"services\" block\\nweb-fe:\\n----┐\\ndeploy:\\n|\\nreplicas: 1\\n|\\nbuild: .\\n| This block\\ncommand: python app.py\\n| defines the\\nports:\\n| *web-fe*\\n- target: 8080\\n| microservice\\npublished: 5001\\n|\\nnetworks:\\n|\\n- counter-net\\n----┘\\nredis:\\n----┐\\ndeploy:\\n|\\nreplicas: 1\\n|\\nimage: \"redis:alpine\"\\n|\\nnetworks:\\n| The *redis*\\ncounter-net\\n| service\\nvolumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\ntarget: /app\\n----┘\\nnetworks:\\n<<--- Networks are defined in this block\\ncounter-net:\\nvolumes:\\n<<--- Volumes are defined in this block\\ncounter-vol:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 136}, page_content='volumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\ntarget: /app\\n----┘\\nnetworks:\\n<<--- Networks are defined in this block\\ncounter-net:\\nvolumes:\\n<<--- Volumes are defined in this block\\ncounter-vol:\\nThe first thing to note is that the file has three top-level keys with a block of code\\nbeneath each:\\n• services\\n• networks\\n• volumes\\nMore top-level keys exist, but this app only uses the three in the list.\\nThe top-level services key is mandatory and is where you define application microser-\\nvices. This app has two microservices called web-fe and redis. The web-fe service runs\\nthe application’s web server and the redis service runs a database backend.\\nLet’s look at both, starting with the web-fe service.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 137}, page_content='9: Multi-container apps with Compose\\n131\\nservices:\\nweb-fe:\\n<<--- Service name. Containers will inherit this name\\ndeploy:\\nreplicas: 1\\n<<--- Deploy a single container for this service\\nbuild: .\\n<<--- Build from the Dockerfile in the current directory\\ncommand: python app/app.py <<-- Execute this command when starting containers\\nports:\\n- target: 8080\\n----┐Map port 8080 in the container\\npublished: 5001\\n----┘to port 5001 on the Docker host\\nnetworks:\\n- counter-net\\n<<--- Attach the service\\'s containers to the \"counter-net\" network\\nLet’s step through it.\\n• web-fe: is the service’s name, and all containers Docker creates for this service\\nwill inherit “web-fe” as part of their names.\\n• deploy.replicas: 1 tells Docker to deploy a single container for this service. You\\ncan specify a different number of replicas to deploy multiple identical containers\\nfor the service. However, you’ll only be able to deploy a single replica on Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 137}, page_content='can specify a different number of replicas to deploy multiple identical containers\\nfor the service. However, you’ll only be able to deploy a single replica on Docker\\nDesktop as only one container can bind to the port in the ports field.\\n• build: . tells Docker to build the image for this service from the Dockerfile in the\\ncurrent directory.\\n• command: python app/app.py is the command Docker executes inside every\\ncontainer it creates for this service. The app.py file must exist in the image, and\\nthe image must have Python installed. The Dockerfile takes care of both of these\\nrequirements.\\n• ports: is where you map network ports from the service’s containers to the\\nDocker host. This example maps port 5001 on the Docker host to port 8080 inside\\nthe container and is why Docker Desktop readers can only deploy a single replica\\nfor this service.\\n• networks: tells Docker to attach this service’s containers to the counter-net'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 137}, page_content='the container and is why Docker Desktop readers can only deploy a single replica\\nfor this service.\\n• networks: tells Docker to attach this service’s containers to the counter-net\\nnetwork. The network should already exist or be defined in the networks top-level\\nkey.\\nIn summary, Compose will build a new image from the Dockerfile in the same directory\\nand start a single container from it. When it starts, the container will have web-fe in\\nits name and run the python app/app.py command. It will attach to the counter-net\\nnetwork, expose the web service on the host’s port 5001.\\nNow, let’s look at the redis service.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 138}, page_content='9: Multi-container apps with Compose\\n132\\nservices:\\n..\\nredis:\\n<<--- Service name. Containers will inherit this name\\nimage: \"redis:alpine\"\\n<<--- Pull the \"redis:alpine\" image for this service\\ndeploy:\\nreplicas: 1\\n<<--- Deploy a single container for this service\\nnetworks:\\ncounter-net:\\n<<--- Attach containers to the \"counter-net\" network\\nvolumes:\\n- type: volume\\nsource: counter-vol\\n----┐Mount the \"counter-vol\" volume\\ntarget: /app\\n----┘to \"/app\" in the containers for this service\\nLet’s step through this one.\\n• redis: is the service’s name, and all containers created as part of this service will\\ninherit “redis” as part of their names.\\n• image: redis:alpine tells Docker to pull the redis:alpine image from Docker\\nHub and use it to start the service’s containers.\\n• deploy.replicas: 1 tells Docker to deploy a single container for this service.\\n• networks: tells Docker to attach the service’s containers to the counter-net\\nnetwork.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 138}, page_content='• deploy.replicas: 1 tells Docker to deploy a single container for this service.\\n• networks: tells Docker to attach the service’s containers to the counter-net\\nnetwork.\\n• volumes: tells Docker to mount the counter-vol volume to the /data directory\\ninside all of the service’s containers. This is where Redis stores data and will mean\\nyou can stop and delete most of the app without losing data.\\nConnecting both services to the counter-net network means they can resolve each\\nother by name and communicate. This is important, as the following extract from the\\napp.py file shows the web app communicating with the redis service by name.\\nimport time\\nimport redis\\nfrom flask import Flask, render_template\\napp = Flask(__name__)\\ncache = redis.Redis(host=\\'redis\\', port=6379)\\n<<---- \"redis\" is the name of the service\\n<Snip>\\nThe network and volumes blocks are extremely simple and define a network called\\ncounter-net and a volume called counter-vol.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 139}, page_content='9: Multi-container apps with Compose\\n133\\nnetworks:\\n<<---- This block defines a new network called \"counter-net\"\\ncounter-net:\\nvolumes:\\n<<---- This block defines a new volume called \"counter-vol\"\\ncounter-vol:\\nNow that we understand the Compose file, let’s deploy the app.\\nDeploying apps with Compose\\nIn this section, you’ll use the app from the Compose file. You’ll need a local copy of the\\nbook’s GitHub repo, and you’ll need to run all commands from the multi-container\\nfolder.\\nRun the following command to deploy the app. By default, it deploys the app defined in\\nthe compose.yaml file in the working directory.\\n$ docker compose up --detach\\n- redis 7 layers [||||||]\\n0B/0B\\nPulled\\n5.2s\\n- b0dd12c8e070: Pull complete\\n<Snip>\\n- 4f4fb700ef54: Pull complete\\n- redis Pulled\\n<Snip>\\n=> [web-fe internal] load build definition from Dockerfile\\n[+] Building 613s (11/11) FINISHED\\n<Snip>\\n[+] Running 5/5\\n- web-fe\\nBuilt\\n0.0s\\n- Network multi-container_counter-net\\nCreated\\n0.0s'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 139}, page_content='<Snip>\\n=> [web-fe internal] load build definition from Dockerfile\\n[+] Building 613s (11/11) FINISHED\\n<Snip>\\n[+] Running 5/5\\n- web-fe\\nBuilt\\n0.0s\\n- Network multi-container_counter-net\\nCreated\\n0.0s\\n- Volume \"multi-container_counter-vol\"\\nCreated\\n0.0s\\n- Container multi-container-redis-1\\nCreated\\n0.0s\\n- Container multi-container-web-fe-1\\nCreated\\n0.0s\\nIt’ll take a few seconds to build the web-fe image, pull the redis image, and then\\nstart the app. We’ll review what happened in a second, but let’s talk about the docker\\ncompose command first.\\nRunning a docker compose up command is the most common way to deploy a\\nCompose app. It reads through the Compose file in the local directory and runs the\\nDocker commands required to deploy the app. This includes building and pulling\\nimages, creating required networks and volumes, and starting all containers.\\nThe command you executed didn’t specify the name or location of the Compose file, so'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 139}, page_content='images, creating required networks and volumes, and starting all containers.\\nThe command you executed didn’t specify the name or location of the Compose file, so\\nDocker assumed it was called compose.yaml in the local directory. However, you can use\\nthe -f flag to point to a Compose file with a different name in a different directory. For'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 140}, page_content='9: Multi-container apps with Compose\\n134\\nexample, the following command will deploy the application defined in a Compose file\\ncalled sample-app.yml in the apps/ddd-book directory.\\n$ docker compose -f apps/ddd-book/sample-app.yml up --detach\\nNow that you’ve deployed the app, you can run regular docker commands to see the\\nimages, containers, networks, and volumes that Compose created.\\nRun the following command to see the image created for the web-fe service and the\\nimage pulled for the redis service.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nredis\\nalpine\\nf773b35a95e1\\n8 days ago\\n61.4MB\\nmulti-container-web-fe\\nlatest\\n811f22c9edb7\\n2 minutes ago\\n99.7MB\\nDocker pulled the redis:alpine image from Docker Hub, but it used the Dockerfile to\\nbuild the multi-container-web-fe:latest image.\\nIf you look at the Dockerfile, you’ll see it pulls the python:alpine image, copies in the\\napp code, installs requirements, and sets the command to start the app.\\nFROM python:alpine\\n<<---- Base image'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 140}, page_content='If you look at the Dockerfile, you’ll see it pulls the python:alpine image, copies in the\\napp code, installs requirements, and sets the command to start the app.\\nFROM python:alpine\\n<<---- Base image\\nCOPY . /app\\n<<---- Copy app code into image\\nWORKDIR /app\\n<<---- Set working directory\\nRUN pip install -r requirements.txt\\n<<---- Install requirements\\nENTRYPOINT [\"python\", \"app/app.py\"]\\n<<---- Set the default app\\nNotice how the newly built image’s name is a combination of the project name and the\\nservice name. The project name is the name of the build context directory, which in our\\nexample is multi-container, and the service name is web-fe. Compose uses this format\\nto name all resources, and the following table shows the names it will give the resources\\nfor our sample app.\\nResource type\\nResource\\nName\\nService\\nweb-fe\\nmulti-container-web-fe-1\\nService\\nredis\\nmulti-container-redis-1\\nNetwork\\ncounter-net\\nmulti-container_counter-net\\nVolume\\ncounter-vol\\nmulti-container_counter-vol'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 140}, page_content='Resource\\nName\\nService\\nweb-fe\\nmulti-container-web-fe-1\\nService\\nredis\\nmulti-container-redis-1\\nNetwork\\ncounter-net\\nmulti-container_counter-net\\nVolume\\ncounter-vol\\nmulti-container_counter-vol\\nList running containers to see the containers Compose created for the app.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 141}, page_content='9: Multi-container apps with Compose\\n135\\n$ docker ps\\nID\\nCOMMAND\\nSTATUS\\nPORTS\\nNAMES\\n61..\\n\"python app/app.py\"\\nUp 35 mins\\n0.0.0.0:5001->8080/tcp..\\nmulti-container-web-fe-1\\n80..\\n\"docker-entrypoint..\"\\nUp 35 mins\\n6379/tcp\\nmulti-container-redis-1\\nAs you can see, the multi-container-web-fe-1 container is running the Python web\\napp and is mapped to port 5001 on all interfaces on the Docker host. We’ll connect to\\nthis later.\\nThe number at the end of the container names allows each service to have multiple\\nreplicas. For example, if the web-fe service had three replicas they would be called\\nmulti-container-web-fe-1, multi-container-web-fe-2, and multi-container-web-\\nfe-3.\\nRun the following commands to see the counter-net network and counter-vol\\nvolume.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n46100cae7441\\nmulti-container_counter-net\\nbridge\\nlocal\\n<Snip>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmulti-container_counter-vol\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 141}, page_content='volume.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n46100cae7441\\nmulti-container_counter-net\\nbridge\\nlocal\\n<Snip>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmulti-container_counter-vol\\n<Snip>\\nWith the application deployed, you can point a web browser at your Docker host on port\\n5001 to view it. You can connect to localhost:5001 if you’re running Docker Desktop.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 142}, page_content='9: Multi-container apps with Compose\\n136\\nRefresh the page a few times and watch the counter increment. This is the app counting\\npage refreshes and storing the value on the volume in the Redis service.\\nCongratulations. You’ve successfully deployed a multi-container application using\\nDocker Compose!\\nManaging apps with Compose\\nIn this section, you’ll see how to stop, restart, delete, and get the status of Compose apps.\\nMake a note of how many times you’ve refreshed the page, and then run the following\\ncommand to shut the app down.\\n$ docker compose down\\n[+] Running 3/3\\n- Container multi-container-redis-1\\nRemoved\\n0.2s\\n- Container multi-container-web-fe-1\\nRemoved\\n0.2s\\n- Network multi-container_counter-net\\nRemoved\\n0.2s\\nThe output shows Docker deleting both containers and the network. However, it\\ndoesn’t mention the volume.\\nRun a docker volumes ls command to see if the volume still exists.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 143}, page_content='9: Multi-container apps with Compose\\n137\\n$ docker volume ls\\n<Snip>\\nlocal\\nmulti-container_counter-vol\\nThe volume still exists because Docker knows we store important information in\\nvolumes that we might want to keep when stopping and restarting apps. In our example,\\nthe redis service stored the refresh count in the volume, meaning we’ll see the same\\ncount when we redeploy the app in a later step.\\nDocker also keeps the images it built and pulled when it started the app. Feel free to run\\na docker images command to prove the images still exist.\\nLet’s explore a few other docker compose commands.\\nRun the following command to redeploy the app.\\n$ docker compose up --detach\\n<Snip>\\n[+] Running 3/3\\n- Network multi-container_counter-net\\nCreated\\n0.2s\\n- Container multi-container-redis-1\\nStarted\\n0.2s\\n- Container multi-container-web-fe-1\\nStarted\\n0.2s\\nNotice how it started much faster this time. This is because the images and volume\\nalready exist.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 143}, page_content='- Container multi-container-redis-1\\nStarted\\n0.2s\\n- Container multi-container-web-fe-1\\nStarted\\n0.2s\\nNotice how it started much faster this time. This is because the images and volume\\nalready exist.\\nGo back to your browser and refresh the app. The refresh count should continue from\\nwhere you left it. This is because Redis stores the count in the /data directory, which\\nuses the volume Docker didn’t delete.\\nSwitch back to the CLI and check the current state of the app with a docker compose\\nps command.\\n$ docker compose ps\\nNAME\\nCOMMAND\\nSERVICE\\nSTATUS\\nPORTS\\nmulti-container-redis-1\\n\"docker-entrypoint..\"\\nredis\\nUp 33 sec\\n6379/tcp\\nmulti-container-web-fe-1\\n\"python app/app.py\"\\nweb-fe\\nUp 33 sec\\n0.0.0.0:5001->8080\\nThe output shows both containers, the commands they’re executing, their current state,\\nand the network ports they’re listening on.\\nRun a docker compose top to list the processes inside each container.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 144}, page_content='9: Multi-container apps with Compose\\n138\\n$ docker compose top\\nmulti-container-redis-1\\nUID\\nPID\\nPPID\\n... CMD\\nlxd\\n12023\\n11980\\nredis-server *:6379\\nmulti-container-web-fe-1\\nUID\\nPID\\nPPID\\n... CMD\\nroot\\n12024\\n12002\\n0\\npython app/app.py python app/app.py\\nroot\\n12085\\n12024\\n0\\n/usr/local/bin/python app/app.py python app/app.py\\nThe PID numbers returned are the PID numbers as seen from the Docker host (not from\\nwithin the containers).\\nRun the following commands to stop the app and recheck its status.\\n$ docker compose stop\\n[+] Running 2/2\\n- Container multi-container-redis-1\\nStopped\\n0.4s\\n- Container multi-container-web-fe-1\\nStopped\\n0.5\\n$ docker compose ps -a\\nNAME\\nCOMMAND\\nSERVICE\\nSTATUS\\nPORTS\\nNAME\\nIMAGE\\n...\\nSERVICE\\nSTATUS\\nmulti-container-redis-1\\nredis:alpine\\n...\\nredis\\nExited (0) 25 seconds ago\\nmulti-container-web-fe-1\\nmulti-container-web-fe\\n...\\nweb-fe\\nExited (0) 25 seconds ago\\nThe app is down, but Docker hasn’t deleted the containers — it’s only stopped them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 144}, page_content='Exited (0) 25 seconds ago\\nmulti-container-web-fe-1\\nmulti-container-web-fe\\n...\\nweb-fe\\nExited (0) 25 seconds ago\\nThe app is down, but Docker hasn’t deleted the containers — it’s only stopped them.\\nRestart the app with the docker compose restart command.\\n$ docker compose restart\\n[+] Running 2/2\\n- Container multi-container-redis-1\\nStarted\\n0.1s\\n- Container multi-container-web-fe-1\\nStarted\\n0.1s\\nCheck the status of the app.\\n$ docker compose ls\\nNAME\\nSTATUS\\nCONFIG FILES\\nmulti-container\\nrunning(2)\\n/Users/nigelpoulton/temp/ddd-book/multi-container/compose.yaml\\nGo back to your browser and refresh the page again. The counter will continue from\\nwhere you left it because Docker didn’t delete the containers or the volumes. Even if\\nyour app doesn’t use volumes, it won’t lose data across container restarts.\\nCongratulations. You’ve deployed and managed a multi-container microservices app\\nusing Docker Compose.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 145}, page_content='9: Multi-container apps with Compose\\n139\\nBefore cleaning up and reviewing the commands, it’s important to understand that\\nthis was a simple example and that Docker Compose can deploy and manage far more\\ncomplex applications.\\nClean up\\nRun the following command to stop and delete the app. The --volumes flag will delete\\nall of the app’s volumes, and the --rmi all will delete all of its images.\\n$ docker-compose down --volumes --rmi all\\n[+] Running 6/6\\n- Container multi-container-web-fe-1\\nRemoved\\n0.2s\\n- Container multi-container-redis-1\\nRemoved\\n0.1s\\n- Volume multi-container_counter-vol\\nRemoved\\n0.0s\\n- Image multi-container-web-fe:latest\\nRemoved\\n0.1s\\n- Image redis:alpine\\nRemoved\\n0.1s\\n- Network multi-container_counter-net\\nRemoved\\n0.1s\\nDeploying apps with Compose – The commands\\n• docker compose up is the command to deploy a Compose app. It creates all\\nimages, containers, networks, and volumes the app needs. It expects you to call'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 145}, page_content='Deploying apps with Compose – The commands\\n• docker compose up is the command to deploy a Compose app. It creates all\\nimages, containers, networks, and volumes the app needs. It expects you to call\\nthe Compose file compose.yaml, but you can specify a custom filename with the -f\\nflag. You’ll normally start the app in the background with the --detach flag.\\n• docker compose stop will stop all containers in a Compose app without deleting\\nthem. You can easily restart them with docker compose restart, and you\\nshouldn’t lose any data.\\n• docker compose restart will restart a stopped Compose app. If you make\\nchanges to the Compose file while it’s stopped, these changes will not appear in\\nthe restarted app. You need to redeploy the app to see any changes you made in the\\nCompose file.\\n• docker compose ps lists each container in the Compose app. It shows the current\\nstate, the command each container is running, and network ports.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 145}, page_content='Compose file.\\n• docker compose ps lists each container in the Compose app. It shows the current\\nstate, the command each container is running, and network ports.\\n• docker compose down will stop and delete a running Compose app. By default, it\\ndeletes containers and networks but not volumes and images.\\nChapter Summary\\nIn this chapter, you learned how to deploy and manage multi-container applications\\nusing Docker Compose.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 146}, page_content='9: Multi-container apps with Compose\\n140\\nCompose is fully integrated into the Docker toolset with its own docker compose sub-\\ncommand. It lets you define multi-container applications in declarative configuration\\nfiles and deploy them with a single command.\\nCompose files define all the containers, networks, volumes, secrets, and other configu-\\nrations an application needs. You then use the docker compose command to post the\\nCompose file to Docker, and Docker deploys it.\\nOnce you’ve deployed the app, you can manage its entire lifecycle using docker\\ncompose sub-commands.\\nDocker Compose is popular with developers, and the Compose file is an excellent\\nsource of application documentation as it defines all the services that make up the app,\\nthe images they use, the ports they expose, the networks and volumes they use, and\\nmuch more. As such, it can help bridge the gap between development and operations\\nteams. You should also treat Compose files as code and store them in version control'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 146}, page_content='much more. As such, it can help bridge the gap between development and operations\\nteams. You should also treat Compose files as code and store them in version control\\nsystems.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 147}, page_content='10: Docker and AI\\nDocker offers two ways of deploying and running AI apps:\\n1. Docker Model Runner (preferred)\\n2. Containers\\nBoth methods run AI apps locally, making them suitable for companies with privacy\\nconcerns, that do not want unpredictable cloud costs, have latency-sensitive require-\\nments, and require full control over things like prompt customization and fine-tuning.\\nHowever, Docker Model Runner is the preferred method and will be the focus of this\\nchapter.\\nI’ve organized the chapter as follows:\\n• Docker Model Runner background\\n• Docker Model Runner architecture\\n• Install Docker Model Runner\\n• Explore Docker Model Runner\\n• Use Docker Model Runner with Compose\\n• Use Docker Model Runner with 3rd-party apps\\n• Running models in containers\\nThroughout the chapter, we’ll use the terms “LLMs”, “models, “AI models”, and “AI apps” to\\nmean the same thing.\\nDocker Model Runner background\\nDocker Model Runner (DMR) is a new technology, fully integrated with the Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 147}, page_content='mean the same thing.\\nDocker Model Runner background\\nDocker Model Runner (DMR) is a new technology, fully integrated with the Docker\\ntoolchain, that executes AI models directly on host machines rather than inside\\ncontainers. Yes… Docker Model Runner executes AI models outside of containers! This\\nis because containers cannot access the majority of AI acceleration hardware like GPUs,\\nNPUs, and TPUs that make AI models fast. This is because most AI acceleration devices\\nare proprietary, with their own drivers and SDKs, and it’s extremely hard for Docker\\nand the wider ecosystem to develop and maintain support for them all.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 148}, page_content='10: Docker and AI\\n142\\nYes, it’s possible for containers to access modern NVIDIA GPUs if you install the\\nNVIDIA Container Toolkit. However, this is complex to install and only works for CUDA-\\ncapable NVIDIA GPUs. By executing models outside of containers, Docker Model\\nRunner gives you the best of both worlds:\\n• Integration with Docker tools and the wider cloud native ecosystem\\n• Easier access to AI acceleration hardware\\nThe early releases of DMR work with NVIDIA GPUs on Windows hosts and the built-\\nin GPUs on Macs with Apple silicon. Future releases will support a broader range of AI\\nacceleration hardware.\\nNow that you know the background, let’s look at Docker Model Runner’s architecture.\\nDocker Model Runner Architecture\\nDMR executes models directly on host hardware, exposes them via OpenAI-compatible\\nendpoints, and integrates with the wider Docker toolchain and cloud native ecosystem.\\nFigure 10.1 shows the high-level architecture and major components.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 148}, page_content='endpoints, and integrates with the wider Docker toolchain and cloud native ecosystem.\\nFigure 10.1 shows the high-level architecture and major components.\\nFigure 10.1 - Docker Model Runner Architecture\\nYou can see Docker Model Runner at the bottom of the diagram in the center. It’s a host\\nprocess that wraps one or more runtimes, provides models with direct access to host'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 149}, page_content='10: Docker and AI\\n143\\nhardware, dynamically loads and unloads models based on demand, and serves them\\nvia OpenAI-compatible endpoints that applications can access from inside containers or\\nvia the network. The Docker CLI can pull and push models from Docker Hub and DMR\\nstores them in a local store for fast access.\\nLet’s dig a little deeper.\\nDMR is a host process separate from the Docker Engine. For Mac users, this means it runs\\noutside the Docker Desktop VM with direct access to hardware. It wraps a pluggable\\nruntime layer that allows you to choose the best runtime for your requirements. Runtime\\nis another word for the core inference engine that loads and executes models and provides\\ninference. Early releases use llama.cpp as the runtime, but future releases will support\\nadditional runtimes.\\nDMR exposes several API endpoints for model management and inference. The\\nmodel management endpoints allow you to query and manage models, whereas the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 149}, page_content='additional runtimes.\\nDMR exposes several API endpoints for model management and inference. The\\nmodel management endpoints allow you to query and manage models, whereas the\\ninference endpoints are OpenAI-compatible. Containers on the same host can access\\nthe endpoints via the special http://model-runner.docker.internal/ hostname, non-\\ncontainerized apps on the same host can reach them via the local Docker socket or the\\nhost’s loopback address on port 12434, and apps running on different hosts can access\\nthem via the DMR host’s IP or DNS name on port 12434.\\nThe initial versions of DMR use a Docker CLI plugin that provides the docker model\\ncommand. Docker Desktop automatically installs the plugin when you enable DMR,\\nbut future versions may integrate DMR functionality into core Docker commands\\nlike docker pull and docker run. If this happens, commands like docker pull and\\ndocker run will read the object manifest to know they’re working with models instead\\nof images or containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 149}, page_content='like docker pull and docker run. If this happens, commands like docker pull and\\ndocker run will read the object manifest to know they’re working with models instead\\nof images or containers.\\nDocker Hub maintains a catalog of verified models below the ai namespace16. You can pull\\nthese in the same way you pull images, and DMR will store them in a local model store in\\nyour filesystem below ∼/.docker/models. As is normal for AI models, they are usually\\nseveral gigabytes in size. You can even push your own models to Docker Hub where they\\nare stored as a new (proposed) OCI artifact type called a model.\\nWe’ll get into more details and see all of this in action as you progress through the\\nchapter. However, a quick word on how DMR compares with other popular model\\nservers.\\nDocker Model Runner vs Ollama vs LM Studio\\nIf you’re already running local models, you’ll recognize similarities with tools like LM\\nStudio and Ollama.\\n16https://hub.docker.com/u/ai'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 150}, page_content='10: Docker and AI\\n144\\nFor example, they can all use llama.cpp as their core inference engine and can expose\\nmodels via OpenAI-style endpoints. This means they all offer similar core functionality\\nand performance. However, Docker Model Runner offers seamless integration with\\nDocker tools and the wider cloud native ecosystem.\\nWith these points in mind, you should seriously consider DMR if you’re:\\n• An existing Docker user who already runs local models\\n• An existing Docker user with plans to start running local models\\n• Already running local models and about to start using Docker for containers\\nIn all of these cases, switching to Docker Model Runner allows you to consolidate tools\\nand ecosystems.\\nHowever, early versions of Docker Model Runner may offer fewer features than some\\nof the alternatives, and you should always test new products against your current and\\nfuture requirements.\\nInstalling Docker Model Runner\\nYou’ll need all of the following to complete the examples:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 150}, page_content='of the alternatives, and you should always test new products against your current and\\nfuture requirements.\\nInstalling Docker Model Runner\\nYou’ll need all of the following to complete the examples:\\n• A Mac or Windows machine, preferably with Apple or NVIDIA GPUs\\n• Docker Desktop v4.41 or newer (includes Docker Compose v2.35)\\n• A clone of the book’s GitHub repo\\nDocker Model Runner also works on CPUs, meaning you can still use it if you don’t\\nhave a machine with supported GPUs. Models will just run slower.\\nYou can run the following command to clone the book’s GitHub repo:\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nChange into the dmr directory.\\n$ cd ddd-book/dmr\\nOpen Docker Desktop’s Settings page, click the Features in development tab, and\\ncheck the Enable Docker Model Runner and Enable host-side TCP support check-\\nboxes. Accept the default port of 12434 and then click the blue Apply & restart button\\nto activate your changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 151}, page_content='10: Docker and AI\\n145\\nChecking the Enable host-side TCP support option maps DMR to port 12434 on the\\nhost’s network interface so that local apps can access it on localhost:12434 and remote\\napps can access it from the network on the same port.\\nOnce you’ve enabled DMR, switch to the command line and verify it’s working.\\n$ docker model status\\nDocker Model Runner is running\\nStatus:\\nllama.cpp: running llama.cpp latest-metal (sha256:ad58230f548...) version: a0f7016\\nDMR is running and you can see it’s using llama.cpp as its core inference engine (run-\\ntime) which, in turn, is using Apple’s Metal API to give models access to my MacBook’s\\nGPUs. Future versions of DMR may support Apple’s MLX framework so that models\\ncan leverage Apple’s Neural Engine for even better performance. As the runtime layer is\\npluggable, things like MLX and support for other hardware can come through the use of\\ndifferent runtimes.\\nCongratulations. You’ve enabled Docker Model Runner and are ready to start using it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 151}, page_content='pluggable, things like MLX and support for other hardware can come through the use of\\ndifferent runtimes.\\nCongratulations. You’ve enabled Docker Model Runner and are ready to start using it.\\nExplore Docker Model Runner\\nIn this section, you’ll learn how to:\\n• Pull models from Docker Hub\\n• List and inspect models\\n• Test models\\n• Inspect the DMR APIs\\nPull models from Docker Hub\\nDocker maintains a catalog of models below the ai namespace17 on Docker Hub. These\\nare part of the Docker Verified Publisher Program, meaning they should be high quality and\\nup to date.\\nPoint your browser at https://hub.docker.com/catalogs/models and click through\\nthe available models. Clicking a particular model shows its model card with detailed\\nmodel info. Figure 10.2 shows the model card for the Mistral model. We’ll look more\\nclosely later in the chapter, but you can see it’s a verified model, you can see the model\\n17https://hub.docker.com/u/ai'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 152}, page_content='10: Docker and AI\\n146\\narchitecture, training cut-off date, model variants, and even benchmark info. However,\\nbenchmark info is from the original model publisher, and you should always perform\\nyour own testing to see how well a model performs for your specific requirements.\\nFigure 10.2 - Model info card\\nRun the following command to download a quantized version of a Gemma3 4B model.\\nQuantization is a way to reduce model size without losing too much model accuracy or\\nperformance. However, even quantized can be several gigabytes and can take a while to\\ndownload. Feel free to download a newer quantized version if available.\\n$ docker model pull ai/gemma3:4B-Q4_K_M\\nDownloaded: 18.10 MB...\\n<Snip>\\nModel pulled successfully\\nOnce the pull operation is complete, list your local models to see the one you down-\\nloaded.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 153}, page_content='10: Docker and AI\\n147\\n$ docker model ls\\nMODEL NAME\\nPARAMS\\nQUANTIZATION\\nARCHITECTURE\\nMODEL ID\\nSIZE\\nai/gemma3:4B-Q4_K_M\\n3.88 B\\nIQ2_XXS/Q4_K_M\\ngemma3\\n0b329b335467\\n2.31G\\nInspecting models\\nDMR automatically pulls images from Docker Hub where it stores and distributes them\\nas a new type of OCI artifact called a model. This model-spec18 is currently in draft and\\nmay change slightly.\\nRun the following command to inspect the manifest of the Gemma3 model you just\\npulled. The command connects to Docker Hub and inspects the manifest from Docker\\nHub and not the local copy you pulled.\\n$ docker manifest inspect ai/gemma3:4B-Q4_K_M | jq\\n{\\n\"schemaVersion\": 2,\\n\"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\\n<<--- Image manifest\\n\"config\": {\\n----┐\\n\"mediaType\": \"application/vnd.docker.ai.model.config.v0.1+json\", | Model config\\n\"size\": 372,\\n| descriptor\\n\"digest\": \"sha256:22273fdf4e6dbaf...af0e6569be41539\"\\n----┘\\n},\\n\"layers\": [\\n{\\n\"mediaType\": \"application/vnd.docker.ai.gguf.v3\",\\n----┐'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 153}, page_content='\"size\": 372,\\n| descriptor\\n\"digest\": \"sha256:22273fdf4e6dbaf...af0e6569be41539\"\\n----┘\\n},\\n\"layers\": [\\n{\\n\"mediaType\": \"application/vnd.docker.ai.gguf.v3\",\\n----┐\\n\"size\": 2489757856,\\n| GGUF descriptor\\n\"digest\": \"sha256:09b370de51ad3...fc96ab2dc1adaa7\"\\n----┘\\n},\\n{\\n\"mediaType\": \"application/vnd.docker.ai.license\",\\n----┐\\n\"size\": 8346,\\n| License descriptor\\n\"digest\": \"sha256:a4b03d96571f0...dc90e3f960823e5\"\\n----┘\\n}\\n]\\n}\\nThe output shows three descriptors relating to the model config and its two layers, and\\nyou’ll recognize it if you’re familiar with the structure of OCI images.\\nWhen you pulled the model, DMR queried Docker Hub (OCI registry) for the requested\\nmodel, read its manifest, pulled the config and two layers, and stored them in the local\\nmodel store with filenames matching the SHAs. This means the config file and layer\\nfiles are in your local filesystem below ∼/.docker/models/blobs/sha256 and you can\\ninspect them with your favorite tools.\\n18https://github.com/docker/model-spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 154}, page_content='10: Docker and AI\\n148\\n$ ls -lh ~/.docker/models/blobs/sha256\\ntotal 13609568\\n-rw-r--r--@ 1\\n2.3G\\n09b370de51ad3bde8c3aea...667ddbafc96ab2dc1adaa7\\n<<---- model file (GGUF)\\n-rw-r--r--@ 1\\n372B\\n22273fd2f4e6dbaf5b5dae...308eb0faf0e6569be41539\\n<<---- model config JSON\\n-rw-r--r--@ 1\\n8.2K\\na4b03d96571f0ad98b1253...328909bdc90e3f960823e5\\n<<---- License\\nThe following command prints the model’s configuration from the local copy of the\\nconfig file. It shows the model format, quantization, parameters, architecture, size, and\\nmore. Yours may have a different SHA and filename.\\n$ cat ~/.docker/models/blobs/sha256/22273fdf4e6dbaf...af0e6569be41539 | jq\\n{\\n\"config\": {\\n\"format\": \"gguf\",\\n\"quantization\": \"IQ2_XXS/Q4_K_M\",\\n\"parameters\": \"3.88 B\",\\n\"architecture\": \"gemma3\",\\n\"size\": \"2.31 GiB\"\\n},\\n\"descriptor\": {\\n\"created\": \"2025-03-26T09:57:32.086694+01:00\"\\n},\\n\"rootfs\": {\\n\"type\": \"rootfs\",\\n\"diff_ids\": [\\n\"sha256:09b370de51ad3bde8c3aea3559a769a59e7772e813667ddbafc96ab2dc1adaa7\",'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 154}, page_content='},\\n\"descriptor\": {\\n\"created\": \"2025-03-26T09:57:32.086694+01:00\"\\n},\\n\"rootfs\": {\\n\"type\": \"rootfs\",\\n\"diff_ids\": [\\n\"sha256:09b370de51ad3bde8c3aea3559a769a59e7772e813667ddbafc96ab2dc1adaa7\",\\n\"sha256:a4b03d96571f0ad98b1253bb134944e508a4e9b9de328909bdc90e3f960823e5\"\\n]\\n}\\n}\\nYou can see the same information with the docker model inspect command.\\nYou can also inspect the model’s GGUF file and license file. However, model files can be\\nlarge, and although they have a header with readable metadata, they also have a large\\nbody with the tensors that represent model parameters, including the weights and\\nbiases, which are not human-readable.\\nPackaging and storing models as OCI artifacts allows you to leverage the huge number\\nof existing public and private OCI registries that most companies already use to store all\\nof the following:\\n• Container images\\n• Signatures\\n• SBOMs\\n• OPA Policies'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 155}, page_content='10: Docker and AI\\n149\\n• Helm charts\\n• Wasm modules\\n• MCP tools\\nAdding AI models to this growing list reduces registry sprawl and makes AI models more\\naccessible to existing cloud-native tools and workflow pipelines.\\nTest your model\\nDMR offers two easy ways to test your models:\\n• The CLI\\n• Docker Desktop UI\\nThe CLI offers very basic testing capabilities with zero conversational history.\\nThe following example opens an interactive REPL (Read, Evaluate, Print, Loop) envi-\\nronment and asks the model two related questions. However, there’s no conversational\\nhistory, and it treats each question independently. I’ve clipped the responses as they can\\nbe quite long.\\n$ docker model run ai/gemma3:4B-Q4_K_M\\nInteractive chat mode started. Type \\'/bye\\' to exit.\\n> How long is a day on Mars?\\nA day on Mars, also known as a \"sol,\" is about **24 hours, 39 minutes, and 35 seconds** long...\\n> What about Venus?\\nOkay, let\\'s talk about Venus! It\\'s a truly fascinating and incredibly hostile planet, often'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 155}, page_content='> What about Venus?\\nOkay, let\\'s talk about Venus! It\\'s a truly fascinating and incredibly hostile planet, often\\ncalled Earth\\'s \"sister planet\" due to its similar size and composition. However, that\\'s\\nwhere the similarities largely end. Here\\'s a breakdown of key information about Venus:...\\nType /bye to return to your shell.\\nDocker Desktop offers a slightly better way to test.\\nOpen the Docker Desktop UI and click the Models tab in the left navigation bar. Click\\nthe model you want to test to open a chat session and then ask it the same questions.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 156}, page_content='10: Docker and AI\\n150\\nFigure 10.3 - Docker Desktop’s Model Chat Window\\nThis time, the environment has realized the two questions are related.\\nInspect the DMR API\\nDocker Model Runner exposes a set of native endpoints for model management and a\\nset of OpenAI-compatible endpoints for model interaction.\\nDMR endpoints\\n/models\\n<<---- GET\\n/models/create\\n<<---- POST\\n/models/{namespace}/{name}\\n<<---- GET and DELETE\\nOpenAI-compatible endpoints'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 157}, page_content='10: Docker and AI\\n151\\n/engines/llama.cpp/v1/models\\n<<---- GET\\n/engines/llama.cpp/v1/chat/completions\\n<<---- POST\\n/engines/llama.cpp/v1/completions\\n<<---- POST\\n/engines/llama.cpp/v1/embeddings\\n<<---- POST\\nLet’s craft an API request to DMR’s OpenAI-compatible chat/completions endpoint so\\nthat it asks the Gemma3 model we pulled earlier how long a Martian day is.\\nThe first thing we need to do is get the list of available models. We already pulled the\\nai/gemma3:4B-Q4_K_M, but it’s always worth querying DMR to ensure the OpenAI\\nendpoints refer to it by the same name.\\nRun the following curl command to get the list of local models and see their names.\\n$ curl -s localhost:12434/engines/v1/models | jq\\n{\\n\"object\": \"list\",\\n\"data\": [\\n{\\n\"id\": \"ai/gemma3:4B-Q4_K_M\",\\n\"object\": \"model\",\\n\"created\": 1742979452,\\n\"owned_by\": \"docker\"\\n}\\n]\\n}\\nGreat, DMR refers to it as ai/gemma3:4B-Q4_K_M.\\nNow, POST your question to DMR’s chat/completions endpoint.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 157}, page_content='\"object\": \"model\",\\n\"created\": 1742979452,\\n\"owned_by\": \"docker\"\\n}\\n]\\n}\\nGreat, DMR refers to it as ai/gemma3:4B-Q4_K_M.\\nNow, POST your question to DMR’s chat/completions endpoint.\\n$ curl -s http://localhost:12434/engines/v1/chat/completions \\\\\\n-H \"Content-Type: application/json\" \\\\\\n-d \\'{\\n\"model\": \"ai/gemma3:4B-Q4_K_M\",\\n\"messages\": [\\n{\\n\"role\": \"system\",\\n\"content\": \"Keep your responses to one sentence only.\"\\n},\\n{\\n\"role\": \"user\",\\n\"content\": \"How long is a day on Mars?\"\\n}\\n],\\n\"temperature\": 0.7,\\n\"max_tokens\": 500\\n}\\' | jq -r \\'.choices[0].message.content\\'\\nA day on Mars, also known as a sol, is approximately 24.6 hours long.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 158}, page_content='10: Docker and AI\\n152\\nIt worked. Let’s quickly step through the command.\\nThe curl command targets DMR’s /engines/v1/chat/completions endpoint. If your\\nDMR has multiple runtimes, you can target a specific one by including it between the\\nbase path and API version. For example, you’d use the following path to explicitly call\\nthe llama.cpp runtime:\\n/engines/llama.cpp/v1/chat/completions\\nThe -d flag indicates the data to send in the request body and includes all of the\\nfollowing:\\n• model: This is the name of the desired model\\n• messages: Includes the system prompt telling the model to give short answers, as\\nwell as the user prompt with the question\\n• temperature: Tells the model how creative to be (usually between 0-1, with 0\\nbeing predictable and 1 being very creative)\\n• max_tokens: Restricts the length of responses\\nNow that you understand how DMR works, let’s see how to integrate it with a Com-\\npose-based chatbot app.\\nUse Docker Model Runner with Compose'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 158}, page_content='• max_tokens: Restricts the length of responses\\nNow that you understand how DMR works, let’s see how to integrate it with a Com-\\npose-based chatbot app.\\nUse Docker Model Runner with Compose\\nIn this section, you’ll use Compose to deploy a chatbot app that uses DMR as its\\ninference server.\\nYou’ll need Docker Desktop v4.41 or newer with Docker Model Runner enabled.\\nThe app is a multi-tier application with three services:\\n• frontend: Chat interface\\n• backend: Backend API\\n• dmr: Model server (DMR)\\nFigure 10.4 shows the chatbot architecture. The fronted service implements a Remix-\\nbased chatbot interface that you access on port 3000. This communicates with a FastAPI\\nbackend server over the project’s default network on port 8000. The backend API\\nserver calls DMR’s OpenAI-compatible chat/completions API with streaming enabled\\nand streams responses to the frontend.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 159}, page_content='10: Docker and AI\\n153\\nFigure 10.4 - Chatbot architecture\\nThe app’s Compose file is in the dmr folder and defines the three services from Figure\\n10.4.\\nservices:\\nfrontend:\\n----┐\\nbuild: ./frontend\\n|\\nports:\\n|\\n- \"3000:3000\"\\n| Frontend\\nenv_file:\\n| service\\n- .env\\n|\\ndepends_on:\\n|\\n- backend\\n----┘\\nbackend:\\n----┐\\nbuild: ./backend\\n|\\nports:\\n|\\n- \"8000:8000\"\\n| Backend\\nenv_file:\\n| service\\n- .env\\n|\\ndepends_on:\\n|\\n- dmr\\n----┘\\ndmr:\\n----┐\\nprovider:\\n|\\ntype: model\\n| DMR\\noptions:\\n|\\nmodel: ${LLM_MODEL_NAME} ----┘\\nLet’s step through the file.\\nThe frontend service builds an image from the Dockerfile and application code in the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 160}, page_content='10: Docker and AI\\n154\\n./frontend folder, exposes port 3000, loads environment variables from the local .env\\nfile, and will only start when the backend service is running.\\nThe backend service builds an image from the Dockerfile and code in the ./backend\\nfolder, listens on port 8000, loads the same environment variables from the same .env\\nfile, and will only start when the dmr service is running.\\nThe dmr service declares Docker Model Runner as part of the Compose app and uses\\nthe provider extension to tell DMR to download and use the model defined in the LLM_-\\nMODEL_NAME variable from the local .env file. You need Docker Compose v2.35 or newer\\nto leverage DMR like this.\\nThe local .env file defines the following two variables that tell the app how to connect to\\nDMR and which model to use:\\nMODEL_HOST=http://model-runner.docker.internal/engines/v1\\nLLM_MODEL_NAME=ai/gemma3:4B-Q4_K_M\\nYou can integrate with remote DMR instances by changing the MODEL_HOST variable'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 160}, page_content='MODEL_HOST=http://model-runner.docker.internal/engines/v1\\nLLM_MODEL_NAME=ai/gemma3:4B-Q4_K_M\\nYou can integrate with remote DMR instances by changing the MODEL_HOST variable\\nto point to your remote DMR instance like this: http://<host>:12434/engines/v1.\\nHowever, the provider extension doesn’t support remote instances yet, so you won’t be\\nable to declare dependencies on DMR. This may change in the future.\\nWhen you deploy the app, Docker will automatically create a network for the project\\ncalled default, build the images for the frontend and backend, and start all three ser-\\nvices. The dependencies ensure the dmr service will start first, then the backend service,\\nand finally the frontend. Docker will connect the frontend and backend services to\\nthe project’s default network so the frontend can send requests to the backend on port\\n8000. The backend will connect to the dmr service (the local instance of Docker Model'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 160}, page_content='the project’s default network so the frontend can send requests to the backend on port\\n8000. The backend will connect to the dmr service (the local instance of Docker Model\\nRunner) via HTTP requests to http://model-runner.docker.internal/engines/v1.\\nThis is a special hostname that all containers can use to access DMR.\\nChange into the dmr folder and run the following commands.\\nDeploy the app.\\n$ docker compose up --build --detach\\n[+] Building 3.3s (25/25) FINISHED\\n[+] Running 6/6\\n- backend\\nBuilt\\n0.0s\\n- frontend\\nBuilt\\n0.0s\\n- Network dmr_default\\nCreated\\n0.0s\\n- dmr\\nCreated\\n1.5s\\n- Container dmr-backend-1\\nStarted\\n0.4s\\n- Container dmr-frontend-1\\nStarted\\n0.2s\\nYou can see it’s built the frontend and backend images, created the project’s network,\\nand started the services in the expected order.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 161}, page_content='10: Docker and AI\\n155\\nOpen your browser to http://localhost:3000 and ask your chatbot some questions.\\nFigure 10.5 - Working chatbot\\nThe example proves the chatbot maintains a conversation history and infers context\\nfrom previous questions.\\nThe small text below the message box displays the name of the model DMR is using and\\nwill match the value of the LLM_MODEL_NAME environment variable in the .env file.\\nCongratulations. You used Compose to deploy a chatbot app that leverages an LLM via\\nDocker Model Runner!\\nUse Docker Model Runner with Open WebUI\\nIn theory, any OpenAI-compatible third-party app can leverage Docker Model Runner\\nvia its OpenAI-compatible endpoints.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 162}, page_content='10: Docker and AI\\n156\\nIn this section, you’ll combine Open WebUI19 with Docker Model Runner to create a\\npowerful and customizable local chatbot experience that looks and feels like commer-\\ncial-grade chatbots such as ChatGPT and Claude.\\nYou’ll need Docker Desktop v4.41 or newer with Docker Model Runner enabled. The\\nexample uses the gemma3:4B-Q4_K_M that you pulled earlier. If you haven’t pulled\\nthe model, DMR will pull it when you deploy the app. You can also experiment with\\ndifferent models.\\nYou’ll complete all of the following steps:\\n1. Check DMR status and local models\\n2. Install Open WebUI as a container\\n3. Connect to Open WebUI and use it\\nCheck DMR status and pull models\\nRun the following command to check the status of DMR.\\n$ docker model status\\nDocker Model Runner is running\\nStatus:\\nllama.cpp: running llama.cpp latest-metal (sha256:af30fb4847b...)\\nDownload a small quantized Qwen model.\\n$ docker model pull ai/qwen3:0.6B-Q4_K_M\\nDownloaded: 0.00 MB\\nModel pulled successfully'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 162}, page_content='Status:\\nllama.cpp: running llama.cpp latest-metal (sha256:af30fb4847b...)\\nDownload a small quantized Qwen model.\\n$ docker model pull ai/qwen3:0.6B-Q4_K_M\\nDownloaded: 0.00 MB\\nModel pulled successfully\\nList models to make sure you have at least two models so you can switch between them\\nin the app.\\n$ docker model ls\\nMODEL NAME\\nPARAMS\\nQUANTIZATION\\nARCH\\nMODEL ID\\nSIZE\\nai/gemma3:4B-Q4_K_M\\n3.88 B\\nIQ2_XXS/Q4_K_M\\ngemma3\\n0b329b335467\\n2.3G\\nai/qwen3:0.6B-Q4_K_M\\n751.63 M\\nIQ2_XXS/Q4_K_M\\nqwen3\\n18e5114fc13b\\n456.11 MiB\\nFeel free to pull additional models.\\n19https://www.openwebui.com/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 163}, page_content='10: Docker and AI\\n157\\nInstall Open WebUI as a container\\nOpen WebUI is a popular AI platform that integrates with Ollama and OpenAI-\\ncompatible model servers to create powerful chatbot experiences. You can install it via\\npip or as a Docker container. We’ll use the following Compose file from the openwebui\\nfolder to install it as a container.\\nvolumes:\\nopen-webui:\\nservices:\\nopen-webui:\\nimage: ghcr.io/open-webui/open-webui:main\\nenvironment:\\n- DEFAULT_MODELS=${MODEL_NAME}\\n- WEBUI_AUTH=False\\n- OPENAI_API_KEY=${OPENAI_KEY}\\n- OPENAI_API_BASE_URL=${MODEL_HOST}\\nvolumes:\\n- open-webui:/app/backend/data\\nports:\\n- \"3001:8080\"\\nrestart: always\\ndepends_on:\\n- dmr\\ndmr:\\nprovider:\\ntype: model\\noptions:\\nmodel: ${MODEL_NAME}\\nThe open-webui service pulls the official Open WebUI image from GitHub Container\\nRegistry, configures it with four environment variables, mounts a volume so you don’t\\nlose your configuration every time you restart it, exposes the web interface on port 3001,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 163}, page_content='Registry, configures it with four environment variables, mounts a volume so you don’t\\nlose your configuration every time you restart it, exposes the web interface on port 3001,\\nand declares a dependency on the dmr service.\\nThe dmr service tells Docker Model Runner to use the model defined in the MODEL_NAME\\nvariable. In our example, this will be the Qwen model you pulled earlier and DMR will\\nautomatically pull it if needed.\\nThere’s a local .env file defining the following variables:\\n• MODEL_HOST: Docker Model Runner base URL\\n• MODEL_NAME: Default model to use\\n• OPENAI_KEY: OpenAI API key (set to “na” as DMR doesn’t require it)\\nChange into the openwebui directory and deploy the app with the following command.\\nThe Open WebUI image is nearly 6GB in size and may take a while to download on a\\nslow internet connection.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 164}, page_content='10: Docker and AI\\n158\\n$ docker compose up\\n[+] Running 16/16\\n- open-webui Pulled\\n227.8s\\n<Snip>\\n[+] Running 4/4\\n- Network open-webui_default\\nCreated\\n0.0s\\n- Volume \"open-webui_open-webui\"\\nCreated\\n0.0s\\n- dmr\\nCreated\\n1.3s\\n- Container open-webui-open-webui-1\\nStarted\\n1.7s\\nAttaching to open-webui-1\\nopen-webui-1\\n| Loading...\\n<Snip>\\nFetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 278481.02it/s]\\n<Snip>\\nThe first time you start Open WebUI it downloads important files before serving the\\napp. You need to wait for these to download before connecting to the app.\\nCongratulations. You’ve installed Open WebUI as a Docker container and can connect\\nto it on http://localhost:3001. A 500: Internal Error message usually means\\nOpen WebUI is still downloading files in the background.\\nConnect to Open WebUI and use it\\nOpen a new browser tab to http://localhost:3001.\\nYou’ll need to create an admin account the first time you access it. Don’t worry though,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 164}, page_content='Connect to Open WebUI and use it\\nOpen a new browser tab to http://localhost:3001.\\nYou’ll need to create an admin account the first time you access it. Don’t worry though,\\neverything is stored locally and nothing leaves your computer.\\nOnce you’ve created your account, you’ll be automatically logged in and will see the\\nOpen WebUI interface as shown in Figure 10.6'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 165}, page_content='10: Docker and AI\\n159\\nFigure 10.6 - Open WebUI interface\\nOpen WebUI is a powerful tool, and I encourage you to investigate its features after\\nyou’ve completed the chapter. For now, Figure 10.6 highlights three important elements.\\nClicking the model selector dropdown lets you select from the models you’ve already\\ndownloaded to Docker Model Runner. If you download new models, they’ll appear in\\nthe list. Changing the model will update the active model shown in the middle of the\\nscreen. Finally, you talk with the chatbot via the prompt box.\\nHowever, before asking your chatbot any questions, I recommend you give it a cus-\\ntomized system prompt so that it responds in a way that’s useful to you. A system prompt\\nis a set of instructions you give the AI model to help it respond in ways that are helpful\\nto you.\\nTo do this, click your user in the bottom left corner, choose Settings > General, and\\nenter a new system prompt. I used the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 165}, page_content='to you.\\nTo do this, click your user in the bottom left corner, choose Settings > General, and\\nenter a new system prompt. I used the following:\\nGive simple answers. Limit responses to two sentences. Never ask if you can help with anything\\nelse.\\nBe sure to click Save to apply your changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 166}, page_content='10: Docker and AI\\n160\\nNow, ask your chatbot some questions to see if it’s useful and maintains a conversational\\nhistory.\\nFigure 10.7 shows a very brief conversation asking how far away the moon is and then\\nthe sun. I phrased the second question to test if the chatbot is intelligent enough to rec-\\nognize it as a follow-up to the previous question. You can see the chatbot remembered\\nthe first question and gave a contextually appropriate answer for the second question.\\nFigure 10.7 - Conversational history\\nYou can also see that Open WebUI saved the conversation in the left navigation pane\\nand that the prompt box has options for executing code, voice recording, and much\\nmore. As previously mentioned, I recommend you play around with Open WebUI’s\\nadvanced features, as you can easily create a powerful local chatbot with many of the\\nfeatures of ChatGPT, Claude, and other advanced chatbot apps.\\nRunning models in containers'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 166}, page_content='advanced features, as you can easily create a powerful local chatbot with many of the\\nfeatures of ChatGPT, Claude, and other advanced chatbot apps.\\nRunning models in containers\\nRunning models in containers is no longer recommended, and I’ve only included this\\nshort section for reference. I do not recommend you complete the example.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 167}, page_content='10: Docker and AI\\n161\\nAs previously stated, AI models run fastest on AI acceleration hardware like GPUs and\\nNPUs. However, exposing them inside containers is very difficult. So much so that\\nDocker containers can only access modern CUDA-capable NVIDIA GPUs, and even\\nthese require the complex installation of the NVIDIA Container Toolkit.\\nIn summary, if you run Docker on a host with CUDA-capable NVIDIA GPUs and install\\nthe NVIDIA Container Toolkit, you can run models inside containers and leverage\\nthe GPUs. If your host has NPUs, TPUs, or GPUs from another manufacturer, models\\ninside containers will run slowly on the host’s CPUs.\\nThe ai-compose folder has two Compose files to deploy a three-tier chatbot like the\\none you deployed in the Use Docker Model Runner with Compose section. The biggest\\ndifference is that this version talks to a containerized Ollama server instead of Docker\\nModel Runner. The two Compose files are:\\n• compose.yaml: Runs the model on CPUs'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 167}, page_content='difference is that this version talks to a containerized Ollama server instead of Docker\\nModel Runner. The two Compose files are:\\n• compose.yaml: Runs the model on CPUs\\n• gpu-compose.yaml: Runs the model on NVIDIA GPUs if you have NVIDIA GPUs\\nand have installed the NVIDIA Container Toolkit (outside of the scope of this\\nbook)\\nThe ollama service, shown below, replaces Docker Model Runner. It pulls a pre-created\\nimage that runs an Ollama server, executes a script to pull a Mistral model into the\\ncontainer, and provides inference. It stores the pulled model in the volume, defines a\\nhealthcheck, and sets some resource limits.\\nollama:\\nimage: nigelpoulton/gsd-book:chat-model\\nvolumes:\\n- ollama_data:/root/.ollama\\nenvironment:\\n- MODEL=${MODEL:-mistral:latest}\\nhealthcheck:\\n<Snip>\\ndeploy:\\nresources:\\nlimits:\\nmemory: 8G\\nYou can start and manage the app with the usual docker compose commands. However,\\nthe app maps to port 3000 on your host and will conflict with the chatbot from earlier in'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 167}, page_content='limits:\\nmemory: 8G\\nYou can start and manage the app with the usual docker compose commands. However,\\nthe app maps to port 3000 on your host and will conflict with the chatbot from earlier in\\nthe chapter. If you want to run this app (not recommended), manually edit the Compose\\nfile to map it to a different port.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 168}, page_content='10: Docker and AI\\n162\\nClean up\\nCongratulations on completing the examples and running local models with Docker\\nModel Runner.\\nIf you followed the examples, you’ll have all of the following running and downloaded.\\n• Docker Model Runner and at least one downloaded model\\n• Two Compose apps (Open WebUI chatbot, and Remix chatbot)\\nRunning the following command from within the openwebui directory will delete the\\nOpen WebUI chatbot app along with its images, networks, and volumes. It will not stop\\nDMR or delete any local models.\\n$ docker compose down --rmi all --volumes\\n[+] Running 2/2\\n- Container openwebui-open-webui-1\\nRemoved\\n1.4s\\n- dmr\\nRemoved\\n0.0s\\n- Image ghcr.io/open-webui/open-webui:main\\nRemoved\\n1.0s\\n- Volume openwebui_open-webui\\nRemoved\\n0.1s\\n- Network openwebui_default\\nRemoved\\n0.2s\\nDon’t worry about the line saying dmr is removed. It’s removing the dmr Compose\\nservice and not disabling Docker Model Runner on the host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 168}, page_content='Removed\\n0.1s\\n- Network openwebui_default\\nRemoved\\n0.2s\\nDon’t worry about the line saying dmr is removed. It’s removing the dmr Compose\\nservice and not disabling Docker Model Runner on the host.\\nChange into the dmr directory and run the same command if you want to delete the\\nRemix chatbot app from the Use Docker Model Runner with Compose section.\\nYou can list your downloaded models with docker model ls and delete them with\\ndocker model rm.\\nFinally, you can disable DMR in Docker Desktop by going to the Settings page, clicking\\nFeatures in development, and then unchecking the Enable Docker Model Runner\\ncheckbox.\\nDocker Model Runner – The commands\\n• docker model status shows if DMR is running and prints basic runtime\\ninformation\\n• docker model pull downloads models from Docker Hub or other OCI-compliant\\nregistries that support models as a mediaType\\n• docker model push pushes models to Docker Hub and other OCI-compliant\\nregistries that support models as a mediaType'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 169}, page_content='10: Docker and AI\\n163\\n• docker model ls lists the models pulled to your local model store\\n• docker model inspect shows detailed model information, including tag, format,\\narchitecture, quantization, and more\\n• docker model rm deletes models from your local store\\nChapter Summary\\nIn this chapter, you learned that Docker Model Runner (DMR) is the best way to run\\nlocal AI models with Docker. It runs as a host process outside of the Docker Engine and\\nexecutes models directly on host hardware rather than inside containers. This gives\\nit access to a wider range of AI acceleration hardware than containers. It dynamically\\nloads and unloads models based on demand and serves them via OpenAI-compatible\\nendpoints. It has a pluggable runtime layer that defaults to llama.cpp.\\nRight now, DMR is a feature of Docker Desktop and works on Mac and Windows.\\nHowever, it will soon be integrated with Docker CE so that we can use it on Linux and\\nas part of CI/CD pipelines.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 169}, page_content='Right now, DMR is a feature of Docker Desktop and works on Mac and Windows.\\nHowever, it will soon be integrated with Docker CE so that we can use it on Linux and\\nas part of CI/CD pipelines.\\nDMR is tightly integrated with the Docker CLI, the Docker API, Docker Hub, Docker\\nCompose, the Docker MCP Toolkit, and more. You learned how to pull models from\\nDocker Hub, list and inspect models, run models, and integrate DMR with Compose\\nand 3rd-party off-the-shelf apps.\\nYou can still run model servers like Ollama inside of containers, but these will usually\\nbe slower than DMR as they have access to a smaller pool of supported AI acceleration\\nhardware.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 170}, page_content='11: Docker and Wasm\\nWasm (WebAssembly) is driving the third wave of cloud computing, and Docker is\\nevolving to take advantage.\\nWe built the first wave on virtual machines (VMs), the second on containers, and\\nwe’re building the third on Wasm. Each wave drives smaller, faster, and more secure\\nworkloads, and all three are working together to drive the future of cloud computing.\\nIn this chapter, you’ll write a simple Wasm application and use Docker to containerize\\nand run it in a container. The goal is to introduce you to Wasm and show you how easy\\nit is to work with Docker and Wasm together.\\nThe terms Wasm and WebAssembly mean the same thing, and we’ll use the term Wasm.\\nI’ve divided the chapter as follows:\\n• Pre-reqs\\n• Intro to Wasm\\n• Write a Wasm app\\n• Containerize a Wasm app\\n• Deploy a Wasm app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 171}, page_content='11: Docker and Wasm\\n165\\nPre-reqs\\nYou’ll need all of the following if you plan on following along:\\n• Docker Desktop 4.37+ with Wasm enabled\\n• Rust 1.82+ with the Wasm target installed\\n• Spin 3.1+\\nAt the time of writing, support for Wasm is a beta feature in Docker Desktop and doesn’t\\nwork with Multipass Docker VMs. This may change in the future. It also means there’s a\\nhigher risk of bugs. I’ve tested the examples in this chapter on Docker Desktop 4.37.0.\\nConfigure Docker Desktop for Wasm\\nOpen the Docker Desktop UI, click the Settings icon at the top right, and make sure Use\\ncontainerd for pulling and storing images is selected on the General tab. Next, click\\nthe Features in development tab, select the Enable Wasm option and click the blue\\nApply & restart button.\\nfigure 11.2 shows some of the settings.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 172}, page_content=\"11: Docker and Wasm\\n166\\nFigure 11.2 - Docker Desktop Wasm settings\\nInstall Rust and configure for Wasm\\nSearch the web for how to install Rust and follow the instructions for your platform.\\nOnce you’ve installed Rust, run the following command to install the wasm32-wasip1\\ntarget so that Rust can compile to Wasm.\\n$ rustup target add wasm32-wasip1\\ninfo: downloading component 'rust-std' for 'wasm32-wasip1'\\ninfo: installing component 'rust-std' for 'wasm32-wasip1'\\nInstall Spin\\nSpin is a Wasm framework and runtime that makes building and running Wasm apps\\neasy.\\nSearch the web for how to install Fermyon spin and follow the instructions for your\\nsystem.\"),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 173}, page_content='11: Docker and Wasm\\n167\\nRun the following command to verify the installation.\\n$ spin --version\\nspin 3.1.0 (1aa89da 2024-12-18)\\nYou’re ready to build and run Wasm apps on your local machine.\\nIntro to Wasm and Wasm containers\\nWasm is a new type of application that is smaller, faster, and more portable than tradi-\\ntional Linux containers. However, traditional Linux containers can do a lot more than\\nWasm apps. For example, Wasm apps are currently great for AI workloads, serverless\\nfunctions, plugins, and edge devices, but not so good for complex networking or heavy\\nI/O.\\nHowever, Wasm is evolving fast and may become better at other workloads in the\\nfuture.\\nDigging a little deeper…\\nAs we’re about to see, Wasm is a new virtual machine architecture that programming\\nlanguages compile to. So, instead of compiling apps to Linux on ARM or Linux on\\nAMD, you compile them to Wasm and they’ll run on any system with a Wasm runtime.\\nFortunately, Docker Desktop ships with several Wasm runtimes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 173}, page_content='AMD, you compile them to Wasm and they’ll run on any system with a Wasm runtime.\\nFortunately, Docker Desktop ships with several Wasm runtimes.\\nRun the following command to see the list of Wasm runtimes installed as part of your\\nDocker Desktop environment. The first time you run the command, it will download\\nthe image.\\n$ docker run --rm -i --privileged --pid=host jorgeprendes420/docker-desktop-shim-manager:latest\\nio.containerd.wasmtime.v1\\nio.containerd.wws.v1\\nio.containerd.slight.v1\\nio.containerd.wasmer.v1\\nio.containerd.spin.v2\\nio.containerd.lunatic.v1\\nio.containerd.wasmedge.v1\\nMy installation has seven Wasm runtimes, including the io.containerd.spin.v2\\nruntime we’ll use in the examples.\\nThese Wasm runtimes allow containerd to deploy and manage Wasm containers. A Wasm\\ncontainer is a Wasm binary running inside a minimal scratch container so that you can\\nbuild, ship, and run them with familiar Docker tools such as the docker run command\\nand Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 173}, page_content='container is a Wasm binary running inside a minimal scratch container so that you can\\nbuild, ship, and run them with familiar Docker tools such as the docker run command\\nand Docker Hub.\\nTalk is cheap, though. Let’s see it in action.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 174}, page_content='11: Docker and Wasm\\n168\\nWrite a Wasm app\\nIn this step, you’ll use spin to create a simple web server and compile it as a Wasm app.\\nIn a later step, you’ll build, share, and run the app as a Wasm container.\\nChange into a new directory and then run the following command to create a new\\nWasm app called hello-world. Respond to the prompts as shown in the example.\\n$ spin new hello-world -t http-rust\\nDescription: Wasm app\\nHTTP path: /hello\\nThe command creates a new hello-world directory and scaffolds a simple Rust-based\\nweb app. Change into this directory and inspect the app files. If you don’t have the tree\\ncommand, you can run an ls -l for similar results.\\n$ cd hello-world\\n$ tree\\n.\\n├──Cargo.toml\\n├──spin.toml\\n└──src\\n└──lib.rs\\nWe’re only interested in the spin.toml and src/lib.rs files.\\nEdit the src/lib.rs file and change the text inside the double quotes as shown in the\\nfollowing snippet. This configures the app to display Docker loves Wasm.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 174}, page_content='Edit the src/lib.rs file and change the text inside the double quotes as shown in the\\nfollowing snippet. This configures the app to display Docker loves Wasm.\\nuse spin_sdk::http::{IntoResponse, Request, Response};\\n<Snip>\\nOk(http::Response::builder()\\n.status(200)\\n.header(\"content-type\", \"text/plain\")\\n.body(\"Docker loves Wasm\")?)\\n<<---- Change text inside quotes\\n.build())\\n}\\nOnce you’ve saved your changes, run a spin build command to compile the app as a\\nWasm binary.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 175}, page_content='11: Docker and Wasm\\n169\\n$ spin build\\nBuilding component hello-world with `cargo build --target wasm32-wasip1 --release`\\n<Snip>\\nFinished building all Spin components\\nIf you look at the first line of the output, you’ll see it’s running a more complex cargo\\nbuild command that compiles the app as a Wasm binary.\\nRun another tree command to see the Wasm binary.\\n$ tree\\n<Snip>\\n└──target\\n└──wasm32-wasip1\\n└──release\\n└──hello_world.wasm\\nThe output is much longer this time, and I’ve trimmed the example in the book so you\\nonly see the hello_world.wasm binary. This is the Wasm app, and it will run on any\\nsystem with the spin Wasm runtime.\\nYou’ll containerize the app in the next section, but you should test it works before\\nproceeding.\\nRun a spin up command to start the app using the local spin runtime you installed\\nearlier.\\n$ spin up\\nLogging component stdio to \".spin/logs/\"\\nServing http://127.0.0.1:3000\\nAvailable Routes:\\nhello-world: http://127.0.0.1:3000/hello'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 175}, page_content='earlier.\\n$ spin up\\nLogging component stdio to \".spin/logs/\"\\nServing http://127.0.0.1:3000\\nAvailable Routes:\\nhello-world: http://127.0.0.1:3000/hello\\nPoint your browser to http://127.0.0.1:3000/hello and make sure the app works.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 176}, page_content='11: Docker and Wasm\\n170\\nFigure 11.3 - Wasm app running locally\\nCongratulations. You just built a simple web server, compiled it to Wasm, and executed\\nit locally using spin! In the next section, you’ll containerize it and run it in Docker.\\nPress Ctrl-C to kill the app.\\nContainerize a Wasm app\\nDocker Desktop lets you containerize Wasm apps so you can use familiar Docker tools\\nto push and pull them to OCI registries and run them inside containers.\\nAs always, you need a Dockerfile that tells Docker how to package the app as an image.\\nCreate a new file called Dockerfile in your current directory and populate it with the\\nfollowing three lines.\\nFROM scratch\\nCOPY /target/wasm32-wasip1/release/hello_world.wasm .\\nCOPY spin.toml .\\nThe file references the scratch empty base image because Wasm containers don’t need a\\nLinux OS.\\nThe two COPY instructions copy the hello_world.wasm Wasm app and the spin.toml\\nfile into the image.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 176}, page_content='The file references the scratch empty base image because Wasm containers don’t need a\\nLinux OS.\\nThe two COPY instructions copy the hello_world.wasm Wasm app and the spin.toml\\nfile into the image.\\nIf you look closely, you’ll see that the spin.toml file expects the Wasm app to be in the\\ntarget/wasm32-wasip1/release/ directory. However, the second COPY instruction'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 177}, page_content='11: Docker and Wasm\\n171\\nplaces it in the root folder. This means we’ll need to update the spin.toml file so\\nit knows where to find the app after the Dockerfile copies it into the image’s root\\ndirectory.\\nEdit the spin.toml file and remove the leading path for the source line as shown.\\n<Snip>\\n[component.hello-world]\\nsource = \"hello_world.wasm\"\\n<<---- Remove any leading directories so it looks like this\\n<Snip>\\nSave your changes.\\nRun the following command to containerize the Wasm app. Be sure to tag the image\\nwith your own Docker Hub username instead of mine.\\n$ docker build \\\\\\n--platform wasi/wasm \\\\\\n--provenance=false \\\\\\n-t nigelpoulton/ddd-book:wasm .\\nThe --platform wasi/wasm flag sets the image as a Wasm image.\\nSome older versions of Docker have an older builder and will fail. If this happens, try\\nrunning the same command, but change the first line to docker buildx build \\\\.\\nList the images on your system.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nwasm'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 177}, page_content='running the same command, but change the first line to docker buildx build \\\\.\\nList the images on your system.\\n$ docker images\\nREPOSITORY\\nTAG\\nIMAGE ID\\nCREATED\\nSIZE\\nnigelpoulton/ddd-book\\nwasm\\n7b55889f1006\\n28 seconds ago\\n104kB\\nSee how the Wasm image looks like a regular image, just smaller.\\nYou can push and pull the image to Docker Hub and other OCI registries as normal.\\nThe following command pushes the image to one of my repos in Docker Hub. Be sure to\\ntag the image with your own Docker username.\\n$ docker push nigelpoulton/ddd-book:wasm\\nThe push refers to repository [docker.io/nigelpoulton/ddd-book]\\n301823195c36: Pushed\\n8966226af76a: Pushed\\nwasm: digest: sha256:7b55889f1006285ed6c394dcc7a56aca8955c107587b2216340e592299b8ae4c size: 695'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 178}, page_content='11: Docker and Wasm\\n172\\nIf you look at Docker Hub, you can see it’s recognized it as a wasi/wasm image. You’ll\\nalso see there’s no vulnerability analysis data. This is because image scanning tools can’t\\nanalyze Wasm images yet.\\nFigure 11.4 - Wasm image on Docker Hub\\nRun a Wasm container\\nNow that you’ve packaged the Wasm app as an OCI image and pushed it to a registry,\\nyou can run it as a container.\\nThe following command runs it in a new container called wasm-ctr and maps it to\\nport 5556 on your Docker host. The --runtime flag makes sure Docker executes the\\ncontainer with the spin Wasm runtime. Older versions of Docker Desktop may not have\\nthe spin runtime and will fail.\\n$ docker run -d --name wasm-ctr \\\\\\n--runtime=io.containerd.spin.v2 \\\\\\n--platform=wasi/wasm \\\\\\n-p 5556:80 \\\\\\nnigelpoulton/ddd-book:wasm /\\nYou can check it’s running with a regular docker ps command.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 179}, page_content='11: Docker and Wasm\\n173\\nConnect your browser to http://localhost:5556/hello to see the app.\\nFigure 11.5 - Wasm app running in container\\nCongratulations, your Wasm app is running inside a Wasm container.\\nClean up\\nRun the following commands to delete the container and the local image. Use your own\\nimage name when deleting the image.\\n$ docker rm wasm-ctr -f\\nwasm-ctr\\n$ docker rmi nigelpoulton/ddd-book:wasm\\nUntagged: nigelpoulton/ddd-book:wasm\\nDeleted: sha256:7b55889f1006285ed6c394dcc7a56aca8955c107587b2216340e592299b8ae4c\\nYou’ll still have a copy of the image on Docker Hub and the spin app in your local\\nfilesystem. Feel free to delete these as well.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 180}, page_content='11: Docker and Wasm\\n174\\nChapter summary\\nIn this chapter, you containerized a Wasm app and ran it in a Wasm container.\\nWasm is a new technology driving a new wave of cloud computing. Wasm apps are\\nsmaller, faster, more secure, and more portable than traditional Linux containers.\\nHowever, they’re not as flexible. For example, at the time of writing, Wasm apps aren’t\\ngreat for apps with heavy I/O requirements or complex networking. This will change\\nquickly as the Wasm ecosystem is evolving fast.\\nFortunately, Docker already works with Wasm, and Docker Desktop ships with a\\nfew popular Wasm runtimes. This means you can use industry-standard tools such as\\ndocker build and docker run to containerize and run Wasm apps. You can even push\\nthem to OCI registries such as Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 181}, page_content='12: Docker Swarm\\nThis chapter that shows you how to deploy a multi-node Swarm cluster and how to run\\napps on it.\\nIt’s a smaller chapter than in previous editions because Swarm is declining in popularity\\nand is no longer core to modern Docker workflows. If you need more of a deep dive,\\nyou can access the longer version in the swarm-chapters folder of the book’s GitHub\\nrepo. I’ve rewritten this shorter chapter to make way for adding the Docker and AI\\nchapter without increasing the cost of the book.\\nI’ve divided this chapter as follows:\\n• Swarm primer\\n• Build a swarm\\n• Deploy a Swarm app\\nThroughout the chapter, we’ll use Swarm with a capital “S” to refer to the Docker Swarm\\norchestration technology, and we’ll use swarm with a lower case “s” to refer to a cluster\\nof Docker nodes.\\nSwarm primer\\nThe orchestration wars were back in the mid-2010s when technologies like Docker\\nSwarm, HashiCorp Nomad, Mesosphere DC/OS, and Kubernetes battled it out to see'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 181}, page_content='of Docker nodes.\\nSwarm primer\\nThe orchestration wars were back in the mid-2010s when technologies like Docker\\nSwarm, HashiCorp Nomad, Mesosphere DC/OS, and Kubernetes battled it out to see\\nwhich would be crowned the de facto container orchestration platform. Fast forward to\\nnow, and it’s clear that Kubernetes came out on top and has the largest and most vibrant\\necosystem. However, Docker Swarm continues to have small followings and can be\\nbetter than Kubernetes for certain use cases. For example, Docker Swarm can be a great\\nsolution for small businesses with small requirements that don’t need the steep learning\\ncurve and overheads of a full Kubernetes environment.\\nWith this in mind, Docker Swarm is two things:\\n1. A secure cluster of Docker nodes (swarm with a little “s”)\\n2. An intelligent application orchestrator (Swarm with a big “S”)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 182}, page_content='12: Docker Swarm\\n176\\nAs you’re about to see, a swarm is a cluster of Docker nodes with one or more manager\\nnodes and optional worker nodes. Managers run the control plane services that secure\\nthe cluster and provide the orchestration intelligence. Workers run user apps. Both\\ntypes of nodes can be physical machines, VMs, cloud instances, and more. The only\\nrequirements are that they run Docker and can communicate over reliable networks.\\nBy default, swarm managers run user apps and control plane services. This is fine for lab\\nenvironments, but you should probably dedicate them to control plane services in busy\\nproduction environments.\\nBuild a swarm\\nIn this section, you’ll build two or more Docker nodes into a highly available swarm.\\nI recommend you go to http://https://labs.play-with-docker.com/ and spin up a\\nfew Docker nodes to follow along. You can also use tools like Multipass and VirtualBox\\nto create local VMs and install Docker on them. However, I do not recommend Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 182}, page_content='few Docker nodes to follow along. You can also use tools like Multipass and VirtualBox\\nto create local VMs and install Docker on them. However, I do not recommend Docker\\nDesktop for this chapter as it only gives you a single Docker node.\\nI’ll build the swarm shown in Figure 12.1 with three managers and two workers.\\nYour swarm can be different, but you should consider the following for production\\nenvironments:\\n• Three managers spread across availability zones for high availability\\n• Enough workers to handle application requirements\\nFigure 12.1 - Five-node swarm'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 183}, page_content='12: Docker Swarm\\n177\\nI’ve configured DNS name resolution so that nodes can communicate via name, and I’ve\\nensured port 2377 isn’t blocked on my network.\\nYou’ll complete the following steps to build your swarm:\\n• Initialize the first swarm manager\\n• Add workers (optional)\\n• Add additional managers\\nIf you only have a small lab, you can build a swarm with just two managers.\\nInitialize your swarm\\nLog on to the node you want to make your first manager and run the following com-\\nmand. If the node has multiple IPs, you’ll be prompted to use the --advertise-addr flag.\\nIf this happens, use the node’s primary IP address.\\n$ docker swarm init\\nSwarm initialized: current node (b8slc7l29tgdetxgy8acy1k1q) is now a manager.\\nTo add a worker to this swarm, run the following command:\\ndocker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nCongratulations. You have a single-node swarm.\\nAdd workers\\nAdding worker nodes is optional, as your managers will also run user apps. Only add'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 183}, page_content='Congratulations. You have a single-node swarm.\\nAdd workers\\nAdding worker nodes is optional, as your managers will also run user apps. Only add\\nworkers if your lab has enough nodes and resources.\\nIf you want to add workers, copy the docker swarm join command from the previous\\noutput and paste it into the nodes you want as workers. Be sure to copy the entire\\ncommand, including the join token.\\nwrkr-1\\n$ docker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nThis node joined a swarm as a worker.\\nwrkr-2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 184}, page_content='12: Docker Swarm\\n178\\n$ docker swarm join --token SWMTKN-1-2hl6...-...3lqg 172.31.40.192:2377\\nThis node joined a swarm as a worker.\\nSwitch back to your manager node and run the following command to see your swarm.\\n$ docker node ls\\nMANAGER\\nENGINE\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nSTATUS\\nVERSION\\nb8slc7l29tgdetxgy8acy1k1q *\\nnode1\\nReady\\nActive\\nLeader\\n27.3.1\\nw3e321uxty2quuqnsk1w19kfc\\nnode4\\nReady\\nActive\\n27.3.1\\nkbodotf68tz8dne2ktk1g5mt4\\nnode5\\nReady\\nActive\\n27.3.1\\nGreat. You’ve got one manager and two workers. Managers have either Leader or\\nReachable in the MANAGER STATUS column, whereas workers leave this column empty.\\nAdd managers for high availability\\nMost production swarms run three managers for high availability. This means one\\nmanager can fail and Swarm operations will continue via the surviving managers.\\nHowever, this is cluster availability and not application availability. For example, if the\\nfailed manager was running the only instance of a database, that database will be\\nunavailable.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 184}, page_content='However, this is cluster availability and not application availability. For example, if the\\nfailed manager was running the only instance of a database, that database will be\\nunavailable.\\nRun the following command from your manager node to extract the command for\\nadding more managers.\\n$ docker swarm join-token manager\\nTo add a manager to this swarm, run the following command:\\ndocker swarm join --token SWMTKN-1-2f4s47lja0z1ddkgv...6ytm3qnq9bu8uei9stiu 172.31.40.192:2377\\nCopy the long docker swarm join command and run it on the nodes you want to add\\nas additional managers.\\nOnce you’ve added all your managers and workers, run another docker node ls to see\\nyour swarm. You can run it from any manager node.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 185}, page_content='12: Docker Swarm\\n179\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\nENGINE VER\\nb8slc7l29tgdetxgy8acy1k1q *\\nnode1\\nReady\\nActive\\nLeader\\n27.3.1\\ny43jr1d754pbjv3arlhpn9pqw\\nnode2\\nReady\\nActive\\nReachable\\n27.3.1\\nk1npnfxr7ykueac4jovmyiv0b\\nnode3\\nReady\\nActive\\nReachable\\n27.3.1\\nw3e321uxty2quuqnsk1w19kfc\\nnode4\\nReady\\nActive\\n27.3.1\\nkbodotf68tz8dne2ktk1g5mt4\\nnode5\\nReady\\nActive\\n27.3.1\\nNotice how one of the managers is showing as the Leader and the other two as Reach-\\nable. This is because Swarm operates an active/passive multi-manager high-availability\\nmodel where one manager controls the cluster and the others provide backup. The\\nasterisk (*) indicates the manager you executed the command from.\\nYour swarm is ready to run apps.\\nDeploy Swarm app\\nIn this section, you’ll deploy an app to your swarm and see Swarm’s orchestration\\ncapabilities. These include scheduling apps across cluster nodes, scaling apps up and\\ndown, self-healing from app failures, and performing rolling updates.\\nThe app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 185}, page_content='capabilities. These include scheduling apps across cluster nodes, scaling apps up and\\ndown, self-healing from app failures, and performing rolling updates.\\nThe app\\nFigure 12.2 shows the application you’ll deploy. It’s a multi-container microservices\\napplication with:\\n• Two services (web-fe and redis)\\n• An encrypted overlay network (counter-net)\\n• A volume (counter-vol)\\n• A published port (5001)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 186}, page_content='12: Docker Swarm\\n180\\nFigure 12.2 - The sample app\\nTerminology: Throughout the remainder of the chapter, we’ll use the\\nterm service to refer to the Docker service object that manages one or more\\nidentical containers in a Swarm app. We’ll use the terms container and replica\\ninterchangeably.\\nLog on to a swarm manager and clone the book’s GitHub repo.\\n$ git clone https://github.com/nigelpoulton/ddd-book.git\\nChange into the ddd-book/swarm-new directory.\\n$ cd ddd-book/swarm-new\\nThe application’s Compose file defines a network called counter-net, a volume called\\ncounter-vol, and two services called web-fe and redis.\\nI’ve annotated the listing to draw your attention to the major parts.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 187}, page_content='12: Docker Swarm\\n181\\nnetworks:\\n----┐\\ncounter-net:\\n|\\ndriver: overlay\\n| Deploy an encrypted overlay network called *counter-net*\\ndriver_opts:\\n|\\nencrypted: \\'yes\\'\\n----┘\\nvolumes:\\ncounter-vol:\\n<<--- Create a volume called *counter-vol*\\nservices:\\nweb-fe:\\n----┐\\nimage: nigelpoulton/ddd-book:swarm-app\\n|\\ncommand: python app.py\\nw\\ndeploy:\\ne\\nreplicas: 4\\nb\\n<<---- Deploy four replicas\\nupdate_config:\\n-\\n<<---- Next 3 lines define how to update the app\\nparallelism: 2\\nf\\n<<---- Update two replicas at a time\\ndelay: 10s\\ne\\n<<---- Wait 10 seconds after each pair\\nfailure_action: rollback\\n<<---- Rollback if there\\'s a failure\\nrestart_policy:\\ns\\ncondition: on-failure\\ne\\n<<---- Restart replicas if they fail\\ndelay: 5s\\nr\\n<<---- Wait five seconds between restart attempts\\nmax_attempts: 3\\nv\\n<<---- Only try three restarts\\nwindow: 120s\\ni\\n<<---- Give up after trying for two minutes\\nnetworks:\\nc\\n- counter-net\\ne\\n<<---- Attach to the *counter-net* network\\nports:\\n|\\n- \"5001:8080\"\\n----┘\\n<<---- Map the app to 5001 on the host\\nredis:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 187}, page_content='i\\n<<---- Give up after trying for two minutes\\nnetworks:\\nc\\n- counter-net\\ne\\n<<---- Attach to the *counter-net* network\\nports:\\n|\\n- \"5001:8080\"\\n----┘\\n<<---- Map the app to 5001 on the host\\nredis:\\n----┐\\n<<---- Redis service\\nimage: \"redis:alpine\"\\n|\\nnetworks:\\n|\\ncounter-net:\\n|\\n<<---- Join the *counter-net* network\\nvolumes:\\n|\\n- type: volume\\n|\\nsource: counter-vol\\n|\\n<<---- Mount the *counter-vol* volume to\\ntarget: /app\\n----┘\\n<<---- /data in the container\\nLet’s step through it.\\nThe networks key defines an encrypted overlay network called counter-net, the\\nvolumes key defines a volume called counter-vol, and the services block defines two\\nservices.\\nThe web-fe service pulls an image from Docker Hub, sets the start command for\\neach replica, and tells Swarm to deploy four identical containers for this service. The\\ndeploy.update_config block tells Swarm how to perform updates whenever a new\\nimage or config change occurs. This file tells Swarm to update two replicas in parallel,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 187}, page_content='deploy.update_config block tells Swarm how to perform updates whenever a new\\nimage or config change occurs. This file tells Swarm to update two replicas in parallel,\\nwait 10 seconds before updating the next two, and perform a rollback if it encounters\\nfailures. The deploy.restart_policy block tells Swarm to restart replicas if they fail,\\nto wait five seconds after each restart attempt, to attempt a maximum of three restarts,\\nand to stop trying after two minutes. It joins all replicas to the counter-net network and\\nmaps port 8080 on each replica to 5001 on the host the replica is running on.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 188}, page_content='12: Docker Swarm\\n182\\nThe redis service pulls an image from Docker Hub, joins the counter-net network,\\nand mounts the counter-vol volume to /data in its container.\\nEncrypting the network keeps application traffic private but incurs a performance\\npenalty that varies based on factors such as traffic type and traffic flow. However, it’s\\nusually around 10%, but you should perform your own testing.\\nDeploy the app\\nA vital part of Swarm is the concept of desired state. This is jargon for what your app\\nshould look like and is defined in the Compose file. In our example, desired state can be\\nsummarised as four replicas of the web-fe service, a single replica of the redis service,\\nand all the networks, volumes, and port mappings.\\nYou’ll need to run the commands in this section from the ddd-book/swarm-new folder of\\nthe manager you downloaded the book’s GitHub repo to.\\nRun the following command to deploy the app and call it ddd.\\n$ docker stack deploy -c compose.yaml ddd'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 188}, page_content='the manager you downloaded the book’s GitHub repo to.\\nRun the following command to deploy the app and call it ddd.\\n$ docker stack deploy -c compose.yaml ddd\\nCreating network ddd_counter-net\\nCreating volume ddd_counter-vol\\nCreating service ddd_web-fe\\nCreating service ddd_redis\\nSwarm has deployed the app and observed state matches desired state — you asked for four\\nreplicas of the web-fe service and a single replica of the redis service, and that’s what\\nyou’ve got.\\nRun the following commands to confirm this.\\n$ docker stack ps ddd\\nDESIRED\\nCURRENT\\nID\\nNAME\\nIMAGE\\nNODE\\nDESIRED\\nSTATE\\npgeupeqyqg5t\\nddd_redis.1\\nredis:alpine\\nwrk2\\nRunning\\nRunning 8 min\\nqbtkiz1p9v1n\\nddd_web-fe.1\\nnigelpoulton/ddd-book:swarm-app\\nwrk1\\nRunning\\nRunning 8 min\\nwbs2ndy22xhh\\nddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nRunning\\nRunning 8 min\\nskqz1mbreluo\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 min\\nsg5u9b6t8m44\\nddd_web-fe.4\\nnigelpoulton/ddd-book:swarm-app\\nmgr3\\nRunning\\nRunning 8 min'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 188}, page_content='mgr1\\nRunning\\nRunning 8 min\\nskqz1mbreluo\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 min\\nsg5u9b6t8m44\\nddd_web-fe.4\\nnigelpoulton/ddd-book:swarm-app\\nmgr3\\nRunning\\nRunning 8 min\\n$ docker stack services ddd\\nID\\nNAME\\nMODE\\nREPLICAS\\nIMAGE\\nPORTS\\notr7927s9m1s\\nddd_redis\\nrepl\\n1/1\\nredis:alpine\\nrsm3x02o9fwc\\nddd_web-fe\\nrepl\\n4/4\\nnigelpoulton/ddd-book:swarm-app\\n*:5001->8080\\nIf you look closely, you’ll see that Swarm has evenly balanced the four web-fe replicas\\nacross your nodes. You can also see the web-fe service is publishing port 5001.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 189}, page_content='12: Docker Swarm\\n183\\nPoint your browser to the IP address of one of your Swarm nodes on port 5001.\\nFigure 12.3\\nManage the app\\nYou can manage Swarm apps in two ways:\\n• Imperatively\\n• Declaratively\\nThe imperative method is where you run Docker CLI commands to make changes. For\\nexample, you can use the docker service scale command to increase and decrease the\\nnumber of service replicas.\\nThe declarative method is the preferred method, where you make all changes via the\\nCompose file. For example, if you want to change the number of replicas for a service,\\nyou edit the Compose file and run another docker stack deploy command.\\nThe following example demonstrates why you should manage Swarm apps declaratively.\\nImagine you’ve deployed an app from a Compose file that defines reporting and catalog services.\\nIt’s currently running one replica of the reporting service, but it’s year-end and demand on the\\nreporting service has gone through the roof. A colleague decides to run an imperative docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 189}, page_content='It’s currently running one replica of the reporting service, but it’s year-end and demand on the\\nreporting service has gone through the roof. A colleague decides to run an imperative docker\\nservice scale command to increase the number of reporting replicas to 10. This fixes the\\nissue, but the observed state of the app no longer matches the desired state defined in its Compose\\nfile — the Compose file only defines one replica, but there are 10 on the cluster. Later in the\\nday, you roll out a new version of the catalog service by specifying a new image version in\\nthe Compose file and running a docker stack deploy command. This pushes the updated\\nCompose file to Swarm as your new desired state, and Swarm compares it to the observed state of'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 190}, page_content='12: Docker Swarm\\n184\\nthe cluster. When it does this, it sees you’ve requested a new version of the app and schedules the\\nupdates. However, it will also reduce the number of replicas from 10 down to 1, as the Compose\\nfile wasn’t used to increase the count to 10. This will cause the reporting service to start running\\nslowly again.\\nThis is why you should make all changes declaratively via your Compose files, and you\\nshould manage your Compose files in a version control system.\\nWith this in mind, let’s complete the following as a single task:\\n• Increase the number of web-fe replicas from 4 to 10\\n• Update the web-fe service to the newer swarm-appv2 image\\nYou know you should do this declaratively, so let’s edit the following lines in the Com-\\npose file.\\n<Snip>\\nservices:\\nweb-fe:\\nimage: nigelpoulton/ddd-book:swarm-appv2\\n<<---- changed to swarm-appv2\\ncommand: python app.py\\ndeploy:\\nreplicas: 10\\n<<---- Changed from 4 to 10\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 190}, page_content='pose file.\\n<Snip>\\nservices:\\nweb-fe:\\nimage: nigelpoulton/ddd-book:swarm-appv2\\n<<---- changed to swarm-appv2\\ncommand: python app.py\\ndeploy:\\nreplicas: 10\\n<<---- Changed from 4 to 10\\n<Snip>\\nSave your changes and redeploy the app. This will send the updated Compose file to the\\nswarm manager, and Swarm will roll out a new version of the web-fe service with all 10\\nreplicas running the new image.\\n$ docker stack deploy -c compose.yaml ddd\\nUpdating service ddd_web-fe (id: rsm3x02o9fwcftt3a87fqcabq)\\nUpdating service ddd_redis (id: otr7927s9m1s5mkz326243kv3)\\nRun a docker stack ps to see the rollout’s progress.\\n$ docker stack ps ddd\\nNAME\\nIMAGE\\nNODE\\nDESIRED\\nCURRENT STATE\\nddd_web-fe.1\\nnigelpoulton/ddd-book:swarm-app\\nwrk1\\nRunning\\nRunning 8 mins ago\\nddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-appv2\\nmgr1\\nRunning\\nRunning 13 secs ago\\n\\\\_ddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nShutdown\\nShutdown 26 secs ago\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 mins ago\\n<Snip>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 190}, page_content='mgr1\\nRunning\\nRunning 13 secs ago\\n\\\\_ddd_web-fe.2\\nnigelpoulton/ddd-book:swarm-app\\nmgr1\\nShutdown\\nShutdown 26 secs ago\\nddd_web-fe.3\\nnigelpoulton/ddd-book:swarm-app\\nmgr2\\nRunning\\nRunning 8 mins ago\\n<Snip>\\nI’ve trimmed the output, and I’ve only listed some of the replicas. However, you can see a\\nfew things.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 191}, page_content='12: Docker Swarm\\n185\\nSwarm has evenly balanced the six new replicas across both worker nodes (not shown in\\nthe book).\\nThe top line shows the ddd_web-fe.1 replica running the old image for the last 8\\nminutes. The next two lines show the ddd_web-fe.2 replica. You can see that the\\nold replica was running the old image and that it was shut down 26 seconds ago and\\nreplaced with a new replica running the new image. The new replica has been running\\nfor 13 seconds.\\nThe last line shows the ddd_web-fe.3 replica is still running the old version.\\nSwarm immediately adds the six new replicas, but honors the update settings in the\\ndeploy.update_config section of your Compose file for existing replicas. This means\\nit updates the four original replicas two at a time and waits 10 seconds before updating\\nanother two.\\nBefore moving on, it’s important to clarify the reconciliation process that just happened.\\nThe application was running four web-fe replicas, all based on the swarm-app image,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 191}, page_content='another two.\\nBefore moving on, it’s important to clarify the reconciliation process that just happened.\\nThe application was running four web-fe replicas, all based on the swarm-app image,\\nand this was recorded on the Swarm as desired state. We edited the Compose file and\\nchanged all web-fe replicas to use the newer swarm-appv2 image and increased the\\nreplica count from four to ten. We saved our changes and ran a docker stack deploy\\ncommand to push this new desired state to Swarm. Shortly after, Swarm compared\\nthe observed state of the cluster with the new desired state and noticed it had four\\nweb-fe replicas running the swarm-app image but should actually have ten web-fe\\nreplicas running the swarm-appv2 image. As such, it deleted the existing four replicas\\nand replaced them with ten new replicas. It even followed rules you defined in the\\ndeploy.update_config section of the Compose file.\\nRefresh your browser to see the updated version of the app.\\nFigure 12.4 - The updated app'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 192}, page_content='12: Docker Swarm\\n186\\nCongratulations, you’ve deployed and managed a Swarm app.\\nClean up\\nIf you’ve been following along, you’ve deployed a Swarm app with two services, a\\nnetwork, and a volume.\\nRun the following command to delete the app. Be warned though, it deletes it without\\nrequesting confirmation.\\n$ docker stack rm ddd\\nRemoving service ddd_redis\\nRemoving service ddd_web-fe\\nRemoving network ddd_counter-net\\nThe command deleted the network and services, but not the volume. This is because\\nSwarm decouples volume lifecycles from containers and services.\\nRun the following command on the node that hosted the redis replica. It will delete the\\nvolume.\\n$ docker volume rm ddd_counter-vol\\nddd_counter-vol\\nYou can delete your Swarm by running a docker swarm leave command on all swarm\\nnodes. You should remove the leader node last, and you may have to use the --force\\nflag.\\nDocker Swarm – The Commands\\n• docker swarm init initializes a new Swarm and makes the node the first manager\\nof the Swarm.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 192}, page_content='flag.\\nDocker Swarm – The Commands\\n• docker swarm init initializes a new Swarm and makes the node the first manager\\nof the Swarm.\\n• docker stack deploy is the command you’ll run to deploy and update Swarm\\napps. You need to specify the Compose file and the name of the app.\\n• docker stack ls lists all Swarm apps and shows the number of services in each.\\n• docker stack ps gives you detailed information about a Swarm app. It tells you\\nwhich node each replica is running on, which images they’re based on, and shows\\nthe desired state and current state of each replica.\\n• docker stack services gives you a line of information for each application\\nservice and includes useful information such as replication mode, how many\\nreplicas, and port mappings.\\n• docker stack rm deletes a Swarm app and doesn’t ask for confirmation.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 193}, page_content='12: Docker Swarm\\n187\\nChapter Summary\\nDocker Swarm lets you group multiple Docker nodes into a secure, highly available\\ncluster and provides advanced application orchestration services similar to Kubernetes.\\nWorking with Swarm is a good way to kick-start your Kubernetes learning.\\nYou built a multi-node swarm, deployed an app to it, scaled the app, and performed a\\nlive rollout. And you did it all declaratively via a Compose file.\\nIf you want to learn Kubernetes, check out my Kubernetes books:\\n• Quick Start Kubernetes: The fastest way to master Kubernetes fundamentals.\\n• The Kubernetes Book: The best-selling Kubernetes book that goes into all the\\ndetail.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 194}, page_content='13: Docker Networking\\nIt’s always the network!\\nAny time we experience infrastructure issues, we always blame the network. One of the\\nreasons we do this is that networks are at the center of everything. With this in mind, it’s\\nimportant you have a strong understanding of Docker networking.\\nIn the early days of Docker, networking was hard. Fortunately, these days it’s almost a\\npleasure ;-)\\nThis chapter will get you up to speed with the fundamentals of Docker networking.\\nYou’ll learn all the theory behind the Container Network Model (CNM) and libnetwork, and\\nyou’ll get your hands dirty with lots of examples. You’ll learn about overlay networks in\\nthe next chapter.\\nI’ve divided the chapter into the following sections:\\n• Docker networking – the TLDR\\n• Docker networking theory\\n• Single-host bridge networks\\n• External access via port mappings\\n• Connecting to existing networks and VLANs\\n• Service Discovery\\n• Ingress load balancing\\nA few quick things before we start.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 194}, page_content='• Single-host bridge networks\\n• External access via port mappings\\n• Connecting to existing networks and VLANs\\n• Service Discovery\\n• Ingress load balancing\\nA few quick things before we start.\\nEverything we’ll cover relates to Linux containers, and I recommend you follow along\\nusing something like Multipass or Play with Docker, as they give you easy access to\\nsome of the Linux commands we’ll use. I don’t recommend following along on Docker\\nDesktop as it runs everything inside a Linux VM and you won’t have access to the Linux\\ncommands.\\nSome of the examples explain how networking works on a swarm. You’ll only be able to\\nfollow these if you’re following along with a Swarm cluster.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 195}, page_content='13: Docker Networking\\n189\\nDocker Networking – The TLDR\\nDocker runs microservices applications comprised of many containers that work\\ntogether to form the overall app. These containers need to be able to communicate,\\nand some will have to connect with external services, such as physical servers, virtual\\nmachines, or something else.\\nFortunately, Docker has solutions for both of these requirements.\\nDocker networking is based on libnetwork, which is the reference implementation of an\\nopen-source architecture called the Container Network Model (CNM).\\nFor a smooth out-of-the-box experience, Docker ships with everything you need\\nfor the most common networking requirements, including multi-host container-to-\\ncontainer networks and options for plugging into existing VLANs. However, the model\\nis pluggable, and the ecosystem can extend Docker’s networking capabilities via drivers\\nthat plug into libnetwork.\\nLast but not least, libnetwork also provides native service discovery and basic load'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 195}, page_content='is pluggable, and the ecosystem can extend Docker’s networking capabilities via drivers\\nthat plug into libnetwork.\\nLast but not least, libnetwork also provides native service discovery and basic load\\nbalancing.\\nThat’s the big picture. Let’s get into the detail.\\nDocker networking theory\\nAt the highest level, Docker networking is based on the following three components:\\n• The Container Network Model (CNM)\\n• Libnetwork\\n• Drivers\\nThe CNM is the design specification and outlines the fundamental building blocks of a\\nDocker network.\\nLibnetwork is a real-world implementation of the CNM. It’s open-sourced as part of\\nthe Moby project20 and used by Docker and other platforms.\\nDrivers extend the model by implementing specific network topologies such as VXLAN\\noverlay networks.\\nFigure 13.1 shows all three.\\n20https://mobyproject.org/'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 196}, page_content='13: Docker Networking\\n190\\nFigure 13.1\\nLet’s take a closer look at each.\\nThe Container Network Model (CNM)\\nEverything starts with a design.\\nThe design guide for Docker networking is the CNM that outlines the fundamental\\nbuilding blocks of a Docker network.\\nI recommend you read the specification document21, but at a high level, it defines three\\nbuilding blocks:\\n• Sandboxes\\n• Endpoints\\n• Networks\\nA sandbox is an isolated network stack inside a container. It includes Ethernet interfaces,\\nports, routing tables, DNS configuration, and everything else you’d expect from a\\nnetwork stack.\\nEndpoints are virtual network interfaces that look, smell, and feel like regular network\\ninterfaces. They connect sandboxes to networks.\\nNetworks are virtual switches (usually software implementations of an 802.1d bridge). As\\nsuch, they group together and isolate one or more endpoints that need to communicate.\\nFigure 13.2 shows how all three connect and relate to familiar infrastructure compo-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 196}, page_content='such, they group together and isolate one or more endpoints that need to communicate.\\nFigure 13.2 shows how all three connect and relate to familiar infrastructure compo-\\nnents. Using CNM terminology, endpoints connect sandboxes to networks. Every container\\nyou create will have a sandbox with at least one endpoint connecting it to a network.\\n21https://github.com/moby/moby/blob/master/libnetwork/docs/design.md'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 197}, page_content='13: Docker Networking\\n191\\nFigure 13.2 - The Container Network Model (CNM)\\nAs the name suggests, the Container Network Model is all about providing networking\\nfor containers. Figure 13.3 shows how CNM components relate to containers —\\neach container gets its own sandbox which hosts the container’s entire network stack,\\nincluding one or more endpoints that act as Ethernet interfaces and can be connected to\\nnetworks.\\nFigure 13.3\\nContainer A has a single interface (endpoint) and is only connected to Network A.\\nHowever, Container B has two interfaces connected to Network A and Network B.\\nThe containers can communicate with each other because they are both connected to\\nNetwork A. However, the two endpoints inside of Container B cannot communicate\\nwith each other as they’re on different networks.\\nIt’s also important to understand that endpoints behave exactly like regular network\\nadapters, meaning you can only connect them to a single network. This is why Con-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 197}, page_content='It’s also important to understand that endpoints behave exactly like regular network\\nadapters, meaning you can only connect them to a single network. This is why Con-\\ntainer B needs two endpoints if it wants to connect to both networks.\\nFigure 13.4 extends the diagram further by adding the Docker host. Even though both\\ncontainers are running on the same host this time, their network stacks are completely\\nisolated and can only communicate via a network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 198}, page_content='13: Docker Networking\\n192\\nFigure 13.4\\nLibnetwork\\nLibnetwork is the reference implementation of the CNM. It’s open-source, cross-\\nplatform (Linux and Windows), maintained by the Moby project, and used by Docker.\\nBefore Docker created libnetwork, it implemented all of its networking code inside\\nthe daemon. However, over time, the daemon became bloated and difficult for other\\nprojects to use. As a result, Docker removed the networking code from the daemon and\\nrefactored it as an external library called libnetwork based on the CNM design. Today,\\nDocker implements all of its core networking in libnetwork.\\nAs well as implementing the core components of the CNM, libnetwork also implements\\nthe network control plane, including management APIs, service discovery, and ingress-\\nbased container load balancing.\\nDrivers\\nLibnetwork implements the control plane, but it relies on drivers to implement the data\\nplane. For example, drivers are responsible for creating networks and ensuring isolation'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 198}, page_content='Drivers\\nLibnetwork implements the control plane, but it relies on drivers to implement the data\\nplane. For example, drivers are responsible for creating networks and ensuring isolation\\nand connectivity.\\nDocker ships with several built-in drivers that we sometimes call native drivers or local\\ndrivers. These include bridge, overlay, and macvlan, and they build the most common\\nnetwork topologies. Third parties can also write network drivers to implement other\\nnetwork topologies and more advanced configurations.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 199}, page_content='13: Docker Networking\\n193\\nFigure 13.5 shows the roles of libnetwork and drivers and how they relate to control\\nplane and data plane responsibilities.\\nFigure 13.5\\nEvery network you create is owned by a driver, and the driver creates and manages\\neverything about the network. For example, if you create an overlay network called\\nprod-fe-cuda, Docker will invoke the overlay driver to create the network and its\\nresources.\\nTo meet the demands of complex, highly fluid environments, a single Docker host or\\nSwarm cluster can have multiple heterogeneous networks managed by different drivers.\\nLet’s look at single-host bridge networks and connecting to existing networks. You’ll\\nlearn about overlay networks in the next chapter.\\nSingle-host bridge networks\\nThe simplest type of Docker network is the single-host bridge network.\\nThe name tells us two things:\\n• Single-host tells us the network only spans a single Docker host'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 199}, page_content='Single-host bridge networks\\nThe simplest type of Docker network is the single-host bridge network.\\nThe name tells us two things:\\n• Single-host tells us the network only spans a single Docker host\\n• Bridge tells us that it’s an implementation of an 802.1d bridge (layer 2 switch)\\nDocker creates single-host bridge networks with the built-in bridge driver. If you run\\nWindows containers you’ll need to use the nat driver, but for all intents and purposes they\\nwork the same.\\nFigure 13.6 shows two Docker hosts with identical local bridge networks, both called\\nmynet. Even though the networks are identical, they are independent and isolated,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 200}, page_content='13: Docker Networking\\n194\\nmeaning the containers in the picture cannot communicate, even if the nodes are part\\nof the same swarm.\\nFigure 13.6\\nEvery new Docker host gets a default single-host bridge network called bridge that\\nDocker connects new containers to unless you override it with the --network flag.\\nThe following commands show the output of a docker network ls command on\\nDocker installation.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\nc7464dce29ce\\nbridge\\nbridge\\nlocal\\n<<---- Default on all Docker hosts\\nc65ab18d0580\\nhost\\nhost\\nlocal\\n42a783df0fbe\\nnone\\nnull\\nlocal\\nAs always, you can run docker inspect commands to get more information. I highly\\nrecommend running the command on your own system and studying the output.\\n$ docker network inspect bridge\\n[\\n{\\n\"Name\": \"bridge\",\\n\"Id\": \"c7464dce2...ba2e3b8\",\\n\"Scope\": \"local\",\\n\"Driver\": \"bridge\",\\n\"EnableIPv6\": false,\\n\"IPAM\": {\\n\"Driver\": \"default\",\\n\"Options\": null,\\n\"Config\": [\\n{\\n\"Subnet\": \"172.17.0.0/16\",\\n\"Gateway\": \"172.17.0.1\"\\n}'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 201}, page_content='13: Docker Networking\\n195\\n]\\n},\\n\"Internal\": false,\\n\"Attachable\": false,\\n\"Ingress\": false,\\n\"ConfigFrom\": {\\n\"Network\": \"\"\\n},\\n<Snip>\\n}\\n]\\nAll bridge networks are based on the battle-hardened Linux bridge technology that has\\nexisted in the Linux kernel for over 20 years. This means they’re high-performance and\\nhighly stable. It also means you can inspect them using standard Linux utilities.\\nThe default bridge network on all Linux-based Docker hosts is called bridge and maps to\\nan underlying Linux bridge in the host’s kernel called docker0. This is shown in Figure\\n13.7.\\nFigure 13.7 - Mapping the default Docker “bridge” network to the “docker0” bridge in the host’s kernel\\nYou can run a docker network inspect command to confirm that the bridge network\\nis based on the docker0 bridge in the host’s kernel. If you’re on Windows using Power-\\nShell, you’ll need to replace grep with SelectString.\\n$ docker network inspect bridge | grep bridge.name\\n\"com.docker.network.bridge.name\": \"docker0\",'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 201}, page_content='Shell, you’ll need to replace grep with SelectString.\\n$ docker network inspect bridge | grep bridge.name\\n\"com.docker.network.bridge.name\": \"docker0\",\\nNow run these Linux commands to inspect the docker 0 bridge from the Linux host.\\nYou might need to manually install the brctl utility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 202}, page_content='13: Docker Networking\\n196\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\ndocker0\\n8000.0242aff9eb4f\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\n$ ip link show docker0\\n3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc...\\nlink/ether 02:42:af:f9:eb:4f brd ff:ff:ff:ff:ff:ff\\nThe first command lists all the bridges on your Docker host and shows if they have any\\ndevices connected to them. The example in the book shows the docker0 bridge with no\\ndevices connected in the interfaces column. You’ll only see the docker_gwbridge if\\nyour host is a member of a swarm cluster.\\nThe second command shows the configuration and state of the docker0 bridge.\\nFigure 13.8 shows the complete stack with containers connecting to the bridge\\nnetwork, which, in turn, maps to the docker0 Linux bridge in the host’s kernel. It also\\nshows how you can use port mappings to publish connected devices on the Docker\\nhost’s interface. More on port mappings later.\\nFigure 13.8'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 202}, page_content='shows how you can use port mappings to publish connected devices on the Docker\\nhost’s interface. More on port mappings later.\\nFigure 13.8\\nIn the next few steps, you’ll complete all of the following:\\n1. Create a new Docker bridge network\\n2. Connect a container to the new network'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 203}, page_content='13: Docker Networking\\n197\\n3. Inspect the new network\\n4. Test name-based discovery\\nRun the following command to create a new single-host bridge network called local-\\nnet.\\n$ docker network create -d bridge localnet\\nf918f1bb0602373bf949615d99cb2bbbef14ede935fbb2ff8e83c74f10e4b986\\nThe long number returned by the command is the network’s ID and you’ll need it in the\\nnext step.\\nAs expected, the command creates a new Docker bridge network called localnet that\\nyou can list and inspect with the usual docker commands. However, behind the scenes,\\nit also creates a new Linux bridge in the host’s kernel.\\nRun another brctl show command to see it.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\ndocker0\\n8000.024258ee84bc\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\nThe example in the book shows a new bridge called br-f918f1bb0602 with no devices\\nconnected. If you look closely at the name, you’ll recognize f918f1bb0602 as the first 12'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 203}, page_content='8000.02427abba76b\\nno\\nThe example in the book shows a new bridge called br-f918f1bb0602 with no devices\\nconnected. If you look closely at the name, you’ll recognize f918f1bb0602 as the first 12\\ncharacters from the ID of the new localnet network you just created.\\nAt this point, the bridge configuration on the host looks like Figure 13.9, with three\\nDocker networks and three associated bridges in the host’s kernel.\\nFigure 13.9\\nLet’s create a new container called c1 and attach it to the new localnet bridge network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 204}, page_content='13: Docker Networking\\n198\\n$ docker run -d --name c1 \\\\\\n--network localnet \\\\\\nalpine sleep 1d\\nOnce you’ve created the container, inspect the localnet network and verify the\\ncontainer is connected to it. You’ll need the jq utility installed for the command to work.\\nLeave off the \"| jq\" if it doesn’t work.\\n$ docker network inspect localnet --format \\'{{json .Containers}}\\' | jq\\n{\\n\"09c5f4926c87da12039b3b510a5950b3fe9db80e13431dc17d870450a45fd84a\": {\\n\"Name\": \"c1\",\\n\"EndpointID\": \"27770ac305773b352d716690fb9f8e05c1b71e10dc66f67b88e93cb923ab9749\",\\n\"MacAddress\": \"02:42:ac:15:00:02\",\\n\"IPv4Address\": \"172.21.0.2/16\",\\n\"IPv6Address\": \"\"\\n}\\n}\\nThe output shows the c1 container and its IP address. This proves Docker connected it\\nto the network.\\nIf you run another brctl show command, you’ll see the c1 container’s interface\\nconnected to the br-1597657726bc bridge.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\nveth833aaf9\\ndocker0\\n8000.024258ee84bc\\nno'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 204}, page_content='connected to the br-1597657726bc bridge.\\n$ brctl show\\nbridge name\\nbridge id\\nSTP enabled\\ninterfaces\\nbr-f918f1bb0602\\n8000.0242372a886b\\nno\\nveth833aaf9\\ndocker0\\n8000.024258ee84bc\\nno\\ndocker_gwbridge\\n8000.02427abba76b\\nno\\nFigure 13.10 shows the updated configuration. Your veth IDs will be different, but the\\nimportant thing to understand is that every veth is like a cable with an interface on\\neither end. One end is connected to the Docker network, and the other end is connected\\nto the associated bridge in the kernel.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 205}, page_content='13: Docker Networking\\n199\\nFigure 13.10\\nIf you add more containers to the localnet network, they’ll all be able to communicate\\nusing names. This is because Docker automatically registers container names with an\\ninternal DNS service and allows containers on the same network to find each other by\\nname. The exception to this rule is the built-in bridge network that does not support\\nDNS resolution.\\nLet’s test name resolution by creating a new container called c2 on the same localnet\\nnetwork and seeing if it can ping the c1 container.\\nRun the following command to create the c2 container on the localnet network. You’ll\\nneed to type exit if you’re still logged in to the c1 container.\\n$ docker run -it --name c2 \\\\\\n--network localnet \\\\\\nalpine sh\\nYour terminal will switch into the c2 container.\\nTry to ping the c1 container by name.\\n# ping c1\\nPING c1 (172.21.0.2): 56 data bytes\\n64 bytes from 172.21.0.2: seq=0 ttl=64 time=1.564 ms\\n64 bytes from 172.21.0.2: seq=1 ttl=64 time=0.338 ms'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 205}, page_content='Try to ping the c1 container by name.\\n# ping c1\\nPING c1 (172.21.0.2): 56 data bytes\\n64 bytes from 172.21.0.2: seq=0 ttl=64 time=1.564 ms\\n64 bytes from 172.21.0.2: seq=1 ttl=64 time=0.338 ms\\n64 bytes from 172.21.0.2: seq=2 ttl=64 time=0.248 ms\\n<Control-c>\\nIt works! This is because all containers run a DNS resolver that forwards name lookups\\nto Docker’s internal DNS server that holds name-to-IP mappings for all containers\\nstarted with the --name or --net-alias flag.\\nType exit to log out of the container and return to your local shell.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 206}, page_content='13: Docker Networking\\n200\\nExternal access via port mappings\\nSo far, we’ve said that containers on bridge networks can only communicate with\\nother containers on the same network. However, you can get around this by mapping\\ncontainers to ports on the Docker host. It’s a bit clunky and has a lot of limitations, but it\\nmight be useful for occasional testing and development work.\\nFigure 13.11 shows a single Docker host running two containers. The web container on\\nthe right is running a web server on port 80 that is mapped to port 5005 on the Docker\\nhost. The client container on the left is sending requests to the Docker host on port\\n5005 and the external client at the bottom is doing the same. Both requests will hit the\\nhost’s IP on port 5005 and be redirected to the web server running in the web container.\\nFigure 13.11\\nLet’s test the setup to see if it works.\\nCreate a new container called web running NGINX on port 80 and map it to port 5005'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 206}, page_content='Figure 13.11\\nLet’s test the setup to see if it works.\\nCreate a new container called web running NGINX on port 80 and map it to port 5005\\non the Docker host. If you’re still logged on to the container from the previous example,\\nyou’ll need to type exit first.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 207}, page_content='13: Docker Networking\\n201\\n$ docker run -d --name web \\\\\\n--network localnet \\\\\\n--publish 5005:80 \\\\\\nnginx\\nVerify the port mapping.\\n$ docker port web\\n80/tcp -> 0.0.0.0:5005\\n80/tcp -> [::]:5005\\nThe output shows the port mapping exists on all interfaces on the Docker host.\\nYou can test external access by pointing a web browser to the Docker host on port 5005.\\nYou’ll need to know the IP or DNS name of your Docker host (if you’re following along\\non Multipass it will probably be your Multipass VM’s 192.168.x.x address). You’ll see\\nthe Welcome to nginx! page.\\nLet’s create another container and see if it can reach the web container via the port\\nmapping.\\nRun the following command to create a new container called client on the bridge\\nnetwork.\\n$ docker run -it --name client --network bridge alpine sh\\n#\\nThe command will log you into the container and your prompt will change.\\nInstall the curl utility.\\n# apk add curl\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/aarch64/APKINDEX.tar.gz'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 207}, page_content='#\\nThe command will log you into the container and your prompt will change.\\nInstall the curl utility.\\n# apk add curl\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/aarch64/APKINDEX.tar.gz\\nfetch https://dl-cdn.alpinelinux.org/alpine/v3.19/community/aarch64/APKINDEX.tar.gz\\n(1/8) Installing ca-certificates (20240226-r0)\\n<Snip>\\nNow connect to the IP of your Docker host on port 5005 to see if you can reach the\\ncontainer.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 208}, page_content='13: Docker Networking\\n202\\n# curl 192.168.64.69:5005\\n<!DOCTYPE html>\\n<html>\\n<head>\\n<title>Welcome to nginx!</title>\\n...\\n</html>\\nYou’ve reached the NGINX web server running on the c1 container via a port mapping\\nto the Docker host’s IP.\\nEven though this works, it’s clunky and doesn’t scale. For example, no other containers\\nor host processes will be able to use port 5005 on the host. This is one of the reasons\\nthat single-host bridge networks are only useful for local development or very small\\napplications.\\nConnecting to existing networks and VLANs\\nThe ability to connect containerized apps to external systems and physical networks is\\nimportant. A common example is partially containerized apps where the parts running\\nin containers need to be able to communicate with the parts not running in containers.\\nThe built-in MACVLAN driver (transparent if you’re using Windows containers) was\\ncreated with this in mind. It gives every container its own IP and MAC address on the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 208}, page_content='The built-in MACVLAN driver (transparent if you’re using Windows containers) was\\ncreated with this in mind. It gives every container its own IP and MAC address on the\\nexternal physical network, making each one look, smell, and feel like a physical server or\\nVM. This is shown in Figure 13.12.\\nFigure 13.12 - MACVLAN driver making containers visible on external networks\\nOn the positive side, MACVLAN performance is good as it doesn’t require port\\nmappings or additional bridges. However, you need to run your host NICs in promis-\\ncuous mode, which isn’t allowed on many corporate networks and public clouds. So,\\nMACVLAN will work on your data center networks if your network team allows\\npromiscuous mode, but it probably won’t work on your public cloud.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 209}, page_content='13: Docker Networking\\n203\\nLet’s dig a bit deeper with the help of some pictures and a hypothetical example. This\\nexample will only work if your host NIC is in promiscuous mode on a network that\\nallows it. It also requires an existing VLAN 100. You can adapt it if the VLAN config on\\nyour physical network is different. You can follow along without the VLANs, but you\\nwon’t get the full experience.\\nAssume you have the network shown in Figure 13.13 with two VLANs:\\nFigure 13.13\\nNext, you add a Docker host and connect it to the network.\\nFigure 13.14\\nNow comes the requirement to attach a container to VLAN 100. To do this, you create a\\nnew Docker network with the macvlan driver and configure it with all of the following:\\n• Subnet info\\n• Gateway\\n• Range of IPs it can assign to containers\\n• Which of the host’s interfaces or sub-interfaces to use\\nRun the following command to create a new MACVLAN network called macvlan100'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 209}, page_content='• Gateway\\n• Range of IPs it can assign to containers\\n• Which of the host’s interfaces or sub-interfaces to use\\nRun the following command to create a new MACVLAN network called macvlan100\\nthat will connect containers to VLAN 100. You may need to change the name of the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 210}, page_content='13: Docker Networking\\n204\\nparent interface to match the parent interface name on your system. For example,\\nchanging -o parent=eth0.100 to -o parent=enp0s1.100. The parent interface must\\nbe connected to the VLAN, and you’ll need to type exit if you’re still logged on to the\\ncontainer from the previous example.\\n$ docker network create -d macvlan \\\\\\n--subnet=10.0.0.0/24 \\\\\\n--ip-range=10.0.0.0/25 \\\\\\n--gateway=10.0.0.1 \\\\\\n-o parent=eth0.100 \\\\\\n<<---- Make sure this matches your system\\nmacvlan100\\nDocker will create the macvlan100 network and a new sub-interface on the host called\\neth0.100@eth0. The config now looks like this.\\nFigure 13.15\\nThe MACVLAN driver creates standard Linux sub-interfaces and tags them with the ID\\nof the VLAN they will connect to. In this example, we’re connecting to VLAN 100, so we\\ntag the sub-interface with .100 (-o parent=eth0.100).\\nWe also used the --ip-range flag to tell the new network which sub-set of IP addresses'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 210}, page_content='tag the sub-interface with .100 (-o parent=eth0.100).\\nWe also used the --ip-range flag to tell the new network which sub-set of IP addresses\\nit can assign to containers. It’s vital that you reserve this range of addresses for Docker,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 211}, page_content='13: Docker Networking\\n205\\nas the MACVLAN driver has no management plane feature to check if IPs are already in\\nuse.\\nIf you inspect the network, you’ll be able to see the important configuration information.\\nI’ve snipped the output to show the most relevant parts.\\n$ docker network inspect macvlan100\\n[\\n{\\n\"Name\": \"macvlan100\",\\n\"Driver\": \"macvlan\",\\n\"IPAM\": {\\n\"Config\": [\\n{\\n\"Subnet\": \"10.0.0.0/24\",\\n\"IPRange\": \"10.0.0.0/25\",\\n\"Gateway\": \"10.0.0.1\"\\n}\\n]\\n},\\n\"Options\": {\\n\"parent\": \"enp0s1.100\"\\n},\\n}\\n]\\nOnce you’ve created the macvlan100 network, you can connect containers to it and\\nDocker will assign the IP and MAC addresses on the underlying VLAN so they’ll be\\nvisible to other systems.\\nThe following command creates a new container called mactainer1 and connects it to\\nthe macvlan100 network.\\n$ docker run -d --name mactainer1 \\\\\\n--network macvlan100 \\\\\\nalpine sleep 1d\\nThe config now looks like Figure 13.16.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 212}, page_content='13: Docker Networking\\n206\\nFigure 13.16\\nHowever, remember that the underlying network (VLAN 100) does not see any of\\nthe MACVLAN magic, it only sees the container with its MAC and IP addresses,\\nmeaning the mactainer1 container will be able to communicate with every other system\\nconnected to VLAN 100!\\nNote: If you can’t get this to work, it might be because your host NIC isn’t\\nin promiscuous mode. Also, remember that public cloud platforms normally\\nblock promiscuous mode.\\nAt this point, you’ve got a MACVLAN network and used it to connect a new container\\nto an existing VLAN. If you have the complete setup, with the existing VLAN, you can\\ntest that the container is reachable form other system on the VLAN.\\nHowever, it doesn’t stop there. The Docker MACVLAN driver supports VLAN trunking.\\nThis means you can create multiple MACVLAN networks that connect to different\\nVLANs. Figure 13.17 shows a single Docker host running two MACVLAN networks\\nconnecting containers to two different VLANs.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 213}, page_content='13: Docker Networking\\n207\\nFigure 13.17\\nTroubleshooting connectivity problems\\nA quick note on troubleshooting connectivity issues before moving on to service\\ndiscovery.\\nDaemon logs and container logs can be useful when troubleshooting connectivity issues.\\nIf you’re running Windows containers, you can view them in the Windows Event\\nViewer or directly in ∼\\\\AppData\\\\Local\\\\Docker. For Linux containers, it depends on\\nwhich init system you’re using. If you’re running a systemd, Docker will post logs to\\njournald and you can view them with the journalctl -u docker.service command.\\nIf you’re using a different init system, you might want to check the following locations:\\n• Ubuntu systems running upstart: /var/log/upstart/docker.log\\n• RHEL-based systems: /var/log/messages\\n• Debian: /var/log/daemon.log\\nYou can also tell Docker how verbose you want daemon logging to be. To do this, edit\\nthe daemon config file at /etc/docker/daemon.json and set \"debug\" to \"true\" and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 213}, page_content='• Debian: /var/log/daemon.log\\nYou can also tell Docker how verbose you want daemon logging to be. To do this, edit\\nthe daemon config file at /etc/docker/daemon.json and set \"debug\" to \"true\" and\\n\"log-level\" to one of the following:'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 214}, page_content='13: Docker Networking\\n208\\n• debug – the most verbose option\\n• info – the default value and second-most verbose option\\n• warn – third most verbose option\\n• error – fourth most verbose option\\n• fatal – least verbose option\\nThe following snippet from a daemon.json enables debugging and sets the level to\\ndebug. It will work on all Docker platforms.\\n{\\n<Snip>\\n\"debug\":true,\\n\"log-level\":\"debug\",\\n<Snip>\\n}\\nIf your daemon.json file doesn’t exist, create it. Also, be sure to restart Docker after\\nmaking any changes to the file.\\nThat was the daemon logs. What about container logs?\\nYou can normally view container logs with the docker logs command. If you’re\\nrunning Swarm, you should use the docker service logs command. However,\\nDocker supports a few different log drivers, and they don’t all work with native Docker\\ncommands. For some of them, you might have to view logs using the platform’s native\\ntools.\\njson-file and journald are probably the easiest to configure and they both work with'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 214}, page_content='commands. For some of them, you might have to view logs using the platform’s native\\ntools.\\njson-file and journald are probably the easiest to configure and they both work with\\nthe docker logs and docker service logs commands.\\nThe following snippet from a daemon.json shows a Docker host configured to use\\njournald.\\n{\\n\"log-driver\": \"journald\"\\n}\\nYou can also start a container or a service with the --log-driver and --log-opts flags\\nto override the settings in daemon.json.\\nContainer logs work on the premise that your application runs as PID 1 and sends logs\\nto STDOUT and errors to STDERR. The logging driver then forwards everything to the\\nlocations configured via the logging driver.\\nThe following is an example of running the docker logs command against a container\\ncalled vantage-db that is configured with the json-file logging driver.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 215}, page_content='13: Docker Networking\\n209\\n$ docker logs vantage-db\\n1:C 2 Feb 09:53:22.903 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\\n1:C 2 Feb 09:53:22.904 # Redis version=4.0.6, bits=64, commit=00000000, modified=0, pid=1\\n1:C 2 Feb 09:53:22.904 # Warning: no config file specified, using the default config.\\n1:M 2 Feb 09:53:22.906 * Running mode=standalone, port=6379.\\n1:M 2 Feb 09:53:22.906 # WARNING: The TCP backlog setting of 511 cannot be enforced...\\n1:M 2 Feb 09:53:22.906 # Server initialized\\n1:M 2 Feb 09:53:22.906 # WARNING overcommit_memory is set to 0!\\nThere’s a good chance you’ll find network connectivity errors in the daemon logs or\\ncontainer logs.\\nService discovery\\nAs well as core networking, libnetwork also provides service discovery that allows all\\ncontainers and Swarm services to locate each other by name. The only requirement is\\nthat the containers be on the same network.\\nUnder the hood, Docker implements a native DNS server and configures every con-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 215}, page_content='that the containers be on the same network.\\nUnder the hood, Docker implements a native DNS server and configures every con-\\ntainer to use it for name resolution.\\nFigure 13.18 shows a container called c1 pinging another container called c2 by name.\\nThe same principle applies to Swarm service replicas.\\nFigure 13.18\\nLet’s step through the process.\\n• Step 1: The c1 container issues a ping c2 command. The container’s local DNS\\nresolver checks its cache to see if it has an IP address for c2. All Docker containers\\nhave a local DNS resolver.\\n• Step 2: The local resolver doesn’t have an IP address for c2, so it initiates a\\nrecursive query to the embedded Docker DNS server. All Docker containers are\\npre-configured to know how to send queries to the embedded DNS server.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 216}, page_content='13: Docker Networking\\n210\\n• Step 3: The Docker DNS server maintains name-to-IP mappings for every\\ncontainer you create with the --name or --net-alias flags. This means it knows\\nthe IP address of the c2 container.\\n• Step 4: The DNS server returns the IP address of the c2 container to the local\\nresolver in the c1 container. If c1 and c2 are on different Docker networks it won’t\\nreturn the IP address — name resolution only works for containers on the same\\nnetwork.\\n• Step 5: The c1 container sends the ping request (ICMP echo request) to the IP\\naddress of c2.\\nJust to confirm a few points.\\nDocker will automatically register the name and IP of every container you create\\nwith the --name or net-alias flag with the embedded Docker DNS service. It also\\nautomatically configures every container to use the embedded DNS service to convert\\nnames to IPs. And name resolution (service discovery) is network scoped, meaning it only\\nworks for containers and services on the same network.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 216}, page_content='names to IPs. And name resolution (service discovery) is network scoped, meaning it only\\nworks for containers and services on the same network.\\nOne last point on service discovery and name resolution…\\nYou can use the --dns flag to start containers and services with a customized list of\\nDNS servers, and you can use the --dns-search flag to add custom search domains\\nfor queries against unqualified names (i.e., when the application doesn’t specify fully\\nqualified DNS names for services they consume). You’ll find both of these useful if your\\napplications query names outside of your Docker environment such as internet services.\\nBoth of these options work by adding entries to the container’s /etc/resolv.conf file.\\nRun the following command to start a new container with the infamous 8.8.8.8\\nGoogle DNS server and nigelpoulton.com as a search domain for unqualified queries.\\n$ docker run -it --name custom-dns \\\\\\n--dns=8.8.8.8 \\\\\\n--dns-search=nigelpoulton.com \\\\\\nalpine sh'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 216}, page_content='Google DNS server and nigelpoulton.com as a search domain for unqualified queries.\\n$ docker run -it --name custom-dns \\\\\\n--dns=8.8.8.8 \\\\\\n--dns-search=nigelpoulton.com \\\\\\nalpine sh\\nYour shell prompt will change to indicate you’re connected to the container.\\nInspect its /etc/resolv.conf file.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 217}, page_content='13: Docker Networking\\n211\\n# cat /etc/resolv.conf\\nGenerated by Docker Engine.\\nThis file can be edited; Docker Engine will not make further changes once it\\nhas been modified.\\nnameserver 8.8.8.8\\nsearch nigelpoulton.com\\nThe file’s contents might be slightly different if you connect the container to a custom\\nnetwork, but the options work the same.\\nType exit to return to your local terminal.\\nIngress load balancing\\nThis section only applies to Docker Swarm.\\nSwarm supports two ways of publishing services to external clients:\\n• Ingress mode (default)\\n• Host mode\\nExternal clients can access ingress mode services via any swarm node — even nodes not\\nhosting a service replica. However, they can only access host mode services via nodes\\nrunning replicas. Figure 13.19 shows both modes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 218}, page_content='13: Docker Networking\\n212\\nFigure 13.19\\nIngress mode is the default, meaning any time you create a service with -p or --publish,\\nDocker will publish it in ingress mode. If you want to publish a service in host mode, you’ll\\nneed to use the --publish flag with the mode=host option. The following example\\npublishes a service in host mode and will only work on a swarm.\\n$ docker service create -d --name svc1 \\\\\\n--publish published=5005,target=80,mode=host \\\\\\nnginx\\nA few notes about the command. docker service create lets you publish services\\nusing either long form syntax or short form syntax.\\nThe short form looks like -p 5005:80 and you’ve seen it a few times already. However,\\nyou cannot publish a service in host mode using the short form.\\nLong form looks like this: --publish published=5005,target=80,mode=host. It’s a\\ncomma-separated list with no whitespace after the commands, and the options work as\\nfollows:\\n• published=5005 makes the service available to external clients via port 5005'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 218}, page_content='comma-separated list with no whitespace after the commands, and the options work as\\nfollows:\\n• published=5005 makes the service available to external clients via port 5005\\n• target=80 makes sure requests hitting the published port get mapped back to port\\n80 on service replicas'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 219}, page_content='13: Docker Networking\\n213\\n• mode=host makes sure requests will only reach the service if they arrive on nodes\\nrunning a service replica\\nYou’ll almost always use ingress mode.\\nBehind the scenes, ingress mode uses a layer 4 routing mesh that Docker calls the\\nservice mesh or the swarm-mode service mesh. Figure 13.20 shows the basic traffic\\nflow when an external request hits the cluster for a service exposed in ingress mode.\\nFigure 13.20\\nLet’s quickly walk through the diagram.\\nThe command at the top deploys a new Swarm service called svc1 with one replica,\\nattaches it to the overnet network and publishes it on port 5005 on the ingress network.\\nDocker automatically creates the ingress network when you create the swarm, and\\nit attaches every node to it. The act of publishing the service on port 5005 makes it\\naccessible via port 5005 on every swarm node because every node is connected to the\\ningress network. Docker also creates a swarm-wide rule to route all traffic hitting nodes'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 219}, page_content='accessible via port 5005 on every swarm node because every node is connected to the\\ningress network. Docker also creates a swarm-wide rule to route all traffic hitting nodes\\non port 5005 to port 80 in the svc1 replicas via the ingress network.\\nNow let’s track that external request.\\n1. The external client sends a request to Node 1 on port 5005\\n2. Node 1 receives the request and knows to forward traffic arriving on port 5005 to\\nthe ingress network\\n3. The ingress network forwards the request to Node 2 which is running a replica\\n4. Node 2 receives the request and passes it to the replica on port 80'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 220}, page_content='13: Docker Networking\\n214\\nIf the service has multiple replicas, swarm is clever enough to balance requests across\\nthem all.\\nClean up\\nIf you’ve been following along, you’ll have a lot of containers, networks, and services\\nthat you probably want to clean up.\\nRun the following command to delete the services you created.\\n$ docker service rm svc1\\nNow, delete the standalone containers you created.\\n$ docker rm c1 c2 client web mactainer1 -f\\nFinally, delete the networks you created.\\n$ docker network rm localnet macvlan100\\nDocker Networking – The Commands\\nDocker networking has its own docker network sub-command, and the main com-\\nmands include:\\n• docker network ls lists all the Docker networks available to the host.\\n• docker network create is how you create a new Docker network. You have\\nto give the network a name and you can use the -d flag to specify which driver\\ncreates it.\\n• docker network inspect provides detailed configuration information about\\nDocker networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 220}, page_content='to give the network a name and you can use the -d flag to specify which driver\\ncreates it.\\n• docker network inspect provides detailed configuration information about\\nDocker networks.\\n• docker network prune deletes all unused networks on a Docker host.\\n• docker network rm Deletes specific networks on a Docker host or swarm.\\nYou also ran some native Linux commands.\\n• brctl show prints a list of all kernel bridges on the Docker host and shows if any\\ncontainers are connected.\\n• ip link show prints bridge configuration data. You ran an ip link show\\ndocker0 to see the configuration of the docker0 bridge on your Docker host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 221}, page_content='13: Docker Networking\\n215\\nChapter Summary\\nThe Container Network Model (CNM) is the design document for Docker networks\\nand defines the three major constructs — sandboxes, endpoints, and networks.\\nLibnetwork is the reference implementation of the CMN and is an open-source project\\nmaintained by the Moby project. Docker uses it to implement its core networking,\\nincluding control plane services such as service discovery.\\nDrivers extend the capabilities of libnetwork by implementing specific network topolo-\\ngies, such as bridge and overlay networks. Docker ships with built-in drivers, but you\\ncan also use third-party drivers.\\nSingle-host bridge networks are the most basic type of Docker network but are only\\nsuitable for local development and very small applications. They do not scale, and you\\nneed to map containers to host ports if you want to publish services outside of the\\nnetwork.\\nOverlay networks are all the rage and are excellent container-only multi-host networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 221}, page_content='need to map containers to host ports if you want to publish services outside of the\\nnetwork.\\nOverlay networks are all the rage and are excellent container-only multi-host networks.\\nWe’ll talk about them in-depth in the next chapter.\\nThe macvlan driver lets you create Docker networks that connect containers to existing\\nphysical networks and VLANs. They make containers first-class citizens on external\\nnetworks by giving them their own MAC and IP addresses. Unfortunately, you have to\\nrun your host NICs in promiscuous mode, meaning they won’t work in public clouds.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 222}, page_content='14: Docker overlay networking\\nOverlay networks are at the center of most cloud-native microservices apps, and this\\nchapter will get you up to speed on how they work in Docker.\\nI’ve divided the chapter into the following sections:\\n• Docker overlay networking – The TLDR\\n• Docker overlay networking history\\n• Building and testing overlay networks\\n• Overlay networks explained\\nLet’s do some networking magic!\\nDocker overlay networking – The TLDR\\nReal-world containers need a reliable and secure way to communicate without caring\\nwhich host they’re running on or which networks those hosts are connected to. This\\nis where overlay networks come into play — they create flat, secure, layer 2 networks\\nthat span multiple hosts. Containers on different hosts can connect to the same overlay\\nnetwork and communicate directly.\\nDocker offers native overlay networking that is simple to configure and secure by\\ndefault.\\nBehind the scenes, Docker builds overlay networking on top of libnetwork and the native'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 222}, page_content='Docker offers native overlay networking that is simple to configure and secure by\\ndefault.\\nBehind the scenes, Docker builds overlay networking on top of libnetwork and the native\\noverlay driver. Libnetwork is the canonical implementation of the Container Network\\nModel (CNM), and the overlay driver implements all of the machinery to build overlay\\nnetworks.\\nDocker overlay networking history\\nIn March 2015, Docker, Inc. acquired a container networking startup called Socket Plane\\nwith two goals in mind:\\n1. Bring overlay networking to Docker'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 223}, page_content='14: Docker overlay networking\\n217\\n2. Make container networking simple for developers\\nThey accomplished both goals, and overlay networking continues to be at the heart of\\ncontainer networking in 2024 and the foreseeable future.\\nHowever, there’s a lot of complexity hiding behind the simple Docker commands.\\nKnowing the commands is probably enough if you’re a casual Docker user. However,\\nif you plan to use Docker in production, especially if you plan to use Swarm and Docker\\nnetworking, then the things we’ll cover will be vital.\\nBuilding and testing Docker overlay networks\\nYou’ll need at least two Docker nodes configured in a swarm to follow along. The\\nexamples in the book show the two nodes on different networks connected by a router,\\nbut yours can be on the same network. You can follow along with two Multipass VMs\\non the same laptop or computer, but any Docker configuration will work as long as the\\nnodes can communicate. I don’t recommend using Docker Desktop as you only get a'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 223}, page_content='on the same laptop or computer, but any Docker configuration will work as long as the\\nnodes can communicate. I don’t recommend using Docker Desktop as you only get a\\nsingle node and won’t get the full experience.\\nFigure 14.1 shows the initial lab configuration. Remember, your nodes can be on\\nthe same network, this will just mean your underlay network is simpler. We’ll explain\\nunderlay networks later.\\nFigure 14.1'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 224}, page_content='14: Docker overlay networking\\n218\\nBuild a Swarm\\nIf you’re following along, you’ll need a swarm because overlay networks leverage the\\nswarm’s key-value store and other security features.\\nThis section builds a two-node swarm with two Docker nodes called node1 and node2.\\nIf you already have a swarm, you can skip this section.\\nYou’ll need to substitute the IP addresses and names with the values from your environ-\\nment. You’ll also need to ensure the following network ports are open between the two\\nnodes:\\n• 2377/tcp for management plane comms\\n• 7946/tcp and 7946/udp for control plane comms (SWIM-based gossip)\\n• 4789/udp for the VXLAN data plane\\nRun the following command on node1.\\n$ docker swarm init\\nSwarm initialized: current node (1ex3...o3px) is now a manager.\\nThe command output includes a docker swarm join command. Copy this command\\nand run it node2.\\n$ docker swarm join \\\\\\n--token SWMTKN-1-0hz2ec...2vye \\\\\\n172.31.1.5:2377\\nThis node joined a swarm as a worker.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 224}, page_content='and run it node2.\\n$ docker swarm join \\\\\\n--token SWMTKN-1-0hz2ec...2vye \\\\\\n172.31.1.5:2377\\nThis node joined a swarm as a worker.\\nYou now have a two-node Swarm with node1 as a manager and node2 as a worker.\\nCreate a new overlay network\\nLet’s create a new encrypted overlay network called uber-net.\\nRun the following command from your manager node (node1).\\n$ docker network create -d overlay -o encrypted uber-net\\nvdu1yly429jvt04hgdm0mjqc6'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 225}, page_content='14: Docker overlay networking\\n219\\nThat’s it. You’ve created a brand-new encrypted overlay network. The network spans\\nboth nodes in the swarm and Docker uses TLS to encrypt it (AES in GCM mode). It also\\nrotates the encryption keys every 12 hours.\\nIf you don’t specify the -o encrypted flag, Docker will still encrypt the control plane\\n(management traffic) but won’t encrypt the data plane (application traffic). This can\\nbe important, as encrypting the data plane can decrease network performance by\\napproximately 10%.\\nList the networks on node1.\\n$ docker network ls\\nNETWORK ID\\nNAME\\nDRIVER\\nSCOPE\\n65585dda7500\\nbridge\\nbridge\\nlocal\\n7e368a1105c7\\ndocker_gwbridge\\nbridge\\nlocal\\na38083cdab1c\\nhost\\nhost\\nlocal\\n4dsqo7jc36ip\\ningress\\noverlay\\nswarm\\nd97e92a23945\\nnone\\nnull\\nlocal\\nvdu1yly429jv\\nuber-net\\noverlay\\nswarm\\n<<---- New overlay network\\nThe new network is at the bottom of the list called uber-net and is scoped to the entire\\nswarm (SCOPE = swarm). This means it spans every node in the swarm. However, if you'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 225}, page_content='<<---- New overlay network\\nThe new network is at the bottom of the list called uber-net and is scoped to the entire\\nswarm (SCOPE = swarm). This means it spans every node in the swarm. However, if you\\nlist networks on node2 you won’t see the uber-net network. This is because Docker\\nonly extends overlay networks to worker nodes when they need them. In our example,\\nDocker will extend the uber-net network to node2 when it runs a container that needs\\nit. This lazy approach to network deployment improves scalability by reducing the\\namount of network gossip on the swarm.\\nAttach a container to the overlay network\\nNow that you have an overlay network let’s connect a container to it.\\nBy default, you can only attach containers that are part of swarm services to overlay\\nnetworks. If you want to add standalone containers, you need to create the overlay with\\nthe --attachable flag.\\nThe example will create a swarm service called test with two replicas on the uber-net'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 225}, page_content='networks. If you want to add standalone containers, you need to create the overlay with\\nthe --attachable flag.\\nThe example will create a swarm service called test with two replicas on the uber-net\\nnetwork. One replica will be deployed to node1 and the other to node2, causing Docker\\nto extend the overlay network to node2.\\nRun the following commands from node1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 226}, page_content='14: Docker overlay networking\\n220\\n$ docker service create --name test \\\\\\n--network uber-net \\\\\\n--replicas 2 \\\\\\nubuntu sleep infinity\\nCheck the status of the service.\\n$ docker service ps test\\nID\\nNAME\\nIMAGE\\nNODE\\nDESIRED STATE\\nCURRENT STATE\\nsm1...1nw\\ntest.1\\nubuntu:latest\\nnode1\\nRunning\\nRunning\\ntro...kgk\\ntest.2\\nubuntu:latest\\nnode2\\nRunning\\nRunning\\nThe NODE column shows one replica running on each node.\\nSwitch over to node2 and run a docker network ls to verify it can now see the uber-\\nnet network.\\nCongratulations. You’ve created a new overlay network spanning two nodes on separate\\nunderlay networks and attached two containers to it. You’ll appreciate the simplicity\\nof what you’ve done when we reach the theory section and learn about the outrageous\\ncomplexity going on behind the scenes!\\nTest the overlay network\\nFigure 14.2 shows the current setup with two containers running on different Docker\\nhosts but connected to the same overlay.\\nFigure 14.2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 227}, page_content='14: Docker overlay networking\\n221\\nThe following steps will walk you through obtaining the container names and IP\\naddresses and then seeing if they can ping each other.\\nSwitch back to node1 and run a docker network inspect to see the overlay network’s\\nsubnet information and any IP addresses it’s assigned to service replicas.\\n$ docker network inspect uber-net\\n[\\n{\\n\"Name\": \"uber-net\",\\n\"Id\": \"vdu1yly429jvt04hgdm0mjqc6\",\\n\"Scope\": \"swarm\",\\n\"Driver\": \"overlay\",\\n\"EnableIPv6\": false,\\n\"IPAM\": {\\n\"Driver\": \"default\",\\n\"Options\": null,\\n\"Config\": [\\n{\\n\"Subnet\": \"10.0.0.0/24\",\\n<<---- Subnet info\\n\"Gateway\": \"10.0.0.1\"\\n<<---- Subnet info\\n}\\n\"Containers\": {\\n\"Name\": \"test.1.tro80xqwm7k1bsyn3mt1fjkgk\",\\n<<---- Replica ID\\n\"IPv4Address\": \"10.0.0.3/24\",\\n<<---- Container IP\\n<Snip>\\n},\\n<Snip>\\nI’ve snipped the output and highlighted the subnet info and the IPs of connected con-\\ntainers. One thing to note is that Docker only shows you the IP addresses of containers'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 227}, page_content='<Snip>\\n},\\n<Snip>\\nI’ve snipped the output and highlighted the subnet info and the IPs of connected con-\\ntainers. One thing to note is that Docker only shows you the IP addresses of containers\\nrunning on the local node. For example, the output in the book only shows the IP of the\\nfirst replica called test.1.tro...kgk. If you run the same command on node2, you’ll\\nsee the name and IP of the other replica.\\nRun the following commands on both nodes to get the local container names, IDs, and\\nIP addresses of both replicas and make a note of them.\\nThe ID at the end of the second command (d7766923a5a7) is the container ID as\\nreturned by the docker ps command. You’ll need to substitute the value from your\\nenvironment.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 228}, page_content='14: Docker overlay networking\\n222\\n$ docker ps\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\nNAME\\nd7766923a5a7\\nubuntu:latest\\n\"sleep infinity\"\\n2 hrs ago\\nUp 2 hrs\\ntest.1.tro...kgk\\n$ docker inspect \\\\\\n--format=\\'{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\\' d7766923a5a7\\n10.0.0.3\\nI have the following in my environment :\\n• replica 1: ID=d7766923a5a7, Name=test.1.tr0...kgk, IP=10.0.0.3\\n• replica 2: ID=b6c897d1186d, Name=test.2.sm1...1nw, IP=10.0.0.4\\nFigure 14.3 shows the configuration so far. Subnet and IP addresses may be different in\\nyour lab.\\nFigure 14.3\\nAs you can see, a layer 2 overlay network spans both nodes, and each container is\\nconnected to it with its own IP. This means the container on node1 can ping the\\ncontainer on node2 even though both nodes are on different underlay networks.\\nLet’s test it. You’ll need the names and IPs of your containers.\\nLog on to either of the containers and install the ping utility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 229}, page_content='14: Docker overlay networking\\n223\\n$ docker exec -it d7766923a5a7 bash\\n# apt update && apt-get install iputils-ping -y\\n<Snip>\\nReading package lists... Done\\nBuilding dependency tree\\nReading state information... Done\\n<Snip>\\nSetting up iputils-ping (3:20190709-3) ...\\nProcessing triggers for libc-bin (2.31-0ubuntu9) ...\\nNow ping the remote container by IP and then by replica ID.\\n# ping 10.0.0.4\\nPING 10.0.0.4 (10.0.0.4) 56(84) bytes of data.\\n64 bytes from 10.0.0.4: icmp_seq=1 ttl=64 time=1.06 ms\\n64 bytes from 10.0.0.4: icmp_seq=2 ttl=64 time=1.07 ms\\n64 bytes from 10.0.0.4: icmp_seq=3 ttl=64 time=1.03 ms\\n64 bytes from 10.0.0.4: icmp_seq=4 ttl=64 time=1.26 ms\\n^C\\n# ping test.2.sm180xqwm7k1bsyn3mt1fj1nw\\nPING test.2.sm180xqwm7k1bsyn3mt1fj1nw (10.0.0.4) 56(84) bytes of data.\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=1 ttl=64 time=2.83 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=2 ttl=64 time=8.39 ms'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 229}, page_content='64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=1 ttl=64 time=2.83 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=2 ttl=64 time=8.39 ms\\n64 bytes from test.2.sm1...1nw.uber-net (10.0.0.4): icmp_seq=3 ttl=64 time=5.88 ms\\n^C\\nCongratulations. The containers can ping each other via the overlay network, and all the\\ntraffic is encrypted.\\nYou can also trace the route of the ping command. This will report a single hop, proving\\nthat the containers are communicating directly via the overlay network — blissfully\\nunaware of any underlay networks being traversed.\\nYou’ll need to install traceroute in the container for this to work.\\n# apt install traceroute\\n<Snip>\\n# traceroute 10.0.0.4\\ntraceroute to 10.0.0.4 (10.0.0.4), 30 hops max, 60 byte packets\\n1\\ntest-svc.2.sm180xqwm7k1bsyn3mt1fj1nw.uber-net (10.0.0.4)\\n1.110ms\\n1.034ms\\n1.073ms\\nSo far, you’ve created an overlay network and a swarm service that connected two'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 229}, page_content='1\\ntest-svc.2.sm180xqwm7k1bsyn3mt1fj1nw.uber-net (10.0.0.4)\\n1.110ms\\n1.034ms\\n1.073ms\\nSo far, you’ve created an overlay network and a swarm service that connected two\\ncontainers to it. Swarm scheduled the containers to two different nodes and you proved\\nthey could ping each other via the overlay network.\\nNow that you’ve seen how easy it is to build and use secure overlay networks, let’s find\\nout how Docker builds them behind the scenes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 230}, page_content='14: Docker overlay networking\\n224\\nOverlay networks explained\\nFirst and foremost, Docker uses VXLAN tunnels to create virtual layer 2 overlay net-\\nworks. So, let’s do a quick VXLAN primer.\\nVXLAN primer\\nAt the highest level, Docker uses VXLANs to create layer 2 networks on top of existing\\nlayer 3 infrastructure. That’s a lot of jargon that means you can create simple networks\\non top of complex networks. The hands-on example in the previous sections created\\na new 10.0.0.0/24 layer 2 network that abstracted a more complex network topology\\nbelow. See Figure 14.4 and remember that your underlay network configuration was\\nprobably different.\\nFigure 14.4\\nFortunately, VXLAN is an encapsulation technology and, therefore, transparent to exist-\\ning routers and network infrastructure. This means the routers and other infrastructure\\nin the underlay network see the VXLAN/overlay traffic as regular IP/UDP packets and\\nhandle it without requiring changes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 230}, page_content='in the underlay network see the VXLAN/overlay traffic as regular IP/UDP packets and\\nhandle it without requiring changes.\\nTo create the overlay, Docker creates a VXLAN tunnel through the underlay networks,\\nand this tunnel is what allows the overlay traffic to flow freely without having to\\ninteract with the complexity of the underlay networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 231}, page_content='14: Docker overlay networking\\n225\\nTerminology: We use the terms underlay networks or underlay infrastructure to\\nrefer to the networks the overlay tunnels through.\\nEach end of the VXLAN tunnel is terminated by a VXLAN Tunnel Endpoint (VTEP), and\\nit’s this VTEP that encapsulates and de-encapsulates the traffic entering and exiting the\\ntunnel. See Figure 14.5.\\nFigure 14.5\\nThe image shows the layer 3 infrastructure as a cloud for two reasons:\\n• It can be a lot more complex than the two networks and a single router from the\\nprevious diagrams\\n• The VXLAN tunnel abstracts the complexity and makes it opaque\\nIn reality, the VXLAN tunnel traverses the underlay network. However, I don’t show\\nthis in the diagram to keep the diagram simple.\\nTraffic flow example\\nThe hands-on examples from earlier had two hosts connected via an IP network. You\\ndeployed an overlay network across both hosts, connected two containers to it, and did'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 231}, page_content='Traffic flow example\\nThe hands-on examples from earlier had two hosts connected via an IP network. You\\ndeployed an overlay network across both hosts, connected two containers to it, and did\\na ping test. Let’s explain some of the things that happened behind the scenes.\\nDocker created a new sandbox (network namespace) on each host with a new switch\\ncalled Br0. It also created a VTEP with one end connected to the Br0 virtual switch and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 232}, page_content='14: Docker overlay networking\\n226\\nthe other end connected to the host’s network stack. The end in the host’s network stack\\ngot an IP address on the underlay network that the host is connected to and was bound\\nto UDP port 4789. Finally, the two VTEPs on each host created a VXLAN tunnel as the\\nbackbone for the overlay network.\\nFigure 14.6 shows the configuration. Remember, the VXLAN tunnel goes through the\\nnetworks at the bottom of the diagram; I’ve just drawn it higher up for readability.\\nFigure 14.6\\nAt this point, you’ve created the VXLAN overlay, and you’re ready to connect contain-\\ners.\\nDocker now creates a virtual Ethernet adapter (veth) in each container and connects it\\nto the local Br0 virtual switch. The final topology looks like Figure 14.7, and although\\nit’s complex, you should now see how the containers communicate over the VXLAN\\noverlay despite their hosts being on two separate networks — the overlay is a virtual\\nnetwork tunneled through the underlay networks.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 233}, page_content='14: Docker overlay networking\\n227\\nFigure 14.7\\nNow that you know how Docker creates overlay networks, let’s see how the two\\ncontainers communicate.\\nWarning! This section is very technical, and you don’t need to understand it\\nall for day-to-day operations.\\nFor this example, we’ll call the container on node1 “C1” and the container on node2\\n“C2”. We’ll also assume C1 wants to ping C2 like we did in the practical example earlier.\\nFigure 14.8 shows the full configuration with container names and IPs added.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 234}, page_content='14: Docker overlay networking\\n228\\nFigure 14.8\\nC1 initiates a ping request to 10.0.0.4 — the IP address of C2.\\nC1 doesn’t have an entry for 10.0.0.4 in its local MAC address table (ARP cache), so\\nit floods the packet on all interfaces, including the veth interface connected to the Br0\\nbridge. The Br0 bridge knows it can forward traffic for 10.0.0.4 to the connected\\nVTEP interface and sends a proxy ARP reply to the container. This results in the veth\\nlearning how to forward the packet by updating its own MAC table to send all future\\npackets for 10.0.0.4 directly to the local VTEP. The Br0 switch knew about the C2\\ncontainer because Docker propagates details of all new containers to every swarm node\\nvia the network’s built-in gossip protocol.\\nNext, the veth in the C1 container sends the ping to the VTEP interface which encapsu-\\nlates it for transmission through the VXLAN tunnel. The encapsulation adds a VXLAN\\nheader containing a VXLAN network ID (VNID) that maps traffic from VLANs to'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 234}, page_content='lates it for transmission through the VXLAN tunnel. The encapsulation adds a VXLAN\\nheader containing a VXLAN network ID (VNID) that maps traffic from VLANs to\\nVXLANs and vice versa — each VLAN gets mapped to its own VNID so that packets\\ncan be de-encapsulated on the receiving end and forwarded to the correct VLAN. This\\nmaintains network isolation.\\nThe encapsulation also wraps the frame in a UDP packet and adds the IP of the remote\\nVTEP on node2 in the destination IP field. It also adds the UDP/4789 socket information.\\nThis encapsulation allows the packets to be routed across the underlay networks\\nwithout the underlays knowing anything about VXLAN.\\nWhen the packet arrives at node2, the host’s kernel sees it’s addressed to UDP port\\n4789 and knows it has a VTEP bound to this socket. This means it sends the packet to\\nthe VTEP, which reads the VNID, de-encapsulates it, and sends it to its own local Br0\\nswitch on the VLAN corresponding to the VNID. From there, it delivers it to the C2'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 235}, page_content='14: Docker overlay networking\\n229\\ncontainer.\\nAnd that, my friends, is how Docker uses VXLAN to build and operate overlay networks\\n— a whole load of mind-blowing complexity beautifully hidden behind a single Docker\\ncommand.\\nI’m hoping that’s enough to get you started and help you when talking to your network-\\ning team about the networking aspects of your Docker infrastructure. On the topic of\\ntalking to your networking team… don’t approach them thinking that you now know\\neverything about VXLAN. If you do, you’ll probably embarrass yourself. I’m speaking\\nfrom experience ;-)\\nOne final thing. Docker also supports layer 3 routing within an overlay network. For\\nexample, you can create a single overlay network with two subnets, and Docker will\\nhandle the routing. The following command will create a new overlay called prod-net\\nwith two subnets. Docker will automatically create two virtual switches called Br0 and\\nBr1 inside the sandbox and handle all the routing.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 235}, page_content='with two subnets. Docker will automatically create two virtual switches called Br0 and\\nBr1 inside the sandbox and handle all the routing.\\n$ docker network create --subnet=10.1.1.0/24 --subnet=11.1.1.0/24 -d overlay prod-net\\nClean up\\nIf you followed along, you’ll have created an overlay network called uber-net and\\ndeployed a service called test. You may also have created a swarm.\\nRun the following command to delete the test service.\\n$ docker service rm test\\nDelete the uber-net network with the following command. You may have to wait a few\\nseconds while Docker deletes the service using it.\\n$ docker network rm uber-net\\nIf you no longer need the swarm, you can run a docker swarm leave -f command on\\nboth nodes. You should run it on node2 first.\\nDocker overlay networking – The commands\\n• docker network create tells Docker to create a new network. You use the -d\\noverlay flag to use the overlay driver to create an overlay network. You can also'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 235}, page_content='Docker overlay networking – The commands\\n• docker network create tells Docker to create a new network. You use the -d\\noverlay flag to use the overlay driver to create an overlay network. You can also\\npass the -o encrypted flag to tell Docker to encrypt network traffic. However,\\nperformance may drop in the region of 10%.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 236}, page_content='14: Docker overlay networking\\n230\\n• docker network ls lists all the container networks visible to a Docker host.\\nDocker hosts running in swarm mode only see overlay networks if they run\\ncontainers attached to the network. This keeps network-related management\\ntraffic to a minimum.\\n• docker network inspect shows detailed information about a particular container\\nnetwork. You can find out the scope, driver, IPv4 and IPv6 info, subnet configura-\\ntion, IP addresses of connected containers, VXLAN network ID, encryption state,\\nand more.\\n• docker network rm deletes a network.\\nChapter Summary\\nIn this chapter, you created a new Docker overlay network and learned about the\\ntechnologies Docker uses to build them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 237}, page_content='15: Volumes and persistent data\\nStateful applications that create and manage data are a big part of modern cloud-native\\napps. This chapter explains how Docker volumes help stateful applications manage their\\ndata.\\nI’ve split the chapter into the following parts:\\n• Volumes and persistent data – The TLDR\\n• Containers without volumes\\n• Containers with volumes\\n• The commands\\nVolumes and persistent data – The TLDR\\nThere are two main types of data — persistent and non-persistent.\\nPersistent data is the stuff you care about and need to keep. It includes things like cus-\\ntomer records, financial data, research results, audit data, and even some types of logs.\\nNon-persistent data is the stuff you don’t care about and don’t need to keep. We call\\napplications that create and manage persistent data stateful apps, and applications that\\ndon’t create or manage persistent data stateless apps.\\nBoth are important, and Docker has solutions for both.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 237}, page_content='applications that create and manage persistent data stateful apps, and applications that\\ndon’t create or manage persistent data stateless apps.\\nBoth are important, and Docker has solutions for both.\\nFor stateless apps, Docker creates every container with an area of non-persistent local\\nstorage that’s tied to the container lifecycle. This storage is suitable for scratch data\\nand temporary files, but you’ll lose it when you delete the container or the container\\nterminates.\\nDocker has volumes for stateful apps that create and manage important data. Volumes are\\nseparate objects that you mount into containers, and they have their own lifecycles. This\\nmeans you don’t lose the volumes or the data on them when you delete containers. You\\ncan even mount volumes into different containers.\\nThat’s the TLDR. Let’s take a closer look.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 238}, page_content='15: Volumes and persistent data\\n232\\nContainers without volumes\\nIn the early days of Docker, containers were only good for stateless applications that\\ndidn’t generate important data. However, despite being stateless, many of these apps still\\nneeded a place to write temporary scratch data. So, as shown in Figure 15.1, Docker\\ncreates containers by stacking read-only image layers and placing a thin layer of local\\nstorage on top. The same technology allows multiple containers to share the same read-\\nonly image layers.\\nFigure 15.1 - Ephemeral container storage\\nThis thin layer of local storage is integral to the read-write nature of containers. For\\nexample, if an application needs to update existing files or add new files, it makes\\nthe changes in the local storage layer, and Docker merges them into the view of the\\ncontainer. However, the local storage is coupled to the container’s lifecycle, meaning it\\ngets created when you create the container, and deleted when you delete it. This means'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 238}, page_content='container. However, the local storage is coupled to the container’s lifecycle, meaning it\\ngets created when you create the container, and deleted when you delete it. This means\\nit’s not a good place for data that you need to keep (persist).\\nDocker keeps the local storage layer on the Docker host’s filesystem, and you’ll hear it\\ncalled various names such as the thin writeable layer, ephemeral storage, read-write storage,\\nand graphdriver storage. It’s usually located in the following locations on your Docker\\nhosts:\\n• Linux containers: /var/lib/docker/<storage-driver>/...\\n• Windows containers: C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\...\\nEven though the local storage layer allows you to update live containers, you should\\nnever do this. Instead, you should treat containers as immutable objects and never change\\nthem once deployed. For example, if you need to fix or change the configuration of a live\\ncontainer, you should create and test a new container with the changes and then replace'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 238}, page_content='them once deployed. For example, if you need to fix or change the configuration of a live\\ncontainer, you should create and test a new container with the changes and then replace\\nthe live container with the new one.\\nTo be clear, applications like databases can change the data they manage. But users\\nand configuration tools should never change the container’s configuration, such as its\\nnetwork or application configuration. You should always make changes like these in a\\nnew container and then replace the old container with the new one.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 239}, page_content='15: Volumes and persistent data\\n233\\nIf your containers don’t create persistent data, this thin writable layer of local storage\\nwill be fine, and you’ll be good to go. However, if your containers create persistent data,\\nyou need to read the next section.\\nContainers with volumes\\nThere are three main reasons you should use volumes to handle persistent data in\\ncontainers:\\n• Volumes are independent objects that are not tied to the lifecycle of a container\\n• You can map volumes to specialized external storage systems\\n• Multiple containers on different Docker hosts can use volumes to access and share\\nthe same data\\nAt a high level, you create a volume, then create a container, and finally mount the\\nvolume into the container. When you mount it into the volume, you mount it into a\\ndirectory in the container’s filesystem, and anything you write to that directory gets\\nstored in the volume. If you delete the container, the volume and data will still exist.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 239}, page_content='directory in the container’s filesystem, and anything you write to that directory gets\\nstored in the volume. If you delete the container, the volume and data will still exist.\\nYou’ll even be able to mount the surviving volume into another container.\\nFigure 15.2 shows a Docker volume outside the container as a separate object. The\\nvolume is mounted into the container’s filesystem at /data, and anything you write to\\nthat directory will be stored on the volume and exist after you delete the container.\\nFigure 15.2 - High-level view of volumes and containers\\nThe image also shows that you can map the volume to an external storage system\\nor a directory on the Docker host. External storage systems can be cloud services or\\ndedicated storage appliances, but either way, the volume’s lifecycle is decoupled from\\nthe container. All of the container’s other directories use the thin writable layer in the\\nlocal storage area on the Docker host.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 240}, page_content='15: Volumes and persistent data\\n234\\nCreating and managing Docker volumes\\nVolumes are first-class objects in Docker. This means there’s a docker volume sub-\\ncommand, and a volume resource in the API.\\nRun the following command to create a new volume called myvol.\\n$ docker volume create myvol\\nmyvol\\nBy default, Docker creates new volumes with the built-in local driver. And, as the name\\nof the driver suggests, these volumes are only available to containers on the same node\\nas the volume. You can use the -d flag to specify a different driver, but you’ll need to\\ninstall the driver first.\\nThird-party drivers22 provide advanced features and access to external storage systems\\nsuch as cloud storage services and on-premises storage systems such as SAN and NAS.\\nFigure 15.3 shows a Docker host connected to an external storage system via a plugin\\n(driver).\\nFigure 15.3 - Plugging external storage into Docker\\nOnce you’ve created the volume, you can see it with the docker volume ls command'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 240}, page_content='(driver).\\nFigure 15.3 - Plugging external storage into Docker\\nOnce you’ve created the volume, you can see it with the docker volume ls command\\nand inspect it with the docker volume inspect command.\\n22https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 241}, page_content='15: Volumes and persistent data\\n235\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nmyvol\\n$ docker volume inspect myvol\\n[\\n{\\n\"CreatedAt\": \"2024-05-15T12:23:14Z\",\\n\"Driver\": \"local\",\\n\"Labels\": null,\\n\"Mountpoint\": \"/var/lib/docker/volumes/myvol/_data\",\\n\"Name\": \"myvol\",\\n\"Options\": null,\\n\"Scope\": \"local\"\\n}\\n]\\nNotice that the Driver and Scope fields are both set to local. This means you created\\nthe volume with the local driver, and it’s only available to containers on this Docker\\nhost. Mountpoint tells you where the volume exists in the Docker host’s filesystem.\\nBy default, Docker gives every volume created with the local driver its own directory\\non the host under /var/lib/docker/volumes. This means anyone with access to the\\nDocker host can bypass the container and access the volume’s contents directly in the\\nhost’s filesystem. You saw this in the Docker Compose chapter when we copied a file\\ndirectly into a volume’s directory on the Docker host, and the file immediately appeared'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 241}, page_content='host’s filesystem. You saw this in the Docker Compose chapter when we copied a file\\ndirectly into a volume’s directory on the Docker host, and the file immediately appeared\\nin the volume inside the container. However, that’s not a recommended practice.\\nNow that you’ve created a volume, you can create containers to use it. However, before\\nyou do that, there are two ways to delete Docker volumes:\\n• docker volume prune\\n• docker volume rm\\nThe docker volume prune --all command deletes all volumes not mounted into a\\ncontainer or service replica, so use it with caution!\\nThe docker volume rm command is more precise and lets you specify which volumes to\\ndelete.\\nNeither command will delete a volume in use by a container or service replica.\\nThe myvol volume you created isn’t used by a container, so you can delete it with either\\ncommand. Be careful if you use the prune command, as it may also delete other volumes.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 242}, page_content='15: Volumes and persistent data\\n236\\n$ docker volume prune --all\\nWARNING! This will remove all local volumes not used by at least one container.\\nAre you sure you want to continue? [y/N] y\\nDeleted Volumes:\\nmyvol\\nTotal reclaimed space: 0B\\nCongratulations. You’ve created, inspected, and deleted a Docker volume, and none\\nof the actions involved a container. This proves that volumes are decoupled from\\ncontainers.\\nAt this point, you know all the commands to create, list, inspect, and delete Docker\\nvolumes. You’ve even seen how to deploy them via Compose files in the Compose and\\nSwarm stacks chapters. However, you can also deploy volumes via Dockerfiles by using\\nthe VOLUME instruction. The format is VOLUME <container-mount-point>. Interestingly,\\nyou cannot specify a host directory when you define volumes in a Dockerfile. This is\\nbecause host directories can differ depending on your host OS, and you could easily'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 242}, page_content='you cannot specify a host directory when you define volumes in a Dockerfile. This is\\nbecause host directories can differ depending on your host OS, and you could easily\\nbreak your builds if you specified a directory that doesn’t exist on a host. As a result,\\ndefining a volume in a Dockerfile requires you to specify host directories at deployment\\ntime.\\nUsing volumes with containers\\nLet’s see how to use volumes with containers.\\nRun the following command to create a new standalone container called voltainer that\\nmounts a volume called bizvol.\\n$ docker run -it --name voltainer \\\\\\n--mount source=bizvol,target=/vol \\\\\\nalpine\\nThe command specified the --mount flag, telling Docker to mount a volume called\\nbizvol into the container at /vol. The command completed successfully even though\\nyou didn’t have a volume called bizvol. This raises an important point:\\n• If you specify a volume that already exists, Docker will use it\\n• If you specify a volume that does not exist, Docker will create it'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 242}, page_content='• If you specify a volume that already exists, Docker will use it\\n• If you specify a volume that does not exist, Docker will create it\\nIn our case, bizvol didn’t exist, so Docker created it and mounted it into the container.\\nType Ctrl PQ to return to your local shell, and then list volumes to make sure Docker\\ncreated it.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 243}, page_content='15: Volumes and persistent data\\n237\\n# <Ctrl-PQ>\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nbizvol\\nEven though volumes are decoupled from containers, Docker won’t let you delete this\\none because it’s in use by the voltainer container.\\nTry to delete it.\\n$ docker volume rm bizvol\\nError response from daemon: remove bizvol: volume is in use - [b44d3f82...dd2029ca]\\nAs expected, you can’t delete it.\\nThe volume is brand new, so it doesn’t have any data. Let’s exec onto the container and\\nwrite some data to it.\\n$ docker exec -it voltainer sh\\n# echo \"I promise to write a book review on Amazon\" > /vol/file1\\nThe command writes some text to a file called file1 in the /vol directory where the\\nvolume is mounted.\\nRun a few commands to make sure the file and data exist.\\n# ls -l /vol\\ntotal 4\\n-rw-r--r-- 1 root\\nroot\\n50 May 23 08:49 file1\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nType exit to return to your Docker host’s shell, and then delete the container with the\\nfollowing commands.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 243}, page_content='root\\n50 May 23 08:49 file1\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nType exit to return to your Docker host’s shell, and then delete the container with the\\nfollowing commands.\\n# exit\\n$ docker rm voltainer -f\\nvoltainer\\nCheck that Docker deleted the container but kept the volume.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 244}, page_content='15: Volumes and persistent data\\n238\\n$ docker ps -a\\nCONTAINER ID\\nIMAGE\\nCOMMAND\\nCREATED\\nSTATUS\\n$ docker volume ls\\nDRIVER\\nVOLUME NAME\\nlocal\\nbizvol\\nAs the volume still exists, you can view its contents in the Docker host’s local filesystem.\\nRemember, though, that it’s not recommended to access volumes directly via the host’s\\nfilesystem. We’re just showing you how to do it for demonstration and educational\\nreasons.\\nRun the following commands from your Docker host terminal. They’ll show the\\ncontents of the volume’s directory on your Docker host. The first command will show\\nthat the file still exists, and the second will show its contents.\\nThis step won’t work on Docker Desktop, as Docker Desktop runs inside a VM. You\\nmay have to prefix the commands with sudo.\\n$ ls -l /var/lib/docker/volumes/bizvol/_data/\\ntotal 4\\n-rw-r--r-- 1 root root 50 Jan 12 14:25 file1\\n$ cat /var/lib/docker/volumes/bizvol/_data/file1\\nI promise to write a book review on Amazon\\nGreat, the volume and the data still exist.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 244}, page_content='total 4\\n-rw-r--r-- 1 root root 50 Jan 12 14:25 file1\\n$ cat /var/lib/docker/volumes/bizvol/_data/file1\\nI promise to write a book review on Amazon\\nGreat, the volume and the data still exist.\\nLet’s see if you can mount the existing bizvol volume into a new service or container.\\nRun the following command to create a new container called newctr that mounts bizvol\\nat /vol.\\n$ docker run -it \\\\\\n--name newctr \\\\\\n--mount source=bizvol,target=/vol \\\\\\nalpine sh\\nYour terminal is now attached to the newctr container. Check to see if the volume and\\ndata are mounted as expected.\\n# cat /vol/file1\\nI promise to write a book review on Amazon\\nCongratulations. You’ve created a volume, written some data to it, deleted the original\\ncontainer, mounted it in a second container, and verified the data still exists.\\nType exit to leave the container and jump over to Amazon to leave the book review you\\npromised to write.\\nIf you left a review, thanks! If you didn’t, I’ll cry, but I’ll live ;-)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 245}, page_content='15: Volumes and persistent data\\n239\\nSharing storage across cluster nodes\\nIntegrating Docker with external storage systems lets you present shared storage to\\nmultiple nodes so that the containers running on different nodes can share the same\\nvolumes. These external systems can be cloud storage services or enterprise storage\\nsystems in your on-premises data centers. For example, you can present a single storage\\nLUN or NFS share (shared volume) to multiple Docker hosts so that any container on\\nthose hosts can access and share the volume. Figure 15.4 shows an external storage\\nsystem presenting a shared volume to two Docker nodes. The Docker nodes use the\\nappropriate driver for the external system to make the shared volume available to either\\nor both containers.\\nFigure 15.4\\nBuilding a shared setup like this requires a lot of things. You need access to specialized\\nstorage systems and knowledge of how they work. You also need a volume driver/plugin'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 245}, page_content='Figure 15.4\\nBuilding a shared setup like this requires a lot of things. You need access to specialized\\nstorage systems and knowledge of how they work. You also need a volume driver/plugin\\nthat works with the external storage system. Finally, you need to know how your\\napplications read and write to the shared storage to avoid potential data corruption.\\nPotential data corruption\\nData corruption is a major concern for any shared storage configuration.\\nAssume the following example based on Figure 15.4.\\nThe application running in ctr1 writes an update to the shared volume. However,\\ninstead of directly committing the update, it keeps it in a local cache for faster recall. At\\nthis point, the application in ctr1 thinks it’s written data to the volume. However, before\\nctr1 flushes its cache and commits the data to the volume, the app in ctr2 updates the\\nsame data with a different value and commits it directly to the volume. At this point,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 245}, page_content='ctr1 flushes its cache and commits the data to the volume, the app in ctr2 updates the\\nsame data with a different value and commits it directly to the volume. At this point,\\nboth applications think they’ve updated the data in the volume, but in reality, only'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 246}, page_content='15: Volumes and persistent data\\n240\\nthe application in ctr2 has. A few seconds later, ctr1 flushes the data to the volume\\nand overwrites the changes made by the application in ctr2. However, neither of the\\napplications is aware of the changes the other has made.\\nThis is why you need to design applications that share data to coordinate updates to\\nshared volumes.\\nClean up\\nIf you’ve been following along, you’ll have a container and a volume.\\nRun the following command to delete the container.\\n$ docker rm\\nNow, run this command to delete the volume.\\n$ docker volume rm bizvol\\nVolumes and persistent data – The Commands\\n• docker volume create creates new volumes. By default, it creates them with the\\nlocal driver, but you can use the -d flag to specify a different driver.\\n• docker volume ls lists all volumes on your Docker host.\\n• docker volume inspect shows you detailed volume information. You can use this\\ncommand to see where a volume exists in the Docker host’s filesystem.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 246}, page_content='• docker volume inspect shows you detailed volume information. You can use this\\ncommand to see where a volume exists in the Docker host’s filesystem.\\n• docker volume prune deletes all volumes not in use by a container or service\\nreplica. Use with caution!\\n• docker volume rm deletes specific volumes that are not in use.\\nChapter Summary\\nThere are two main types of data: persistent and non-persistent.\\nPersistent data is data you need to keep, and non-persistent data is data you don’t need\\nto keep.\\nBy default, all containers get a layer of writable non-persistent storage that lives and dies\\nwith the container. We sometimes call this local storage, and it’s ideal for non-persistent'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 247}, page_content='15: Volumes and persistent data\\n241\\ndata. However, if your apps create data you need to keep, you should store the data in a\\nDocker volume.\\nDocker volumes are first-class objects in the Docker API, and you manage them\\nindependently of containers using their own docker volume sub-command. This means\\ndeleting containers doesn’t delete the data in their volumes.\\nA few third-party plugins exist that provide Docker with access to specialized external\\nstorage systems.\\nVolumes are the recommended way to work with persistent data in Docker environ-\\nments.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 248}, page_content='16: Docker security\\nIf security is hard, we’re less likely to implement it. Fortunately, most of the security\\nin Docker is easy and pre-configured with sensible defaults. This means you get a\\nmoderately secure experience with zero effort. The defaults are not perfect, but they’re a\\ngood starting point.\\nDocker supports all major Linux security technologies and adds some of its own. As\\nsuch, I’ve divided the chapter so we cover the Linux security technologies first and\\nfinish the chapter covering the Docker technologies:\\n• Docker security – The TLDR\\n• Linux security technologies\\n– Kernel namespaces\\n– Control Groups\\n– Capabilities\\n– Mandatory Access Control\\n– seccomp\\n• Docker security technologies\\n– Swarm security\\n– Docker Scout and vulnerability scanning\\n– Docker Content Trust\\n– Docker secrets\\nThe chapter focuses heavily on Linux, but the sections relating to Docker security\\ntechnologies apply to Linux and Windows containers.\\nDocker security – The TLDR'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 248}, page_content='– Docker secrets\\nThe chapter focuses heavily on Linux, but the sections relating to Docker security\\ntechnologies apply to Linux and Windows containers.\\nDocker security – The TLDR\\nGood security is about layers and defence in depth, and more layers is always better.\\nFortunately, Docker offers a lot of security layers, including the ones shown in Figure\\n16.1.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 249}, page_content='16: Docker security\\n243\\nFigure 16.1\\nAs you can see, Docker leverages the common Linux security and workload isolation\\ntechnologies, including namespaces, control groups, capabilities, mandatory access control\\n(MAC), and seccomp. It ships with sensible defaults for each one, but you can customize\\nthem to your specific requirements.\\nDocker also has its own security technologies, including Docker Scout and Docker\\nContent Trust.\\nDocker Scout offers class-leading vulnerability scanning that scans your images, provides\\ndetailed reports on known vulnerabilities, and recommends solutions. Docker Content\\nTrust (DCT) lets you cryptographically sign and verify images.\\nIf you use Docker Swarm, you’ll also get all of the following that Docker automatically\\nconfigures: cryptographic node IDs, mutual authentication (TLS), automatic CA\\nconfiguration and certificate rotation, secure cluster join tokens, an encrypted cluster\\nstore, encrypted networks, and more.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 249}, page_content='configuration and certificate rotation, secure cluster join tokens, an encrypted cluster\\nstore, encrypted networks, and more.\\nOther security-related technologies also exist, but the important thing to know is that\\nDocker works with the major Linux security technologies and adds a few of its own.\\nSometimes, the Linux security technologies can be complex and challenging to work\\nwith, but the native Docker ones are always easy.\\nKernel Namespaces\\nKernel namespaces, usually shortened to namespaces, are the main technology for building\\ncontainers.\\nLet’s quickly compare namespaces and containers with hypervisors and virtual ma-\\nchines (VM).'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 250}, page_content='16: Docker security\\n244\\nNamespaces virtualize operating system constructs such as process trees and filesystems,\\nwhereas hypervisors virtualize physical resources such as CPUs and disks. In the VM model,\\nhypervisors create virtual machines by grouping virtual CPUs, virtual disks, and virtual\\nnetwork cards so that every VM looks, smells, and feels like a physical machine. In the\\ncontainer model, namespaces create virtual operating systems (containers) by grouping\\nvirtual process trees, virtual filesystems, and virtual network interfaces so that every\\ncontainer looks, smells, and feels exactly like a regular OS.\\nAt a very high level, namespaces provide lightweight isolation but do not provide a\\nstrong security boundary. Compared with VMs, containers are more efficient, but\\nvirtual machines are more secure.\\nDon’t worry, though. Platforms like Docker implement additional security technologies,\\nsuch as cgroups, capabilities, and seccomp, to improve container security.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 250}, page_content='virtual machines are more secure.\\nDon’t worry, though. Platforms like Docker implement additional security technologies,\\nsuch as cgroups, capabilities, and seccomp, to improve container security.\\nNamespaces are a tried and tested technology that’s existed in the Linux kernel for\\na very long time. However, they were complex and hard to work with until Docker\\ncame along and hid all the complexity behind the simple docker run command and a\\ndeveloper-friendly API.\\nAt the time of writing, every Docker container gets its own instance of the following\\nnamespaces:\\n• Process ID (pid)\\n• Network (net)\\n• Filesystem/mount (mnt)\\n• Inter-process Communication (ipc)\\n• User (user)\\n• UTS (uts)\\nFigure 16.2 shows a single Docker host running two containers. The host OS has its\\nown collection of namespaces we call the root namespaces, and each container has its own\\ncollection of equivalent isolated namespaces. Applications in containers think they’re'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 250}, page_content='own collection of namespaces we call the root namespaces, and each container has its own\\ncollection of equivalent isolated namespaces. Applications in containers think they’re\\nrunning on their own host and are unaware of the root namespaces or namespaces in\\nother containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 251}, page_content='16: Docker security\\n245\\nFigure 16.2\\nLet’s briefly look at how Docker uses each namespace:\\n• Process ID namespace: Docker uses the pid namespace to give each container\\nits own isolated process tree. This means every container gets its own PID 1 and\\ncannot see or access processes running in other containers. Nor can any container\\nsee or access processes running on the host.\\n• Network namespace: Docker uses the net namespace to provide each container\\nwith an isolated network stack. This stack includes interfaces, IP addresses,\\nport ranges, and routing tables. For example, every container gets its own eth0\\ninterface with its own unique IP and range of ports.\\n• Mount namespace: Every container has its own mnt namespace with its own\\nunique isolated root (/) filesystem. This means every container can have its own\\n/etc, /var, /dev, and other important filesystem constructs. Processes inside a\\ncontainer cannot access the host’s filesystem or filesystems in other containers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 251}, page_content='/etc, /var, /dev, and other important filesystem constructs. Processes inside a\\ncontainer cannot access the host’s filesystem or filesystems in other containers.\\n• Inter-process Communication namespace: Docker uses the ipc namespace\\nfor shared memory access within a container. It also isolates the container from\\nshared memory on the host and other containers.\\n• User namespace: Docker gives each container its own users that are only valid\\ninside the container. It also lets you map those users to different users on the\\nDocker host. For example, you can map a container’s root user to a non-root user\\non the host.\\n• UTS namespace: Docker uses the uts namespace to provide each container with\\nits own hostname.\\nRemember, a container is a collection of namespaces that Docker organizes to look like\\na regular OS. These namespaces provide isolation, but they are not a strong enough'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 252}, page_content='16: Docker security\\n246\\nsecurity boundary on their own. This is why Docker augments container security with\\nthe technologies we’re about to discuss.\\nControl Groups\\nIf namespaces are about isolation, control groups (cgroups) are about limits.\\nThink of containers as similar to rooms in a hotel. While each room might appear to be\\nisolated, they actually share a lot of things such as water supply, electricity supply, air\\nconditioning, swimming pool, gym, elevators, breakfast bar, and more. Containers are\\nsimilar — even though they’re isolated, they share a lot of common resources such as the\\nhost’s CPU, RAM, network I/O, and disk I/O.\\nDocker uses cgroups to limit a container’s use of these shared resources and prevent any\\ncontainer from consuming them all and causing a denial of service (DoS) attack.\\nCapabilities\\nThe Linux root user is extremely powerful, and you shouldn’t use it to run apps and\\ncontainers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 252}, page_content='container from consuming them all and causing a denial of service (DoS) attack.\\nCapabilities\\nThe Linux root user is extremely powerful, and you shouldn’t use it to run apps and\\ncontainers.\\nHowever, it’s not as simple as running them as non-root users, as most non-root users\\nare so powerless that they are practically useless. What’s needed is a way to run apps and\\ncontainers with the exact set of permissions they need — nothing more, nothing less.\\nThis is where capabilities come to the rescue.\\nUnder the hood, the Linux root user is a combination of a long list of capabilities. Some\\nof these capabilities include:\\n• CAP_CHOWN: lets you change file ownership\\n• CAP_NET_BIND_SERVICE: lets you bind a socket to low-numbered network\\nports\\n• CAP_SETUID: lets you elevate the privilege level of a process\\n• CAP_SYS_BOOT: lets you reboot the system.\\nThe list goes on and is long.\\nDocker leverages capabilities so that you can run containers as root but strip out'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 252}, page_content='• CAP_SYS_BOOT: lets you reboot the system.\\nThe list goes on and is long.\\nDocker leverages capabilities so that you can run containers as root but strip out\\nall the capabilities you don’t need. For example, suppose the only capability your\\ncontainer needs is the ability to bind to low-numbered network ports. In that case,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 253}, page_content='16: Docker security\\n247\\nDocker can start the container as root, drop all root capabilities, and then add back the\\nCAP_NET_BIND_SERVICE capability.\\nThis is a good example of implementing the principle of least privilege as you end up\\nwith a container that only has the capabilities it needs. Docker also sets restrictions to\\nprevent containers from re-adding dropped capabilities.\\nDocker ships with sensible out-of-the-box capabilities, but you should configure your\\nown for your production apps and containers. However, configuring your own requires\\nextensive effort and testing.\\nMandatory Access Control systems\\nDocker works with major Linux MAC technologies such as AppArmor and SELinux.\\nDepending on your Linux distribution, Docker applies default AppArmor or SELinux\\nprofiles to all new containers, and according to the Docker documentation, the default\\nprofiles are moderately protective while providing wide application compatibility.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 253}, page_content='profiles to all new containers, and according to the Docker documentation, the default\\nprofiles are moderately protective while providing wide application compatibility.\\nYou can tell Docker to start containers without these policies, and you can configure\\nyour own. However, as with capabilities, configuring your own policies is very powerful\\nbut requires a lot of effort and testing.\\nseccomp\\nDocker uses seccomp to limit which syscalls a container can make to the host’s kernel.\\nSyscalls are how applications ask the Linux kernel to perform tasks. At the time of writ-\\ning, Linux has over 300 syscalls and the default Docker profile disables approximately\\n40-50.\\nAs per the Docker security philosophy, all new containers get a default seccomp profile\\nconfigured with sensible defaults designed to provide moderate security without impacting\\napplication compatibility.\\nAs always, you can customize your own seccomp profiles or tell Docker to start'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 253}, page_content='configured with sensible defaults designed to provide moderate security without impacting\\napplication compatibility.\\nAs always, you can customize your own seccomp profiles or tell Docker to start\\ncontainers without one. Unfortunately, the Linux syscall table is long, and configuring\\ncustom seccomp policies may be prohibitively complex for some users.\\nFinal thoughts on the Linux security technologies\\nDocker supports most of the important Linux security technologies and ships with\\nsensible defaults that add security without being too restrictive. Figure 16.3 shows how\\nDocker uses them to build a defence in depth security posture with multiple layers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 254}, page_content='16: Docker security\\n248\\nFigure 16.3 - Linux security defense in depth\\nSome of these technologies require knowledge of the Linux kernel and can be complex\\nto customize. Fortunately, many platforms, including Docker, ship with defaults that are\\na good place to start.\\nDocker security technologies\\nLet’s switch our focus to some of the security technologies Docker offers.\\nSwarm security\\nDocker Swarm lets you cluster multiple Docker hosts and manage applications declar-\\natively. Every Swarm comprises manager nodes and worker nodes that can be Linux or\\nWindows. Managers host the control plane and are responsible for configuring the\\ncluster and dispatching work tasks. Workers run application containers.\\nFortunately, swarm mode includes many security features that Docker automatically\\nconfigures with sensible defaults. These include:\\n• Cryptographic node IDs\\n• TLS for mutual authentication'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 255}, page_content='16: Docker security\\n249\\n• Secure join tokens\\n• CA configuration with automatic certificate rotation\\n• Encrypted cluster store\\n• Encrypted networks\\nLet’s walk through building a secure swarm and configuring some of the security\\naspects.\\nIf you’re following along, you’ll need three Docker hosts that can ping each other by\\nname. The examples use three hosts called mgr1, mgr2, and wrk1.\\nConfigure a secure Swarm\\nRun the following command from the node you want to be the first manager. We’ll run\\nthe example from mgr1.\\n$ docker swarm init\\nSwarm initialized: current node (7xam...662z) is now a manager.\\nThat’s it! You’ve configured a secure swarm with a cryptographic cluster ID, an en-\\ncrypted cluster store, a certificate authority (CA) with a 90-day certificate rotation\\npolicy, a set of secure join tokens to use when adding new managers and workers, and\\nconfigured the current manager with a client certificate for mutual TLS — all with a\\nsingle command!'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 255}, page_content='policy, a set of secure join tokens to use when adding new managers and workers, and\\nconfigured the current manager with a client certificate for mutual TLS — all with a\\nsingle command!\\nThe CA is for internal Swarm security, and you should be careful using it for anything\\nelse.\\nFigure 16.4 shows the current swarm configuration. Some of the details may be\\ndifferent in your lab.\\nFigure 16.4'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 256}, page_content='16: Docker security\\n250\\nLet’s join mgr2 as an additional manager.\\nJoining new managers is a two-step process:\\n• Extract the secure join token\\n• Execute a docker swarm join command with the join token on the node you’re\\nadding\\nRun the following command from mgr1 to extract the manager join token.\\n$ docker swarm join-token manager\\nTo add a manager to this swarm, run the following command:\\ndocker swarm join --token \\\\\\nSWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz \\\\\\n172.31.5.251:2377\\nThe output gives you the full command and join token to run on mgr2. The join token\\nand IP address will be different in your lab.\\nThe format of the join command is:\\n• docker swarm join --token <manager-join-token> <ip-of-existing-\\nmanager>:<swarm-port>\\nThe format of the token is:\\n• SWMTKN-1-<hash-of-cluster-certificate>-<manager-join-token>\\nCopy the command and run it on mgr2:\\n$ docker swarm join --token SWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz 172.31.5.251:2377\\nThis node joined a swarm as a manager.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 256}, page_content='Copy the command and run it on mgr2:\\n$ docker swarm join --token SWMTKN-1-1dmtwu...r17stb-2axi5...8p7glz 172.31.5.251:2377\\nThis node joined a swarm as a manager.\\nList the nodes in your swarm.\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\n7xamk...ge662z\\nmgr1\\nReady\\nActive\\nLeader\\ni0ue4...zcjm7f *\\nmgr2\\nReady\\nActive\\nReachable'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 257}, page_content='16: Docker security\\n251\\nYou now have a two-node swarm with mgr1 and mgr2 as managers. Both have access to\\nthe cluster store and are configured with client certificates for mutual TLS.\\nIn the real world, you’ll always run three or five managers for high availability.\\nFigure 16.5 shows the updated swarm with both managers.\\nFigure 16.5\\nAdding worker nodes is a similar two-step process — extract the join token and run the\\ncommand on the node.\\nRun the following command on either of the managers to expose the worker join\\ncommand and token.\\n$ docker swarm join-token worker\\nTo add a worker to this swarm, run the following command:\\ndocker swarm join --token \\\\\\nSWMTKN-1-1dmtw...17stb-ehp8g...w738q \\\\\\n172.31.5.251:2377\\nCopy the command and run it on wrk1:\\n$ docker swarm join --token SWMTKN-1-1dmtw...17stb-ehp8g...w738q 172.31.5.251:2377\\nThis node joined a swarm as a worker.\\nRun another docker node ls from either of your managers.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 258}, page_content='16: Docker security\\n252\\n$ docker node ls\\nID\\nHOSTNAME\\nSTATUS\\nAVAILABILITY\\nMANAGER STATUS\\n7xamk...ge662z *\\nmgr1\\nReady\\nActive\\nLeader\\nailrd...ofzv1u\\nwrk1\\nReady\\nActive\\ni0ue4...zcjm7f\\nmgr2\\nReady\\nActive\\nReachable\\nYour swarm has two managers and a worker. The managers are configured for high\\navailability (HA) and the cluster store is replicated to both. The worker node is part of\\nthe swarm but cannot access the cluster store. Figure 16.6 shows the final configuration.\\nFigure 16.6\\nNow that you’ve built a secure Swarm, let’s examine some of the security aspects.\\nSwarm join tokens\\nThe only requirement for joining managers and workers is possession of the secure join\\ntoken. This means you should keep them safe and never post them on public repos or\\neven internal repos that are not restricted.\\nEvery swarm maintains two distinct join tokens:\\n• Manager token\\n• Worker token\\nEvery join token has four distinct fields separated by dashes (-):\\n• PREFIX - VERSION - SWARM ID - TOKEN'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 258}, page_content='Every swarm maintains two distinct join tokens:\\n• Manager token\\n• Worker token\\nEvery join token has four distinct fields separated by dashes (-):\\n• PREFIX - VERSION - SWARM ID - TOKEN\\nThe prefix is always SWMTKN and allows you to pattern-match against it to prevent people\\nfrom accidentally posting it publicly. The VERSION field indicates the version of the'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 259}, page_content='16: Docker security\\n253\\nswarm. The Swarm ID field is a hash of the swarm’s certificate. The TOKEN field is the\\nworker or manager token.\\nAs you can see in the following table, the manager and worker tokens for any given\\nswarm are identical except for the final TOKEN field.\\nRole\\nPrefix\\nVersion\\nSwarm ID\\nToken\\nManager\\nSWMTKN\\n1\\n1dmtwusdc…r17stb\\n2axi53zjbs45lqxykaw8p7glz\\nWorker\\nSWMTKN\\n1\\n1dmtwusdc…r17stb\\nehp8gltji64jbl45zl6hw738q\\nIf you suspect either of your join tokens are compromised, you can revoke them and\\nissue new ones with a single command. The following example revokes the existing\\nmanager token and issues a new one.\\n$ docker swarm join-token --rotate manager\\nSuccessfully rotated manager join token.\\nExisting managers are unaffected, but you can only add new ones with the new token.\\nAs expected, the last field is the only difference between the old and new tokens.\\nDocker keeps a copy of join tokens in the encrypted cluster store.\\nTLS and mutual authentication'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 259}, page_content='As expected, the last field is the only difference between the old and new tokens.\\nDocker keeps a copy of join tokens in the encrypted cluster store.\\nTLS and mutual authentication\\nDocker issues every manager and worker with a client certificate that they use for\\nmutual authentication. It identifies the node, the swarm it’s a member of, and whether\\nit’s a manager or worker.\\nYou can inspect a node’s client certificate on Linux with the following command.\\n$ sudo openssl x509 \\\\\\n-in /var/lib/docker/swarm/certificates/swarm-node.crt \\\\\\n-text\\nCertificate:\\nData:\\nVersion: 3 (0x2)\\nSerial Number:\\n7c:ec:1c:8f:f0:97:86:a9:1e:2f:4b:a9:0e:7f:ae:6b:7b:b7:e3:d3\\nSignature Algorithm: ecdsa-with-SHA256\\nIssuer: CN = swarm-ca\\nValidity\\nNot Before: May 23 08:23:00 2024 GMT\\nNot After : Aug 21 09:23:00 2024 GMT\\nSubject: O = tcz3w1t7yu0s4wacovn1rtgp4, OU = swarm-manager,'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 260}, page_content='16: Docker security\\n254\\nCN = 2gxz2h1f0rnmc3atm35qcd1zw\\nSubject Public Key Info:\\n<SNIP>\\nAs shown in Figure 16.7, the Subject field uses the standard O, OU, and CN fields to\\nspecify the Swarm ID, the node’s role, and the node ID:\\n• The Organization (O) field stores the Swarm ID\\n• The Organizational Unit (OU) field stores the node’s role in the swarm\\n• The Canonical Name (CN) field stores the node’s crypto ID.\\nYou can also see the certificate rotation period in the Validity section.\\nFigure 16.7\\nYou can match these values to the corresponding values from a docker info command.\\n$ docker info\\n<SNIP>\\nSwarm: active\\nNodeID: 2gxz2h1f0rnmc3atm35qcd1zw\\n<<---- Relates to the CN field\\nIs Manager: true\\n<<---- Relates to the OU field\\nClusterID: tcz3w1t7yu0s4wacovn1rtgp4\\n<<---- Relates to the O field\\n<SNIP>\\nCA Configuration:\\nExpiry Duration: 3 months\\n<<---- Relates to the validity block\\nForce Rotate: 0\\nRoot Rotation In Progress: false\\n<SNIP>'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 261}, page_content='16: Docker security\\n255\\nSwarm CA configuration\\nYou can use the docker swarm update command to configure the certificate rotation\\nperiod. The following example changes it to 30 days.\\n$ docker swarm update --cert-expiry 720h\\nSwarm allows nodes to renew certificates early so that all nodes don’t update at exactly\\nthe same time.\\nYou can configure a new swarm to use an external CA by passing the --external-ca\\nflag to docker swarm init command, and you can use the docker swarm ca command\\nto manage other CA-related settings.\\n$ docker swarm ca --help\\nUsage:\\ndocker swarm ca [OPTIONS]\\nDisplay and rotate the root CA\\nOptions:\\n--ca-cert pem-file\\nPath to the PEM-formatted root CA certificate to use\\nfor the new cluster\\n--ca-key pem-file\\nPath to the PEM-formatted root CA key to use for the\\nnew cluster\\n--cert-expiry duration\\nValidity period for node certificates (ns|us|ms|s|m|h)\\n(default 2160h0m0s)\\n-d, --detach\\nExit immediately instead of waiting for the root rotation\\nto converge'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 261}, page_content='new cluster\\n--cert-expiry duration\\nValidity period for node certificates (ns|us|ms|s|m|h)\\n(default 2160h0m0s)\\n-d, --detach\\nExit immediately instead of waiting for the root rotation\\nto converge\\n--external-ca external-ca\\nSpecifications of one or more certificate signing endpoints\\n-q, --quiet\\nSuppress progress output\\n--rotate\\nRotate the swarm CA - if no certificate or key are\\nprovided, new ones will be generated\\nThe cluster store\\nThe cluster store is where Docker keeps the configuration and state of a swarm. It’s also\\ncritical to other Docker technologies, such as overlay networks and secrets. This is why\\noverlay networks and many other advanced security features only work in swarm mode.\\nThe cluster store is based on the popular etcd distributed database and is automatically\\nencrypted and replicated to all managers.\\nDocker handles day-to-day maintenance, but you should implement strong backup and\\nrecovery procedures for production clusters.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 261}, page_content='encrypted and replicated to all managers.\\nDocker handles day-to-day maintenance, but you should implement strong backup and\\nrecovery procedures for production clusters.\\nThat’s enough about swarm mode security for now. Let’s look at some Docker security\\ntechnologies that don’t require swarm mode.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 262}, page_content='16: Docker security\\n256\\nDocker Scout and vulnerability scanning\\nEvery container runs multiple software packages that are susceptible to bugs and\\nvulnerabilities that malicious actors can exploit.\\nImage scanning analyzes your images and produces a detailed list of all the software\\npackages it uses. We call this list a software bill of materials (SBOM), and the image\\nscanning system compares the SBOM against databases of known vulnerabilities and\\nprovides a report of vulnerabilities in your software. Most vulnerability scanners will\\nrank the vulnerabilities and provide advice on fixes.\\nVulnerability scanning is now an integral part of most software supply chains.\\nDocker Scout is Docker’s native scanning platform and works with Docker Hub,\\nDocker Desktop, the Docker CLI, and even has its own Docker Scout Dashboard.\\nHowever, it’s a subscription-based service.\\nOther scanning platforms are available, but most of these also require some form of\\nsubscription.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 262}, page_content='However, it’s a subscription-based service.\\nOther scanning platforms are available, but most of these also require some form of\\nsubscription.\\nIf you’re using Docker Desktop, you can run the following command to see an example\\nof Docker Scout.\\n$ docker scout quickview nigelpoulton/tu-demo:latest\\n✓Provenance obtained from attestation\\n✓Pulled\\n✓Image stored for indexing\\n✓Indexed 66 packages\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\n│\\n0C\\n4H\\n2M\\n0L\\ndigest\\n│\\nb4210d0aa52f\\n│\\nBase image\\n│\\npython:3-alpine\\n│\\n0C\\n2H\\n1M\\n0L\\nUpdated base image │\\npython:3.11-alpine\\n│\\n0C\\n1H\\n1M\\n0L\\n│\\n│\\nThe output shows zero critical vulnerabilities (0C), four high (4H), two medium (2M),\\nand zero low (0L).\\nYou can also run a docker scout cves command to get more detailed information,\\nincluding remediation advice.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 263}, page_content='16: Docker security\\n257\\n$ docker scout cves nigelpoulton/tu-demo:latest\\n✓SBOM of image already cached, 66 packages indexed\\n\\uffffDetected 6 vulnerable packages with a total of 8 vulnerabilities\\n## Overview\\n│\\nAnalyzed Image\\n────────────────────┼────────────────────────────────\\nTarget\\n│\\nnigelpoulton/tu-demo:latest\\ndigest\\n│\\nb4210d0aa52f\\nplatform\\n│linux/arm64\\nvulnerabilities │\\n0C\\n4H\\n2M\\n0L\\nsize\\n│26 MB\\npackages\\n│66\\n## Packages and Vulnerabilities\\n0C\\n1H\\n1M\\n0L\\nexpat 2.5.0-r2\\npkg:apk/alpine/expat@2.5.0-r2?os_name=alpine&os_version=3.19\\n\\uffffHIGH CVE-2023-52425\\nhttps://scout.docker.com/v/CVE-2023-52425\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n\\uffffMEDIUM CVE-2023-52426\\nhttps://scout.docker.com/v/CVE-2023-52426\\nAffected range : <2.6.0-r0\\nFixed version\\n: 2.6.0-r0\\n<Snip>\\nI’ve snipped the output, so it only shows some of the vulnerabilities. However, even\\nfrom the snipped output in the book, you can see:\\n• Scout has scanned 66 packages and detected several vulnerabilities'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 263}, page_content='from the snipped output in the book, you can see:\\n• Scout has scanned 66 packages and detected several vulnerabilities\\n• We’re using version 2.5.0-r2 of the expat package which has one high (1H) and\\none medium (1M) vulnerability\\n• The high vulnerability is listed as CVE-2023-52425 and the medium as CVE-2023-\\n52426\\n• The report includes links to Scout reports containing more info on each vulnera-\\nbility\\n• Scout recommends updating to expat version 2.6.0-r0 which contains fixes for\\nboth\\nFigure 16.8 shows what it looks like in in Docker Desktop, and you get similar integra-\\ntions and views in Docker Hub.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 264}, page_content='16: Docker security\\n258\\nFigure 16.8 - Docker Scout integration with Docker Desktop\\nIf you subscribe to Docker Scout, you can use the scout.docker.com portal to configure\\npolicies and integrations with Docker Hub and other registries.\\nAs good as vulnerability scanning is, it only scans images and doesn’t detect security\\nproblems with networks, nodes, or orchestrators. Also, not all image scanners are equal.\\nFor example, the best ones perform deep binary-level scans, whereas others may just\\nlook at package names and do not inspect content closely.\\nIn summary, scanning tools are great for inspecting your images and detecting known\\nvulnerabilities. Beware though, with great knowledge comes great responsibility — once\\nyou’re aware of vulnerabilities, you’re responsible for mitigating or fixing them.\\nSigning and verifying images with Docker Content\\nTrust\\nDocker Content Trust (DCT) makes it simple for you to verify the integrity and pub-'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 264}, page_content='Signing and verifying images with Docker Content\\nTrust\\nDocker Content Trust (DCT) makes it simple for you to verify the integrity and pub-\\nlisher of images and is especially important when you’re pulling images over untrusted\\nnetworks such as the internet.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 265}, page_content='16: Docker security\\n259\\nAt a high level, DCT lets you sign your images when you push them to registries like\\nDocker Hub. It also lets you verify the images you pull and run as containers.\\nFigure 16.9 shows the high-level process.\\nFigure 16.9 - Docker Content Trust image signing and verification\\nYou can also use DCT to provide context, such as whether or not a developer has signed\\nan image for use in a particular environment such as prod or dev, or whether an image\\nhas been superseded by a newer version and is therefore stale.\\nThe following steps walk you through configuring Docker Content Trust, signing and\\npushing an image, and then pulling the signed image.\\nIf you plan on following along, you’ll need a cryptographic key pair. If you don’t already\\nhave one, you can run the following docker trust command to generate one. The\\ncommand generates a new key pair called nigel and loads it to the local trust store ready\\nfor use. It will prompt you to enter a passphrase; don’t forget it :-)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 265}, page_content='command generates a new key pair called nigel and loads it to the local trust store ready\\nfor use. It will prompt you to enter a passphrase; don’t forget it :-)\\n$ docker trust key generate nigel\\nGenerating key for nigel...\\nEnter passphrase for new nigel key with ID 1f78609:\\nRepeat passphrase for new nigel key with ID 1f78609:\\nSuccessfully generated and loaded private key.... key available: /Users/nigelpoulton/nigel.pub\\nIf you already have a key pair, you can import and load it with docker trust key load\\nkey.pem --name nigel.\\nThe next step is associating your key pair with the image repository to which you’ll push\\nsigned images. This example associates the nigel.pub key with the nigelpoulton/ddd-\\ntrust repo on Docker Hub. Your key file and repo will be different, and the repository\\ndoesn’t have to exist before you run the command.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 266}, page_content='16: Docker security\\n260\\n$ docker trust signer add --key nigel.pub nigel nigelpoulton/ddd-trust\\nAdding signer \"nigel\" to nigelpoulton/dct...\\nInitializing signed repository for nigelpoulton/dct...\\nEnter passphrase for root key with ID aee3314:\\nEnter passphrase for new repository key with ID 1a18dd1:\\nRepeat passphrase for new repository key with ID 1a18dd1:\\nSuccessfully initialized \"nigelpoulton/dct\"\\nSuccessfully added signer: nigel to nigelpoulton/dct\\nNow that you’ve loaded the key pair and associated it with a repository, the final step is\\nto sign an image and push it to the repo.\\nThe following command signs a local image called nigelpoulton/ddd-trust:signed\\nand pushes it to Docker Hub. Your image will have a different name and you’ll push it to\\na different repo.\\n$ docker trust sign nigelpoulton/ddd-trust:signed\\nSigning and pushing trust data for local image nigelpoulton/ddd-trust:signed may...\\nThe push refers to repository [docker.io/nigelpoulton/ddd-trust]'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 266}, page_content='$ docker trust sign nigelpoulton/ddd-trust:signed\\nSigning and pushing trust data for local image nigelpoulton/ddd-trust:signed may...\\nThe push refers to repository [docker.io/nigelpoulton/ddd-trust]\\n6495b414566f: Mounted from nigelpoulton/ddd-book\\n798676f7ef8b: Mounted from nigelpoulton/ddd-book\\nbca4290a9639: Mounted from nigelpoulton/ddd-book\\n28ad2149d870: Mounted from nigelpoulton/ddd-book\\n4f4fb700ef54: Mounted from nigelpoulton/ddd-book\\n5e1fc7f5df34: Mounted from nigelpoulton/ddd-book\\nsigned: digest: sha256:b65f9a1aa4e670bbafd0fbb91281ea95f9cdc5728aa546579e248dfbc0ea4bde\\nSigning and pushing trust metadata\\nEnter passphrase for nigel key with ID 92330ea:\\nSuccessfully signed docker.io/nigelpoulton/ddd-trust:signed\\nThe push operation creates the repo on Docker Hub and then signs and pushes the\\nimage. You can view the repo on Docker Hub, and you can run the following command\\nto inspect its signing data.\\n$ docker trust inspect nigelpoulton/ddd-trust:signed --pretty'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 266}, page_content='image. You can view the repo on Docker Hub, and you can run the following command\\nto inspect its signing data.\\n$ docker trust inspect nigelpoulton/ddd-trust:signed --pretty\\nSignatures for nigelpoulton/ddd-trust:signed\\nSIGNED TAG\\nDIGEST\\nSIGNERS\\nsigned\\n30e6d35703c578ee...4fcbbcbb0f281\\nnigel\\nList of signers and their keys for nigelpoulton/ddd-trust:signed\\nSIGNER\\nKEYS\\nnigel\\n4d6f1bf55702\\nAdministrative keys for nigelpoulton/ddd-trust:signed\\nRepository Key:\\n5e72e54afafb8444f...6b2744b32010ad22\\nRoot Key:\\n40418fc47544ca630...69a2cb89028c22092'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 267}, page_content='16: Docker security\\n261\\nYou can export the DOCKER_CONTENT_TRUST variable with a value of 1 to force a Docker\\nhost to sign and verify all images.\\n$ export DOCKER_CONTENT_TRUST=1\\nOnce enabled, you won’t be able to pull and work with unsigned images.\\nTest it by trying to pull an unsigned image.\\n$ docker pull nigelpoulton/ddd-book:web0.2\\nError: remote trust data does not exist for docker.io/nigelpoulton/ddd-book: notary.docker.io\\ndoes not have trust data for docker.io/nigelpoulton/ddd-book\\nYou can no longer pull images without trust data!\\nDelete the local copy of the image you just signed and pushed so that you can try pulling\\nit from Docker Hub. Your image name will be different.\\n$ docker rmi nigelpoulton/ddd-trust:signed\\nUntagged: nigelpoulton/ddd-trust:signed@sha256...\\n<Snip>\\nNow, try pulling the image.\\n$ docker pull nigelpoulton/ddd-trust:signed\\nPull (1 of 1): nigelpoulton/ddd-trust:signed@sha256:30e6...'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 267}, page_content='Untagged: nigelpoulton/ddd-trust:signed@sha256...\\n<Snip>\\nNow, try pulling the image.\\n$ docker pull nigelpoulton/ddd-trust:signed\\nPull (1 of 1): nigelpoulton/ddd-trust:signed@sha256:30e6...\\ndocker.io/nigelpoulton/ddd-trust@sha256:30e6... Pulling from nigelpoulton/ddd-trust\\n08409d417260: Pull complete\\nDigest: sha256:30e6d35703c578ee703230b9dc87ada2ba958c1928615ac8a674fcbbcbb0f281\\nStatus: Downloaded newer image for nigelpoulton/ddd-trust@sha256:30e6...\\nTagging nigelpoulton/ddd-trust@sha256:30e6d... as nigelpoulton/ddd-trust:signed\\ndocker.io/nigelpoulton/ddd-trust:signed\\nThe pull worked because the image has valid trust data.\\nIn summary, Docker Content Trust is an important technology that helps you verify the\\nintegrity of the images you pull and run. It’s simple to configure in its basic form, but\\nmore advanced features, such as context, can be more complex.\\nDocker Secrets\\nMost applications leverage sensitive data such as passwords, certificates, and SSH keys.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 267}, page_content='more advanced features, such as context, can be more complex.\\nDocker Secrets\\nMost applications leverage sensitive data such as passwords, certificates, and SSH keys.\\nFortunately, Docker lets you wrap them inside secrets to keep them secure.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 268}, page_content='16: Docker security\\n262\\nNote: Secrets only work in swarm mode as they leverage the cluster store.\\nBehind the scenes, Docker encrypts secrets when they’re at rest in the cluster store and\\nwhile they’re in flight on the network. It also uses in-memory filesystems to mount secrets\\ninto containers and operates a least-privilege model, where secrets are only available\\nto services that have been explicitly granted access. There’s even a docker secret\\ncommand.\\nFigure 16.10 shows the high-level workflow of creating a secret and deploying it to\\nservice replicas:\\nFigure 16.10 - Secret workflow\\nLet’s go through the five steps in the diagram. I’ve used a key symbol to show the secret,\\nand it’s only available to the dark containers.\\n1. You create the secret\\n2. Docker stores it in the encrypted cluster store\\n3. You create a service (the dark containers) and grant it access to the secret\\n4. Docker encrypts the secret when sending it over the network to service replicas'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 268}, page_content='3. You create a service (the dark containers) and grant it access to the secret\\n4. Docker encrypts the secret when sending it over the network to service replicas\\n5. Docker mounts the secret into service replicas as an unencrypted file in an in-\\nmemory filesystem\\nThe light-colored containers are part of a different service and cannot access the secret.\\nAs soon as replicas using the secret terminate, Docker destroys the in-memory filesys-\\ntem and flushes the secret from the node.\\nDocker mounts secrets in their unencrypted form so that applications can use them\\nwithout needing keys to decrypt them.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 269}, page_content='16: Docker security\\n263\\nYou can create and manage secrets with the docker secret command and attach them\\nto services by passing the --secret flag to the docker service create command.\\nClean up\\nIf you’ve followed along, you’ve created a swarm, added a signer, created a new repo\\non Docker Hub, and exported an environment variable to sign and verify images\\nautomatically.\\nRun the following command to disable Docker Content Trust. You’ll need to run it on\\nevery node where you enabled Docker Content Trust.\\n$ unset DOCKER_CONTENT_TRUST\\nRemove the signer from the repository you created. Your signer and repository will have\\ndifferent names.\\n$ docker trust signer remove nigel nigelpoulton/ddd-trust\\nRemoving signer \"nigel\" from nigelpoulton/ddd-trust...\\nall signed tags are currently revoked, use docker trust sign to fix\\nYou may also want to delete the repositories you created on Docker Hub and delete the\\nlocal key files on your system (usually a .pub file in your home directory)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 269}, page_content='You may also want to delete the repositories you created on Docker Hub and delete the\\nlocal key files on your system (usually a .pub file in your home directory)\\nDelete the swarm by running the following command on all swarm nodes. You should\\nrun it on the swarm managers last.\\n$ docker swarm leave -f\\nChapter Summary\\nYou can configure Docker to be extremely secure. It supports all of the major Linux\\nsecurity technologies such as kernel namespaces, cgroups, capabilities, MAC, and\\nseccomp. It ships with sensible defaults for all of these, but you can customize and even\\ndisable them.\\nIn addition to the Linux security technologies, Docker includes an extensive set of\\nits own security technologies. Swarms are built on TLS and are secure out of the box.\\nDocker Scout performs binary-level image scans and provides detailed reports of\\nknown vulnerabilities and suggested fixes. Docker Content Trust lets you sign and'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 269}, page_content='Docker Scout performs binary-level image scans and provides detailed reports of\\nknown vulnerabilities and suggested fixes. Docker Content Trust lets you sign and\\nverify images, and Docker secrets allow you to share sensitive data with swarm services.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 270}, page_content='What next\\nThank you so much for reading my book. You’re on your way to mastering Docker and\\ncontainers, and you’ve learned some skills running local LLMs.\\nGet involved with the community\\nThere’s a vibrant cloud-native community full of helpful people. Get involved with\\nDocker groups and chats on the internet, and look up your local Docker or cloud-native\\nmeetup (search for “Docker meetup near me”).\\nKubernetes\\nNow that you understand Docker, Kubernetes is a great next step. It’s a lot like Swarm\\nbut has a larger scope and a more active community.\\nIf you liked this book, you’ll love my Kubernetes books.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 271}, page_content='What next\\n265\\nFeedback and reviews\\nBooks live and die by Amazon reviews and stars.\\nI live and breathe this book, ensuring you get the most up-to-date content that’s easy to\\nread and understand. So, please take a moment to leave a kind review on Amazon or\\nGoodreads.\\nAlso, ping me at ddd@nigelpoulton.com if you want to suggest content or fixes for\\nfuture editions.\\nConnect with me\\nFinally, thanks for reading my book. Feel free to connect with me on any of the usual\\nplatforms to discuss Docker, Kubernetes, Wasm, AI, and other technologies.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 272}, page_content='Terminology\\nThis glossary defines some of the most common Docker and container-related terms\\nused in the book.\\nIf you think I’ve missed anything important, ping me at ddd@nigelpoulton.com.\\nTerm\\nDefinition (according to Nigel)\\nAI acceleration hardware\\nHardware, such as GPUs, NPUs, and TPUs\\nthat speed up the execution (inference) of AI\\nmodels.\\nAPI\\nApplication Programming Interface. In the\\ncase of Docker, all resources are defined in\\nthe Docker API, which is RESTful and\\nexposed via the Docker Daemon.\\nBase image\\nThe first layer of all container images.\\nCreated by the Dockerfile FROM instruction\\nand usually contains a minimal set of OS\\nconstructs required by an application.\\nBuild\\nThe process of building a new container\\nimage. Docker builds images by stepping\\nthrough a set of instructions defined in a\\nDockerfile.\\nBuild Cloud\\nA subscription service that performs fast and\\nefficient image builds in Docker’s cloud\\ninfrastructure. It allows you to share a\\ncommon build cache among teams for very'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 272}, page_content='Dockerfile.\\nBuild Cloud\\nA subscription service that performs fast and\\nefficient image builds in Docker’s cloud\\ninfrastructure. It allows you to share a\\ncommon build cache among teams for very\\nfast builds.\\nBuildKit\\nDocker’s build engine that implements\\nadvanced build features such as advanced\\ncaching, multi-stage builds, and\\nmulti-architecture builds.\\nBuildx\\nDocker’s latest and greatest build client that\\nsupports all the latest features of BuildKit,\\nsuch as multi-stage builds and\\nmulti-architecture images. Buildx has been\\nDocker’s default build client since Docker\\nEngine v23.0 and Docker Desktop v4.19.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 273}, page_content='Terminology\\n267\\nTerm\\nDefinition (according to Nigel)\\nCapability\\nLinux kernel technology used by Docker to\\ncreate user accounts with the precise set of\\nsystem access they need.\\nChatbot\\nA computer program that can participate in\\ntext-based human conversations and is often\\nindistinguishable from a human.\\nCloud native\\nA loaded term that means different things to\\ndifferent people. Cloud native is a way of\\ndesigning, building, and working with\\nmodern applications and infrastructure. I\\nconsider an application to be cloud native if it\\ncan self-heal, scale on demand, perform\\nrolling updates, and versioned rollbacks.\\nCluster store\\nDocker Swarm’s distributed database that\\nholds the state of the cluster and apps. Based\\non the etcd distributed database, it is\\nautomatically encrypted and automatically\\ndistributed across all swarm managers for\\nhigh availability.\\nCompose\\nAn open specification for defining, deploying,\\nand managing multi-container microservices\\napps. Docker implements the Compose spec'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 273}, page_content='distributed across all swarm managers for\\nhigh availability.\\nCompose\\nAn open specification for defining, deploying,\\nand managing multi-container microservices\\napps. Docker implements the Compose spec\\nand provides the docker compose command\\nto make it easy to work with Compose apps.\\nContainer\\nA container is a collection of kernel\\nnamespaces organized to look, smell, and feel\\nlike a regular operating system. Each\\ncontainer runs a single application, and\\ncontainers are smaller, faster, and more\\nportable than virtual machines. We\\nsometimes call them Docker containers or OCI\\ncontainers\\nContainer Network Model\\nPluggable interface enabling different\\nnetwork topologies and architectures. Third\\nparties provide CNM plugins for overlay\\nnetworks and BGP networks, as well as\\nvarious implementations of each.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 274}, page_content='Terminology\\n268\\nTerm\\nDefinition (according to Nigel)\\nContainer runtime\\nSoftware running on every Docker node\\nresponsible for pulling container images,\\nstarting containers, stopping containers, and\\nother low-level container operations. Docker\\nuses two runtimes that work together:\\ncontainerd is Docker’s high-level runtime\\nthat manages lifecycle events such as starting\\nand stopping containers, whereas runc is\\nDocker’s low-level runtime that interfaces\\nwith kernel constructs such as namespaces\\nand cgroups.\\ncontainerd\\nIndustry-standard container runtime used by\\nDocker and most Kubernetes clusters.\\nDonated to the CNCF by Docker, Inc.\\nPronounced “container dee”.\\nContainerize\\nThe process of packaging an application and\\nall dependencies into a container image.\\nControl Groups (cgroups)\\nLinux kernel feature that Docker uses to limit\\nthe amount of host CPU, RAM, disk, and\\nnetwork resources a container uses.\\nDesired state\\nHow your cluster and applications should be.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 274}, page_content='Linux kernel feature that Docker uses to limit\\nthe amount of host CPU, RAM, disk, and\\nnetwork resources a container uses.\\nDesired state\\nHow your cluster and applications should be.\\nFor example, the desired state of an application\\nmicroservice might be five replicas of xyz\\ncontainer listening on port 8080/tcp. Vital to\\nreconciliation.\\nDocker\\nPlatform that makes it easy to work with\\ncontainerized apps. It allows you to build\\nimages, as well as run and manage standalone\\ncontainers and multi-container apps.\\nDocker Debug\\nDocker CLI plugin that lets you easily debug\\nslim images and containers that don’t ship\\nwith any debugging tools.\\nDocker Desktop\\nDesktop application for Linux, Mac, and\\nWindows that makes working with Docker\\neasy. It has a slick UI and many advanced\\nfeatures like image management, vulnerability\\nscanning, and Wasm support.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 275}, page_content='Terminology\\n269\\nTerm\\nDefinition (according to Nigel)\\nDocker Hub\\nHigh-performance OCI-compliant image\\nregistry. Docker Hub has over 57PB of\\nstorage and handles an average of 30K\\nrequests per second.\\nDocker, Inc.\\nUS-based technology company making it easy\\nfor developers to build, ship, and run\\ncontainerized applications. The company\\nbehind the Docker platform.\\nDocker init\\nA new Docker CLI plugin that creates\\nhigh-fidelity Dockerfiles and makes it easy to\\nscaffold Compose apps.\\nDocker Model Runner\\nDocker’s native tool for running local AI\\nmodels directly on host hardware (outside of\\ncontainers). Exposes OpenAI-compatible\\nendpoints.\\nDocker Scout\\nDocker’s native vulnerability scanning service.\\nScout is a subscription service that integrates\\nwith the Docker CLI, Docker Desktop,\\nDocker Hub, and other image registries.\\nDockerfile\\nPlain text file with instructions telling Docker\\nhow to build an application into a container\\nimage.\\netcd\\nThe open-source distributed database used by\\nDocker Swarm.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 275}, page_content='Dockerfile\\nPlain text file with instructions telling Docker\\nhow to build an application into a container\\nimage.\\netcd\\nThe open-source distributed database used by\\nDocker Swarm.\\nGGUF\\nBinary file format for storing LLM weights\\nand metadata.\\nGPU\\nGraphics Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nImage\\nArchive containing application code, all\\ndependencies, and the metadata required to\\nstart a single application as a container. We\\nsometimes call them OCI images, container\\nimages, or Docker images.\\nIngress network\\nHidden network on all Docker Swarm\\nclusters used to publish services to external\\nclients.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 276}, page_content='Terminology\\n270\\nTerm\\nDefinition (according to Nigel)\\nKernel namespace\\nFeature of the Linux kernel used by Docker to\\nisolate containers from processes running on\\nthe host and in other containers.\\nllama.cpp\\nPopular core inference engine (LLM runtime)\\nused by model servers like Docker Model\\nRunner and Ollama. Open source project that\\ncan run LLMs on low-grade consumer CPUs\\nas well as some high-performance GPUs.\\nLarge Language Model (LLM)\\nAn AI application that can participate in\\nhuman conversations and create human-like\\nanswers and ideas. The book’s AI chatbot app\\nuses an LLM that is trained as a coding\\nassistant that can help answer coding\\nquestions and provide coding samples.\\nLayer\\nImage layers contain modifications to the\\nbase image or the layer below them. Docker\\nbuilds images by stacking layers, each\\ncontaining changes to the layer below it. A\\nsimple example is a base layer that has basic\\nOS constructs, followed by a layer with the\\napplication. The two combined layers create'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 276}, page_content='containing changes to the layer below it. A\\nsimple example is a base layer that has basic\\nOS constructs, followed by a layer with the\\napplication. The two combined layers create\\nthe image with the OS and app.\\nlibcontainer\\nA Go library that uses namespaces, cgroups,\\nand capabilities to build containers. Docker\\nuses libcontainer via the runc low-level\\nruntime that is a CLI wrapper around\\nlibcontainer.\\nlibnetwork\\nThe Go library used by Docker to create and\\nmanage container networks.\\nManifest (OCI)\\nJSON document describing the configuration\\nand layers of OCI artifacts such as images and\\nmodels.\\nMicroservices\\nDesign pattern for modern applications.\\nIndividual application features are developed\\nas their own small applications\\n(microservices/containers) and communicate\\nvia APIs. They work together to form a useful\\napplication.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 277}, page_content='Terminology\\n271\\nTerm\\nDefinition (according to Nigel)\\nModel\\nAI program that has been pre-trained to\\naccept prompts and give human-like\\nresponses. We refer to AI programs as models.\\nMLX\\nApple’s machine learning framework that\\ngives AI models access to the unified memory\\narchitecture of Apple’s M series chips.\\nMulti-architecture builds (sometimes called\\nmulti-platform builds)\\nAllows you to build images for multiple\\narchitectures and platforms with a single\\ndocker build command. For example, you\\ncan run a single docker build command on\\nan AMD-based Windows system to build an\\nAMD image and an ARM image.\\nMulti-stage build\\nAllows you to create very small images (slim\\nimages). You build your images in stages and\\nonly carry forward the necessary artifacts for\\neach next stage. Each build stage is\\nrepresented by its own FROM instruction in\\nyour Dockerfile, and later build stages use the\\nCOPY --from instruction to use artifacts from\\nprevious stages and leave everything else\\nbehind.\\nNPU'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 277}, page_content='represented by its own FROM instruction in\\nyour Dockerfile, and later build stages use the\\nCOPY --from instruction to use artifacts from\\nprevious stages and leave everything else\\nbehind.\\nNPU\\nNeural Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nObserved state\\nAlso known as current state or actual state. The\\nmost up-to-date view of the cluster and\\nrunning applications. Docker Swarm is\\nalways working to make observed state match\\ndesired state.\\nOllama\\nOpen-source runtime for running LLMs\\nlocally. A bit like Docker for LLMs — Ollama\\ncan pull and push LLMs and run them locally\\non your computer.\\nOpenAI-compatible endpoint\\nAPI service that accepts requests formatted\\naccording to OpenAI’s API specifications and\\nreturns responses in the same format.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 278}, page_content='Terminology\\n272\\nTerm\\nDefinition (according to Nigel)\\nOpen Container Initiative (OCI)\\nLightweight governance body responsible for\\ncreating and maintaining standards for\\nlow-level container technologies such as\\nimages, runtimes, and registries. Docker\\ncreates OCI-compliant images, implements\\nan OCI-compliant runtime, and Docker Hub\\nis an OCI-compliant registry.\\nOrchestrator\\nSoftware that deploys and manages apps.\\nDocker Swarm and Kubernetes are examples\\nof orchestrators that manage microservices\\napps, keep them healthy, scale them up and\\ndown, and more…\\nOverlay network\\nA large flat layer-2 network that spans\\nmultiple swarm nodes. All containers on the\\nsame overlay network can communicate with\\neach other, even if they’re on different Docker\\nhosts on different networks. The built-in\\noverlay driver creates overlay networks using\\nadvanced VXLAN technologies. Only used by\\nDocker Swarm.\\nPush\\nUpload an image to a registry.\\nPull\\nDownload an image from a registry.\\nQuantization'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 278}, page_content='overlay driver creates overlay networks using\\nadvanced VXLAN technologies. Only used by\\nDocker Swarm.\\nPush\\nUpload an image to a registry.\\nPull\\nDownload an image from a registry.\\nQuantization\\nThe process of reducing the size and memory\\nrequirements of an AI model without\\nsacrificing too much performance and model\\naccuracy.\\nReconciliation\\nThe process of watching the state of an\\napplication and ensuring observed state\\nmatches desired state. Docker Swarm runs\\nreconciliation loops, ensuring applications\\nrun how you want them to.\\nRegistry\\nCentral place for storing and retrieving\\nimages. We sometimes call them OCI registries,\\ncontainer registries, or Docker registries.\\nRepository\\nAn area of a registry where you store related\\ncontainer images. You can set access controls\\nper repository.'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 279}, page_content='Terminology\\n273\\nTerm\\nDefinition (according to Nigel)\\nREPL\\nRead, Evaluate, Print, Loop. CLI environment\\nfor testing and interacting with LLMs.\\nSeccomp\\nSecure computing Linux kernel feature used\\nby Docker to restrict the syscalls available to a\\ncontainer.\\nSecret\\nThe way Docker Swarm lets you inject\\nsensitive data into a container at run-time.\\nService\\nCapital “S” is a Docker Swarm feature that\\naugments containers with self-healing,\\nscaling, rollouts, and rollbacks.\\nSpin\\nFramework that makes it easy to build,\\ndeploy, and run Wasm apps. Docker Desktop\\nships with the spin runtime. Created by\\nFermyon Technologies, Inc.\\nSwarm (also known as Docker Swarm)\\nDocker’s native orchestration platform. A\\nlightweight and easy alternative to\\nKubernetes.\\nTPU\\nTensor Processing Unit. AI acceleration\\nhardware that speeds up the performance of\\nAI models.\\nVolume\\nWhere containers store important data they\\nneed to keep. You can create and delete\\nvolumes independently from containers.\\nWasm (WebAssembly)'),\n",
       " Document(metadata={'producer': 'XeTeX 0.99998', 'creator': 'LaTeX with hyperref package', 'creationdate': '2025-05-12T21:28:19+00:00', 'source': '../data/docker.pdf', 'file_path': '../data/docker.pdf', 'total_pages': 280, 'format': 'PDF 1.5', 'title': 'Docker Deep Dive', 'author': 'Nigel Poulton', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': \"D:20250512212819-00'00'\", 'page': 279}, page_content='AI models.\\nVolume\\nWhere containers store important data they\\nneed to keep. You can create and delete\\nvolumes independently from containers.\\nWasm (WebAssembly)\\nNew virtual machine architecture that is\\nsmaller, faster, more portable, and more\\nsecure than traditional containers. Wasm apps\\nrun anywhere with a Wasm runtime.\\nYAML\\nYet Another Markup Language. You write\\nCompose files in YAML. It’s a superset of\\nJSON.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d7879ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc58f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(texts))]\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "pc = Pinecone(api_key=os.getenv(\"pinecone_api_key\"))\n",
    "index_name = \"rag-01\"\n",
    "pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "        )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "212ebe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21712b2b-658b-4c69-9431-409bb09d2447',\n",
       " '39bdc125-602a-496a-b674-dfa254effcee',\n",
       " '388fc58d-aacf-418b-bcc9-07d057070c02',\n",
       " '83a3f19c-b186-4d96-a6b5-72096127aca5',\n",
       " '1ee438dd-a223-4e59-9d2e-b9e5f2f8de66',\n",
       " '1a3a6624-e5d0-4879-bf46-fa02c216118c',\n",
       " 'dae615a5-a613-4566-ba95-4b7e3782e7a1',\n",
       " '5cabcf02-3207-4f71-a32c-7e638855ab0b',\n",
       " '7049224d-200e-49aa-a345-a81336d301a5',\n",
       " '14584d99-a4ba-4a6b-a0bc-9d0e7cf55e81',\n",
       " '5420c922-0ef6-4052-90db-2efd35a5456a',\n",
       " '8d0ee4b0-a3fd-4e7d-b8db-58213321b6a6',\n",
       " '88d2a08f-1fb9-46a7-8cb4-0ccf3229d4fe',\n",
       " 'a4d321d7-59fd-485f-b993-fb406b8144c3',\n",
       " 'ae6e8748-9619-4d19-8c86-ce6f17023726',\n",
       " '9883fc31-38c0-44ef-b961-7ec431a46b2c',\n",
       " '57d7f2a2-9d2e-4c83-9e97-496d90bb3eaa',\n",
       " 'bd1262c5-ce00-47c4-8090-ee17321e8e45',\n",
       " 'a3cd1615-f4d1-47cc-b8c4-f0b1b1af4ec8',\n",
       " 'cd147d1b-9fe3-4334-8b43-8881fbde310d',\n",
       " '42c76f9e-0593-4552-8c03-ef2d6847543f',\n",
       " '75b0b029-9211-4d40-ae2a-dd1f7de21bf0',\n",
       " '98c81913-cf0f-4417-bac2-e64ec1c93749',\n",
       " '7036223f-005f-4d4e-a05e-bf74f6d90bb4',\n",
       " 'e8eb6960-536c-42f1-b6a1-ec5842190392',\n",
       " 'c69fa1d0-cf17-4525-966f-79b965b02bd1',\n",
       " 'd33fffdb-1640-4036-94ff-19bfa17439dc',\n",
       " '9e95de1c-0e91-4af3-a9b6-36250cbd9413',\n",
       " 'e715db44-81ea-4f24-b03a-57184e9e13c8',\n",
       " 'bd6af25d-03e8-4ea4-98cf-7c823b2e5548',\n",
       " 'ec4a475a-35d1-4ee1-a1db-c278dcb92bca',\n",
       " 'a90d3dee-29a1-4bdf-b312-b44b890ee354',\n",
       " '6f933951-b1e8-4b9a-81c7-94b71a9712f3',\n",
       " '8c2c0cf4-d525-43db-818e-99a5e12bea1c',\n",
       " '6cbb75a9-5af4-4f98-b214-3dbeeaed6850',\n",
       " 'f0468498-306b-4178-99ca-ae9d1d23527e',\n",
       " '5c3204dd-f02f-4707-a1fe-f9f16cf8889f',\n",
       " 'f497e79c-5e6f-40ce-b4fe-a1c39b92b2b5',\n",
       " '50d51033-fba7-4973-905b-b8bec576fa2d',\n",
       " 'dc6c913e-1d32-4edc-9c64-d4498dfe163d',\n",
       " '15c62671-8f94-4e03-9d00-ed9d62d3c0b2',\n",
       " 'd2699e00-0835-4c34-a1a0-186531087fcb',\n",
       " '6c62380d-0ed6-4214-ab44-37036ebebf86',\n",
       " '895120e7-dd58-41fe-aa92-bbd7443dabb6',\n",
       " '76cb31e3-e74e-4917-bec7-b3ca6964bcce',\n",
       " 'ebab9644-a41c-4e0b-867f-dfec6c479ad3',\n",
       " 'a5690afc-158a-4ffb-b623-f12690b688a5',\n",
       " '07f39357-fa3a-4d65-afe7-c9c81638f8fb',\n",
       " '4eca7f16-627f-4e73-940b-49731e6329c3',\n",
       " 'ad07a1e7-ab8b-42e5-9b02-4a9c015ca04f',\n",
       " '90d887f6-2d13-4861-bfd1-ac7e1e838ec4',\n",
       " '388d0162-5189-40f5-9d51-9068bb8e7a7c',\n",
       " '95a87410-7cba-4f32-9215-08d061b1b4d0',\n",
       " '6358a190-4c3a-4ef2-8ee6-353635a782f8',\n",
       " '5b86faae-ee3c-4068-924a-42f6750d1322',\n",
       " '28f379de-b825-4600-a006-ae493641cf84',\n",
       " '42daf1fd-97e4-4ce7-bc17-f999a0f98ad8',\n",
       " '61fb1ca6-c9c2-43e5-a1e8-138995db6e90',\n",
       " '92e670b0-5e02-4f43-a2b0-a40dcde91ef2',\n",
       " '71d1c3e7-01d8-48ed-9e14-ffc0fab6043c',\n",
       " '183fd9a1-40c2-4a10-8f52-4380cf18530b',\n",
       " '049fb5a1-b91a-4d44-975a-e24cc51ee7dd',\n",
       " '6d51cf81-5b10-47d6-acd0-db402b42cb9c',\n",
       " '2b1184b1-8940-47cb-a1c3-f53d5c2e7f7b',\n",
       " '8edd24b9-81d3-456e-a773-12299af99068',\n",
       " '27aab996-d8c2-45a1-9d73-6373966b3080',\n",
       " 'b312d46c-8983-4872-877c-c6a320a9f49c',\n",
       " '012956f8-3fa4-4064-bac4-29de74c5ec5e',\n",
       " 'efb045c7-4c1e-495c-a092-de5b2b7a54ef',\n",
       " '4f071af6-0c43-4bdb-9306-625301c3cdc9',\n",
       " 'b0931377-e2e2-44d3-a386-fcaf83992a2f',\n",
       " '1153bc13-d08e-4363-a95f-94359b29934f',\n",
       " '10f09148-cf8e-4a49-84a0-0326cf2f1462',\n",
       " 'db02bc95-d4da-4ae9-a13c-75ff428767ec',\n",
       " '676c0cbd-ad42-4877-8b64-bf64c5541e63',\n",
       " '94535680-d112-4142-895d-ac1f7e8c9c32',\n",
       " '11093185-7aaa-4044-8d6e-3bb7dd63e464',\n",
       " 'a0078b5f-6fce-4d07-b1ac-ec527e1f4a97',\n",
       " '473994b7-c11a-4981-b954-273c2e9e42f7',\n",
       " '93062ea5-6f17-4119-a719-533f355d7524',\n",
       " '83c552da-62a7-422c-b189-3de29eb6146b',\n",
       " '577d548a-b24b-401f-a1c6-6dc43e470dd1',\n",
       " '1f47ffad-afe2-48a2-9058-9c20ac542fe4',\n",
       " 'bff7d259-003d-4f39-9fb8-ea850c550a1f',\n",
       " '5f63f86b-ac59-49eb-8005-a8c7ba12afc2',\n",
       " '1148e549-cbd6-4be1-8826-8c7cebe927e3',\n",
       " 'ca559754-80c9-41e0-ae26-34c123988435',\n",
       " '8ec02b61-2bac-4898-8732-cb5b49c9dc8a',\n",
       " 'aa671fe9-b91a-4f1c-ae3b-519d4db1b171',\n",
       " '5c1c27f0-1086-40d2-8897-87ec1ba2470b',\n",
       " 'fdd7b307-76df-4ff8-950a-d5129a7421e6',\n",
       " 'fc49c9b0-b3ee-4848-82d0-179417f91ffb',\n",
       " '7af82859-e388-4f8f-99fd-2b09ec0b8f85',\n",
       " '661d31a2-046d-4250-8d37-47222792468f',\n",
       " 'ee89d95f-a9d1-4eba-a4c9-7dc3eefee2ce',\n",
       " '60962eed-f825-49c3-90b7-4cc300139f38',\n",
       " 'fa5c44ea-c8b1-41d7-b38d-ad1977c9a0a3',\n",
       " 'cf7dcc3b-90b5-4d78-921a-6e5f90a1c9c6',\n",
       " '5b3fda7c-c548-41af-b8e6-8a6c18b85c05',\n",
       " 'b8584e17-665e-452c-8d1b-c848bb08fac0',\n",
       " 'd132f205-eb8a-4fdd-8263-4350c21d46e8',\n",
       " 'aa87d965-8a04-4bc5-a0e6-305cb1e0a0b9',\n",
       " 'a42d7ac0-ae2b-44c9-a9c6-fd48deb573f1',\n",
       " '35f3f8f0-5476-49bb-9e0b-876a5197bed4',\n",
       " '6eb23ac1-c3c5-4382-a6b7-9e5052b2888d',\n",
       " 'eb6c9bc0-0ce6-4266-9c09-db7d178342f1',\n",
       " 'b5898e64-e03b-4847-b216-57d3368c511f',\n",
       " '0a1246fa-61b8-470c-9b09-9e9d6adb4936',\n",
       " '09ad7cfb-2dee-4fd9-8766-211d8ff25938',\n",
       " 'c5e1856e-b529-442a-aad1-fa9c7e7cc716',\n",
       " 'dec68852-be60-4eee-998c-2effa43581ca',\n",
       " '613f3cb4-1150-4a4a-9c08-1e48ba291bb1',\n",
       " '99d527aa-7cac-4266-b2a0-af27de773ef2',\n",
       " 'ef576302-dc45-44ce-b5ce-673c3ce4653b',\n",
       " 'f719821f-4f60-40dc-b6de-c749938b1e08',\n",
       " '8be0f829-3148-4f92-9de9-1709e57ed1d9',\n",
       " 'f8b50a2a-0931-4914-9802-82d238297553',\n",
       " '26b648a2-cea3-44b2-b6c7-3ae8363892df',\n",
       " '39d24e42-b50e-48f9-9808-06fbb896ac0f',\n",
       " 'ffd753a7-1b68-4edf-a05a-372624ea0a41',\n",
       " 'e8f0da2e-fa7c-4629-8bb2-9416ac71cf26',\n",
       " '13f0c392-4235-418b-b143-f8947a08c342',\n",
       " '8723837a-2253-45ca-8ce0-19d2e821ac19',\n",
       " 'a6f873c1-0c6c-474f-b309-99a23050a26f',\n",
       " '8244399e-e430-408d-9729-34143eec8396',\n",
       " '577c01d4-91d8-464c-b6e3-b5d70c9d6867',\n",
       " '723718c4-51aa-4fcf-b694-c6ad7c527f21',\n",
       " '390e6721-fa5a-46d2-8a30-f601ac2e2f44',\n",
       " 'd1730bd8-6b2a-4fc1-a29f-a05cd431a169',\n",
       " 'a6835b67-c6d8-45f0-a5ad-59111ea6c27d',\n",
       " '00ae2d06-6014-4b5d-be9f-8c643c05890e',\n",
       " 'b1d0780b-9d07-470e-a784-8cb35c87084b',\n",
       " 'f959e3ab-b38e-44bd-88ca-1aa474838c3d',\n",
       " '659dda34-2e0f-441e-a84f-09a187193d10',\n",
       " '9ca53e0b-d9a4-4f64-8846-0a3f5084756e',\n",
       " '7402b321-4315-4cb6-80d1-2059d3b7fa1a',\n",
       " 'aee916e3-5286-4ae9-9950-cb3ed231e4d8',\n",
       " 'e0e8e5b8-b7e2-4e9f-b5e6-2c81d411241a',\n",
       " '80cd87ae-70e7-462f-a804-f297af34fda7',\n",
       " 'eafee51c-f58e-4d61-a018-ee32415429a0',\n",
       " '7210e877-7f3a-4af2-a1cd-6f1ee391806c',\n",
       " '696d116c-6232-4fa4-9990-3893915269db',\n",
       " '84f946e1-7b20-4706-b43c-080d0c7f07df',\n",
       " 'f532ee63-abc7-4c63-a6ef-b49768dc81ca',\n",
       " '9b4658a5-f2ab-47f2-8d58-361436142da7',\n",
       " '4275950b-cd57-4aa9-844f-c43a1e7807e8',\n",
       " '7513ecab-4cd6-4ef6-9abd-fba82ffae4dc',\n",
       " '069e1a75-062a-4a1d-ba4d-bf931776aa94',\n",
       " '642198a9-1c9a-44d0-a522-f5b9a75eec5c',\n",
       " '00459d01-6948-44e1-955e-dff974e7c72e',\n",
       " 'ed705d8b-443c-4632-92d3-ef37a0df2a8f',\n",
       " '565c0c9d-e9a3-48f7-b4f0-d2d93d713c36',\n",
       " '077d9838-1660-4545-9389-ccfda264171f',\n",
       " 'f685b819-05ed-489a-8684-bdb87558a921',\n",
       " 'c6e1ab6b-e028-4028-909b-37148433c7ae',\n",
       " '4681bf2f-4f96-4948-a854-5efa7235059e',\n",
       " '75186d75-d106-49dd-8ad2-c3f1f966b039',\n",
       " '3f2f89a1-f22a-432e-a88b-d2ef7ec1434f',\n",
       " 'f2188cfc-ac45-49d7-9058-a861cff4c7b8',\n",
       " 'b9e9c4f7-c290-447b-b4fd-b53e7c76711a',\n",
       " '17f01803-d938-4b2b-89ea-81a92a159a0d',\n",
       " '500b00ad-0bde-4ea3-acdd-904d88af2fd5',\n",
       " 'abf62243-1100-4168-890b-96c6b5ded7a6',\n",
       " 'd7ea3269-3f8a-4d72-b7af-436924ed450e',\n",
       " 'fc79264c-2b4d-4d95-86b5-6ab12a554d36',\n",
       " '190f0585-dc7a-4bc3-82fb-a8a15b44bad2',\n",
       " '067594d6-21ac-4b0c-9f2d-70c6cb801536',\n",
       " 'd9801ee2-efa4-4354-9dc1-ebee5f32840c',\n",
       " 'ce9cc966-462e-4936-9995-a0aad6c8e377',\n",
       " '0dea53c4-e198-4845-bafa-d0b601d1969c',\n",
       " 'cf5d79d9-4a31-4286-8466-59d372195b9d',\n",
       " 'fdb9cdfb-4420-4cc0-a028-cf6d34e6f871',\n",
       " '978a3467-b830-420f-846b-4ef1a599439d',\n",
       " '32d670fa-5ff0-458e-b35c-d949ac88521c',\n",
       " '77ea4b6e-b79f-498f-b2b6-8d5b2e596601',\n",
       " 'bdb3f83f-2312-468f-9b4e-412b30074ea8',\n",
       " '5b853f95-5e17-48b8-bbd0-ad2dfbc3f831',\n",
       " '26bc1a6a-16da-47bd-a61f-c94000801912',\n",
       " '8560483f-fdbb-4415-b909-29814cec2d76',\n",
       " 'fcb1963f-f47e-47a7-8bf1-0735c0d4dde4',\n",
       " '3a201aab-ec92-4b9b-bd4c-da4b69705822',\n",
       " '823c1754-4908-4613-8789-0a67e3704883',\n",
       " 'e358ef1f-718d-4462-af51-0d6f9f290f52',\n",
       " 'baa91c6c-c01d-47a0-8960-2001d2350e0e',\n",
       " 'f67ee632-8128-420f-a78a-a13b349d8c82',\n",
       " 'a63c4285-a84b-4b3c-92a4-3636fbbd5561',\n",
       " 'e471bf22-2a48-4658-ac8d-6bb90a7c7533',\n",
       " 'e21d8b94-0c4c-456b-815b-da183373ef25',\n",
       " 'a2dab3f6-28b8-401a-8c44-fcf8ad1baaa2',\n",
       " '55ea8802-1adb-4226-8065-1ca44525222e',\n",
       " 'ec6e4e41-ed7f-4b74-8c4e-1370c906b78f',\n",
       " 'f7af645c-b6d2-4f1b-8345-adfe27be9014',\n",
       " '002f9def-cba9-4636-9f4f-3b475414dbda',\n",
       " 'd1cfccc0-91d8-476f-b904-504196e4b9d6',\n",
       " '7dc7e8e1-f91e-41d1-917d-03b2b056d37f',\n",
       " '773090e3-39ef-4d3b-9697-9358a7b20540',\n",
       " '157ff516-6eec-4ade-905a-a8b3c9cff4f8',\n",
       " '04431c41-2de3-4c10-be85-105f15b734ca',\n",
       " '09e33935-f601-4ab2-986c-9bf215f112ba',\n",
       " 'd854596a-47f6-4629-ac8c-cf08d7a22930',\n",
       " 'cefbe16d-c36a-4722-878f-df09a877fc12',\n",
       " '2dd4c436-a883-4e5f-8637-83c13cebd0d6',\n",
       " '358a2235-e060-492c-9702-75aa21634c2b',\n",
       " 'fd14c2ca-f1db-4dd7-a9e4-289da9622625',\n",
       " '012e5347-0ee4-4867-8ef3-9962f39d296c',\n",
       " 'e59d3c9b-a851-41d5-8277-f8cbdbbe8856',\n",
       " '9c59fe27-5f45-49a5-8d07-33ff8d6e57dd',\n",
       " '9d646e91-e463-4501-9126-6f18eb17d904',\n",
       " '1d4afcc6-1bb0-4b98-b619-00887ec1dbe2',\n",
       " 'd39352b4-ea3c-48af-b268-48d2b86c74e9',\n",
       " '57c521e6-ce3c-417f-960a-400a0f98b785',\n",
       " 'b0fc69dc-5bd8-495d-8327-9158b91537d7',\n",
       " '4ceac42e-4b0d-4411-9c08-2c85e26b0872',\n",
       " 'a67017c8-440f-4c3d-b1f0-995bffb2db6b',\n",
       " '0f81ac73-0aa6-4ff8-bc70-d4fc94d5e017',\n",
       " '38b48e7d-afc6-4bac-8dd7-0ffe40200296',\n",
       " 'a2052152-2f00-4dea-8972-82edd31b9e4d',\n",
       " '9ee4ad92-1353-4100-9cd2-a6dc31c23324',\n",
       " '621012b8-8007-462b-bc03-6aa63fe173c5',\n",
       " 'e2213d97-c17f-47ba-8615-ebd3be98d298',\n",
       " 'e5e2a167-e746-46e4-b8fa-38a57ea9596a',\n",
       " '0c1069aa-b21d-4c66-904e-53aa88dcbc97',\n",
       " '8a2f9d1c-2317-483a-8cc2-1d32b30ac133',\n",
       " '4aebe503-dac3-4012-9e5c-644d0e164ee6',\n",
       " 'c946a0ca-35bf-4098-9a42-5caed68c3a13',\n",
       " 'e1a57395-5522-4ba3-a629-fa42f2334c18',\n",
       " '53a0c3cf-f925-4be8-a12f-4f452791e32c',\n",
       " '466ed35d-6d81-4d18-81f1-928bb5b0e61c',\n",
       " 'd2efc8b3-208e-4165-bb25-f0f941a96bfc',\n",
       " 'd2590a1a-dfeb-43da-9cee-9f98dc6cb749',\n",
       " '175deb86-c93d-40d0-bc9f-cd38e95bd388',\n",
       " '094e6fb3-5a91-4296-910a-33ad49e087c2',\n",
       " '29983d68-57d6-4e43-9d71-1b489fdcc3ad',\n",
       " '58f9e600-00a3-4a31-ba17-781b1a4c8552',\n",
       " '1c18045b-9490-47fa-ae13-faf3c3b0ccbe',\n",
       " '189d6da0-b864-425b-b450-082d02228cf9',\n",
       " '038b79f0-0156-465a-80b6-c1c863cb4767',\n",
       " 'cbbd5be0-a7a2-425f-ba30-463154aeca9e',\n",
       " '1d6cb74a-6b23-40db-98bf-8238a4a9a5ce',\n",
       " '46c1a7dc-3ed0-45d6-bb11-c48dea5c1c6e',\n",
       " '9e753766-6d0b-4107-acd7-55d7a87894cf',\n",
       " '34dfeb56-86ce-4142-888b-9f5215cc2313',\n",
       " '6ee47830-aacd-467b-aede-89a5401493a8',\n",
       " '33a42323-78c1-4f28-b3e6-4e268ba16070',\n",
       " 'ef34822b-07e9-44f8-942b-03ddbe34620c',\n",
       " '5de5c085-12ce-4903-884d-008ccea37a2c',\n",
       " 'a23acfa5-4a48-43be-8e69-e18d634fee9a',\n",
       " '6dc365fe-16fd-4bee-98fd-f25b3804c2fb',\n",
       " '2671e165-8cf5-4033-add5-66f975e901f4',\n",
       " '53f06409-d924-4e38-bf6d-68602fa57863',\n",
       " 'd1b7eb01-11d3-4c56-ad95-b597ec757744',\n",
       " 'b11138d2-df4b-4d84-91bd-fb04e202a588',\n",
       " '5a7371c2-95c7-4d0d-bb1a-46401855f2d6',\n",
       " 'b7cfe68c-453e-4987-b9c2-5fb42cf6c17e',\n",
       " 'f86229e9-99e8-4f23-aa2d-5c86079f8079',\n",
       " '69bca797-ad8c-4158-b74a-641aea37dbed',\n",
       " '7e04a626-0763-4a3f-92ef-2e84a21b52e6',\n",
       " '8dd9c513-99e1-4455-806e-4c9c34f050f8',\n",
       " 'ed904c80-370b-4612-861c-fae9d6835ed3',\n",
       " 'aaf604cf-34f0-44b8-8e92-0f80564191bb',\n",
       " '10b2bc1b-43f4-4373-96fa-ed10907373d3',\n",
       " 'ba8b3c1f-e0aa-4e5a-a428-b38c821624ba',\n",
       " '1d708186-8a97-48c0-9aca-1e10e2941e01',\n",
       " '7bf52e9b-c741-4cd3-8475-fb702e752c39',\n",
       " '42e2663c-71af-4884-856b-631c5ced09c2',\n",
       " '66555617-dd27-436b-b67f-238452430ca0',\n",
       " '47fc4449-c0e5-4467-a8a8-d7b5efa81f8d',\n",
       " 'd775fe6a-e193-43a8-a096-4b658d05a052',\n",
       " '8045de53-128e-442f-8818-f301d5d98fe7',\n",
       " '63358fbd-c9d6-4e4b-9eb4-97f0d7d825c2',\n",
       " '2166a125-4eb5-48c9-8247-2091ddf782f9',\n",
       " '26160595-c5be-40d4-aafe-06932abe9737',\n",
       " '580aef05-c817-4395-977f-91107a4a306f',\n",
       " 'b9d000bf-dad4-4079-b363-4a17194b6a2b',\n",
       " '74cc0ef9-290a-40f4-baef-91ee34de5706',\n",
       " 'a476c43f-6895-4a40-af32-e12756f51e62',\n",
       " '9bd7ff9a-ce08-4eee-a9dd-dfcb71945e1c',\n",
       " '1741277b-0f75-4a72-9865-23e82030bcc1',\n",
       " '4d05234b-a14f-4d22-a4d8-c884ba00cc29',\n",
       " 'a86d1b68-34bb-47e2-a17d-afb29d0d8156',\n",
       " '72e44a0d-e455-474f-a3c3-d848780ad661',\n",
       " 'a00f9902-e0dc-4359-96e4-7b2f6a7c2233',\n",
       " '9a3aa69a-4a6f-4e53-9e12-5eb41597830c',\n",
       " '0145e79d-9308-4ea9-a2a1-d26563f0a1a6',\n",
       " '939b34e9-1b69-45f3-8a1f-bf8803f39b76',\n",
       " 'edcbdc4b-8b48-4a9b-bcd1-13ced037b8fa',\n",
       " 'e257a032-b6ae-4319-bd60-7adb6502c84a',\n",
       " '08f57c44-9a71-48c7-8db5-b735c5b87dda',\n",
       " '8ecc787f-0bd3-443f-92df-c12bc00c92f5',\n",
       " '74059e57-2f6e-44c8-9811-7e9986ceab38',\n",
       " 'd907a8cb-cf45-4754-945e-9426051f02c4',\n",
       " 'bc59fd46-f93f-49d6-9e71-00196c4e1803',\n",
       " 'e08d4e34-f33c-4b06-8e07-89768c13399b',\n",
       " 'd9d287a3-625b-4688-bd2c-b783e14cbbb9',\n",
       " 'ee8529b6-9c23-4e49-a5f7-73c64523efab',\n",
       " '7d8db3e2-47ab-4b92-bb88-6ad9a2a9aa8f',\n",
       " '31e789c0-2873-4284-bfc2-85b92590d552',\n",
       " '686e468c-dd32-493b-be10-34aea6e4c886',\n",
       " '74b6d07e-300d-431c-ba39-6f22eb7e00f0',\n",
       " '389bf20d-da34-4720-b1e6-63e3e3cb980d',\n",
       " '0fb2094e-6201-4410-9b0c-42911b3cccd5',\n",
       " '9cd66cf5-17fd-4146-8a5b-09a3545c18a3',\n",
       " 'e1c9cfd1-dff6-4961-b1cb-d4093367f79c',\n",
       " '2423cc0c-f43a-4ecc-be76-813eb53bf210',\n",
       " '85b603b3-5b60-432b-95a3-0f2e26334e20',\n",
       " '790dc362-03ac-4889-9bad-088001f3f6ef',\n",
       " 'a931a706-9b09-489c-8cc2-e3fb8972afad',\n",
       " 'f91a9496-25b7-47be-89ed-722ff6d0d049',\n",
       " 'e45c617f-f3db-4694-9d58-fbc732eb2d24',\n",
       " 'd289d4cb-31c2-42fa-8cf1-a35119a4c01a',\n",
       " '2cd17701-d9f5-4c7d-a4c1-8d4a2b70b810',\n",
       " 'e7aff76d-f6cb-4f92-974c-a9d8bb0a0f90',\n",
       " 'dc89e9c5-c24d-428b-9ccc-17ae5f03bf55',\n",
       " '6d177bab-28c3-4401-a46e-048eca62543c',\n",
       " 'cd3254a7-dcb1-42ed-abc5-16569d958584',\n",
       " 'db8f887a-5f76-4a54-bda2-82612b72eff1',\n",
       " '6bcec442-538a-4701-8d16-0a8108568a9e',\n",
       " '3c0bb6d8-5c77-426c-b406-a0ff99f22fa0',\n",
       " '4fa38d71-98ea-4946-8805-ffea3d161884',\n",
       " 'ca2948f2-9f3b-44d7-a186-30601add1b42',\n",
       " '8df73508-00e4-4dd4-a774-cf2d20e9354a',\n",
       " '716ce328-c56f-4dd4-b85d-10bcba8c6457',\n",
       " 'bc958cba-98aa-4214-80e1-102e02f089a5',\n",
       " 'f7700b74-0f14-4afb-8312-fcdaacfa4745',\n",
       " '10e25022-647a-4121-9065-887770334666',\n",
       " '6e13748f-20ed-471d-8944-cbadd89f875e',\n",
       " '15d4a045-75f9-44ed-a61e-9891a5eaadd1',\n",
       " '816570ed-eb50-4628-8750-733cf84c2e6d',\n",
       " 'b5c583e6-670a-4772-b307-e9bba20a20ce',\n",
       " 'd38e3afd-09d4-4bf3-bf0f-2bce030a8fd6',\n",
       " 'f97641c3-faa2-4858-977c-0dcec0a3d4a0',\n",
       " '92e80f10-cc0b-4f01-a328-cfea4057948f',\n",
       " 'b5b0b20f-04b6-494d-b1ba-fbdb69c1c870',\n",
       " 'ca410b13-d2df-47b2-8a0c-c994e017af8b',\n",
       " 'b245e0e8-9882-44ff-8537-0dd6dd89f0af',\n",
       " 'c814446f-146b-4e9f-ba32-fdb33a4323d1',\n",
       " '80d9c525-ba97-4598-8ffc-c86190e3ed6b',\n",
       " '67c54fae-654f-43a8-9505-d9d958e60e79',\n",
       " 'e80dfa08-988e-43fc-aa4c-c075de313c52',\n",
       " '382c0270-bc34-465d-8de2-ab879027d5cf',\n",
       " '1bc44570-b4c9-4174-a1be-c8672dc93888',\n",
       " 'd129fb0c-ba44-4d41-9ddf-fe689fb03bb2',\n",
       " 'eb38ae53-d0b5-4c97-b367-eedaaae0e6ac',\n",
       " 'dc218d4e-eff2-4686-8e5a-14b5310e7ba2',\n",
       " 'b8874bed-6ca0-495b-952e-f478e5791193',\n",
       " '6d4fa30a-e2a5-4f06-96e4-ab466bf83e6e',\n",
       " 'afc1a358-c98b-4001-9178-01d2508a1326',\n",
       " '088ce26b-2605-41fa-9552-d3fa108a5b34',\n",
       " '599e82aa-228a-421f-8547-4d4e0baf94cf',\n",
       " 'c65a323e-44aa-4458-9c26-26fd26dc3517',\n",
       " '8eeed66b-07f9-4500-b718-20c972ab66e4',\n",
       " '277cd1ba-6a4f-41cb-b051-8ff100e84da0',\n",
       " '764ef808-5811-4268-bd94-a6184adeeaea',\n",
       " '4906413b-d65e-4d8d-a548-dc40f04daa80',\n",
       " 'e364c69c-51d4-4fa3-aa25-b72d0cce8675',\n",
       " '4f9a50c1-2c2d-48b1-bceb-8588a51ab3ce',\n",
       " 'af42e109-9a99-47c6-a4d2-56143693d564',\n",
       " 'dc6d6eae-9990-4110-9360-9cf139ff59d2',\n",
       " 'b1e123f4-3bcd-4b09-9b6c-5f33e41ddb7c',\n",
       " '9a53ed84-2706-4883-afe7-39aa316dbf73',\n",
       " '80bd00ee-bc9a-4f4c-b342-ac950d04b1de',\n",
       " '311d580b-8341-44a9-83e9-1fca0cbae256',\n",
       " 'da2d504e-2482-4833-b9e5-ab271041ee9a',\n",
       " 'e7b6e330-d8d5-4a4b-9fc1-97a7454271c5',\n",
       " 'e3cce03f-8ffa-4d87-9085-db442357829a',\n",
       " 'c9ddf591-18d5-413a-9160-aa52c3c0989e',\n",
       " '4e3d6448-c618-4f04-96b2-999ac12e8ba9',\n",
       " '1174b720-bb06-4081-88b9-48190d1fcaa5',\n",
       " '2ab55736-5450-4516-ba6e-ca9f5cb2bde4',\n",
       " '7eb731b4-401f-4e0e-b827-ee9bfa76d1b0',\n",
       " '37c56456-fe09-4911-b289-6ecee7ef75c4',\n",
       " '661b8ad8-7458-4abf-a3ec-9f0e849e1888',\n",
       " '29c22953-c151-4de6-a733-3669d1e3b653',\n",
       " '4d426423-a89b-44b1-aa52-e484e1a81d66',\n",
       " '24a5e605-7342-40e7-87ec-9038d60a3460',\n",
       " 'c6d240bf-2d3f-4932-8b1d-1cf57ba46abb',\n",
       " '1968808f-7702-4fe4-9a88-994e53858798',\n",
       " '03fbf78e-c19f-4ffe-9d71-6cf2c84d9da5',\n",
       " '9359bd7b-8820-43b4-a8ee-6177ffd80088',\n",
       " '6f51b8aa-ea5e-4a42-b471-67be1299fc27',\n",
       " '21c3c436-87d1-4671-bcd4-3b67b0cecf39',\n",
       " 'ce501c49-7d35-4cc0-9ef6-10fde104fa92',\n",
       " 'bed76bad-4ffd-4060-963c-dacf6121a4f7',\n",
       " '541047ed-f211-4b65-a8ba-9fbbc676a180',\n",
       " '5b5b296c-d1da-4449-8af2-31ad38b82c13',\n",
       " '5cbc0ea0-0a0f-4094-a29c-160a0e1b04a4',\n",
       " 'b34e9401-be2d-4dd1-87ae-45a0f35ae7ff',\n",
       " 'b3d28f12-e4e7-4ad2-ab22-3ffba5a54d79',\n",
       " 'f1ec47c5-633a-433b-a230-eb99e339f941',\n",
       " '2a20447e-fdf0-4549-88a0-7cb438ca8e66',\n",
       " '65115524-63ba-452b-bf1b-5ce78a52f8b1',\n",
       " '64349f1d-7d38-4e72-9d14-330aab868563',\n",
       " '60953a98-99b7-4de3-b67d-6b05323a64e5',\n",
       " 'f9348adb-8011-4909-b5d3-dfb1a7fc3c3b',\n",
       " 'a005624a-43ca-45c4-95a1-eb7a6c4eea24',\n",
       " '022e5a70-44f0-4df3-9c11-f072ce2617bd',\n",
       " '7ebe1e9b-fef6-4276-9a0f-f8e6888daced',\n",
       " '895b2a19-59e3-4c7f-9075-e6c184514dee',\n",
       " '4d2ff06e-c71b-4637-be35-a399360354a9',\n",
       " 'f9dd0e5d-99bb-4274-91ef-06ad20803b0c',\n",
       " '05673a3b-0c95-4ef2-9c94-85b9918321ab',\n",
       " 'd0f8f7e9-d5d9-4a8b-a0fc-0ffdc7e56f40',\n",
       " '60f7ba54-6351-47ae-ba3a-20e8ef4bdfc0',\n",
       " 'c78f2fee-317a-4339-ae9c-7def1140e697',\n",
       " '61583184-949f-4c25-ab56-d7b1c0c60eb0',\n",
       " '87c5f19c-595f-44f5-b7ea-22f4616cfb76',\n",
       " '426a19a3-04da-4caf-9d05-5b2ce9ded217',\n",
       " '02bebe62-9d12-4ce8-bac3-91dac16842df',\n",
       " 'fd013ec4-9acd-45de-a54e-155094bb52c2',\n",
       " '937f1604-aa35-4fe1-b8d7-46874613ea06',\n",
       " 'e6b71c42-9370-4d83-bdb0-bfada252106d',\n",
       " '02d3d396-aaf3-44de-a616-0bc164591681',\n",
       " '9234adb9-6563-488e-80ac-383cc8f36ab0',\n",
       " '08da60be-0a22-492c-a09e-2ccd1e4095e7',\n",
       " 'fb649090-5beb-4bfa-98cd-fd7822050820',\n",
       " '20438f69-714e-4491-999d-b6f09f5b4b1c',\n",
       " '0317c3c5-2720-4923-bf99-5c1da9840c85',\n",
       " '322745d9-436b-4621-8e63-0dfe12269f6a',\n",
       " 'c46d41c9-e93a-4334-94f0-72d39d08fbfb',\n",
       " '16c07dec-a514-4b3a-8006-79a995398abc',\n",
       " '8924ebf6-92b9-4fb6-b4f4-ecb24c3ced79',\n",
       " '0628f371-2eb5-4644-b91c-b4ce1e559f0a',\n",
       " 'd9e6d861-e93c-49c3-92b6-3cf4172b959b',\n",
       " '2e9f0fa8-863c-4bd2-8602-1e37319a6eb8',\n",
       " 'eecad414-d8a1-4300-b24b-f9264f4681d6',\n",
       " '5ab340f1-9ca9-42f4-a7ad-0e31329c5841',\n",
       " 'd631b96d-5f7b-458c-bbee-3d9afb8c0388',\n",
       " '928f59fd-8e57-4fa4-8427-00c26ee2384f',\n",
       " 'b7734ad9-73cd-4f7a-ba13-002df677b84a',\n",
       " '2c17c682-8d53-4020-abec-4380de3d0c29',\n",
       " '9fcc6447-2ebb-4c15-9bb5-80396e2c1ad6',\n",
       " '495246e4-ff94-44aa-9e91-32bc41c98553',\n",
       " '90f8138e-60a8-46d9-aba8-e062526350bb',\n",
       " '90c7c18c-4143-4265-b824-89c6380da0b7',\n",
       " 'b3a41590-0067-4771-83ba-0dbaa0c81667',\n",
       " '4dc88489-4ac9-4ae7-a99f-c302cd0240aa',\n",
       " 'ddf11347-85da-405b-a426-c0c9a644c225',\n",
       " 'f7154b66-93ad-4692-9ffa-49014f1a0c7f',\n",
       " 'e718c8d1-f993-4f3a-8a81-456beecbf999',\n",
       " '05d94a4d-3b17-46cc-8d9c-cfb1db52c0e9',\n",
       " '29e0d5cd-cc4e-4784-a999-5ca530b304fc',\n",
       " 'e5d25932-83f5-4c0f-b622-41a45fa57bd4',\n",
       " '4e328688-b59b-4d6a-aa07-eaa499247ed1',\n",
       " '0d36bf13-4407-40fa-b39b-db3b16bfbc3e',\n",
       " '70e8a330-7b08-4308-a6fd-4c2ada414e19',\n",
       " '92cf6674-a0a7-4c5d-b346-54f17238d054',\n",
       " '54320d35-2ca9-4083-a3e3-87d1a9fe9638',\n",
       " '22837869-d66a-4ff2-9c9d-6b967fa9230a',\n",
       " 'd22290a8-8dcf-4553-bd27-2bb0beaef253',\n",
       " '6dc831f1-76e0-485c-ba38-cbc0f7733360',\n",
       " '5d6c02b3-96d5-45d3-8c68-1f8cd3b86180',\n",
       " '98886eca-df0a-45dc-916d-d54a1d9469fc',\n",
       " '132f5e54-3ad5-4a71-9d3d-3cc1cb55535b',\n",
       " 'b870bddf-5fac-4b23-9ab4-1e42f2ead86b',\n",
       " 'e3e04a20-2978-4b39-a6ac-f5ccfbdc7da8',\n",
       " '215dcaa5-b775-47b4-a868-b27920e20ff4',\n",
       " '397bd9b4-14f4-4018-9d9e-962d6ba3ca56',\n",
       " 'c878ebb9-0413-4cc5-8f3e-a4eb452c3aeb',\n",
       " '82cc97ab-ff12-4449-b9f9-feb4622c37a5',\n",
       " '19ef2683-8d80-4c4f-897a-120db3f7c993',\n",
       " 'be9ebf0e-aac3-4d9e-bda5-81241ef3211c',\n",
       " 'a486495a-fc21-4c89-98c8-bd180634954c',\n",
       " '06214797-2446-42b0-bcc0-0f63fad00b44',\n",
       " 'd2bac223-46c9-46aa-a320-c7955b05d859',\n",
       " '8fe55bd2-a318-4251-8fc7-f3e998cbdec0',\n",
       " '0292bcaf-df66-43a5-bd98-e8a0a84e9af6',\n",
       " '26f5a982-0a62-4f5d-83d5-37bfd8b4de9e',\n",
       " 'f28b5520-5aae-4b13-b7dc-1ed51a3708a4',\n",
       " 'dba7268c-6dfd-48c5-8bd4-7d75b3378e2e',\n",
       " '8e5d2e8f-1cb9-4189-99c5-d00bace9969c',\n",
       " 'e9550b23-6669-4ad5-9b18-bdb215b06aa9',\n",
       " '0c88e64a-236c-43d7-8487-335b96052ebb',\n",
       " '81c73c65-f4e4-45ef-b82d-cebf685bf999',\n",
       " '1518573b-605e-48f5-9b7e-cdfca5f68450',\n",
       " '65768a35-62b6-4e27-ae40-fb61a7436cbc',\n",
       " '7a102b23-9677-44a1-9b7b-e2d2bcb61034',\n",
       " '9ce26044-cf68-473b-8d9d-a733349dc4fb',\n",
       " 'c35a2916-5de2-42a1-8073-6f4b53a3f39e',\n",
       " 'fc25b5ea-b763-440c-89b9-413fc6dbf1ab',\n",
       " '35117d82-710b-4f33-a80c-8639e33248bc',\n",
       " 'aa8fc768-45ec-445b-a6ed-000afc7b8f05',\n",
       " '39527fe6-a3c4-43f0-a051-5941649bfb59',\n",
       " '718005b2-c890-4cd2-87f2-b79149107ea7',\n",
       " '76fbbb98-efba-4feb-939d-8716d46a9417',\n",
       " '58673cd3-94f5-46c4-9049-ac15cba68701',\n",
       " '0ae4ab2f-f1b0-4478-9ea0-36d45c016ed2',\n",
       " 'e37777f2-9eb1-4a11-bfad-4c3cfb5b3bc5',\n",
       " '6d4370df-629e-4767-a3d4-139d6fa8ea26',\n",
       " '4167f8a2-249c-4d70-9b14-1a4bda42390a',\n",
       " '12958106-db84-47ed-a4a6-79c1d1f7a23a',\n",
       " '62386a0d-7cca-41fc-b1ff-4855b4d3e716',\n",
       " '4f2d5ef0-0406-4faf-826e-f91c8dcbe9f8',\n",
       " '2e0946e8-344d-4803-9727-f27516072b33',\n",
       " 'b7bbfdb5-c523-459e-b1dc-802a2536eec5',\n",
       " 'a82c605a-f70e-4289-9309-31f41c8775ca',\n",
       " '6b9b7fd9-681b-4825-88f5-75079ee1f3c7',\n",
       " '63445250-06e9-4f6e-9bfc-c7985c334050',\n",
       " '17d1b155-c521-4b22-b32f-f3c8899baa1c',\n",
       " '87f7b6b0-4419-4909-9437-7e0a1d165b1b',\n",
       " 'd507698a-f6ac-47fc-b6f0-b829f3aa04e3',\n",
       " '5ed4173b-388d-4851-85db-7a4b743c10ea',\n",
       " 'c3c18a6d-5200-4f4e-a262-9a292c47bc11',\n",
       " '064cae47-42f6-44ae-b730-3aed741c363f',\n",
       " 'ce04f94c-4b58-4367-ae41-a75c3b903e57',\n",
       " '88b25f2b-34f0-44b4-854e-37483423d7d2',\n",
       " 'ff73a153-1efb-4faf-825f-38e8f3631725',\n",
       " '13f0ba2e-ab03-48c4-be77-14f52f064e4e',\n",
       " '41b47dda-e3cf-4434-9a66-cb2d74698e10',\n",
       " '9b4f147b-9400-458e-ba7d-17aaa94008b8',\n",
       " '45cdebed-b29a-42b8-9848-680091c8de7e',\n",
       " 'ba32008a-3fbd-4287-9843-2da7794a0406',\n",
       " '1f19dd0a-3510-47a2-a706-fa4c2ede4a16',\n",
       " '18503129-7681-416d-add5-7815774b1282',\n",
       " '59996c46-25ef-4063-a20e-14ff264903a3',\n",
       " '23b008db-4fc4-4a72-afe8-fd2c994749d7',\n",
       " '7bea91e5-505f-4d5e-b3ba-887f8f8ddad4',\n",
       " '6dbefb44-d7bf-408b-adb6-730a1c35c5ae',\n",
       " '195f47dc-26e3-4a75-884c-1e84bdb539e8',\n",
       " 'bcf66247-c83b-4774-9705-63228cf0ded5',\n",
       " '5bc94b8b-a1d9-40a3-8873-d3690bf45b5d',\n",
       " '494ff13a-a8ca-41a3-8226-4d1d0104ce5f',\n",
       " '20a194d0-3313-4228-a79f-7b9ff048d4f7',\n",
       " '0b86f808-e9e3-40b7-881c-947a1a1c2eda',\n",
       " '5840d847-6f86-40b7-85bb-0491278975c9',\n",
       " '138c9235-a5f9-4bc8-9c9b-b3c02580c8e6',\n",
       " 'a5dba3b7-506b-4e74-84eb-31c37aa8a2ed',\n",
       " '480a70fd-e79c-4a88-928c-b3a9d184b6ae',\n",
       " '24c5a5ba-b56d-4c15-b07c-ccc085015de9',\n",
       " '4d9fbe3e-d72e-488d-9670-3cf202b11d65',\n",
       " '1e2e4f1f-bca5-42d7-9916-3692d5fbb20f',\n",
       " '70a17df5-3412-48ff-a65a-9d12a75c04fa',\n",
       " '3470e234-a64a-4ba0-9b48-c0cb4b4bd18b',\n",
       " '31758620-6283-4ffd-a6b0-178f1842d5fe',\n",
       " 'b3a9b524-dd4f-49d4-9930-0e57b698d33a',\n",
       " '82415ccf-58c8-4f1f-84ed-f8e6d9eaaa60',\n",
       " 'c5e2090c-435a-4164-a6dc-968b8f9a99c7',\n",
       " '44e8cb89-5d66-43d8-8e6b-e2fd0217996d',\n",
       " 'c7b0f4a1-95d2-4f33-8bd2-0106924b149e',\n",
       " 'ffdedbea-2915-4637-b598-3d608d8fe8cf',\n",
       " 'd67a2d98-1e96-43c5-b521-f85095e3f0cc',\n",
       " '89e5611c-f5ae-401e-b13a-58f7eb35615c',\n",
       " '6e36efc9-bb21-4a13-8ecd-b08dcfb1620f',\n",
       " '902d99f6-6693-4613-be23-3eebe8466fb0',\n",
       " '458b3b4e-bcf8-4722-b480-27855c241c1f',\n",
       " '927c3ed9-5fb4-4b65-b107-6689438e123f',\n",
       " 'ffcb1043-b4f5-41f6-9065-0d3d1bf9ef5f',\n",
       " '38563a18-81d2-4ce4-947c-684477ddebb4',\n",
       " '0c0765b3-a1a0-4297-b1dc-fbed0366883f',\n",
       " 'dc3d8a98-22c4-4ae5-965a-ba674e29279c',\n",
       " 'a96e1bbb-0708-4918-8f40-80ec87917486',\n",
       " '0b91d2da-ccde-497f-8d27-a54636b3c382',\n",
       " 'a65e05df-8089-4ff0-9a47-8af550470eb6',\n",
       " 'd96ef391-38b3-4c0a-8bee-47efe184291e',\n",
       " '96e25fc3-cce7-4494-aba8-fa56c0b484c1',\n",
       " 'fdfe7931-1d3f-4c5f-a4ff-62b543917056',\n",
       " '921bbec1-716b-45a0-88ce-6468d8ed3976',\n",
       " '5dadb730-883a-4027-acc1-0adc70681d8c',\n",
       " '91c85624-4d0e-495f-ae3b-c8fcf9ee7491',\n",
       " '9c8ce890-5bc3-48f9-b133-bc917b4fa392',\n",
       " '32e9d0c1-5f05-4f45-b25f-5408ac519b05',\n",
       " '7d035714-60bb-4ada-92ce-e532641eac21',\n",
       " '638a65b5-dc6d-4355-9877-ca879222c99f',\n",
       " '5e198010-49a5-44a9-b1d6-d813b33d93ca',\n",
       " 'dd9d1406-d817-4dbf-8c6d-7910a405cba4',\n",
       " '19d9d333-b3e2-4251-817c-7e573fbd71eb',\n",
       " '85c4d498-770e-4a16-86f2-2789ccb06dba',\n",
       " 'a575dc12-ac3e-469f-9680-2daf7e89e613',\n",
       " '7d39a91c-bd9c-4a86-b1c0-8cecb8a3d5f5',\n",
       " '44da225a-142f-4bf6-b479-534a11bc8fa0',\n",
       " '1bfa8653-1116-4a1b-bfb4-1aa4b9034ccf',\n",
       " '32bd1f50-be35-41bc-9c4b-38ba25e1cb22',\n",
       " '5d979122-dfaa-4b6c-9ae0-2ca9c26bdda9',\n",
       " 'e200ae0d-61a4-4e3e-ad55-2e779ad23cc0',\n",
       " '2431721d-8c72-45b1-8d2a-dfd68ec13c53']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(index = index, embedding=embeddings)\n",
    "vector_store.add_documents(documents=texts, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0be0be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56c4e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(api_key=os.getenv(\"GOOGLE_API_KEY\"), model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cdf574b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run a Docker image, you need to start a container from that image. The provided documents mention using commands like `docker version` to ensure Docker is installed and running, and they illustrate running a container based on the `nginx:latest` image in detached mode using the `-p` flag to map ports.  However, the exact command to run a docker image is not explicitly stated in the given extracts, but it is implied that you use `docker run <image_name>`'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = input(\"How may I help you\")\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(user_query, k=3)\n",
    "context = [doc.page_content for doc in retrieved_docs]\n",
    "\n",
    "\n",
    "template = f\"\"\"You are an LLM which answers queries regarding Docker ,\n",
    "            you have access to a RAG knowlege source which is a complete docker deep dive book\n",
    "            Here is the user query {user_query}. Answer with respect to the retrieved documents from the RAG\n",
    "            pipeline using similarity/cosine search . Retrieved Docs : {context}\n",
    "            \"\"\"\n",
    "\n",
    "prompt = template.format(user_query=user_query, context=context)\n",
    "ans = llm.invoke(prompt)\n",
    "ans.content\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
